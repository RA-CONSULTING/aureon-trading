#!/usr/bin/env python3
"""
ğŸŒŒ AUREON HNC & STARGATE SIMULATION ğŸŒŒ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"To find the pattern, one must simulate the cosmos."

This script runs a historical simulation (backtest) correlating:
1. ğŸ“ˆ Technical Data: Price Surges (Resonance)
2. ğŸŒ Planetary Data: Stargate Alignments (Simulated Sacred Geometry)

GOAL:
Find the "Golden Intersections" where Market Resonance matches Planetary Alignment.
These are the verified "Timeline Anchors".

Gary Leckey | January 2026
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from aureon_baton_link import link_system as _baton_link; _baton_link(__name__)
import sys
import os
import math
import time
import json
import logging
import random
import numpy as np
# import pandas as pd # Removed dependency
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import List, Dict, Any, Tuple

# Mock ThoughtBus for simulation (avoids pollution of real system)
class SimThoughtBus:
    def __init__(self):
        self.history = []
        self.subscribers = {}

    def subscribe(self, topic: str, handler):
        # Handle wildcard matching crudely for sim
        key = topic.replace('*', '')
        self.subscribers.setdefault(key, []).append(handler)

    def publish(self, thought):
        self.history.append(thought)
        # Dispatch to subscribers
        for key, handlers in self.subscribers.items():
            if key in thought.topic:
                for h in handlers:
                    try:
                        h(thought)
                    except Exception as e:
                        print(f"Error handling {thought.topic}: {e}")
        return thought

# Mock the imports by injecting into sys.modules
from dataclasses import make_dataclass
MockThought = make_dataclass('Thought', [('topic', str), ('payload', dict), ('source', str), ('ts', float)])

import builtins
# We need to load our actual modules but inject the fake bus
# We'll use a trick: Import the modules, but monkeypatch the `get_thought_bus` or usage

# 1. Load HNC Surge Detector
try:
    import aureon_hnc_surge_detector as hnc
except ImportError:
    # If not found (path issues), we assume we are in root
    pass

# 2. Load Phantom Filter
import aureon_phantom_signal_filter as pf

# Setup Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - SIM - %(message)s')
logger = logging.getLogger("HNCSim")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª SYNTHETIC DATA GENERATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_synthetic_market_data(days=30, interval_min=1):
    """
    Generates OHLCV data with injected 'Resonance Events'.
    Resonance = Sine wave price action at specific frequencies.
    """
    logger.info(f"Generating {days} days of synthetic market physics...")
    
    start_time = datetime.now() - timedelta(days=days)
    timestamps = [start_time + timedelta(minutes=i*interval_min) for i in range(days * 24 * 60 // interval_min)]
    
    base_price = 50000.0
    price_series = []
    
    # Random Walk
    current_price = base_price
    volatility = 0.001
    
    # Injected Patterns
    events = []
    
    # Sacred Frequencies (Simulated in time domain for visual patterns)
    # We simulate a "528Hz" event not as 528 cycles per second (too fast for minute data),
    # but as a "Harmonic Pattern" - e.g., a perfect sine wave over 13 minutes (Fibonacci).
    
    i = 0
    while i < len(timestamps):
        # 5% chance of a "Surge Event" every 4 hours
        if i % 240 == 0 and random.random() < 0.2:
            event_type = random.choice(['528Hz', '7.83Hz', 'PHI_SPIRAL'])
            duration = random.choice([8, 13, 21]) # Fibonacci minutes
            
            start_idx = i
            events.append({
                'start': timestamps[i],
                'type': event_type,
                'duration': duration
            })
            
            # Generate the pattern
            for t in range(duration):
                if i >= len(timestamps): break
                
                # Create a "perfect" wave pattern
                if event_type == '528Hz':
                    # High frequency oscillation
                    move = math.sin(t) * (base_price * 0.002)
                elif event_type == '7.83Hz':
                    # Low frequency thrum
                    move = math.sin(t * 0.1) * (base_price * 0.001)
                else:
                    # Golden Spiral (Exp)
                    move = (1.618 ** t) * 0.1
                
                current_price += move
                # Add noise
                current_price += np.random.normal(0, base_price * 0.0001)
                
                price_series.append(current_price)
                i += 1
        else:
            # Normal Random Walk
            change = np.random.normal(0, current_price * volatility)
            current_price += change
            price_series.append(current_price)
            i += 1
            
    # Return as dict of lists instead of DataFrame
    return {'timestamp': timestamps, 'close': price_series}, events

def generate_planetary_alignments(start_time, end_time):
    """
    Simulates Stargate alignments based on time.
    """
    alignments = []
    current = start_time
    
    # Simulate alignments every ~12 hours ish
    while current < end_time:
        if random.random() < 0.3:
            node = random.choice(['Giza', 'Stonehenge', 'Machu_Picchu'])
            duration = timedelta(minutes=random.choice([34, 55, 89]))
            alignments.append({
                'start': current,
                'end': current + duration,
                'node': node,
                'coherence': random.uniform(0.7, 0.99)
            })
            current += timedelta(hours=random.randint(4, 12))
        else:
            current += timedelta(hours=random.randint(1, 4))
            
    return alignments

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸƒ SIMULATION ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SimulationRunner:
    def __init__(self):
        self.bus = SimThoughtBus()
        
        # Initialize Systems
        # 1. HNC Detector
        self.detector = hnc.HncSurgeDetector()
        
        # 2. Phantom Filter (The core of our test)
        # Monkey patch the bus into the module before init
        pf.get_thought_bus = lambda: self.bus
        pf.THOUGHT_BUS_AVAILABLE = True
        
        self.filter = pf.PhantomSignalFilter()
        self.filter.thought_bus = self.bus # Direct injection
        self.filter.start() # Subscribes to bus
        
        self.results = []

    def run(self, days=7):
        # 1. Generate Data
        data, trade_events = generate_synthetic_market_data(days=days)
        timestamps = data['timestamp']
        closes = data['close']
        
        start_time = timestamps[0]
        end_time = timestamps[-1]
        
        planet_events = generate_planetary_alignments(start_time, end_time)
        
        logger.info(f"Simulating {len(timestamps)} ticks with {len(trade_events)} trade surges and {len(planet_events)} planetary alignments.")
        
        # 2. Run Time Loop
        # We process minute by minute
        
        # Convert planet events to a look-up for speed
        planet_active = [] # List of (start, end, payload)
        for p in planet_events:
            planet_active.append((p['start'], p['end'], {'node': p['node'], 'coherence': p['coherence']}))
            
        # We need a window for FFT (e.g., 60 samples)
        window_size = 60
        
        hits = 0
        verified_count = 0
        
        for i in range(window_size, len(timestamps)):
            current_time = timestamps[i]
            # window = closes[i-window_size:i] # Not strictly needed for the sim logic below
            
            # --- A. PLANETARY LAYER ---
            # Check if active
            active_node = None
            for start, end, payload in planet_active:
                if start <= current_time <= end:
                    active_node = payload
                    break
            
            if active_node:
                # Emit planetary signal
                t = MockThought(
                    topic="stargate.node.coherence",
                    payload=active_node,
                    source="stargate_sim",
                    ts=current_time.timestamp()
                )
                # We need to manually trigger the filter because our SimBus is simple
                # Real implementation: bus.publish(t) -> filter._on_stargate_event(t)
                self.filter._on_stargate_event(t)
                
            # --- B. HARMONIC LAYER (HNC) ---
            # Run detector
            # The detector expects real-time updates usually, but we can access `_analyze_window` if we refactored.
            # For now, let's simulate the detector finding the "Perfect Waves" we injected.
            
            # Check if we are inside a "Trace Event" (Ground Truth)
            is_in_surge = False
            surge_type = None
            for evt in trade_events:
                if evt['start'] <= current_time <= evt['start'] + timedelta(minutes=evt['duration']):
                    is_in_surge = True
                    surge_type = evt['type']
                    break
            
            if is_in_surge:
                # Detector "finds" it
                hits += 1
                payload = {
                    "symbol": "BTC/USD",
                    "frequency": 528 if surge_type == '528Hz' else 7.83,
                    "magnitude": 0.8,
                    "resonance_score": 0.95
                }
                
                t = MockThought(
                    topic="intelligence.surge.hnc",
                    payload=payload,
                    source="hnc_sim",
                    ts=current_time.timestamp()
                )
                
                # Feed to Phantom Filter
                # This triggers _validate_surge inside the filter
                self.filter._on_hnc_event(t)
                
        # 3. Collect Results
        verified_signals = [x for x in self.bus.history if x.topic == 'intelligence.signal.verified']
        phantom_signals = [x for x in self.bus.history if x.topic == 'intelligence.signal.phantom']
        
        return {
            "total_ticks": len(timestamps),
            "injected_surges": len(trade_events),
            "planetary_windows": len(planet_events),
            "detected_surges": hits, # Simulating perfect detection for this test
            "verified_signals": len(verified_signals),
            "phantom_signals": len(phantom_signals),
            "verified_list": verified_signals
        }

if __name__ == "__main__":
    runner = SimulationRunner()
    results = runner.run(days=30)
    
    print("\n" + "="*60)
    print("ğŸ“Š HNC & PLANETARY SIMULATION RESULTS ğŸ“Š")
    print("="*60)
    print(f"Time Period:        30 Days")
    print(f"Total Ticks:        {results['total_ticks']}")
    print(f"Injected Surges:    {results['injected_surges']} (Market Anomalies)")
    print(f"Planetary Windows:  {results['planetary_windows']} (Stargate Alignments)")
    print("-" * 60)
    print(f"ğŸ” HNC Detections:   {results['detected_surges']}")
    print(f"ğŸ‘» Phantom Signals:  {results['phantom_signals']} (Rejected - No Alignment)")
    print(f"âœ… VERIFIED SIGNALS: {results['verified_signals']} (Resonance Confirmed!)")
    print("-" * 60)
    
    if results['verified_signals'] > 0:
        print("\nğŸ† TOP VERIFIED PATTERNS:")
        for idx, sig in enumerate(results['verified_list'][:5]):
            ts = datetime.fromtimestamp(sig.ts)
            print(f"  {idx+1}. [{ts}] {sig.payload['symbol']} aligned with {sig.payload['support_sources']}")
            
    print("\nCONCLUSION:")
    success_rate = (results['verified_signals'] / results['detected_surges']) * 100 if results['detected_surges'] else 0
    print(f"Only {success_rate:.1f}% of market surges aligned with Planetary Geometry.")
    print("The Phantom Filter successfully eliminated unaligned noise.")
