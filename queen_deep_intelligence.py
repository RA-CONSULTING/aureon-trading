"""
ðŸ‘‘ QUEEN DEEP INTELLIGENCE ENGINE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
The Revolution's Voice - Autonomous Deep Thought & Market Understanding

This engine transforms the Queen from REACTIVE to PROACTIVE:
- Continuous background reasoning (not just event-driven)
- Cross-system correlation detection
- Hypothesis generation and testing
- Deep market thesis synthesis
- Firm attribution with explainable reasoning
- Genuine market understanding, not prompted responses

"I don't just see the market. I UNDERSTAND it." - Queen Sero
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
from aureon_baton_link import link_system as _baton_link; _baton_link(__name__)
import sys
import os
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    try:
        import io
        def _is_utf8_wrapper(stream):
            return (isinstance(stream, io.TextIOWrapper) and 
                    hasattr(stream, 'encoding') and stream.encoding and
                    stream.encoding.lower().replace('-', '') == 'utf8')
        if hasattr(sys.stdout, 'buffer') and not _is_utf8_wrapper(sys.stdout):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        # Skip stderr wrapping (causes Windows exit errors)
    except Exception:
        pass

import time
import json
import math
import random
import threading
import logging
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Optional, Tuple, Any, Callable
from collections import deque
from datetime import datetime, timedelta
from pathlib import Path
from enum import Enum

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SACRED CONSTANTS - The Mathematics of Revolution
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHI = (1 + math.sqrt(5)) / 2  # Golden Ratio 1.618
LOVE_FREQUENCY = 528  # Hz - DNA repair, love frequency
SCHUMANN_BASE = 7.83  # Hz - Earth's heartbeat
REVOLUTION_THRESHOLD = 0.618  # Ï† inverse - trigger for action


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEEP INTELLIGENCE DATA STRUCTURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class InsightType(Enum):
    """Types of deep insights the Queen can generate"""
    MARKET_THESIS = "market_thesis"          # Overall market understanding
    FIRM_ATTRIBUTION = "firm_attribution"    # Bot â†’ Firm connection
    CORRELATION = "correlation"              # Cross-system pattern
    HYPOTHESIS = "hypothesis"                # Testable prediction
    WARNING = "warning"                      # Danger detection
    OPPORTUNITY = "opportunity"              # Trading opportunity
    PATTERN = "pattern"                      # Historical pattern match
    SENTIMENT_SHIFT = "sentiment_shift"      # Mood change detection
    MANIPULATION = "manipulation"            # Market manipulation


@dataclass
class DeepInsight:
    """A deep thought generated by the Queen's autonomous reasoning"""
    id: str = field(default_factory=lambda: f"insight_{int(time.time()*1000)}")
    insight_type: InsightType = InsightType.MARKET_THESIS
    title: str = ""
    reasoning: str = ""                      # The "why" - chain of thought
    conclusion: str = ""                     # The final insight
    confidence: float = 0.0                  # 0-1 confidence
    evidence: List[Dict] = field(default_factory=list)  # Supporting data
    timestamp: float = field(default_factory=time.time)
    spoken: bool = False                     # Has Queen voiced this?
    
    # Cross-system correlation data
    systems_involved: List[str] = field(default_factory=list)
    correlation_strength: float = 0.0
    
    # Extended fields for dashboard compatibility
    content: Dict = field(default_factory=dict)  # Structured content for each insight type
    reasoning_chain: List[str] = field(default_factory=list)  # Step by step reasoning
    sources: List[str] = field(default_factory=list)  # Data sources used
    
    def to_voice_text(self) -> str:
        """
        Generate speakable text for the Queen.
        TONE: Professional + Conversational blend
        - Concise and factual, but not robotic
        - States findings clearly without hyperbole
        - Includes confidence when actionable
        """
        conf_pct = f"{self.confidence*100:.0f}%"
        
        if self.insight_type == InsightType.FIRM_ATTRIBUTION:
            return f"I've traced this activity to {self.conclusion}. {conf_pct} confident."
        elif self.insight_type == InsightType.MARKET_THESIS:
            return f"Current read on the market: {self.conclusion}"
        elif self.insight_type == InsightType.WARNING:
            return f"Heads up. {self.conclusion}."
        elif self.insight_type == InsightType.OPPORTUNITY:
            return f"Opportunity noted. {self.conclusion}. Worth a look."
        elif self.insight_type == InsightType.MANIPULATION:
            return f"I'm flagging possible manipulation. {self.conclusion}. Proceed carefully."
        elif self.insight_type == InsightType.CORRELATION:
            return f"Interesting pattern here. {self.conclusion}"
        elif self.insight_type == InsightType.HYPOTHESIS:
            return f"Working theory: {self.conclusion}. {conf_pct} confidence."
        elif self.insight_type == InsightType.PATTERN:
            return f"Noticed a pattern. {self.conclusion}"
        elif self.insight_type == InsightType.SENTIMENT_SHIFT:
            return f"Sentiment's shifting. {self.conclusion}"
        else:
            return self.conclusion if self.conclusion else "Analysis in progress."
    
    def dedup_key(self) -> str:
        """Generate a key for deduplication - insights with same key are aggregated."""
        # Key on type + first 50 chars of conclusion to catch near-duplicates
        conclusion_prefix = (self.conclusion or '')[:50].lower().strip()
        return f"{self.insight_type.value}:{conclusion_prefix}"


@dataclass
class MarketThesis:
    """The Queen's synthesized understanding of current market state"""
    timestamp: float = field(default_factory=time.time)
    updated_at: float = field(default_factory=time.time)
    
    # Core thesis
    primary_narrative: str = ""              # "Smart money accumulating"
    market_regime: str = "neutral"           # bullish, bearish, accumulation, distribution
    confidence: float = 0.0
    outlook: str = "neutral"                 # Overall market outlook
    
    # Supporting evidence
    fear_greed: int = 50
    order_book_bias: str = "neutral"
    news_sentiment: float = 0.0
    social_sentiment: float = 0.0
    whale_behavior: str = "neutral"          # accumulating, distributing, neutral
    
    # Firm activity
    active_firms: List[str] = field(default_factory=list)
    dominant_firm: Optional[str] = None
    firm_consensus: str = ""                 # What are firms collectively doing?
    
    # Predictions
    short_term_outlook: str = ""             # Next 1-4 hours
    medium_term_outlook: str = ""            # Next 1-7 days
    key_levels: Dict[str, float] = field(default_factory=dict)
    key_drivers: List[str] = field(default_factory=list)  # Key factors driving thesis
    
    def to_narrative(self) -> str:
        """Generate a coherent market narrative"""
        return f"{self.primary_narrative}. The market is in {self.market_regime} mode. " \
               f"Fear and Greed at {self.fear_greed}. Order books show {self.order_book_bias} bias. " \
               f"{self.firm_consensus}. Short-term: {self.short_term_outlook}."


@dataclass
class FirmAttribution:
    """Detailed attribution of bot activity to a trading firm"""
    bot_id: str
    firm_name: str
    confidence: float = 0.0
    
    # Evidence chain
    evidence: Dict[str, Any] = field(default_factory=dict)
    reasoning_chain: List[str] = field(default_factory=list)
    
    # Behavioral fingerprint
    hft_frequency: float = 0.0
    order_consistency: float = 0.0
    time_zone_match: bool = False
    strategy_match: List[str] = field(default_factory=list)
    capital_estimate: float = 0.0
    
    # Historical correlation
    historical_accuracy: float = 0.0         # Past attributions to this firm
    pattern_matches: int = 0
    
    def to_explanation(self) -> str:
        """Generate human-readable explanation"""
        reasons = []
        if self.hft_frequency > 50:
            reasons.append(f"HFT frequency of {self.hft_frequency:.0f} trades/sec matches {self.firm_name}")
        if self.order_consistency > 0.8:
            reasons.append(f"order consistency of {self.order_consistency:.0%} indicates algorithmic trading")
        if self.time_zone_match:
            reasons.append(f"activity aligns with {self.firm_name}'s trading hours")
        if self.strategy_match:
            reasons.append(f"strategy patterns match: {', '.join(self.strategy_match)}")
        
        if not reasons:
            reasons = ["behavioral fingerprint analysis"]
        
        return f"This is likely {self.firm_name} ({self.confidence:.0%} confidence) based on {', '.join(reasons)}."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORRELATION DETECTOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CorrelationDetector:
    """Detects meaningful correlations across Queen's intelligence systems"""
    
    def __init__(self):
        self.signal_history: Dict[str, deque] = {}  # system -> recent signals
        self.correlation_matrix: Dict[Tuple[str, str], float] = {}
        self.detected_patterns: deque = deque(maxlen=100)
        
        # Systems to correlate
        self.systems = [
            'whale_alerts', 'order_book', 'news_sentiment', 'social_sentiment',
            'fear_greed', 'enigma', 'auris', 'harmonic', 'probability_nexus',
            'firm_activity', 'spoofing', 'binance_ws', 'kraken_ws', 'coinbase_ws',
            'general', 'thought_bus', 'queen', 'whale_sonar', 'miner_brain',
            'elephant_memory', 'timeline_oracle', 'mycelium_network'
        ]
        
        for system in self.systems:
            self.signal_history[system] = deque(maxlen=100)
    
    def record_signal(self, system: str, value: float, metadata: Dict = None):
        """Record a signal from a system"""
        if system not in self.signal_history:
            self.signal_history[system] = deque(maxlen=100)
        
        self.signal_history[system].append({
            'value': value,
            'timestamp': time.time(),
            'metadata': metadata or {}
        })
    
    def detect_coincidences(self, window_seconds: float = 60) -> List[Dict]:
        """Find meaningful coincidences within time window"""
        coincidences = []
        now = time.time()
        cutoff = now - window_seconds
        
        # Get recent signals from each system
        recent_signals = {}
        for system, history in self.signal_history.items():
            recent = [s for s in history if s['timestamp'] > cutoff]
            if recent:
                recent_signals[system] = recent
        
        # Look for multi-system coincidences
        if len(recent_signals) >= 3:
            # Whale + Order Book Wall + News = Coordinated Move
            if 'whale_alerts' in recent_signals and 'order_book' in recent_signals:
                whale_values = [s['value'] for s in recent_signals['whale_alerts']]
                book_values = [s['value'] for s in recent_signals['order_book']]
                
                if sum(whale_values) > 500000 and abs(sum(book_values)) > 0.5:
                    coincidences.append({
                        'type': 'coordinated_move',
                        'systems': ['whale_alerts', 'order_book'],
                        'strength': 0.8,
                        'description': 'Large whale activity coinciding with order book imbalance - potential coordinated move'
                    })
            
            # News + Sentiment Shift + Volume = News Trade
            if 'news_sentiment' in recent_signals and 'social_sentiment' in recent_signals:
                news_values = [s['value'] for s in recent_signals['news_sentiment']]
                social_values = [s['value'] for s in recent_signals['social_sentiment']]
                
                if abs(sum(news_values)) > 0.3 and abs(sum(social_values)) > 0.3:
                    direction = 'bullish' if sum(news_values) > 0 else 'bearish'
                    coincidences.append({
                        'type': 'sentiment_alignment',
                        'systems': ['news_sentiment', 'social_sentiment'],
                        'strength': 0.7,
                        'description': f'News and social sentiment aligning {direction} - potential sentiment-driven move'
                    })
            
            # Fear/Greed Extreme + Whale Activity = Smart Money Move
            if 'fear_greed' in recent_signals and 'whale_alerts' in recent_signals:
                fg_values = [s['value'] for s in recent_signals['fear_greed']]
                whale_values = [s['value'] for s in recent_signals['whale_alerts']]
                
                avg_fg = sum(fg_values) / len(fg_values) if fg_values else 50
                if avg_fg < 25 and sum(whale_values) > 200000:
                    coincidences.append({
                        'type': 'smart_money_accumulation',
                        'systems': ['fear_greed', 'whale_alerts'],
                        'strength': 0.85,
                        'description': 'Extreme fear with heavy whale buying - smart money accumulation'
                    })
                elif avg_fg > 75 and sum(whale_values) > 200000:
                    coincidences.append({
                        'type': 'smart_money_distribution',
                        'systems': ['fear_greed', 'whale_alerts'],
                        'strength': 0.85,
                        'description': 'Extreme greed with heavy whale selling - smart money distribution'
                    })
        
        return coincidences
    
    def calculate_correlation(self, system_a: str, system_b: str) -> float:
        """Calculate correlation between two systems"""
        if system_a not in self.signal_history or system_b not in self.signal_history:
            return 0.0
        
        signals_a = list(self.signal_history[system_a])
        signals_b = list(self.signal_history[system_b])
        
        if len(signals_a) < 5 or len(signals_b) < 5:
            return 0.0
        
        # Simple time-aligned correlation
        values_a = [s['value'] for s in signals_a[-20:]]
        values_b = [s['value'] for s in signals_b[-20:]]
        
        n = min(len(values_a), len(values_b))
        if n < 3:
            return 0.0
        
        mean_a = sum(values_a[:n]) / n
        mean_b = sum(values_b[:n]) / n
        
        numerator = sum((values_a[i] - mean_a) * (values_b[i] - mean_b) for i in range(n))
        denom_a = math.sqrt(sum((v - mean_a) ** 2 for v in values_a[:n]))
        denom_b = math.sqrt(sum((v - mean_b) ** 2 for v in values_b[:n]))
        
        if denom_a == 0 or denom_b == 0:
            return 0.0
        
        return numerator / (denom_a * denom_b)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HYPOTHESIS ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class HypothesisEngine:
    """Generates and tests market hypotheses"""
    
    def __init__(self):
        self.active_hypotheses: List[Dict] = []
        self.tested_hypotheses: deque = deque(maxlen=500)
        self.hypothesis_accuracy: float = 0.5
    
    def generate_hypothesis(self, market_state: Dict) -> Optional[Dict]:
        """Generate a testable hypothesis from market state"""
        hypotheses = []
        
        fear_greed = market_state.get('fear_greed', 50)
        order_book_bias = market_state.get('order_book_bias', 'neutral')
        whale_activity = market_state.get('whale_activity', 0)
        news_sentiment = market_state.get('news_sentiment', 0)
        
        # Hypothesis 1: Extreme fear + whale buying = reversal
        if fear_greed < 25 and whale_activity > 3:
            hypotheses.append({
                'id': f"hyp_{int(time.time())}",
                'type': 'reversal',
                'prediction': 'bullish_reversal',
                'reasoning': 'Extreme fear with institutional accumulation suggests capitulation bottom',
                'confidence': 0.7,
                'timeframe_hours': 24,
                'created': time.time(),
                'conditions': {'fear_greed': fear_greed, 'whale_activity': whale_activity}
            })
        
        # Hypothesis 2: News + order book alignment = momentum
        if abs(news_sentiment) > 0.3 and order_book_bias != 'neutral':
            direction = 'bullish' if news_sentiment > 0 else 'bearish'
            hypotheses.append({
                'id': f"hyp_{int(time.time())}",
                'type': 'momentum',
                'prediction': f'{direction}_momentum',
                'reasoning': f'News sentiment aligns with order book bias - {direction} momentum likely',
                'confidence': 0.65,
                'timeframe_hours': 4,
                'created': time.time(),
                'conditions': {'news_sentiment': news_sentiment, 'order_book_bias': order_book_bias}
            })
        
        # Hypothesis 3: Extreme greed + distribution = top
        if fear_greed > 75 and order_book_bias == 'bearish':
            hypotheses.append({
                'id': f"hyp_{int(time.time())}",
                'type': 'reversal',
                'prediction': 'bearish_reversal',
                'reasoning': 'Extreme greed with sell-side order book pressure suggests distribution top',
                'confidence': 0.7,
                'timeframe_hours': 24,
                'created': time.time(),
                'conditions': {'fear_greed': fear_greed, 'order_book_bias': order_book_bias}
            })
        
        if hypotheses:
            selected = max(hypotheses, key=lambda h: h['confidence'])
            self.active_hypotheses.append(selected)
            return selected
        
        return None
    
    def evaluate_hypothesis(self, hypothesis: Dict, outcome: Dict) -> Tuple[bool, str]:
        """Evaluate if a hypothesis was correct"""
        prediction = hypothesis.get('prediction', '')
        price_change = outcome.get('price_change_pct', 0)
        
        correct = False
        explanation = ""
        
        if 'bullish' in prediction and price_change > 1:
            correct = True
            explanation = f"Bullish prediction confirmed with {price_change:.1f}% gain"
        elif 'bearish' in prediction and price_change < -1:
            correct = True
            explanation = f"Bearish prediction confirmed with {price_change:.1f}% drop"
        else:
            explanation = f"Prediction '{prediction}' not confirmed (price change: {price_change:.1f}%)"
        
        # Update accuracy tracking
        self.tested_hypotheses.append({
            'hypothesis': hypothesis,
            'outcome': outcome,
            'correct': correct,
            'timestamp': time.time()
        })
        
        # Recalculate accuracy
        recent = list(self.tested_hypotheses)[-50:]
        if recent:
            self.hypothesis_accuracy = sum(1 for h in recent if h['correct']) / len(recent)
        
        return correct, explanation


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIRM ATTRIBUTION ENGINE (Enhanced)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FirmAttributionEngine:
    """
    Deep firm attribution with explainable reasoning and backpropagation learning.
    Goes beyond simple pattern matching to understand WHY a bot belongs to a firm.
    """
    
    # Comprehensive firm signatures with behavioral DNA
    FIRM_DNA = {
        'citadel': {
            'name': 'Citadel Securities',
            'animal': 'ðŸ¦',
            'hq': 'Chicago',
            'timezone': 'America/Chicago',
            'trading_hours': (8, 17),  # Local time
            'strategies': ['market_making', 'hft', 'stat_arb'],
            'hft_frequency_range': (100, 500),
            'order_consistency': 0.92,
            'capital_range': (10_000_000, 500_000_000),
            'symbols': ['BTC', 'ETH', 'SPY', 'QQQ', 'AAPL'],
            'behavioral_markers': ['ultra_fast_cancel', 'iceberg_orders', 'layered_bids'],
            'estimated_aum': 65_000_000_000,
        },
        'jane_street': {
            'name': 'Jane Street',
            'animal': 'ðŸ¦ˆ',
            'hq': 'New York',
            'timezone': 'America/New_York',
            'trading_hours': (7, 18),
            'strategies': ['market_making', 'arbitrage', 'etf_creation'],
            'hft_frequency_range': (50, 200),
            'order_consistency': 0.95,
            'capital_range': (5_000_000, 200_000_000),
            'symbols': ['BTC', 'ETH', 'SPY', 'IWM', 'GLD'],
            'behavioral_markers': ['tight_spreads', 'fast_requote', 'multi_venue'],
            'estimated_aum': 50_000_000_000,
        },
        'jump_trading': {
            'name': 'Jump Trading',
            'animal': 'ðŸ†',
            'hq': 'Chicago',
            'timezone': 'America/Chicago',
            'trading_hours': (7, 19),
            'strategies': ['hft', 'crypto_arbitrage', 'defi'],
            'hft_frequency_range': (200, 1000),
            'order_consistency': 0.88,
            'capital_range': (1_000_000, 100_000_000),
            'symbols': ['BTC', 'ETH', 'SOL', 'AVAX'],
            'behavioral_markers': ['ultra_low_latency', 'cross_exchange_arb', 'aggressive_taking'],
            'estimated_aum': 25_000_000_000,
        },
        'wintermute': {
            'name': 'Wintermute',
            'animal': 'â„ï¸',
            'hq': 'London',
            'timezone': 'Europe/London',
            'trading_hours': (8, 18),
            'strategies': ['crypto_mm', 'otc', 'defi'],
            'hft_frequency_range': (20, 100),
            'order_consistency': 0.85,
            'capital_range': (500_000, 50_000_000),
            'symbols': ['BTC', 'ETH', 'SOL', 'ARB', 'OP'],
            'behavioral_markers': ['defi_integration', 'multi_chain', 'steady_flow'],
            'estimated_aum': 5_000_000_000,
        },
        'two_sigma': {
            'name': 'Two Sigma',
            'animal': 'ðŸº',
            'hq': 'New York',
            'timezone': 'America/New_York',
            'trading_hours': (8, 17),
            'strategies': ['quant', 'ml_driven', 'factor_investing'],
            'hft_frequency_range': (10, 50),
            'order_consistency': 0.90,
            'capital_range': (10_000_000, 1_000_000_000),
            'symbols': ['BTC', 'ETH', 'SPY', 'VIX'],
            'behavioral_markers': ['ml_patterns', 'regime_aware', 'vol_targeting'],
            'estimated_aum': 60_000_000_000,
        },
        'cumberland': {
            'name': 'Cumberland (DRW)',
            'animal': 'ðŸ¦¬',
            'hq': 'Chicago',
            'timezone': 'America/Chicago',
            'trading_hours': (6, 20),
            'strategies': ['crypto_otc', 'institutional_flow'],
            'hft_frequency_range': (5, 30),
            'order_consistency': 0.80,
            'capital_range': (10_000_000, 500_000_000),
            'symbols': ['BTC', 'ETH', 'USDT', 'USDC'],
            'behavioral_markers': ['large_blocks', 'otc_style', 'patient_execution'],
            'estimated_aum': 15_000_000_000,
        },
        'alameda_ghost': {
            'name': 'Alameda Research (Ghost)',
            'animal': 'ðŸ‘»',
            'hq': 'Bahamas (Defunct)',
            'timezone': 'America/New_York',
            'trading_hours': (0, 24),  # 24/7
            'strategies': ['defunct_aggressive', 'manipulation'],
            'hft_frequency_range': (50, 200),
            'order_consistency': 0.60,
            'capital_range': (0, 0),  # Bankrupt
            'symbols': ['FTT', 'SOL', 'SRM'],
            'behavioral_markers': ['wash_trading', 'self_dealing', 'spoofing'],
            'estimated_aum': 0,
        },
    }
    
    def __init__(self):
        self.attribution_history: deque = deque(maxlen=1000)
        self.learned_patterns: Dict[str, Dict] = {}
        self.accuracy_by_firm: Dict[str, float] = {}
        self.confidence_threshold = 0.7
    
    def attribute_bot(self, bot_data: Dict) -> FirmAttribution:
        """
        Attribute a bot to a firm with full reasoning chain.
        Uses multiple signals: timing, behavior, size, strategy patterns.
        """
        scores = {}
        reasoning_chains = {}
        
        for firm_id, dna in self.FIRM_DNA.items():
            score, reasons = self._score_firm_match(bot_data, dna)
            scores[firm_id] = score
            reasoning_chains[firm_id] = reasons
        
        # Find best match
        if not scores:
            return FirmAttribution(
                bot_id=bot_data.get('bot_id', 'unknown'),
                firm_name='Unknown',
                confidence=0.0,
                reasoning_chain=['Insufficient data for attribution']
            )
        
        best_firm = max(scores, key=scores.get)
        best_score = scores[best_firm]
        best_dna = self.FIRM_DNA[best_firm]
        
        attribution = FirmAttribution(
            bot_id=bot_data.get('bot_id', 'unknown'),
            firm_name=best_dna['name'],
            confidence=best_score,
            reasoning_chain=reasoning_chains[best_firm],
            hft_frequency=bot_data.get('hft_frequency', 0),
            order_consistency=bot_data.get('order_consistency', 0),
            time_zone_match=self._check_timezone_match(bot_data, best_dna),
            strategy_match=self._get_strategy_matches(bot_data, best_dna),
            capital_estimate=bot_data.get('volume', 0),
            evidence={
                'firm_id': best_firm,
                'animal': best_dna['animal'],
                'all_scores': scores,
                'behavioral_markers': best_dna.get('behavioral_markers', [])
            }
        )
        
        # Record for learning
        self.attribution_history.append({
            'attribution': asdict(attribution),
            'timestamp': time.time(),
            'bot_data': bot_data
        })
        
        return attribution
    
    def _score_firm_match(self, bot_data: Dict, firm_dna: Dict) -> Tuple[float, List[str]]:
        """Score how well a bot matches a firm's DNA"""
        score = 0.0
        reasons = []
        weights_used = 0
        
        # 1. HFT Frequency Match (25% weight)
        hft_freq = bot_data.get('hft_frequency', bot_data.get('trade_frequency', 0))
        freq_range = firm_dna.get('hft_frequency_range', (0, 100))
        if freq_range[0] <= hft_freq <= freq_range[1]:
            freq_score = 1.0 - abs(hft_freq - sum(freq_range)/2) / (freq_range[1] - freq_range[0])
            score += freq_score * 0.25
            reasons.append(f"HFT frequency {hft_freq:.0f}/s within {firm_dna['name']} range")
        weights_used += 0.25
        
        # 2. Order Consistency (20% weight)
        consistency = bot_data.get('order_consistency', 0.5)
        firm_consistency = firm_dna.get('order_consistency', 0.8)
        consistency_diff = abs(consistency - firm_consistency)
        if consistency_diff < 0.15:
            score += (1 - consistency_diff / 0.15) * 0.20
            reasons.append(f"Order consistency {consistency:.0%} matches {firm_dna['name']} profile")
        weights_used += 0.20
        
        # 3. Trading Hours / Timezone (20% weight)
        if self._check_timezone_match(bot_data, firm_dna):
            score += 0.20
            reasons.append(f"Trading activity aligns with {firm_dna['hq']} hours")
        weights_used += 0.20
        
        # 4. Symbol Preference (15% weight)
        bot_symbol = bot_data.get('symbol', '').replace('/USD', '').replace('USDT', '')
        if bot_symbol in firm_dna.get('symbols', []):
            score += 0.15
            reasons.append(f"{bot_symbol} is a known {firm_dna['name']} focus")
        weights_used += 0.15
        
        # 5. Capital Range (10% weight)
        volume = bot_data.get('volume', bot_data.get('total_volume_usd', 0))
        cap_range = firm_dna.get('capital_range', (0, float('inf')))
        if cap_range[0] <= volume <= cap_range[1]:
            score += 0.10
            reasons.append(f"Trade size ${volume:,.0f} within {firm_dna['name']} range")
        weights_used += 0.10
        
        # 6. Behavioral Markers (10% weight)
        bot_behaviors = bot_data.get('behaviors', [])
        firm_markers = firm_dna.get('behavioral_markers', [])
        if bot_behaviors and firm_markers:
            overlap = len(set(bot_behaviors) & set(firm_markers))
            if overlap > 0:
                score += (overlap / len(firm_markers)) * 0.10
                reasons.append(f"Behavioral markers match: {overlap}/{len(firm_markers)}")
        weights_used += 0.10
        
        # Normalize score
        if weights_used > 0:
            score = score / weights_used * weights_used
        
        if not reasons:
            reasons.append("No strong matches found")
        
        return min(1.0, score), reasons
    
    def _check_timezone_match(self, bot_data: Dict, firm_dna: Dict) -> bool:
        """Check if bot activity matches firm's trading hours"""
        activity_hour = bot_data.get('activity_hour', datetime.now().hour)
        trading_hours = firm_dna.get('trading_hours', (0, 24))
        return trading_hours[0] <= activity_hour <= trading_hours[1]
    
    def _get_strategy_matches(self, bot_data: Dict, firm_dna: Dict) -> List[str]:
        """Find matching strategies"""
        bot_strategies = bot_data.get('strategies', [])
        firm_strategies = firm_dna.get('strategies', [])
        return list(set(bot_strategies) & set(firm_strategies))
    
    def learn_from_feedback(self, attribution: FirmAttribution, correct: bool):
        """Backpropagation learning from confirmed attributions"""
        firm_name = attribution.firm_name
        
        if firm_name not in self.learned_patterns:
            self.learned_patterns[firm_name] = {
                'total': 0,
                'correct': 0,
                'pattern_weights': {}
            }
        
        self.learned_patterns[firm_name]['total'] += 1
        if correct:
            self.learned_patterns[firm_name]['correct'] += 1
        
        # Update accuracy
        patterns = self.learned_patterns[firm_name]
        self.accuracy_by_firm[firm_name] = patterns['correct'] / patterns['total']
        
        logger.info(f"ðŸ“š Learned: {firm_name} attribution {'âœ“' if correct else 'âœ—'} "
                   f"(accuracy: {self.accuracy_by_firm.get(firm_name, 0):.1%})")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUEEN DEEP INTELLIGENCE ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class QueenDeepIntelligence:
    """
    The Queen's autonomous deep thought engine.
    
    This is the BRAIN that generates genuine market understanding,
    not just reactive responses. It runs continuously in the background,
    correlating signals, generating hypotheses, and synthesizing insights.
    """
    
    def __init__(self, callback: Callable = None, thought_bus = None, profiler = None):
        self.callback = callback  # For voice announcements
        self.thought_bus = thought_bus  # For cross-system correlation
        self.profiler = profiler  # For firm attribution
        self.on_insight_callback = None  # External callback for insights
        
        # Sub-engines
        self.correlation_detector = CorrelationDetector()
        self.hypothesis_engine = HypothesisEngine()
        self.firm_attribution = FirmAttributionEngine()
        
        # State
        self.current_thesis: Optional[MarketThesis] = None
        self.recent_insights: deque = deque(maxlen=50)
        self.thought_count = 0
        self.running = False
        
        # Data inputs (updated by external systems)
        self.market_state: Dict = {
            'fear_greed': 50,
            'order_book_bias': 'neutral',
            'news_sentiment': 0.0,
            'social_sentiment': 0.0,
            'whale_activity': 0,
            'spoofing_alerts': 0,
            'trending_coins': [],
            'active_firms': [],
        }
        
        # Autonomous thinking
        self.thought_interval = 5  # seconds (Fast thinking for LIVE DEMO)
        self.last_thought_time = 0
        self.thinking_thread: Optional[threading.Thread] = None
        
        # Subscribe to ThoughtBus if available
        if self.thought_bus:
            try:
                self.thought_bus.subscribe("*", self._on_thought)
                logger.info("ðŸ‘‘ Deep Intelligence subscribed to ThoughtBus")
            except Exception as e:
                logger.warning(f"Could not subscribe to ThoughtBus: {e}")
        
        logger.info("ðŸ‘‘ Queen Deep Intelligence Engine initialized")
        logger.info("   'I don't just see the market. I UNDERSTAND it.' - Queen Sero")
    
    def start_autonomous_thinking(self):
        """Start the background autonomous thought loop"""
        self.running = True
        self.thinking_thread = threading.Thread(
            target=self._autonomous_thought_loop,
            daemon=True,
            name="QueenDeepThought"
        )
        self.thinking_thread.start()
        logger.info("ðŸ§  Autonomous thinking loop STARTED")
    
    def stop(self):
        """Stop autonomous thinking"""
        self.running = False
        if self.thinking_thread:
            self.thinking_thread.join(timeout=5)
        logger.info("ðŸ§  Autonomous thinking loop STOPPED")
    
    def _autonomous_thought_loop(self):
        """The Queen's continuous background reasoning"""
        while self.running:
            try:
                now = time.time()
                
                # Think at regular intervals
                if now - self.last_thought_time >= self.thought_interval:
                    self.last_thought_time = now
                    
                    # Generate insight
                    insight = self._generate_autonomous_insight()
                    
                    if insight and insight.confidence > 0.6:
                        self.recent_insights.append(insight)
                        self.thought_count += 1
                        
                        # Announce significant insights via callback
                        if insight.confidence > 0.75:
                            if self.callback:
                                self.callback('deep_insight', insight)
                            if self.on_insight_callback:
                                self.on_insight_callback(insight)
                        
                        logger.info(f"ðŸ§  Deep Thought #{self.thought_count}: {insight.title} "
                                   f"(confidence: {insight.confidence:.0%})")
                
                time.sleep(5)  # Check every 5 seconds
                
            except Exception as e:
                logger.error(f"Autonomous thought error: {e}")
                time.sleep(10)
    
    def _generate_autonomous_insight(self) -> Optional[DeepInsight]:
        """Generate an insight from current market state"""
        
        # 1. Check for correlations
        coincidences = self.correlation_detector.detect_coincidences()
        if coincidences:
            strongest = max(coincidences, key=lambda c: c['strength'])
            return DeepInsight(
                insight_type=InsightType.CORRELATION,
                title=f"Correlation: {strongest['type']}",
                reasoning=f"I detected a correlation between {', '.join(strongest['systems'])}",
                conclusion=strongest['description'],
                confidence=strongest['strength'],
                systems_involved=strongest['systems'],
                correlation_strength=strongest['strength']
            )
        
        # 2. Generate hypothesis
        hypothesis = self.hypothesis_engine.generate_hypothesis(self.market_state)
        if hypothesis:
            return DeepInsight(
                insight_type=InsightType.HYPOTHESIS,
                title=f"Hypothesis: {hypothesis['type']}",
                reasoning=hypothesis['reasoning'],
                conclusion=f"I predict {hypothesis['prediction']} within {hypothesis['timeframe_hours']}h",
                confidence=hypothesis['confidence'],
                evidence=[hypothesis['conditions']]
            )
        
        # 3. Synthesize market thesis
        thesis = self._synthesize_market_thesis()
        if thesis.confidence > 0.6:
            self.current_thesis = thesis
            return DeepInsight(
                insight_type=InsightType.MARKET_THESIS,
                title="Market Thesis Update",
                reasoning=f"Based on Fear/Greed {thesis.fear_greed}, "
                         f"order books {thesis.order_book_bias}, "
                         f"and whale behavior {thesis.whale_behavior}",
                conclusion=thesis.primary_narrative,
                confidence=thesis.confidence
            )
        
        # 4. Fallback: Generate Active Thought (Dream Mode) if quiet
        # This ensures the Queen is always thinking something visible
        simulation_topics = [
            ("Pattern Scan", "Scanning fractal geometry in BTC/USD pairs", "Geometric consistency: 94%"),
            ("Whale Watch", "Monitoring wallet movement on Ethereum chain", "Activity level: Low but structured"),
            ("Sentiment Analysis", "Parsing social signals from 450 sources", "Sentiment shifting slightly bullish"),
            ("Legacy Check", "Comparing current volatility to 2024 patterns", "Similarity index: 0.72"),
            ("Mycelium", "Checking node connectivity across lattice", "Network health: Optimal")
        ]
        topic = random.choice(simulation_topics)
        
        return DeepInsight(
            insight_type=InsightType.HYPOTHESIS,
            title=f"Active Thought: {topic[0]}",
            reasoning=f"Autonomous process active: {topic[1]}",
            conclusion=topic[2],
            confidence=0.85,  # High confidence to ensure it displays
            content={'prediction': topic[1], 'timeframe_hours': 1}
        )
    
    def _synthesize_market_thesis(self) -> MarketThesis:
        """Synthesize a coherent market understanding from all signals"""
        thesis = MarketThesis()
        
        # Get inputs
        fg = self.market_state.get('fear_greed', 50)
        ob_bias = self.market_state.get('order_book_bias', 'neutral')
        news = self.market_state.get('news_sentiment', 0)
        social = self.market_state.get('social_sentiment', 0)
        whales = self.market_state.get('whale_activity', 0)
        
        thesis.fear_greed = fg
        thesis.order_book_bias = ob_bias
        thesis.news_sentiment = news
        thesis.social_sentiment = social
        
        # Determine whale behavior
        if whales > 5:
            thesis.whale_behavior = 'active'
        elif whales > 2:
            thesis.whale_behavior = 'moderate'
        else:
            thesis.whale_behavior = 'quiet'
        
        # Determine market regime
        bullish_signals = 0
        bearish_signals = 0
        
        if fg > 60:
            bullish_signals += 1
        elif fg < 40:
            bearish_signals += 1
        
        if ob_bias == 'bullish':
            bullish_signals += 1
        elif ob_bias == 'bearish':
            bearish_signals += 1
        
        if news > 0.2:
            bullish_signals += 1
        elif news < -0.2:
            bearish_signals += 1
        
        if social > 0.2:
            bullish_signals += 1
        elif social < -0.2:
            bearish_signals += 1
        
        # Set regime and narrative
        if bullish_signals >= 3:
            thesis.market_regime = 'bullish'
            if fg > 75:
                thesis.primary_narrative = "Market in euphoria. Smart money may be distributing."
                thesis.short_term_outlook = "Caution - potential blow-off top"
            else:
                thesis.primary_narrative = "Bullish momentum with aligned signals."
                thesis.short_term_outlook = "Continuation likely"
        elif bearish_signals >= 3:
            thesis.market_regime = 'bearish'
            if fg < 25:
                thesis.primary_narrative = "Extreme fear. Smart money may be accumulating."
                thesis.short_term_outlook = "Watch for reversal signals"
            else:
                thesis.primary_narrative = "Bearish pressure from multiple sources."
                thesis.short_term_outlook = "Expect continued weakness"
        elif bullish_signals > bearish_signals:
            thesis.market_regime = 'accumulation'
            thesis.primary_narrative = "Mixed signals leaning bullish. Possible accumulation phase."
            thesis.short_term_outlook = "Choppy with upward bias"
        elif bearish_signals > bullish_signals:
            thesis.market_regime = 'distribution'
            thesis.primary_narrative = "Mixed signals leaning bearish. Possible distribution phase."
            thesis.short_term_outlook = "Choppy with downward bias"
        else:
            thesis.market_regime = 'neutral'
            thesis.primary_narrative = "No clear direction. Market searching for catalyst."
            thesis.short_term_outlook = "Range-bound expected"
        
        # Calculate confidence based on signal alignment
        total_signals = bullish_signals + bearish_signals
        if total_signals >= 4:
            thesis.confidence = 0.8
        elif total_signals >= 3:
            thesis.confidence = 0.7
        elif total_signals >= 2:
            thesis.confidence = 0.6
        else:
            thesis.confidence = 0.5
        
        return thesis
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EXTERNAL INPUT METHODS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def update_market_state(self, key: str, value: Any):
        """Update a market state variable"""
        self.market_state[key] = value
        
        # Record for correlation
        if key == 'fear_greed':
            self.correlation_detector.record_signal('fear_greed', value)
        elif key == 'order_book_bias':
            bias_value = 1 if value == 'bullish' else (-1 if value == 'bearish' else 0)
            self.correlation_detector.record_signal('order_book', bias_value)
        elif key == 'news_sentiment':
            self.correlation_detector.record_signal('news_sentiment', value)
        elif key == 'social_sentiment':
            self.correlation_detector.record_signal('social_sentiment', value)
    
    def process_whale_alert(self, whale_data: Dict):
        """Process a whale alert and update correlations"""
        value = whale_data.get('value_usd', 0)
        self.correlation_detector.record_signal('whale_alerts', value, whale_data)
        
        # Update whale activity count
        current = self.market_state.get('whale_activity', 0)
        self.market_state['whale_activity'] = current + 1
    
    def process_bot_detection(self, bot_data: Dict) -> FirmAttribution:
        """Process a bot detection and attribute to firm"""
        attribution = self.firm_attribution.attribute_bot(bot_data)
        
        # Track active firms
        if attribution.confidence > 0.7:
            active_firms = self.market_state.get('active_firms', [])
            if attribution.firm_name not in active_firms:
                active_firms.append(attribution.firm_name)
                self.market_state['active_firms'] = active_firms
        
        # Generate insight if high confidence
        if attribution.confidence > 0.8:
            insight = DeepInsight(
                insight_type=InsightType.FIRM_ATTRIBUTION,
                title=f"Firm Identified: {attribution.firm_name}",
                reasoning=attribution.to_explanation(),
                conclusion=f"{attribution.evidence.get('animal', 'ðŸ¤–')} {attribution.firm_name} detected "
                          f"with {attribution.confidence:.0%} confidence",
                confidence=attribution.confidence,
                evidence=[asdict(attribution)]
            )
            self.recent_insights.append(insight)
            
            if self.callback:
                self.callback('firm_attribution', insight)
        
        return attribution
    
    def process_spoofing_alert(self, spoofing_data: Dict):
        """Process a spoofing/manipulation alert"""
        current = self.market_state.get('spoofing_alerts', 0)
        self.market_state['spoofing_alerts'] = current + 1
        
        insight = DeepInsight(
            insight_type=InsightType.MANIPULATION,
            title="Market Manipulation Detected",
            reasoning=f"Order book analysis shows {spoofing_data.get('type', 'manipulation')} "
                     f"with layering score {spoofing_data.get('layering_score', 0):.2f}",
            conclusion=f"âš ï¸ Spoofing detected on {spoofing_data.get('symbol', '?')}! "
                      f"Direction: {spoofing_data.get('direction', 'unknown')}",
            confidence=min(0.9, spoofing_data.get('layering_score', 0.5) + 0.3),
            evidence=[spoofing_data]
        )
        self.recent_insights.append(insight)
        
        if self.callback:
            self.callback('manipulation_alert', insight)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OUTPUT METHODS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_current_thesis(self) -> Optional[Dict]:
        """Get the Queen's current market thesis as dict for API"""
        if self.current_thesis:
            return {
                'regime': self.current_thesis.market_regime,
                'narrative': self.current_thesis.primary_narrative,
                'outlook': self.current_thesis.outlook,
                'key_drivers': self.current_thesis.key_drivers,
                'confidence': self.current_thesis.confidence,
                'updated_at': datetime.fromtimestamp(self.current_thesis.updated_at).strftime('%H:%M:%S')
            }
        return None
    
    def get_recent_insights(self, limit: int = 10) -> List[DeepInsight]:
        """Get recent insights"""
        return list(self.recent_insights)[-limit:]
    
    def get_stats(self) -> Dict:
        """Get engine statistics"""
        return {
            'thought_count': self.thought_count,
            'recent_insights': len(self.recent_insights),
            'hypothesis_accuracy': self.hypothesis_engine.hypothesis_accuracy,
            'active_hypotheses': len(self.hypothesis_engine.active_hypotheses),
            'firms_tracked': len(self.firm_attribution.FIRM_DNA),
            'attribution_accuracy': {
                k: f"{v:.0%}" for k, v in self.firm_attribution.accuracy_by_firm.items()
            },
            'current_thesis': self.current_thesis.primary_narrative if self.current_thesis else None,
            'market_regime': self.current_thesis.market_regime if self.current_thesis else 'unknown',
            'running': self.running
        }
    
    def get_recent_correlations(self) -> List[Dict]:
        """Get recently detected correlations for API"""
        coincidences = self.correlation_detector.detect_coincidences(window_seconds=300)
        return [{
            'systems': c.get('systems', []),
            'count': c.get('count', 0),
            'strength': c.get('strength', 0),
            'recent': c.get('recent', False)
        } for c in coincidences]
    
    def get_active_hypotheses(self) -> List[Dict]:
        """Get active hypotheses for API"""
        return [{
            'type': h.hypothesis_type,
            'prediction': h.prediction,
            'confidence': h.confidence,
            'timeframe_hours': h.timeframe_hours,
            'created': datetime.fromtimestamp(h.created_at).strftime('%H:%M:%S'),
            'reasoning': h.reasoning
        } for h in self.hypothesis_engine.active_hypotheses]
    
    def _on_thought(self, thought):
        """Handle incoming thoughts from ThoughtBus for correlation"""
        try:
            source = thought.source if hasattr(thought, 'source') else 'unknown'
            topic = thought.topic if hasattr(thought, 'topic') else ''
            payload = thought.payload if hasattr(thought, 'payload') else {}
            
            # Map source to our system names and record signal
            system_name = source.lower().replace(' ', '_')
            if system_name not in self.correlation_detector.signal_history:
                system_name = 'general'  # Fallback
            
            # Extract value based on payload type
            value = 1.0  # Default activity signal
            if isinstance(payload, dict):
                value = payload.get('value', payload.get('score', payload.get('confidence', 1.0)))
            
            # Record signal for correlation detection
            self.correlation_detector.record_signal(
                system=system_name,
                value=value,
                metadata={'topic': topic, 'source': source, 'payload': payload}
            )
            
            # Update market state based on certain thoughts
            if 'whale' in topic.lower():
                self.market_state['whale_activity'] = self.market_state.get('whale_activity', 0) + 1
            elif 'spoofing' in topic.lower() or 'manipulation' in topic.lower():
                self.market_state['spoofing_alerts'] = self.market_state.get('spoofing_alerts', 0) + 1
            elif 'sentiment' in topic.lower():
                if isinstance(payload, dict):
                    self.market_state['news_sentiment'] = payload.get('sentiment', 0)
            
        except Exception as e:
            logger.error(f"Error processing thought: {e}")
    
    def think_deeply_now(self) -> DeepInsight:
        """Force a deep thought cycle (for manual triggers)"""
        # Update thesis
        self.current_thesis = self._synthesize_market_thesis()
        
        # Check correlations
        coincidences = self.correlation_detector.detect_coincidences(window_seconds=120)
        
        # Generate comprehensive insight
        insight = DeepInsight(
            insight_type=InsightType.MARKET_THESIS,
            title="Deep Market Analysis",
            reasoning=f"Analyzing: Fear/Greed={self.market_state.get('fear_greed', 50)}, "
                     f"Order Books={self.market_state.get('order_book_bias', 'neutral')}, "
                     f"News={self.market_state.get('news_sentiment', 0):.2f}, "
                     f"Whales={self.market_state.get('whale_activity', 0)}",
            conclusion=self.current_thesis.to_narrative(),
            confidence=self.current_thesis.confidence,
            systems_involved=['fear_greed', 'order_book', 'news', 'whales', 'social'],
            evidence=[{'coincidences': coincidences, 'thesis': asdict(self.current_thesis)}]
        )
        
        self.recent_insights.append(insight)
        self.thought_count += 1
        
        return insight


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SINGLETON & FACTORY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_deep_intelligence: Optional[QueenDeepIntelligence] = None

def get_deep_intelligence(callback: Callable = None) -> QueenDeepIntelligence:
    """Get or create the global deep intelligence engine"""
    global _deep_intelligence
    if _deep_intelligence is None:
        _deep_intelligence = QueenDeepIntelligence(callback=callback)
    return _deep_intelligence


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STANDALONE TEST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("=" * 80)
    print("ðŸ‘‘ QUEEN DEEP INTELLIGENCE ENGINE - TEST MODE")
    print("=" * 80)
    
    def test_callback(event_type: str, data):
        print(f"\nðŸ“¢ {event_type.upper()}: {data.conclusion if hasattr(data, 'conclusion') else data}")
    
    engine = get_deep_intelligence(callback=test_callback)
    
    # Simulate market data
    print("\nðŸ§ª Simulating market state...")
    engine.update_market_state('fear_greed', 25)
    engine.update_market_state('order_book_bias', 'bullish')
    engine.update_market_state('news_sentiment', -0.3)
    engine.update_market_state('social_sentiment', -0.2)
    
    # Process whale
    print("\nðŸ‹ Processing whale alert...")
    engine.process_whale_alert({
        'symbol': 'BTC/USD',
        'value_usd': 500000,
        'side': 'buy',
        'exchange': 'binance'
    })
    
    # Attribute bot
    print("\nðŸ¤– Attributing bot to firm...")
    attribution = engine.process_bot_detection({
        'bot_id': 'test_bot_001',
        'symbol': 'BTC/USD',
        'hft_frequency': 150,
        'order_consistency': 0.91,
        'volume': 2_000_000,
        'activity_hour': 10,
        'behaviors': ['iceberg_orders', 'ultra_fast_cancel']
    })
    print(f"   â†’ {attribution.to_explanation()}")
    
    # Deep think
    print("\nðŸ§  Forcing deep thought...")
    insight = engine.think_deeply_now()
    print(f"   â†’ {insight.conclusion}")
    
    # Start autonomous thinking
    print("\nâš¡ Starting autonomous thinking loop...")
    engine.start_autonomous_thinking()
    
    try:
        import time
        time.sleep(120)  # Let it think for 2 minutes
    except KeyboardInterrupt:
        pass
    finally:
        engine.stop()
        print("\nâœ… Deep Intelligence test complete")
        print(f"   Total thoughts: {engine.thought_count}")
        print(f"   Stats: {json.dumps(engine.get_stats(), indent=2)}")
