#!/usr/bin/env python3
"""
üêôüåå AUREON  ECOSYSTEM - THE UNIFIED TRADING ENGINE üååüêô
================================================================

Version: 0.9.0-beta
================================================================
ONE DYNAMIC PYTHON FOR THE ENTIRE KRAKEN ECOSYSTEM

Combines ALL the best from:
- aureon_51_live.py (51% win rate strategy)
- aureon_infinite_kraken.py (10-9-1 Queen Hive compounding)
- aureon_multiverse.py (Temporal analysis)
- aureon_mycelium.py (Neural network intelligence)
- aureon_qgita.py (9 Auris nodes)
- kraken_multi_sim.py (Multi-strategy analysis)

FEATURES:
‚îú‚îÄ üî¥ Real-time WebSocket prices
‚îú‚îÄ üéØ Multiple strategies running simultaneously
‚îú‚îÄ üçÑ Neural network pattern detection
‚îú‚îÄ üêÖ 9 Auris nodes for market analysis
‚îú‚îÄ üí∞ Compounding with 10-9-1 model
‚îú‚îÄ üìä Dynamic opportunity scoring
‚îî‚îÄ üîÑ Infinite loop - never stops growing

GOAL: 51%+ Win Rate with NET PROFIT after ALL fees

Gary Leckey & GitHub Copilot | November 2025
"From Atom to Multiverse - We don't quit!"
"""

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# WINDOWS UTF-8 FIX - MUST BE AT VERY TOP BEFORE ALL OTHER IMPORTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
import os
import sys
import io

if sys.platform == 'win32':
    # Set environment variable for Python's default encoding
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    
    # Force UTF-8 encoding for stdout/stderr to support emojis
    try:
        # Check if not already wrapped to avoid double-wrapping
        if hasattr(sys.stdout, 'buffer') and not isinstance(sys.stdout, io.TextIOWrapper):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        if hasattr(sys.stderr, 'buffer') and not isinstance(sys.stderr, io.TextIOWrapper):
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except Exception:
        pass

import json
import time
import math
import random
import asyncio
import tempfile
import logging
from aureon_memory_core import memory as spiral_memory  # üß† MEMORY CORE INTEGRATION

# üß† THOUGHT BUS - UNITY CONSCIOUSNESS üß†
try:
    from aureon_thought_bus import ThoughtBus, Thought
    THOUGHT_BUS = ThoughtBus(persist_path="thoughts.jsonl")
    THOUGHT_BUS_AVAILABLE = True
except ImportError:
    THOUGHT_BUS = None
    THOUGHT_BUS_AVAILABLE = False
    print("‚ö†Ô∏è  Thought Bus not available - Brain running in isolation")

# üõ°Ô∏è IMMUNE SYSTEM - SELF-HEALING INTELLIGENCE üõ°Ô∏è
try:
    from aureon_immune_system import AureonImmuneSystem
    IMMUNE_SYSTEM_AVAILABLE = True
except ImportError:
    AureonImmuneSystem = None
    IMMUNE_SYSTEM_AVAILABLE = False
    print("‚ö†Ô∏è  Immune System not available - Running without self-healing")

# Custom StreamHandler that forces UTF-8 encoding on Windows
class SafeStreamHandler(logging.StreamHandler):
    def __init__(self, stream=None):
        super().__init__(stream or sys.stdout)
    
    def emit(self, record):
        try:
            msg = self.format(record)
            stream = self.stream
            # Write with UTF-8 encoding, replace errors
            try:
                stream.write(msg + self.terminator)
                self.flush()
            except UnicodeEncodeError:
                # If encoding fails, replace unencodable characters
                msg_safe = msg.encode('utf-8', errors='replace').decode('utf-8')
                stream.write(msg_safe + self.terminator)
                self.flush()
        except Exception:
            self.handleError(record)

# üõ°Ô∏è CRITICAL: Configure Root Logger IMMEDIATELY with SafeStreamHandler
# This ensures ALL subsequent loggers (including those from imported modules)
# use this safe handler and don't crash on Windows when printing emojis.

def sanitize_logging_environment():
    """
    Aggressively removes unsafe StreamHandlers from the root logger
    and ensures only SafeStreamHandler is used.
    """
    root_logger = logging.getLogger()
    handlers_removed = 0
    
    # Remove unsafe handlers
    for h in list(root_logger.handlers):
        if isinstance(h, logging.StreamHandler) and not isinstance(h, SafeStreamHandler):
            try:
                root_logger.removeHandler(h)
                handlers_removed += 1
            except Exception:
                pass
            
    # Add SafeStreamHandler if missing
    has_safe_handler = any(isinstance(h, SafeStreamHandler) for h in root_logger.handlers)
    if not has_safe_handler:
        safe_handler = SafeStreamHandler(sys.stdout)
        safe_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        root_logger.addHandler(safe_handler)
        root_logger.setLevel(logging.INFO)
        
    if sys.platform == 'win32' and handlers_removed > 0:
        # Use safe print just in case
        try:
            sys.stdout.buffer.write(f"üõ°Ô∏è  Windows Unicode Protection: Removed {handlers_removed} unsafe handlers.\n".encode('utf-8'))
        except Exception:
            pass

# Initial sanitization
sanitize_logging_environment()



# Load environment variables from .env file FIRST before any other imports
def _load_dotenv_fallback(dotenv_path: str = '.env') -> None:
    """Minimal .env loader (stdlib-only).

    Used when `python-dotenv` is not installed. This intentionally only supports
    simple `KEY=VALUE` lines and ignores comments and blank lines.
    It does not override existing environment variables.
    """
    try:
        if not os.path.exists(dotenv_path):
            return
        with open(dotenv_path, 'r', encoding='utf-8') as f:
            for raw_line in f:
                line = raw_line.strip()
                if not line or line.startswith('#'):
                    continue
                if '=' not in line:
                    continue
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                if not key:
                    continue
                os.environ.setdefault(key, value)
    except Exception:
        # Never crash startup because of .env parsing.
        return


try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    _load_dotenv_fallback()

try:
    import websockets
    WEBSOCKETS_AVAILABLE = True
except ImportError:
    websockets = None
    WEBSOCKETS_AVAILABLE = False
import threading
import logging
try:
    import statistics
except ImportError:
    # Fallback for statistics if missing
    class Statistics:
        def mean(self, data): return sum(data) / len(data) if data else 0
        def stdev(self, data): 
            if not data or len(data) < 2: return 0
            m = sum(data) / len(data)
            return (sum((x - m) ** 2 for x in data) / (len(data) - 1)) ** 0.5
    statistics = Statistics()

from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any, Set, Deque
from dataclasses import dataclass, field
from collections import deque, defaultdict
from threading import Thread, Lock
from pathlib import Path

# Set up logger for this module
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
if not logger.handlers:
    # Use SafeStreamHandler instead of standard StreamHandler
    handler = SafeStreamHandler(sys.stdout)
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(handler)

    # üîß Miner Blueprint Constants (enhancements)
    CASCADE_FACTOR = 10.0       # Amplify weak signals
    KT_EFFICIENCY = 4.24        # Capital efficiency multiplier
    MIN_GAMMA_THRESHOLD = 0.20  # Independent entry threshold
    MIN_HOLD_MINUTES = 50       # Resonance holding minimum
    PSI_FILTER = 0.037          # Top 3.7% opportunities only

# Add current directory to path
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, ROOT_DIR)
try:
    from unified_exchange_client import UnifiedExchangeClient, MultiExchangeClient
except ImportError as e:
    print(f"‚ö†Ô∏è  Unified Exchange Client not available: {e}")
    # Define dummy classes to prevent crash if critical module is missing
    class UnifiedExchangeClient:
        def __init__(self, *args, **kwargs): self.dry_run = True
    class MultiExchangeClient:
        def __init__(self, *args, **kwargs): 
            self.dry_run = True
            self.clients = {}
        def get_all_balances(self): return {}
        def get_24h_tickers(self): return []
        def get_ticker(self, *args): return {}
        def place_market_order(self, *args, **kwargs): return {}
        def convert_to_quote(self, *args): return 0.0

# üáÆüá™üéØ IRA SNIPER MODE - Core imports (top-level for reliability)
from ira_sniper_mode import (
    apply_sniper_mode,
    check_sniper_exit,
    get_sniper_config,
    map_sniper_platform_assets,
    sniper_authorizes_kill,  # üéØ ABSOLUTE KILL AUTHORITY
    sniper_override_active,  # üõ°Ô∏è Check if sniper has control
    # ‚ö° ACTIVE KILL SCANNER - Intelligent Hunting System
    get_active_scanner,
    register_sniper_target,
    scan_sniper_targets,
    execute_sniper_kill,
    get_scanner_status,
    # üß†‚õèÔ∏è LEARNING & MINER INTEGRATION
    sync_scanner_with_cascade,
    get_scanner_learning_stats,
    # üçÑ MYCELIUM STATE AGGREGATOR - Unified Intelligence Network
    get_mycelium_aggregator,
    mycelium_sync,
    register_to_mycelium,
)

try:
    from aureon_lattice import GaiaLatticeEngine, CarrierWaveDynamics  # üåç GAIA FREQUENCY PHYSICS
    LATTICE_AVAILABLE = True
except ImportError:
    LATTICE_AVAILABLE = False
    print("‚ö†Ô∏è  Gaia Lattice Engine not available (numpy missing?): Running in degraded mode")
    class GaiaLatticeEngine:
        def __init__(self): pass
        def get_state(self): return {}
        def update(self, opps): return {}
        def filter_signals(self, opps): return opps
        def get_field_purity(self): return 1.0

try:
    from aureon_enhancements import EnhancementLayer
    ENHANCEMENTS_AVAILABLE = True
except ImportError:
    ENHANCEMENTS_AVAILABLE = False
    print("‚ö†Ô∏è  Enhancement Layer not available: Running without codex integration")
    class EnhancementLayer:
        def __init__(self): pass
        def get_unified_modifier(self, *args, **kwargs): return type('obj', (object,), {'trading_modifier': 1.0, 'confidence': 0.5, 'reasons': []})()
        def display_status(self): return "‚ú® ENHANCEMENTS | Disabled"
    class CarrierWaveDynamics:
        pass

from gaia_planetary_reclaimer import GaiaPlanetaryReclaimer
try:
    from aureon_market_pulse import MarketPulse
    from aureon_war_band import WarBand
except ImportError:
    print("‚ö†Ô∏è  Market Pulse/War Band not available: Running in degraded mode")
    class MarketPulse:
        def __init__(self, client): pass
        def analyze_market(self): return {}
    class WarBand:
        def __init__(self, client, pulse): pass
        def update(self): pass

# üîÆ NEXUS PREDICTOR - 79.6% Win Rate Validated Over 11 Years!
try:
    from nexus_predictor import NexusPredictor
    NEXUS_PREDICTOR_AVAILABLE = True
    print("üîÆ Nexus Predictor loaded - 79.6% win rate validated!")
except ImportError:
    NEXUS_PREDICTOR_AVAILABLE = False
    print("‚ö†Ô∏è  Nexus Predictor not available")

# üß† MINER BRAIN - COGNITIVE TRADING INTELLIGENCE üß†
try:
    from aureon_miner_brain import MinerBrain
    BRAIN_AVAILABLE = True
    print("üß† Miner Brain loaded - Cognitive Intelligence Active!")
except ImportError:
    BRAIN_AVAILABLE = False
    print("‚ö†Ô∏è  Miner Brain not available")

# üåê‚ö° GLOBAL HARMONIC FIELD - UNIFIED 42-SOURCE FIELD ‚ö°üåê
try:
    from global_harmonic_field import GlobalHarmonicField, get_global_field, compute_global_omega
    HARMONIC_FIELD_AVAILABLE = True
    print("üåê‚ö° Global Harmonic Field loaded - 42 sources ‚Üí 7 layers ‚Üí Œ©")
except ImportError as e:
    HARMONIC_FIELD_AVAILABLE = False
    print(f"‚ö†Ô∏è  Global Harmonic Field not available: {e}")

# üåç‚ö° HNC FREQUENCY INTEGRATION ‚ö°üåç
try:
    from hnc_master_protocol import HarmonicNexusCore, HNCTradingBridge, LiveMarketFrequencyFeed
    HNC_AVAILABLE = True
except ImportError as e:
    HNC_AVAILABLE = False
    print(f"‚ö†Ô∏è  HNC module not available - frequency analysis disabled: {e}")

# üåç‚ö° HNC PROBABILITY MATRIX INTEGRATION ‚ö°üåç
try:
    from hnc_probability_matrix import HNCProbabilityIntegration, ProbabilityMatrix
    PROB_MATRIX_AVAILABLE = True
except ImportError as e:
    PROB_MATRIX_AVAILABLE = False
    print(f"‚ö†Ô∏è  Probability Matrix not available: {e}")
    print(f"‚ö†Ô∏è  HNC module not available - frequency analysis disabled: {e}")

# üåç‚ö° COINAPI ANOMALY DETECTION ‚ö°üåç
try:
    from coinapi_anomaly_detector import CoinAPIClient, AnomalyDetector, AnomalyType
    COINAPI_AVAILABLE = True
except ImportError as e:
    COINAPI_AVAILABLE = False
    print(f"‚ö†Ô∏è  CoinAPI Anomaly Detector not available: {e}")

# üåâ AUREON BRIDGE - ULTIMATE ‚Üî UNIFIED COMMUNICATION üåâ
try:
    from aureon_bridge import AureonBridge, Opportunity as BridgeOpportunity, CapitalState, Position as BridgePosition
    BRIDGE_AVAILABLE = True
except ImportError as e:
    BRIDGE_AVAILABLE = False
    print(f"‚ö†Ô∏è  Aureon Bridge not available: {e}")

# üåê AUREON UI BRIDGE - LIVE DATA VALIDATOR FROM aureoninstitute.com üåê
try:
    from aureon_ui_bridge import (
        AureonUIBridge, AureonUIValidator, UIMyceliumConnector,
        get_ui_bridge, get_ui_connector, validate_trade_against_ui,
        get_harmonic_field_status, get_fear_greed_status,
        UIValidatedSignal, FrequencyBand, RiskLevel, Element
    )
    UI_BRIDGE_AVAILABLE = True
except ImportError as e:
    UI_BRIDGE_AVAILABLE = False
    print(f"‚ö†Ô∏è  UI Bridge not available: {e}")

# üåå‚ö° HNC IMPERIAL PREDICTABILITY ENGINE ‚ö°üåå
try:
    from hnc_imperial_predictability import (
        ImperialTradingIntegration, PredictabilityEngine, CosmicStateEngine,
        CosmicPhase, MarketTorque, ImperialPredictabilityMatrix
    )
    IMPERIAL_AVAILABLE = True
except ImportError as e:
    IMPERIAL_AVAILABLE = False
    print(f"‚ö†Ô∏è  Imperial Predictability not available: {e}")

# üî≠ QUANTUM TELESCOPE & HARMONIC UNDERLAY üî≠
try:
    from aureon_quantum_telescope import QuantumTelescope, LightBeam, GeometricSolid
    from hnc_6d_harmonic_waveform import SixDimensionalHarmonicEngine, WaveState
    QUANTUM_AVAILABLE = True
except ImportError as e:
    QUANTUM_AVAILABLE = False
    print(f"‚ö†Ô∏è  Quantum Telescope/Harmonic Engine not available: {e}")

# üåç‚ö° EARTH RESONANCE ENGINE ‚ö°üåç
try:
    from earth_resonance_engine import EarthResonanceEngine, get_earth_engine
    EARTH_RESONANCE_AVAILABLE = True
except ImportError as e:
    EARTH_RESONANCE_AVAILABLE = False
    print(f"‚ö†Ô∏è  Earth Resonance Engine not available: {e}")

# üåå‚ö° AUREON NEXUS - UNIFIED NEURAL TRADING ENGINE ‚ö°üåå
try:
    from aureon_nexus import NexusBus, MasterEquation, QueenHive, AureonNexus, NEXUS as NEXUS_BUS
    NEXUS_AVAILABLE = True
    # üß† UNITY: Connect Nexus to Thought Bus
    if NEXUS_BUS and THOUGHT_BUS_AVAILABLE:
        NEXUS_BUS.thought_bus = THOUGHT_BUS
        print("   üß† Nexus connected to Thought Bus")
except ImportError as e:
    NEXUS_AVAILABLE = False
    NEXUS_BUS = None
    print(f"‚ö†Ô∏è  Aureon Nexus not available: {e}")

# üéØ PROBABILITY LOADER & POSITION HYGIENE üéØ
try:
    from probability_loader import ProbabilityLoader, PositionHygieneChecker, load_position_state
    PROBABILITY_LOADER_AVAILABLE = True
except ImportError as e:
    PROBABILITY_LOADER_AVAILABLE = False
    print(f"‚ö†Ô∏è  Probability Loader not available: {e}")
    class ProbabilityLoader:
        def __init__(self, *args, **kwargs): pass
        def load_all_reports(self): return {}
        def is_fresh(self): return False
        def get_top_signals(self, *args): return []
        def get_consensus_signals(self, *args): return []
    class PositionHygieneChecker:
        def __init__(self): pass
        def check_positions(self, *args): return {'flagged': [], 'count': 0}

# üìä TRADE LOGGER - COMPREHENSIVE DATA LOGGING üìä
try:
    from trade_logger import get_trade_logger, TradeLogger
    TRADE_LOGGER_AVAILABLE = True
    trade_logger = get_trade_logger()
except ImportError as e:
    TRADE_LOGGER_AVAILABLE = False
    trade_logger = None
    print(f"‚ö†Ô∏è  Trade Logger not available: {e}")

# üí∞ COST BASIS TRACKER - REAL PURCHASE PRICES üí∞
try:
    from cost_basis_tracker import CostBasisTracker, get_cost_basis_tracker
    COST_BASIS_AVAILABLE = True
except ImportError as e:
    COST_BASIS_AVAILABLE = False
    print(f"‚ö†Ô∏è  Cost Basis Tracker not available: {e}")
    # Fallback stub
    class CostBasisTracker:
        def __init__(self): self.positions = {}
        def sync_from_exchanges(self): return 0
        def get_entry_price(self, symbol): return None
        def set_entry_price(self, *args, **kwargs): pass
        def update_position(self, *args, **kwargs): pass
        def can_sell_profitably(self, symbol, price, quantity=None, **kw): return True, {'recommendation': 'NO_TRACKER'}
        def print_status(self): pass
    def get_cost_basis_tracker(): return CostBasisTracker()

# üåç‚ö° GLOBAL FINANCIAL ECOSYSTEM FEED ‚ö°üåç
try:
    from global_financial_feed import GlobalFinancialFeed, MacroSnapshot
    GLOBAL_FEED_AVAILABLE = True
    print("   üåç Global Financial Ecosystem Feed ACTIVE")
except ImportError as e:
    GLOBAL_FEED_AVAILABLE = False
    print(f"‚ö†Ô∏è  Global Financial Feed not available: {e}")
    # Fallback stub
    class GlobalFinancialFeed:
        def get_snapshot(self): return None
        def get_probability_adjustment(self, symbol, prob): return prob, {}
        def get_trading_signal(self, symbol): return {'macro_bias': 'NEUTRAL', 'macro_strength': 50}
        def print_dashboard(self): pass

# üìä PROBABILITY VALIDATION ENGINE üìä
try:
    from probability_validator import ProbabilityValidator, get_validator
    VALIDATOR_AVAILABLE = True
    print("   üìä Probability Validation Engine ACTIVE")
except ImportError as e:
    VALIDATOR_AVAILABLE = False
    print(f"‚ö†Ô∏è  Probability Validator not available: {e}")
    # Fallback stub
    class ProbabilityValidator:
        def record_prediction(self, **kwargs): return ""
        def validate_pending(self, func): return []
        def get_confidence_adjustment(self, *args): return 1.0
        def print_dashboard(self): pass
    def get_validator(): return ProbabilityValidator()

# üåà‚ú® AUREON ENHANCEMENTS - RAINBOW BRIDGE, SYNCHRONICITY, STARGATE ‚ú®üåà
try:
    from aureon_enhancements import EnhancementLayer, apply_enhancement_to_signal, get_emotional_color
    ENHANCEMENTS_AVAILABLE = True
except ImportError as e:
    ENHANCEMENTS_AVAILABLE = False
    print(f"‚ö†Ô∏è  Aureon Enhancements not available: {e}")

# ==== AUREON COGNITION BUS (self-talking JSON thoughts) ====
from aureon_thought_bus import ThoughtBus, Thought
from aureon_cognition_runtime import MinerModule, RiskModule, ExecutionModule

# ==== WORLD NEWS FEED (external data gathering) ====
try:
    from aureon_news_feed import NewsFeed, NewsFeedConfig, create_news_feed
    NEWS_FEED_AVAILABLE = True
except ImportError:
    NEWS_FEED_AVAILABLE = False
    print("‚ö†Ô∏è  News Feed module not available")

# ==== WIKIPEDIA KNOWLEDGE BASE (autonomous knowledge gathering) ====
try:
    from aureon_knowledge_base import KnowledgeBase, create_knowledge_base
    KNOWLEDGE_BASE_AVAILABLE = True
except ImportError:
    KNOWLEDGE_BASE_AVAILABLE = False
    print("‚ö†Ô∏è  Knowledge Base module not available")

# ==== WISDOM SCANNER - CONSCIOUSNESS EXPANSION ENGINE ====
try:
    from aureon_wisdom_scanner import AureonWisdomScanner, ScannerConfig, WisdomScannerThoughtBusAdapter
    WISDOM_SCANNER_AVAILABLE = True
    print("   üìö Wisdom Scanner loaded - Consciousness Expansion Active!")
except ImportError as e:
    WISDOM_SCANNER_AVAILABLE = False
    print(f"‚ö†Ô∏è  Wisdom Scanner not available: {e}")

# ==== üáÆüá™üéØ UNIFIED SNIPER BRAIN - THE KILL SHOT ENGINE ====
try:
    from unified_sniper_brain import get_unified_brain, UnifiedSniperBrain
    SNIPER_BRAIN_AVAILABLE = True
    print("   üéØ UNIFIED SNIPER BRAIN LOADED - Ready for kills!")
except ImportError as e:
    SNIPER_BRAIN_AVAILABLE = False
    UnifiedSniperBrain = None
    print(f"‚ö†Ô∏è  Sniper Brain not available: {e}")

# ==== ‚öîÔ∏è WAR STRATEGY - QUICK KILL PROBABILITY ENGINE ====
try:
    from war_strategy import (
        WAR_STRATEGIST, get_quick_kill_estimate, should_attack, 
        start_raid, complete_raid, get_raid_status, get_war_briefing,
        REQUIRED_R, WIN_THRESHOLD, NET_PENNY_TARGET, IDEAL_BARS, MAX_ACCEPTABLE_BARS
    )
    WAR_STRATEGY_AVAILABLE = True
    print("   ‚öîÔ∏è WAR STRATEGY LOADED - Quick Kill Probability Active!")
except ImportError as e:
    WAR_STRATEGY_AVAILABLE = False
    WAR_STRATEGIST = None
    print(f"‚ö†Ô∏è  War Strategy not available: {e}")

# ==== üáÆüá™ BHOY'S WISDOM - STRATEGIC QUOTES ====
try:
    from bhoys_wisdom import celebrate_penny_profit, get_contextual_wisdom
    BHOYS_WISDOM_AVAILABLE = True
    print("   üçÄ Bhoy's Wisdom loaded - Through a Bhoy's Eyes Active!")
except ImportError as e:
    BHOYS_WISDOM_AVAILABLE = False
    def celebrate_penny_profit(amount, symbol): return "Our revenge will be the laughter of our children."
    def get_contextual_wisdom(context): return "Tiocfaidh √°r l√°!"
    print(f"‚ö†Ô∏è  Bhoy's Wisdom not available: {e}")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚òòÔ∏èüî• CELTIC WARFARE SYSTEMS - IRISH GUERRILLA INTELLIGENCE üî•‚òòÔ∏è
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ==== ‚òòÔ∏è GUERRILLA WARFARE ENGINE ====
try:
    from guerrilla_warfare_engine import (
        IntelligenceNetwork, FlyingColumn, BattlefrontStatus,
        TacticalMode, IntelligenceReport, GUERRILLA_CONFIG, get_celtic_wisdom
    )
    GUERRILLA_ENGINE_AVAILABLE = True
    print("   ‚òòÔ∏è Guerrilla Warfare Engine loaded - Flying Columns Ready!")
except ImportError as e:
    GUERRILLA_ENGINE_AVAILABLE = False
    IntelligenceNetwork = None
    print(f"‚ö†Ô∏è  Guerrilla Engine not available: {e}")

# ==== ‚ö° CELTIC PREEMPTIVE STRIKE ENGINE ====
try:
    from celtic_preemptive_strike import (
        PreemptiveExitEngine, DawnRaidDetector,
        PreemptiveSignal, PreemptiveSignalType
    )
    PREEMPTIVE_STRIKE_AVAILABLE = True
    print("   ‚ö° Preemptive Strike Engine loaded - Move Before They React!")
except ImportError as e:
    PREEMPTIVE_STRIKE_AVAILABLE = False
    PreemptiveExitEngine = None
    print(f"‚ö†Ô∏è  Preemptive Strike not available: {e}")

# ==== üåê MULTI-BATTLEFRONT COORDINATOR ====
try:
    from multi_battlefront_coordinator import (
        MultiBattlefrontWarRoom, CampaignPhase, ArbitrageOpportunity
    )
    BATTLEFRONT_COORDINATOR_AVAILABLE = True
    print("   üåê Multi-Battlefront Coordinator loaded - Unity of Command!")
except ImportError as e:
    BATTLEFRONT_COORDINATOR_AVAILABLE = False
    MultiBattlefrontWarRoom = None
    print(f"‚ö†Ô∏è  Battlefront Coordinator not available: {e}")

# ==== üáÆüá™ IRISH PATRIOT SCOUTS ====
try:
    from irish_patriot_scouts import (
        PatriotScoutNetwork, PatriotScout, PatriotScoutDeployer,
        PATRIOT_CONFIG, get_patriot_wisdom
    )
    PATRIOT_SCOUTS_AVAILABLE = True
    print("   üáÆüá™ Irish Patriot Scouts loaded - Warriors Ready!")
except ImportError as e:
    PATRIOT_SCOUTS_AVAILABLE = False
    PatriotScoutNetwork = None
    PatriotScoutDeployer = None
    print(f"‚ö†Ô∏è  Patriot Scouts not available: {e}")

# ==== üéØ IRA CELTIC SNIPER ====
try:
    from ira_sniper_mode import (
        IraCelticSniper, get_celtic_sniper, SNIPER_CONFIG,
        check_sniper_exit, celebrate_sniper_kill,
        get_sniper_config, map_sniper_platform_assets, apply_sniper_mode
    )
    CELTIC_SNIPER_AVAILABLE = True
    print("   üéØ IRA Celtic Sniper loaded - Zero Loss Mode Active!")
except ImportError as e:
    CELTIC_SNIPER_AVAILABLE = False
    IraCelticSniper = None
    print(f"‚ö†Ô∏è  Celtic Sniper not available: {e}")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üí∞ PENNY PROFIT ENGINE - DYNAMIC DOLLAR-BASED EXIT THRESHOLDS üí∞
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéØ Calculates EXACT thresholds for ANY trade size dynamically!
# No more preset lookup tables - formula calculates on-the-fly.

PENNY_PROFIT_CONFIG = {}  # Optional overrides from JSON
PENNY_PROFIT_ENABLED = True  # Always enabled - dynamic calculation works without config
PENNY_TARGET_NET = 0.01  # Default target: $0.01 net profit per trade

# Shared-goal net target guardrails: 1‚Äì3 pennies after all costs.
GLOBAL_NET_PROFIT_RANGE = (0.01, 0.03)

# Binance must always capture between $0.01 and $0.03 NET after all fees
BINANCE_NET_PROFIT_RANGE = GLOBAL_NET_PROFIT_RANGE

# Default fee rates by exchange (can be overridden by CONFIG or JSON)
DEFAULT_FEE_RATES = {
    'binance': 0.001,    # 0.10% taker
    'kraken': 0.0026,    # 0.26% taker  
    'capital': 0.0012,   # ~0.12% spread
    'alpaca': 0.0025,    # 0.25% commission
}


def load_penny_profit_config():
    """Load penny profit configuration (optional - for fee rate overrides).
    
    The engine works WITHOUT a config file using dynamic calculation.
    Config file only needed to override default fee rates or target.
    """
    global PENNY_PROFIT_CONFIG, PENNY_PROFIT_ENABLED, PENNY_TARGET_NET
    config_path = os.path.join(ROOT_DIR, 'penny_profit_config.json')
    
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r') as f:
                PENNY_PROFIT_CONFIG = json.load(f)
            loaded_target = float(PENNY_PROFIT_CONFIG.get('target_net_win', 0.01) or 0.01)

            # Clamp the configured target into our shared-goal guardrails.
            min_net, max_net = GLOBAL_NET_PROFIT_RANGE
            PENNY_TARGET_NET = max(min_net, min(max_net, loaded_target))
            if PENNY_TARGET_NET != loaded_target:
                print(
                    f"üí∞ Penny Profit Engine - DYNAMIC (target clamped: requested ${loaded_target:.2f} ‚Üí ${PENNY_TARGET_NET:.2f} net per trade)"
                )
            else:
                print(f"üí∞ Penny Profit Engine - DYNAMIC (target: +${PENNY_TARGET_NET:.2f} net per trade)")
        except Exception as e:
            print(f"‚ö†Ô∏è  Penny config load error: {e} - using dynamic defaults")
    else:
        print(f"üí∞ Penny Profit Engine - DYNAMIC MODE (target: +${PENNY_TARGET_NET:.2f} net)")
    
    PENNY_PROFIT_ENABLED = True  # Always enabled with dynamic calculation


def clamp_target_net_for_exchange(exchange: str, target_net: float) -> Tuple[float, bool]:
    """
    Apply exchange-specific clamping to the desired net target.
    
    For Binance we must guarantee that every full trade cycle nets between
    $0.01 and $0.03 after *all* costs (fees, slippage, spread).
    """
    ex_lower = (exchange or 'binance').lower()

    # Global guardrails: always keep targets within 1‚Äì3 pennies.
    global_min, global_max = GLOBAL_NET_PROFIT_RANGE
    globally_clamped = max(global_min, min(global_max, target_net))
    was_clamped = globally_clamped != target_net
    target_net = globally_clamped

    if ex_lower == 'binance':
        min_net, max_net = BINANCE_NET_PROFIT_RANGE
        clamped = max(min_net, min(max_net, target_net))
        return clamped, was_clamped or (clamped != target_net)
    return target_net, was_clamped


def get_exchange_fee_rate(exchange: str) -> float:
    """Get fee rate for exchange - checks CONFIG, then JSON, then defaults.
    
    Priority order:
    1. Global CONFIG (most accurate - actual observed rates)
    2. penny_profit_config.json fee_rate
    3. DEFAULT_FEE_RATES fallback
    """
    ex_lower = (exchange or 'binance').lower()
    
    # Priority 1: Check global CONFIG for actual observed fees
    try:
        if ex_lower == 'kraken':
            return CONFIG.get('KRAKEN_FEE_TAKER', DEFAULT_FEE_RATES['kraken'])
        elif ex_lower == 'binance':
            return CONFIG.get('BINANCE_FEE_TAKER', DEFAULT_FEE_RATES['binance'])
        elif ex_lower == 'alpaca':
            return CONFIG.get('ALPACA_FEE_TAKER', DEFAULT_FEE_RATES['alpaca'])
        elif ex_lower == 'capital':
            return CONFIG.get('CAPITAL_FEE', DEFAULT_FEE_RATES['capital'])
    except (NameError, KeyError):
        pass  # CONFIG not loaded yet
    
    # Priority 2: Check penny_profit_config.json
    if PENNY_PROFIT_CONFIG:
        exchanges = PENNY_PROFIT_CONFIG.get('exchanges', {})
        if ex_lower in exchanges:
            return exchanges[ex_lower].get('fee_rate', DEFAULT_FEE_RATES.get(ex_lower, 0.002))
    
    # Priority 3: Default fallback
    return DEFAULT_FEE_RATES.get(ex_lower, 0.002)


def required_price_increase(initial_usd: float, fee_rate: float, target_profit: float = 0.01) -> float:
    """
    üìê EXACT MATHEMATICAL FORMULA for required price increase to achieve target net profit.
    
    Formula: r = ((1 + P/A) / (1 - f)¬≤) - 1
    
    This accounts for fee compounding over both legs:
    1. Buy: Spend A USD, receive crypto worth A√ó(1-f) after fee
    2. Sell: Crypto sold at price√ó(1+r), then fee deducted again
    3. Final USD = A √ó (1-f)¬≤ √ó (1+r) = A + P
    
    Args:
        initial_usd (A): Position size in USD
        fee_rate (f): Fee rate per leg (e.g., 0.001 for 0.1%)
        target_profit (P): Target net profit in USD (default $0.01)
    
    Returns:
        r: Required price increase as decimal (multiply by 100 for %)
    """
    if initial_usd <= 0 or fee_rate < 0 or target_profit <= 0:
        return 0.0
    
    # Exact formula accounting for compounding fees
    r = ((1 + target_profit / initial_usd) / ((1 - fee_rate) ** 2)) - 1
    return r


def get_penny_threshold(exchange: str, trade_size: float) -> dict:
    """üéØ EXACT PENNY PROFIT - Uses precise mathematical formula for ANY trade size!
    
    üìê EXACT FORMULA (accounts for fee compounding):
        r = ((1 + P/A) / (1 - f)¬≤) - 1
        
    Where:
        A = trade_size (initial USD)
        P = target net profit ($0.01)
        f = fee rate per leg
        r = required price increase (decimal)
    
    The sell target price = buy_price √ó (1 + r)
    
    Args:
        exchange: Exchange name ('binance', 'kraken', 'alpaca', 'capital')
        trade_size: Entry value in dollars (ANY amount!)
    
    Returns:
        dict with: required_pct, win_gte, stop_lte, fee_rate, trade_size, target_net
    """
    if not PENNY_PROFIT_ENABLED:
        return None
    
    # üîß FIX: Ensure we always return a threshold for valid positions
    # Use minimum $1 trade size if entry_value is corrupted/zero
    if trade_size <= 0:
        trade_size = 1.0  # Fallback to $1 minimum
    
    exchange_name = (exchange or 'binance').lower()
    
    fee_rate = get_exchange_fee_rate(exchange_name)
    target_net, was_clamped = clamp_target_net_for_exchange(exchange_name, PENNY_TARGET_NET)
    
    # Add safety margins for slippage and spread (from CONFIG)
    # This ensures we account for ALL costs, not just exchange fees.
    slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
    spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
    
    # Total effective rate per leg (Fee + Slippage + Spread)
    total_rate = fee_rate + slippage + spread
    
    # üìê EXACT CALCULATION using proper compounding formula
    # We use total_rate to ensure the price increase covers ALL costs
    r = required_price_increase(trade_size, total_rate, target_net)
    
    # Calculate the realized net after both legs to confirm it meets the target
    net_after_costs = trade_size * ((1 - total_rate) ** 2 * (1 + r) - 1)

    # Safety: if rounding left us below Binance minimum, bump to the floor
    if exchange_name == 'binance' and net_after_costs < BINANCE_NET_PROFIT_RANGE[0]:
        target_net = BINANCE_NET_PROFIT_RANGE[0]
        r = required_price_increase(trade_size, total_rate, target_net)
        net_after_costs = trade_size * ((1 - total_rate) ** 2 * (1 + r) - 1)

    # win_gte is the gross P&L needed (price increase √ó position)
    # Since gross_pnl = exit_value - entry_value = entry_value √ó r
    win_gte = trade_size * r
    
    # Approximate fee cost for reference (linear estimate)
    # This is just for display/logging - the real math is in 'r'
    approx_fees = 2 * total_rate * trade_size
    
    # Stop Loss: Risk ~3x the win target (gives ~25% breakeven win rate)
    # üîß FIX: 1.5x was too tight - normal volatility triggered stops before profits!
    # With 3x, we give positions room to breathe and hit penny profit.
    stop_lte = -(win_gte * 3.0)
    
    return {
        'required_pct': round(r * 100, 4),  # As percentage
        'required_r': r,                      # As decimal
        'cost': round(approx_fees, 6),        # Approximate total fees
        'win_gte': round(win_gte, 6),         # Gross P&L trigger for TP
        'stop_lte': round(stop_lte, 6),       # Gross P&L trigger for SL
        'fee_rate': fee_rate,
        'trade_size': trade_size,
        'target_net': target_net,
        'target_net_requested': PENNY_TARGET_NET,
        'target_net_clamped': was_clamped,
        'binance_net_range': BINANCE_NET_PROFIT_RANGE if exchange_name == 'binance' else None,
        'expected_net_after_costs': round(net_after_costs, 6),
        'is_dynamic': True
    }


def check_penny_exit(exchange: str, entry_value: float, gross_pnl: float, symbol: str = None) -> dict:
    """ÔøΩüá™üéØ ZERO LOSS SNIPER - ONLY exit on CONFIRMED NET PROFIT.
    
    The sniper NEVER misses. We hold until we have guaranteed profit.
    NO STOP LOSSES. NO LOSSES. EVER.
    
    "Every kill will be a confirmed net profit."
    
    Args:
        exchange: Exchange name
        entry_value: Position entry value in dollars (ANY size!)
        gross_pnl: Current gross P&L (before fees)
        symbol: Trading symbol for wisdom quotes
    
    Returns:
        {'should_tp': bool, 'should_sl': bool, 'threshold': dict, 'gross_pnl': float, 'sniper_active': bool}
    """
    threshold = get_penny_threshold(exchange, entry_value)
    
    if not threshold:
        return {'should_tp': False, 'should_sl': False, 'threshold': None, 'gross_pnl': gross_pnl, 'sniper_active': False}
    
    # üéØ ZERO LOSS MODE: ONLY exit on CONFIRMED NET PROFIT
    # Check Take Profit: gross P&L >= win threshold
    should_tp = gross_pnl >= threshold['win_gte']
    
    # üö´ NO STOP LOSSES - WE DON'T LOSE
    # The sniper holds until the kill is confirmed
    should_sl = False  # NEVER trigger stop loss
    
    # üáÆüá™üéØ SNIPER BRAIN - Get wisdom for the kill
    sniper_wisdom = None
    if should_tp and BHOYS_WISDOM_AVAILABLE:
        # Calculate approximate net profit
        net_profit = gross_pnl - threshold.get('cost', 0)
        sniper_wisdom = celebrate_penny_profit(net_profit, symbol or 'UNKNOWN')
    
    return {
        'should_tp': should_tp,
        'should_sl': should_sl,  # Always False - we don't lose
        'threshold': threshold,
        'gross_pnl': gross_pnl,
        'sniper_active': True,
        'zero_loss_mode': True,
        'sniper_wisdom': sniper_wisdom
    }


# Load on import (sets PENNY_PROFIT_ENABLED = True)
load_penny_profit_config()

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MODULE-LEVEL LOT SIZE CACHE - Used by UnifiedTradeConfirmation
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
_MODULE_LOT_SIZE_CACHE: Dict[str, Tuple[Optional[float], Optional[float]]] = {}

def get_exchange_lot_size(exchange: str, symbol: str, client=None) -> Tuple[Optional[float], Optional[float]]:
    """
    Module-level lot size lookup for any exchange.
    Returns (step_size, min_qty) or (None, None) if unavailable.
    """
    global _MODULE_LOT_SIZE_CACHE
    cache_key = f"{exchange}:{symbol}"
    
    if cache_key in _MODULE_LOT_SIZE_CACHE:
        return _MODULE_LOT_SIZE_CACHE[cache_key]
    
    exchange_name = (exchange or '').lower()
    result = (None, None)
    
    try:
        if exchange_name == 'binance' and client:
            # Try to get from Binance exchange info
            try:
                info = client.client.session.get(
                    f"{client.client.base}/api/v3/exchangeInfo",
                    params={'symbol': symbol},
                    timeout=5
                ).json()
                for sym_info in info.get('symbols', []):
                    if sym_info['symbol'] == symbol:
                        for f in sym_info.get('filters', []):
                            if f['filterType'] == 'LOT_SIZE':
                                step = float(f.get('stepSize', 0))
                                min_q = float(f.get('minQty', 0))
                                result = (step, min_q)
                                break
            except Exception:
                # Fallback defaults for common Binance pairs
                binance_defaults = {
                    'BTCUSDC': (0.00001, 0.00001), 'BTCUSDT': (0.00001, 0.00001),
                    'ETHUSDC': (0.0001, 0.0001), 'ETHUSDT': (0.0001, 0.0001),
                    'SOLUSDC': (0.001, 0.001), 'SOLUSDT': (0.001, 0.001),
                    'SHIBUSDC': (1, 1), 'SHIBUSDT': (1, 1),
                    'XLMUSDC': (0.1, 0.1), 'XLMUSDT': (0.1, 0.1),
                }
                result = binance_defaults.get(symbol, (0.00000001, 0.00000001))
                
        elif exchange_name == 'kraken':
            # Kraken common lot sizes
            kraken_defaults = {
                'XBTUSD': (0.0001, 0.0001), 'XBTUSDC': (0.0001, 0.0001),
                'ETHUSD': (0.001, 0.001), 'ETHUSDC': (0.001, 0.001),
                'SOLUSD': (0.01, 0.01), 'SOLUSDC': (0.01, 0.01),
                'SHIBUSD': (50000, 50000), 'SHIBUSDC': (50000, 50000),  # Kraken SHIB is in large lots!
                'XLMUSD': (1, 1), 'XLMUSDC': (1, 1),
                'BCHUSD': (0.001, 0.001), 'BCHUSDC': (0.001, 0.001),
            }
            # Also handle Kraken's X-prefixed naming
            alt_symbol = symbol
            if symbol.startswith('X') and len(symbol) > 4:
                alt_symbol = symbol[1:]  # XXBT -> XBT
            result = kraken_defaults.get(symbol, kraken_defaults.get(alt_symbol, (0.00000001, 0.00000001)))
            
        elif exchange_name == 'capital':
            # üíº Capital.com CFD lot sizes - they use contract sizes
            # Most CFDs have 1 unit minimum, crypto CFDs vary
            capital_defaults = {
                # Crypto CFDs on Capital.com
                'BTCUSD': (0.01, 0.01), 'Bitcoin': (0.01, 0.01),
                'ETHUSD': (0.1, 0.1), 'Ethereum': (0.1, 0.1),
                'SOLUSD': (1.0, 1.0), 'Solana': (1.0, 1.0),
                'XRPUSD': (10.0, 10.0), 'Ripple': (10.0, 10.0),
                'ADAUSD': (10.0, 10.0), 'Cardano': (10.0, 10.0),
                'DOTUSD': (1.0, 1.0), 'Polkadot': (1.0, 1.0),
                'DOGEUSD': (100.0, 100.0), 'Dogecoin': (100.0, 100.0),
                'SHIBUSD': (100000.0, 100000.0), 'Shiba': (100000.0, 100000.0),
                # Forex/Indices - standard lot decimals
                'EURUSD': (0.01, 0.01), 'GBPUSD': (0.01, 0.01),
                'US500': (0.1, 0.1), 'UK100': (0.1, 0.1),
                'Gold': (0.01, 0.01), 'XAUUSD': (0.01, 0.01),
            }
            result = capital_defaults.get(symbol, (1.0, 1.0))  # Default 1 unit for CFDs
            
        elif exchange_name == 'alpaca':
            # ü¶ô Alpaca crypto/stock lot sizes
            # Stocks are fractional, crypto varies
            alpaca_defaults = {
                # Crypto on Alpaca
                'BTC/USD': (0.0001, 0.0001), 'BTCUSD': (0.0001, 0.0001),
                'ETH/USD': (0.001, 0.001), 'ETHUSD': (0.001, 0.001),
                'SOL/USD': (0.01, 0.01), 'SOLUSD': (0.01, 0.01),
                'DOGE/USD': (1.0, 1.0), 'DOGEUSD': (1.0, 1.0),
                'SHIB/USD': (1000.0, 1000.0), 'SHIBUSD': (1000.0, 1000.0),
                # Stocks - fractional shares supported
                'AAPL': (0.001, 0.001), 'TSLA': (0.001, 0.001),
                'NVDA': (0.001, 0.001), 'MSFT': (0.001, 0.001),
            }
            result = alpaca_defaults.get(symbol, (0.001, 0.001))  # Default fractional for stocks
            
    except Exception as e:
        print(f"‚ö†Ô∏è Lot size lookup failed for {exchange}/{symbol}: {e}")
        
    _MODULE_LOT_SIZE_CACHE[cache_key] = result
    return result

def truncate_to_lot_size(quantity: float, step_size: float) -> float:
    """Truncate quantity to valid lot size step."""
    if step_size <= 0 or quantity <= 0:
        return quantity
    steps = int(quantity / step_size)
    return steps * step_size

def validate_order_quantity(exchange: str, symbol: str, quantity: float, price: float = 0, client=None) -> Tuple[Optional[float], Optional[str]]:
    """
    Validate and adjust quantity for exchange lot size requirements.
    Returns (adjusted_quantity, error_message) - error_message is None if valid.
    """
    if quantity is None or quantity <= 0:
        return None, "Invalid quantity"
        
    exchange_name = (exchange or '').lower()
    step_size, min_qty = get_exchange_lot_size(exchange, symbol, client)
    
    # Truncate to lot size
    if step_size and step_size > 0:
        quantity = truncate_to_lot_size(quantity, step_size)
        
    if quantity <= 0:
        return None, f"Quantity below lot step {step_size}"
        
    # Check minimum quantity
    if min_qty and quantity < min_qty:
        return None, f"Qty {quantity:.8f} below {exchange_name.upper()} min {min_qty:.8f}"
        
    # Check minimum notional
    min_notional = CONFIG.get(f'{exchange_name.upper()}_MIN_NOTIONAL', 1.0)
    if price and price > 0:
        notional = quantity * price
        if notional < min_notional:
            return None, f"Notional ${notional:.2f} below {exchange_name.upper()} min ${min_notional:.2f}"
            
    return quantity, None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONFIGURATION - THE UNIFIED PARAMETERS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CONFIG = {
    'EXCHANGE': os.getenv('EXCHANGE', 'both').lower(), # BOTH Binance AND Kraken for multi-exchange trading
    # Trading Parameters
    'BASE_CURRENCY': os.getenv('BASE_CURRENCY', 'USD'),  # USD or GBP
    
    # Platform-Specific Fees (as decimals)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üêô KRAKEN (Actual observed: ~0.40% per trade on small volume)
    'KRAKEN_FEE_MAKER': 0.0026,     # 0.26% maker fee 
    'KRAKEN_FEE_TAKER': 0.0040,     # 0.40% taker fee (actual observed)
    'KRAKEN_FEE': 0.0040,           # Legacy field (uses taker)
    
    # üü° BINANCE (UK Account - Spot only)
    'BINANCE_FEE_MAKER': 0.0010,    # 0.10% maker (with BNB discount: 0.075%)
    'BINANCE_FEE_TAKER': 0.0010,    # 0.10% taker (with BNB discount: 0.075%)
    'BINANCE_FEE': 0.0010,          # Default taker
    
    # ü¶ô ALPACA (Crypto)
    'ALPACA_FEE_MAKER': 0.0015,     # 0.15% maker (crypto)
    'ALPACA_FEE_TAKER': 0.0025,     # 0.25% taker (crypto)
    'ALPACA_FEE_STOCK': 0.0000,     # $0 commission for stocks!
    'ALPACA_FEE': 0.0025,           # Default taker for crypto
    'ALPACA_ANALYTICS_ONLY': False, # ü¶ô ALPACA TRADING ENABLED! Battlefield open!
    
    # üíº CAPITAL.COM (CFD/Spread Betting)
    'CAPITAL_FEE_SPREAD': 0.0010,   # ~0.1% avg spread cost (varies by instrument)
    'CAPITAL_FEE_OVERNIGHT': 0.0001,# Daily overnight financing (annualized ~2.5%)
    'CAPITAL_FEE': 0.0010,          # Default spread cost
    
    # General
    'SLIPPAGE_PCT': 0.0020,         # 0.20% estimated slippage per trade (increased for safety)
    'SPREAD_COST_PCT': 0.0010,      # 0.10% estimated spread cost (increased for safety)
    'TAKE_PROFIT_PCT': 1.8,         # FALLBACK: 1.8% (penny profit uses dollar thresholds instead)
    'STOP_LOSS_PCT': 1.5,           # FALLBACK: 1.5% (penny profit uses dollar thresholds instead)
    'MAX_POSITIONS': 30,            # üî• Legacy cap (unused when UNLIMITED_POSITIONS is enabled)
    'UNLIMITED_POSITIONS': True,    # ü™ô Penny-unity mode: no limit to active positions
    'TARGET_FILL_RATE': 0.33,       # üéØ TARGET: Keep 1/3 of positions filled (10 of 30)
    'MIN_TRADE_USD': 1.44,          # Minimum trade notional in base currency
    'BINANCE_MIN_NOTIONAL': 1.0,    # Refuse sells if notional < $1 to avoid LOT_SIZE noise
    'KRAKEN_MIN_NOTIONAL': 5.25,    # Kraken enforces ~$5 minimum notional on spot
    'CAPITAL_MIN_NOTIONAL': 10.0,   # üíº Capital.com CFD minimum ~$10 (varies by instrument)
    'ALPACA_MIN_NOTIONAL': 1.0,     # ü¶ô Alpaca crypto ~$1 min, stocks $1
    'PORTFOLIO_RISK_BUDGET': 3.00,  # 300% - allow significant positions for existing portfolio holders
    'MIN_EXPECTED_EDGE_GBP': 0.001, # Require positive edge
    'DEFAULT_WIN_PROB': 0.55,       # Target win probability
    'WIN_RATE_CONFIDENCE_TRADES': 25,
    'EQUITY_MIN_DELTA': 0.10,       # Smaller delta for frequent compounding
    'EQUITY_TOLERANCE_GBP': 0.0,
    
    # üéØ TRAILING STOP CONFIGURATION
    'ENABLE_TRAILING_STOP': True,           # Enable trailing stop system
    'TRAILING_ACTIVATION_PCT': 0.8,         # Activate at 0.8% profit (was 0.5% - lock in more profit first)
    'TRAILING_DISTANCE_PCT': 0.5,           # Trail 0.5% behind peak (was 0.3% - less whipsaw)
    'USE_ATR_TRAILING': True,               # Use ATR for dynamic trailing

    # ü¶æ ONE GOAL AGGRESSION MODE
    # When enabled, entry gating is heavily biased toward TAKING any opportunity
    # that can plausibly hit the net penny target, using additive sizing based on
    # available funds and continuing nonstop.
    'AGGRESSIVE_ONE_GOAL': os.getenv('AGGRESSIVE_ONE_GOAL', '1') == '1',
    'AGGRESSIVE_MIN_PROB': float(os.getenv('AGGRESSIVE_MIN_PROB', '0.30') or 0.30),
    'AGGRESSIVE_BLOCK_ONLY_STRONG_SELL': os.getenv('AGGRESSIVE_BLOCK_ONLY_STRONG_SELL', '1') == '1',
    'AGGRESSIVE_STRONG_SELL_CONF': float(os.getenv('AGGRESSIVE_STRONG_SELL_CONF', '0.80') or 0.80),
    'AGGRESSIVE_IGNORE_MATRIX_HOLD': os.getenv('AGGRESSIVE_IGNORE_MATRIX_HOLD', '1') == '1',
    'AGGRESSIVE_IGNORE_BRAIN_REDUCE': os.getenv('AGGRESSIVE_IGNORE_BRAIN_REDUCE', '1') == '1',
    'AGGRESSIVE_IGNORE_IMPERIAL_SELL': os.getenv('AGGRESSIVE_IGNORE_IMPERIAL_SELL', '1') == '1',
    'ATR_TRAIL_MULTIPLIER': 1.5,            # Trail at 1.5x ATR below peak
    
    # üöÄ KRAKEN ADVANCED ORDERS - Server-Side TP/SL (executes even if bot offline!)
    'USE_SERVER_SIDE_ORDERS': os.getenv('USE_SERVER_SIDE_ORDERS', '1') == '1',  # Enable Kraken native TP/SL
    'PREFER_LIMIT_ORDERS': os.getenv('PREFER_LIMIT_ORDERS', '1') == '1',        # üí∞ USE LIMIT ORDERS for maker fees (0.1% vs 0.2%!)
    'USE_TRAILING_STOP_ORDERS': os.getenv('USE_TRAILING_STOP_ORDERS', '0') == '1',  # Native trailing stops
    
    # üí∞ PROFIT GATES - PENNY PROFIT MODE!
    # Target: +$0.01 net profit per trade. Dollar thresholds loaded from penny_profit_config.json
    # These percentages are FALLBACK only when penny profit config not available
    'MIN_NET_PROFIT_PCT': 0.008,    # 0.8% fallback if penny config missing
    'SERVER_SIDE_TP_PCT': 1.8,              # Take profit % for server-side orders (fallback)
    'SERVER_SIDE_SL_PCT': 1.5,              # Stop loss % for server-side orders (fallback)
    'SERVER_TRAILING_PCT': 2.0,             # Trailing stop distance % for native trailing
    
    # Dynamic Portfolio Rebalancing
    'ENABLE_REBALANCING': True,     # Sell underperformers to buy better opportunities
    'REBALANCE_THRESHOLD': -50.0,   # üî• Sell big losers (>50% loss) to free capital for better opportunities
    'MIN_HOLD_CYCLES': 10,          # Hold at least 10 cycles (~10 mins) before rebalance (was 3)

    # ‚è±Ô∏è TIMEBOXED HOLDING (Momentum-preserving penny scalps)
    # If a position cannot secure net penny profit quickly, it is not a good setup.
    'MAX_HOLD_MINUTES': float(os.getenv('MAX_HOLD_MINUTES', '5')),          # Hard max hold per position
    'ENABLE_TIMEBOX_EXIT': os.getenv('ENABLE_TIMEBOX_EXIT', '1') == '1',    # Force-close when max hold exceeded

    # üö´ NO-LOSS DEFAULT: force scouts should not bypass the quick-profit gates unless explicitly allowed
    'ALLOW_FORCE_SCOUT_BYPASS_CONSENSUS': os.getenv('ALLOW_FORCE_SCOUT_BYPASS_CONSENSUS', '0') == '1',
    # ü§ë GREEDY HOE MODE: ALL THE QUOTE CURRENCIES!
    'QUOTE_CURRENCIES': ['USDC', 'USDT', 'USD', 'GBP', 'EUR', 'BTC', 'ETH', 'BNB', 'FDUSD', 'TUSD', 'BUSD'],
    
    # üåæ Startup Harvesting
    'HARVEST_ON_STARTUP': True,      # üî• ENABLED - Actively harvest and trade!
    'HARVEST_MIN_VALUE': 0.50,       # Lowered - harvest even small gains
    
    # Scout Deployment (from immediateWaveRider.ts)
    'DEPLOY_SCOUTS_IMMEDIATELY': True,   # üöÄ Deploy positions immediately on first scan - HIT THE GROUND RUNNING!
    'SCOUT_MIN_MOMENTUM': 0.1,           # Very low threshold - get into trades FAST
    'SCOUT_FORCE_COUNT': 10,             # ü§ë GREEDY: 10 scouts on startup!
    'SCOUT_MIN_VOLATILITY': 1.0,         # ü§ë LOWERED: More coins qualify
    'SCOUT_MIN_VOLUME_QUOTE': 50000,     # ü§ë LOWERED: Trade thinner books too
    'SCOUT_PER_QUOTE_LIMIT': 3,          # Spread early scouts across quote currencies (3 per quote)
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ‚öîÔ∏èüè¥ 4 BATTLEFRONTS - MULTI-EXCHANGE WAR CONFIGURATION ‚öîÔ∏èüè¥
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # "We're not a one trick pony - we fight on ALL fronts!" 
    # Each battlefield has its own scouts, harvester, and sniper coverage
    # Mycelium Network coordinates to prevent duplicate positions across fronts
    #
    'MULTI_BATTLEFIELD_MODE': True,       # ‚öîÔ∏è Enable 4-front warfare
    'BATTLEFIELDS': {
        'binance': {
            'enabled': True,
            'scouts_per_exchange': 3,     # 3 scouts on Binance front
            'sniper_active': True,        # üéØ Sniper covering Binance
            'harvester_active': True,     # üåæ Harvesting Binance positions
            'asset_classes': ['crypto'],
            'quote_currencies': ['USDC', 'USDT', 'FDUSD', 'BTC', 'ETH', 'BNB', 'EUR', 'GBP'],
            'min_trade_usd': 1.44,
            'max_positions': 15,
        },
        'kraken': {
            'enabled': True,
            'scouts_per_exchange': 3,     # 3 scouts on Kraken front
            'sniper_active': True,        # üéØ Sniper covering Kraken
            'harvester_active': True,     # üåæ Harvesting Kraken positions
            'asset_classes': ['crypto'],
            'quote_currencies': ['USD', 'EUR', 'GBP', 'USDT', 'USDC', 'BTC', 'ETH'],
            'min_trade_usd': 5.25,
            'max_positions': 15,
        },
        'capital': {
            'enabled': True,
            'scouts_per_exchange': 2,     # 2 scouts on Capital.com CFD front
            'sniper_active': True,        # üéØ Sniper covering Capital CFDs
            'harvester_active': True,     # üåæ Harvesting CFD positions
            'asset_classes': ['forex', 'indices', 'commodities', 'stocks'],  # NO crypto!
            'quote_currencies': ['USD', 'GBP'],
            'min_trade_usd': 10.0,
            'max_positions': 10,
        },
        'alpaca': {
            'enabled': True,              # ü¶ô ALPACA BATTLEFIELD ACTIVATED!
            'scouts_per_exchange': 3,     # 3 scouts on Alpaca front (crypto + stocks)
            'sniper_active': True,        # üéØ Sniper covering Alpaca
            'harvester_active': True,     # üåæ Harvester active on Alpaca
            'asset_classes': ['stocks', 'crypto'],
            'quote_currencies': ['USD'],
            'min_trade_usd': 1.0,         # Fractional shares = low minimum!
            'max_positions': 10,
        },
    },
    'PREVENT_DUPLICATE_POSITIONS': True,  # üçÑ Mycelium tracks cross-exchange to avoid doubling up
    
    # Kelly Criterion & Risk Management
    'USE_KELLY_SIZING': True,       # Use Kelly instead of fixed %
    'KELLY_SAFETY_FACTOR': 0.5,     # Half-Kelly for safety
    'BASE_POSITION_SIZE': 0.04,     # Base size when Kelly disabled (reduced for smaller trades)
    'MAX_POSITION_SIZE': 0.25,      # Hard cap per trade
    'MAX_SYMBOL_EXPOSURE': 0.30,    # Max 30% in one symbol
    
    # üéµ FREQUENCY-BASED TRADING (Historical Data Shows Clear Patterns!)
    # 256_ROOT = 100% win rate (9/9), 432_NATURAL = 18% (3/17)
    # Hour 14-15 = 90%+ WR, Hour 16-17 = 8% WR
    'DEFAULT_FREQUENCY': 256,       # Default to 256 (ROOT) which wins, NOT 432 which loses!
    'WINNING_FREQUENCIES': ['256_ROOT', '174_FOUNDATION', '528_LOVE'],  # Trade these
    'LOSING_FREQUENCIES': ['432_NATURAL', '440_DISTORTION'],            # Avoid these
    'WINNING_HOURS': [14, 15, 19, 0],  # Historical winners
    'LOSING_HOURS': [16, 17, 23, 1],   # Historical losers - BLOCK!
    'MAX_DRAWDOWN_PCT': 50.0,       # Circuit breaker at 50% DD - raised to allow recovery trades
    'MIN_NETWORK_COHERENCE': 0.20,  # NEVER pause - always trade!
    
    # üéØ‚ö° TURBO HUNTER - PROACTIVE 90%+ WIN RATE SEEKING ‚ö°üéØ
    # "It knows what's gonna happen - HUNT the winners, close in 1 min!"
    'ENABLE_TURBO_HUNT': True,      # üî• ENABLED: Actively hunt elite setups
    'TURBO_HUNT_MIN_WR': 0.85,      # Only execute on 85%+ expected win rate
    'TURBO_HUNT_MAX_PER_CYCLE': 3,  # Max trades per turbo hunt cycle
    'TURBO_TARGET_CYCLE_SECONDS': 60,  # Target 1-minute full cycle completion
    
    # Opportunity Filters - ü™ô PENNY PROFIT FIRST ü™ô
    'MIN_MOMENTUM': -5.0,           # ü™ô PENNY MODE: Allow slightly down coins (dip buying)
    'MAX_MOMENTUM': 50.0,           # Avoid parabolic pumps (reversal risk)
    'MIN_VOLUME': 10000,            # ü™ô PENNY MODE: Lower volume = more opportunities
    'MIN_SCORE': 20,                # ü™ô PENNY MODE: Very low score threshold - trust the math
    
    # üéØ OPTIMAL WIN RATE MODE
    'ENABLE_OPTIMAL_WR': True,      # Enable all win rate optimizations
    
    # üî• FORCE TRADE MODE - Bypasses all gates for testing
    'FORCE_TRADE': os.getenv('FORCE_TRADE', '0') == '1',
    'FORCE_TRADE_SYMBOL': os.getenv('FORCE_TRADE_SYMBOL', ''),  # Specific symbol or empty for best available
    
    # üî≠ QUANTUM TELESCOPE
    'ENABLE_QUANTUM_TELESCOPE': True,
    'ENABLE_HARMONIC_UNDERLAY': True,
    'QUANTUM_WEIGHT': 0.15,         # Weight of Quantum Telescope in Lambda field
    'HARMONIC_WEIGHT': 0.20,        # Weight of 6D harmonic coherence in Lambda field
    'HARMONIC_GATE': 0.10,          # ü™ô PENNY MODE: Very low - don't block penny trades
    'HARMONIC_PROB_MIN': 0.30,      # ü™ô PENNY MODE: Almost always pass
    'OPTIMAL_MIN_GATES': 0,         # ü™ô PENNY MODE: ZERO gates required - penny math is king
    'OPTIMAL_MIN_COHERENCE': 0.10,  # ü™ô PENNY MODE: Almost no coherence needed
    'OPTIMAL_TREND_CONFIRM': True,  # Require trend confirmation
    'OPTIMAL_MULTI_TF_CHECK': True, # Multi-timeframe coherence check
    
    # Compounding (10-9-1 Model)
    'COMPOUND_PCT': 0.90,           # 90% compounds
    'HARVEST_PCT': 0.10,            # 10% harvests
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üåÄ MEDICINE WHEEL FREQUENCY ALPHABET - Native American Light Language üåÄ
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # The Four Directions encode the sacred frequency alphabet:
    # EAST (Yellow/Fire)  ‚Üí 528 Hz - Birth/New Beginnings - LOVE frequency
    # SOUTH (Black/Water) ‚Üí 396 Hz - Youth/Growth - Liberation frequency  
    # WEST (Red/Earth)    ‚Üí 432 Hz - Adults/Harvest - Cosmic frequency
    # NORTH (White/Wind)  ‚Üí 963 Hz - Elders/Wisdom - Unity frequency
    # CENTER (Green)      ‚Üí 528 Hz - Creator/Balance - DNA REPAIR ‚≠ê
    # GREEN = Yellow (East) + Blue (Sky) = Heart chakra = 528Hz LOVE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # Auris Node Frequencies (Hz) - Aligned with Medicine Wheel
    'FREQ_TIGER': 741.0,           # SOL - Awakening intuition
    'FREQ_FALCON': 852.0,          # LA - Spiritual order (EAST spirit animal variant)
    'FREQ_HUMMINGBIRD': 963.0,     # SI - Unity/NORTH Elder wisdom
    'FREQ_DOLPHIN': 528.0,         # MI - GREEN BORAX LOVE üíö CENTER/EAST
    'FREQ_DEER': 396.0,            # UT - Liberation/SOUTH Growth
    'FREQ_OWL': 432.0,             # Cosmic harmony/WEST Harvest
    'FREQ_PANDA': 412.3,           # Transition frequency
    'FREQ_CARGOSHIP': 174.0,       # Foundation/grounding
    'FREQ_CLOWNFISH': 639.0,       # FA - Connection/relationships
    
    # Medicine Wheel Direction Frequencies (Native American Light Language)
    'MEDICINE_WHEEL_EAST': 528.0,  # Yellow/Fire - Birth - EAGLE spirit
    'MEDICINE_WHEEL_SOUTH': 396.0, # Black/Water - Youth - WOLF spirit
    'MEDICINE_WHEEL_WEST': 432.0,  # Red/Earth - Adult - BUFFALO spirit
    'MEDICINE_WHEEL_NORTH': 963.0, # White/Wind - Elder - BEAR spirit
    'MEDICINE_WHEEL_CENTER': 528.0,# GREEN - Creator - ALL spirits unified
    
    # Coherence Thresholds - OPTIMAL WIN RATE MODE üéØ
    'HIGH_COHERENCE_MODE': False,   # DISABLED: Allow trading in any coherence
    'ENTRY_COHERENCE': 0.20,       # LOWERED: Allow more trades (was 0.35)
    'EXIT_COHERENCE': 0.15,        # LOWERED: Exit more flexibly (was 0.25)
    
    # Lambda Field Components (from coherenceTrader.ts)
    'ENABLE_LAMBDA_FIELD': os.getenv('ENABLE_LAMBDA_FIELD', '1') == '1',  # Full Œõ(t) = S(t) + O(t) + E(t)
    'OBSERVER_WEIGHT': 0.3,         # O(t) = Œõ(t-1) √ó 0.3 (self-reference)
    'ECHO_WEIGHT': 0.2,             # E(t) = avg(Œõ[t-5:t]) √ó 0.2 (memory)
    
    # üåç‚ö° HNC Frequency Integration ‚ö°üåç
    'ENABLE_HNC_FREQUENCY': os.getenv('ENABLE_HNC', '1') == '1',  # Use HNC frequency for sizing
    'HNC_FREQUENCY_WEIGHT': 0.25,    # H(t) weight in Lambda field
    'HNC_COHERENCE_THRESHOLD': 0.50, # Min triadic coherence for full sizing
    'HNC_HARMONIC_BONUS': 1.15,      # 15% bonus for harmonic resonance (256/528 Hz)
    
    # üîä PHASE 2: FREQUENCY FILTERING OPTIMIZATION üîä
    'ENABLE_FREQUENCY_FILTERING': True,        # Enable frequency-based signal quality
    'FREQUENCY_BOOST_300HZ': 1.50,            # 50% boost for 300-399Hz (98.8% prediction accuracy!)
    'FREQUENCY_BOOST_528HZ': 1.35,            # 35% boost for 528Hz Love Frequency (83.3% WR)
    'FREQUENCY_SUPPRESS_963HZ': 0.6,          # 40% suppression for 963Hz (poor performer)
    'FREQUENCY_SUPPRESS_600HZ': 0.75,         # 25% suppression for 600-699Hz (0% accuracy)
    'FREQUENCY_NEUTRAL_BASELINE': 1.0,        # All other frequencies baseline multiplier
    'FREQUENCY_WIN_RATE_TARGET': 0.60,        # Phase 2 target: 60%+ win rate
    'HNC_DISTORTION_PENALTY': 0.70,           # 30% penalty for 440 Hz distortion
    
    # üéµ SOLFEGGIO FREQUENCY BOOSTS (Ancient Sacred Healing Tones) üéµ
    'FREQUENCY_BOOST_174HZ': 1.20,            # 174Hz - Pain Relief, Foundation
    'FREQUENCY_BOOST_285HZ': 1.25,            # 285Hz - Healing, Tissue Regeneration  
    'FREQUENCY_BOOST_396HZ': 1.40,            # 396Hz - Liberation from Fear/Guilt (UT)
    'FREQUENCY_BOOST_417HZ': 1.30,            # 417Hz - Undoing Situations, Change (RE)
    'FREQUENCY_BOOST_639HZ': 1.25,            # 639Hz - Connection, Relationships (FA)
    'FREQUENCY_BOOST_741HZ': 1.15,            # 741Hz - Awakening Intuition (SOL)
    'FREQUENCY_BOOST_852HZ': 1.20,            # 852Hz - Returning to Spiritual Order (LA)
    
    # üåç EARTH & COSMIC FREQUENCIES üåç
    'FREQUENCY_BOOST_SCHUMANN': 1.45,         # 7.83Hz - Earth's heartbeat (√óharmonics)
    'FREQUENCY_BOOST_432HZ': 1.30,            # 432Hz - Universal tuning, cosmic harmony
    'FREQUENCY_BOOST_136HZ': 1.25,            # 136.1Hz - OM, Earth's year frequency
    
    # üî¥ DISTORTION FREQUENCIES (AVOID) üî¥
    'FREQUENCY_SUPPRESS_440HZ': 0.70,         # 440Hz - Artificial concert pitch, dissonance
    'FREQUENCY_SUPPRESS_HIGH_CHAOS': 0.50,    # 1000+Hz - Chaotic, unstable
    
    # üåç‚ö° HNC Probability Matrix (2-Hour Window) ‚ö°üåç
    'ENABLE_PROB_MATRIX': os.getenv('ENABLE_PROB_MATRIX', '1') == '1',
    'ENABLE_PROBABILITY_GENERATOR': os.getenv('ENABLE_PROBABILITY_GENERATOR', '1') == '1',  # Auto-regenerate every 15s
    'PROB_MIN_CONFIDENCE': 0.45,     # Lowered to admit more entries
    'PROB_HIGH_THRESHOLD': 0.65,     # High probability threshold for boost
    'PROB_LOW_THRESHOLD': 0.40,      # Low probability threshold for reduction
    'PROB_LOOKBACK_MINUTES': 60,     # Hour -1 lookback window
    'PROB_FORECAST_WEIGHT': 0.4,     # Weight of Hour +1 in position sizing
    
    # üåå‚ö° HNC Imperial Predictability Engine ‚ö°üåå
    'ENABLE_IMPERIAL': os.getenv('ENABLE_IMPERIAL', '1') == '1',  # Cosmic synchronization
    'IMPERIAL_POSITION_WEIGHT': 0.35,   # Weight of imperial modifier in sizing
    'IMPERIAL_MIN_COHERENCE': 0.30,     # Lowered: Minimum cosmic coherence to trade
    'IMPERIAL_DISTORTION_LIMIT': 0.50,  # Raised: Allow trades up to 50% distortion
    'IMPERIAL_COSMIC_BOOST': True,      # Apply cosmic phase boost
    'IMPERIAL_YIELD_THRESHOLD': 1e30,   # Min imperial yield for action
    
    # üåç‚ö° Earth Resonance Engine ‚ö°üåç
    'ENABLE_EARTH_RESONANCE': os.getenv('ENABLE_EARTH_RESONANCE', '1') == '1',
    'EARTH_COHERENCE_THRESHOLD': 0.50,  # Field coherence gate threshold (lowered for WR)
    'EARTH_PHASE_LOCK_THRESHOLD': 0.60, # Phase lock gate threshold (lowered from 0.85)
    'EARTH_PHI_AMPLIFICATION': True,    # Use PHI (1.618) position boost
    'EARTH_SENTIMENT_MAPPING': True,    # Map fear/greed to emotional frequencies
    'EARTH_EXIT_URGENCY': True,         # Use resonance for exit urgency
    
    # üåç‚ö° CoinAPI Anomaly Detection ‚ö°üåç
    'ENABLE_COINAPI': os.getenv('ENABLE_COINAPI', '0') == '1',  # Requires API key
    'COINAPI_SCAN_INTERVAL': 300,    # Scan for anomalies every 5 minutes
    'COINAPI_MIN_SEVERITY': 0.40,    # Minimum severity to act on anomaly
    'COINAPI_BLACKLIST_DURATION': 3600,  # Block symbol for 1 hour on wash trading
    'COINAPI_ADJUST_COHERENCE': True,    # Adjust coherence based on anomalies
    'COINAPI_PRICE_SOURCE': 'multi_exchange',  # Use aggregated prices when available
    
    # WebSocket
    'WS_URL': 'wss://ws.kraken.com',
    'WS_RECONNECT_DELAY': 5,        # Seconds between reconnect attempts
    'WS_HEARTBEAT_TIMEOUT': 60,     # Max seconds without WS message
    
    # State Persistence
    'STATE_FILE': 'aureon_kraken_state.json',
    
    # Elephant Memory (Quackers)
    'LOSS_STREAK_LIMIT': 3,
    'COOLDOWN_MINUTES': 13,       # Fibonacci timing
    
    # System Flux Prediction (30-Span)
    'FLUX_SPAN': 30,              # Number of assets to analyze for flux
    'FLUX_THRESHOLD': 0.80,       # Raised from 0.60 - only override in VERY strong bearish/bullish
}


def get_max_positions_limit() -> Optional[int]:
    """Return the active position cap or None for unlimited trading."""
    if CONFIG.get('UNLIMITED_POSITIONS'):
        return None

    max_positions = CONFIG.get('MAX_POSITIONS')
    try:
        max_positions_int = int(max_positions)
    except Exception:
        return None

    return max_positions_int if max_positions_int > 0 else None


def max_positions_label() -> str:
    """Human-readable label for max position status."""
    limit = get_max_positions_limit()
    return "unlimited" if limit is None else str(limit)


def has_one_minute_profit_consensus(opp: Dict) -> Tuple[bool, str, Dict[str, float]]:
    """ü™ô PENNY PROFIT MODE: Super relaxed consensus check.
    
    The penny profit math is the REAL gate. This function is now very lenient
    to allow the bot to actually trade and let the penny math do its job.
    
    Returns (ok, reason, details) where `ok` indicates entry is allowed.
    """

    # ü¶æ AGGRESSIVE ONE-GOAL: never block entries here.
    if CONFIG.get('AGGRESSIVE_ONE_GOAL', False):
        details = {
            'prob_quick': float((opp.get('quick_kill') or {}).get('prob_quick_kill', 0.5) or 0.5),
            'confidence': float((opp.get('quick_kill') or {}).get('confidence', 0.5) or 0.5),
            'estimated_seconds': float((opp.get('quick_kill') or {}).get('estimated_seconds', 300) or 300),
        }
        return True, "aggressive override", details

    qk = opp.get('quick_kill') or {}

    # Pull estimates from opportunity
    prob_quick = qk.get('prob_quick_kill') or qk.get('prob_penny_profit', 0.0)
    confidence = qk.get('confidence', 0.0) if isinstance(qk.get('confidence'), (int, float)) else 0.0
    est_seconds = qk.get('estimated_seconds')
    if est_seconds is None and isinstance(qk.get('estimated_minutes'), (int, float)):
        est_seconds = qk['estimated_minutes'] * 60

    # Refresh estimate from War Strategy if missing/weak
    if (est_seconds is None or prob_quick <= 0) and WAR_STRATEGY_AVAILABLE:
        try:
            estimate = get_quick_kill_estimate(
                opp.get('symbol'),
                opp.get('exchange', 'unknown'),
                opp.get('prices'),
            )
            est_seconds = estimate.estimated_seconds
            prob_quick = max(prob_quick, estimate.prob_quick_kill)
            confidence = max(confidence, estimate.confidence)
            opp['quick_kill'] = {**estimate.to_dict(), **qk}
        except Exception as e:
            logger.debug(f"Quick kill refresh failed for {opp.get('symbol')}: {e}")

    # ü™ô PENNY MODE: Provide defaults if missing - DON'T BLOCK
    if est_seconds is None:
        est_seconds = 300  # Assume 5 minutes if unknown
    if prob_quick <= 0:
        prob_quick = 0.5  # Assume 50/50 if unknown
    if confidence <= 0:
        confidence = 0.5  # Assume medium confidence if unknown

    details = {
        'prob_quick': prob_quick,
        'confidence': confidence,
        'estimated_seconds': est_seconds,
    }

    # ü™ô PENNY PROFIT MODE: Very relaxed thresholds
    # Time: Allow up to 10 minutes (penny profit doesn't need to be instant)
    # Prob: Allow 30% or higher (the penny math protects us)
    # Conf: Allow 20% or higher (we're betting on math, not predictions)
    meets_time = est_seconds <= 600  # 10 minutes instead of 1
    meets_prob = prob_quick >= 0.30  # 30% instead of 50%
    meets_confidence = confidence >= 0.20  # 20% instead of 50%

    if meets_time and meets_prob and meets_confidence:
        return True, "penny profit consensus", details
    
    # ü™ô FALLBACK: Even if conditions not met, allow trade if score is decent
    # This ensures we don't block trades just because predictions are missing
    score = opp.get('score', 0)
    if score >= 30:  # If opportunity has decent score, let it through
        return True, "score override", details

    unmet = []
    if not meets_time:
        unmet.append(f"time {est_seconds/60:.1f}m")
    if not meets_prob:
        unmet.append(f"prob {prob_quick:.2f}")
    if not meets_confidence:
        unmet.append(f"conf {confidence:.2f}")

    return False, ", ".join(unmet), details

PHI = (1 + math.sqrt(5)) / 2  # Golden Ratio = 1.618

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéπ QUANTUM BRAIN / PIANO STATE BRIDGE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

BRAIN_STATE_PATH = os.path.join(tempfile.gettempdir(), "aureon_multidimensional_brain_output.json")
_BRAIN_CACHE: Dict[str, Any] = {}
_BRAIN_CACHE_TIME: float = 0.0


def load_brain_state() -> Dict[str, Any]:
    """Load cached Quantum Brain/Piano state if recently updated."""
    global _BRAIN_CACHE, _BRAIN_CACHE_TIME
    try:
        now = time.time()
        if now - _BRAIN_CACHE_TIME < 10:
            return _BRAIN_CACHE
        if not os.path.exists(BRAIN_STATE_PATH):
            return {}
        with open(BRAIN_STATE_PATH) as f:
            data = json.load(f)
        piano = data.get('piano', {}) if isinstance(data, dict) else {}
        meta = data.get('meta', {}) if isinstance(data, dict) else {}
        cascade = meta.get('multiverse_cascade') or data.get('multiverse_cascade')
        _BRAIN_CACHE = {
            'piano_lambda': piano.get('lambda'),
            'piano_coherence': piano.get('coherence'),
            'rainbow_state': piano.get('rainbow_state'),
            'cascade': cascade,
            'timestamp': data.get('timestamp') or meta.get('timestamp'),
        }
        _BRAIN_CACHE_TIME = now
        return _BRAIN_CACHE
    except Exception:
        return {}


def get_brain_multiplier() -> float:
    """Compute a trading multiplier from Piano/Brain resonance."""
    brain = load_brain_state()
    if not isinstance(brain, dict):
        return 1.0
    mult = 1.0
    piano_coh = brain.get('piano_coherence')
    piano_lambda = brain.get('piano_lambda')
    rainbow_state = (brain.get('rainbow_state') or '').upper()

    if piano_coh is not None:
        mult *= 1.0 + max(0.0, piano_coh - 0.5) * 0.2  # up to +10%
    if piano_lambda is not None and piano_lambda > 1.5:
        mult *= 1.0 + (piano_lambda - 1.0) * 0.05       # mild lambda boost

    rainbow_boost = {
        'UNITY': 1.10,
        'AWE': 1.07,
        'LOVE': 1.05,
        'RESONANCE': 1.03,
    }
    if rainbow_state in rainbow_boost:
        mult *= rainbow_boost[rainbow_state]

    return mult


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîó MINER STATE CONNECTOR - AUTO-DETECT RUNNING MINER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class MinerStateConnector:
    """
    üîó MINER STATE CONNECTOR üîó
    
    Automatically detects and connects to a running miner by monitoring
    the shared state file. This enables the ecosystem to receive live
    quantum state even when running standalone (without orchestrator).
    
    The miner writes to: /tmp/aureon_multidimensional_brain_output.json
    We read this file periodically to get:
    - Unified Coherence (Œ®)
    - Planetary Gamma (Œì)
    - Cascade Multiplier
    - Lighthouse Window status
    - Piano Lambda (Œõ)
    - Rainbow State
    """
    
    # State file path (same as miner writes to)
    STATE_FILE = os.path.join(tempfile.gettempdir(), 'aureon_multidimensional_brain_output.json')
    
    # Alternative paths to check
    ALT_PATHS = [
        os.path.join(tempfile.gettempdir(), 'aureon_brain_state.json'),
        os.path.join(os.path.dirname(__file__), 'aureon_brain_state.json'),
        'aureon_brain_state.json',
    ]
    
    # How fresh the state must be to consider miner "connected" (seconds)
    FRESHNESS_THRESHOLD = 30  
    
    def __init__(self):
        self._state_file: Optional[str] = None
        self._last_state: Dict[str, Any] = {}
        self._last_read_time: float = 0
        self._read_interval: float = 2.0  # Check every 2 seconds
        self._miner_connected: bool = False
        self._connection_time: Optional[float] = None
        
        # Cached quantum values
        self.unified_coherence: float = 0.5
        self.planetary_gamma: float = 0.5
        self.cascade_multiplier: float = 1.0
        self.is_lighthouse: bool = False
        self.piano_lambda: float = 1.0
        self.piano_coherence: float = 0.0
        self.rainbow_state: str = "UNKNOWN"
        self.probability_edge: float = 0.0
        self.harmonic_signal: str = "HOLD"
        self.hnc_probability: float = 0.5
        
        # Statistics
        self._successful_reads: int = 0
        self._failed_reads: int = 0
        
        logger.info("üîó Miner State Connector initialized - will auto-detect running miner")
        
    def _find_state_file(self) -> Optional[str]:
        """Find the miner state file from possible locations."""
        # Check primary path first
        if os.path.exists(self.STATE_FILE):
            return self.STATE_FILE
        
        # Check alternatives
        for path in self.ALT_PATHS:
            if os.path.exists(path):
                return path
        
        return None
    
    def _is_state_fresh(self, state: Dict) -> bool:
        """Check if the state file is fresh enough to be from a running miner."""
        timestamp = state.get('timestamp', 0)
        if timestamp == 0:
            # Try last_broadcast as alternative timestamp
            timestamp = state.get('last_broadcast', 0)
        
        if timestamp == 0:
            return False
        
        age = time.time() - timestamp
        return age < self.FRESHNESS_THRESHOLD
    
    def check_connection(self) -> bool:
        """
        Check if a miner is currently running and connected.
        Updates cached quantum state if connected.
        
        Returns:
            True if miner is connected and sending fresh data
        """
        now = time.time()
        
        # Rate limit reads
        if (now - self._last_read_time) < self._read_interval:
            return self._miner_connected
        
        self._last_read_time = now
        
        try:
            # Find state file
            state_file = self._find_state_file()
            if not state_file:
                if self._miner_connected:
                    logger.info("üîó‚ùå Miner disconnected - state file not found")
                self._miner_connected = False
                return False
            
            # Read state file
            with open(state_file, 'r') as f:
                state = json.load(f)
            
            # Check freshness
            if not self._is_state_fresh(state):
                if self._miner_connected:
                    logger.info("üîó‚ö†Ô∏è Miner state stale - last update too old")
                self._miner_connected = False
                return False
            
            # Update cached values
            self._update_from_state(state)
            self._last_state = state
            self._successful_reads += 1
            
            # Log connection if newly connected
            if not self._miner_connected:
                self._miner_connected = True
                self._connection_time = now
                logger.info(f"üîó‚úÖ MINER CONNECTED! Live quantum state detected")
                logger.info(f"   Œ®={self.unified_coherence:.3f} | Œì={self.planetary_gamma:.3f} | "
                          f"Cascade={self.cascade_multiplier:.2f}x | Lighthouse={'üåü' if self.is_lighthouse else '‚¨ú'}")
            
            return True
            
        except json.JSONDecodeError as e:
            logger.debug(f"Miner state JSON error: {e}")
            self._failed_reads += 1
            return self._miner_connected
        except Exception as e:
            logger.debug(f"Miner state read error: {e}")
            self._failed_reads += 1
            return self._miner_connected
    
    def _update_from_state(self, state: Dict):
        """Update cached quantum values from miner state."""
        # Core quantum values
        self.unified_coherence = float(state.get('unified_coherence', state.get('psi', 0.5)) or 0.5)
        self.planetary_gamma = float(state.get('planetary_gamma', state.get('gamma', 0.5)) or 0.5)
        self.cascade_multiplier = float(state.get('cascade_multiplier', state.get('cascade', 1.0)) or 1.0)
        self.is_lighthouse = bool(state.get('is_lighthouse', state.get('is_optimal_window', False)))
        
        # Piano/Rainbow state
        self.piano_lambda = float(state.get('piano_lambda', state.get('lambda_field', 1.0)) or 1.0)
        self.piano_coherence = float(state.get('piano_coherence', 0.0) or 0.0)
        self.rainbow_state = str(state.get('rainbow_state', 'UNKNOWN') or 'UNKNOWN')
        
        # Probability/Signal
        self.probability_edge = float(state.get('probability_edge', 0.0) or 0.0)
        self.harmonic_signal = str(state.get('harmonic_signal', 'HOLD') or 'HOLD')
        self.hnc_probability = float(state.get('hnc_probability', 0.5) or 0.5)
    
    def get_quantum_context(self) -> Dict[str, Any]:
        """
        Get quantum context dict suitable for MinerBrain.run_cycle().
        
        Returns:
            Dict with quantum state from miner (or defaults if not connected)
        """
        # Always check connection first
        self.check_connection()
        
        return {
            'quantum_coherence': self.unified_coherence,
            'planetary_gamma': self.planetary_gamma,
            'cascade_multiplier': self.cascade_multiplier,
            'is_lighthouse': self.is_lighthouse,
            'piano_lambda': self.piano_lambda,
            'piano_coherence': self.piano_coherence,
            'rainbow_state': self.rainbow_state,
            'probability_edge': self.probability_edge,
            'harmonic_signal': self.harmonic_signal,
            'hnc_probability': self.hnc_probability,
            'miner_connected': self._miner_connected,
            'signal_confidence': min(0.95, 0.5 + self.probability_edge),
        }
    
    def get_status(self) -> Dict[str, Any]:
        """Get connector status for display."""
        return {
            'connected': self._miner_connected,
            'connection_time': self._connection_time,
            'uptime': time.time() - self._connection_time if self._connection_time else 0,
            'successful_reads': self._successful_reads,
            'failed_reads': self._failed_reads,
            'last_state_age': time.time() - self._last_state.get('timestamp', 0) if self._last_state else float('inf'),
            'state_file': self._state_file,
        }
    
    @property
    def is_connected(self) -> bool:
        """Property to check if miner is currently connected."""
        return self._miner_connected


# Global miner connector instance
MINER_CONNECTOR = MinerStateConnector()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß†üåç ECOSYSTEM BRAIN BRIDGE - UNIFIED INTELLIGENCE HUB
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class EcosystemBrainBridge:
    """
    üß†üåç ECOSYSTEM BRAIN BRIDGE üåçüß†
    
    The central intelligence hub that connects:
    - MinerBrain (7 Civilizations Wisdom) ‚Üí Trading Decisions
    - QuantumProcessingBrain (Miner Optimizer) ‚Üí Cascade Amplification
    - AdaptiveLearningEngine ‚Üí Brain Feedback Loop
    - CascadeAmplifier ‚Üí Brain-Guided Signal Boost
    
    This bridge ensures ALL trading decisions are informed by:
    1. Ancient wisdom (Celtic, Aztec, Egyptian, Pythagorean, Chinese, Hindu, Mayan, Norse, etc.)
    2. Quantum coherence from the mining optimizer
    3. Adaptive learning from past trades
    4. Cascade amplification from win streaks
    5. üî∑ Diamond Lattice sacred geometry ZPE boost
    
    üß† 11 CIVILIZATIONS UNITE for trading decisions!
    """
    
    def __init__(self):
        # Brain state cache
        self._brain_wisdom: Dict[str, Any] = {}
        self._brain_consensus: str = "NEUTRAL"
        self._brain_confidence: float = 0.5
        self._brain_action: str = "HOLD"
        self._civilization_signals: Dict[str, str] = {}
        
        # Quantum state from miner (if available)
        self._quantum_coherence: float = 0.5
        self._planetary_gamma: float = 0.5
        self._cascade_multiplier: float = 1.0
        self._is_lighthouse: bool = False
        
        # üî∑ DIAMOND LATTICE - Sacred Geometry Computational Boost
        self._diamond_coherence: float = 0.5
        self._diamond_boost: float = 1.0
        self._diamond_phi_alignment: float = 0.0
        self._diamond_zpe: float = 0.0
        
        # Market intelligence from brain
        self._fear_greed: int = 50
        self._btc_price: float = 0.0
        self._market_pulse: str = "NEUTRAL"
        self._manipulation_risk: float = 0.0
        
        # Timing - Brain runs EVERY SECOND for autonomous cognition
        self._last_cycle_time: float = 0.0
        self._cycle_interval: float = 1.0  # Run brain EVERY SECOND
        
        logger.info("üß†üåç Ecosystem Brain Bridge initialized - AUTONOMOUS MODE (1s cycles)")
        
        # Reference to global miner connector for auto-detection
        self._miner_connector = MINER_CONNECTOR
        
    def run_wisdom_cycle(self, brain: 'MinerBrain', quantum_context: Dict = None) -> Dict[str, Any]:
        """
        Run a full wisdom cycle with bidirectional brain sync.
        
        Automatically connects to a running miner if available, pulling live
        quantum state (Œì, cascade, lighthouse) from the shared state file.
        
        Args:
            brain: MinerBrain instance
            quantum_context: Optional quantum state from miner optimizer (auto-detected if not provided)
        
        Returns:
            Full wisdom result with trading recommendations
        """
        if not brain:
            return {}
        
        now = time.time()
        if (now - self._last_cycle_time) < self._cycle_interval:
            return self._brain_wisdom  # Return cached
        
        try:
            logger.info("üß†‚ö° Ecosystem Brain Cycle starting...")
            
            # Build quantum context - prefer live miner data if available
            if not quantum_context:
                # üîó AUTO-DETECT: Check if miner is running and get live quantum state
                miner_context = self._miner_connector.get_quantum_context()
                
                if miner_context.get('miner_connected'):
                    # Live miner data available!
                    quantum_context = miner_context
                    
                    # Update our cached state from live miner
                    self._quantum_coherence = miner_context['quantum_coherence']
                    self._planetary_gamma = miner_context['planetary_gamma']
                    self._cascade_multiplier = miner_context['cascade_multiplier']
                    self._is_lighthouse = miner_context['is_lighthouse']
                    
                    # üî∑ Extract Diamond Lattice state if available
                    self._diamond_coherence = miner_context.get('diamond_coherence', 0.5)
                    self._diamond_boost = miner_context.get('diamond_boost', 1.0)
                    self._diamond_phi_alignment = miner_context.get('diamond_phi_alignment', 0.0)
                    self._diamond_zpe = miner_context.get('diamond_zpe', 0.0)
                    
                    logger.info(f"üîóüåü Live miner data: Œ®={self._quantum_coherence:.3f} | "
                              f"Œì={self._planetary_gamma:.3f} | Cascade={self._cascade_multiplier:.2f}x"
                              f" | üî∑Diamond={self._diamond_boost:.2f}x")
                else:
                    # Fallback to stored brain state
                    brain_state = load_brain_state()
                    quantum_context = {
                        'quantum_coherence': self._quantum_coherence or 0.5,
                        'planetary_gamma': self._planetary_gamma or 0.5,
                        'cascade_multiplier': self._cascade_multiplier or 1.0,
                        'is_lighthouse': self._is_lighthouse,
                        'piano_lambda': brain_state.get('piano_lambda') or 1.0,
                        'harmonic_signal': 'HOLD',
                        'signal_confidence': 0.5,
                        'miner_connected': False,
                    }
            
            # üåê INJECT UNIVERSAL MARKET INTELLIGENCE INTO BRAIN CONTEXT
            if UNIVERSAL_MARKET_INTEL:
                universal_context = UNIVERSAL_MARKET_INTEL.get_brain_context()
                quantum_context['universal_market'] = universal_context
                quantum_context['market_sentiment'] = universal_context.get('market_sentiment', 0.5)
                quantum_context['total_assets_scanned'] = universal_context.get('universal_market_scanned', 0)
                quantum_context['sector_trends'] = universal_context.get('sector_trends', {})
            
            # Run brain cycle with quantum context
            result = brain.run_cycle(quantum_context=quantum_context)
            
            if result:
                self._brain_wisdom = result
                self._last_cycle_time = now
                
                # Extract unified consensus
                self._brain_consensus = result.get('unified_consensus', 'NEUTRAL')
                self._brain_confidence = result.get('unified_confidence', 50) / 100
                self._brain_action = result.get('unified_action', 'HOLD')
                
                # Extract civilization signals
                self._civilization_signals = result.get('civilization_actions', {})
                
                # Extract market intelligence
                live_pulse = result.get('live_pulse', {})
                self._fear_greed = live_pulse.get('fear_greed', 50)
                self._btc_price = live_pulse.get('btc_price', 0.0)
                self._market_pulse = live_pulse.get('pulse', 'NEUTRAL')
                self._manipulation_risk = result.get('manipulation_probability', 0.0)
                
                # Update CascadeAmplifier with brain state
                self._update_cascade_amplifier()
                
                # Update AdaptiveLearner with brain insights
                self._update_adaptive_learner()
                
                logger.info(f"üß†üåç Brain Cycle Complete: {self._brain_consensus} | Conf: {self._brain_confidence:.0%}")
                
            return result
            
        except Exception as e:
            import traceback
            logger.error(f"üß† Brain Cycle Error: {e}")
            logger.error(f"üß† Traceback: {traceback.format_exc()}")
            return {}
    
    def _update_cascade_amplifier(self):
        """Update CascadeAmplifier with brain wisdom."""
        try:
            # Update lighthouse gamma from brain's planetary awareness
            CASCADE_AMPLIFIER.update_lighthouse(self._planetary_gamma)
            
            # If brain says BULLISH with high confidence, boost cascade
            if self._brain_consensus == 'BULLISH' and self._brain_confidence > 0.7:
                # Simulate a "wisdom win" - the brain's confidence is a positive signal
                CASCADE_AMPLIFIER.mirror_coherence = min(1.0, CASCADE_AMPLIFIER.mirror_coherence + 0.05)
                
            # If brain says BEARISH with high confidence, decay cascade slightly
            elif self._brain_consensus == 'BEARISH' and self._brain_confidence > 0.7:
                CASCADE_AMPLIFIER.mirror_coherence = max(0.3, CASCADE_AMPLIFIER.mirror_coherence - 0.02)
                
        except Exception as e:
            logger.debug(f"Cascade update failed: {e}")
    
    def _update_adaptive_learner(self):
        """Feed brain insights to AdaptiveLearningEngine."""
        try:
            # Store brain consensus as a feature for learning
            brain_feature = {
                'brain_consensus': self._brain_consensus,
                'brain_confidence': self._brain_confidence,
                'fear_greed': self._fear_greed,
                'manipulation_risk': self._manipulation_risk,
                'civilization_agreement': sum(1 for s in self._civilization_signals.values() 
                                               if 'ACCUMULATE' in s or 'BUY' in s or 'ATTACK' in s) / 7,
            }
            
            # The adaptive learner can use this to correlate brain states with trade outcomes
            if hasattr(ADAPTIVE_LEARNER, 'record_brain_state'):
                ADAPTIVE_LEARNER.record_brain_state(brain_feature)
                
        except Exception as e:
            logger.debug(f"Adaptive learner update failed: {e}")
    
    def update_quantum_state(self, coherence: float, gamma: float, cascade: float, lighthouse: bool):
        """Update quantum state from miner optimizer."""
        self._quantum_coherence = coherence
        self._planetary_gamma = gamma
        self._cascade_multiplier = cascade
        self._is_lighthouse = lighthouse
    
    def update_diamond_state(self, diamond_coherence: float, diamond_boost: float, 
                             phi_alignment: float, zpe: float):
        """
        üî∑ Update Diamond Lattice state from miner.
        
        The Diamond provides sacred geometry computational boost:
        - Central coherence (Œ®) from octahedron center
        - Hash boost from golden ratio alignment
        - œÜ alignment (how perfect the geometry is)
        - ZPE extraction rate
        """
        self._diamond_coherence = diamond_coherence
        self._diamond_boost = diamond_boost
        self._diamond_phi_alignment = phi_alignment
        self._diamond_zpe = zpe
        
        # Diamond boost amplifies cascade multiplier!
        if diamond_boost > 1.5:
            logger.info(f"üî∑‚ö° Diamond Boost Active: {diamond_boost:.2f}x | œÜ={phi_alignment:.3f}")
    
    def get_trading_recommendation(self) -> Dict[str, Any]:
        """
        Get trading recommendation based on brain wisdom.
        
        Returns dict with:
        - action: BUY/HOLD/SELL
        - confidence: 0-1
        - position_multiplier: scaling factor for position size
        - reasoning: list of reasons
        """
        # Default neutral recommendation
        rec = {
            'action': 'HOLD',
            'confidence': 0.5,
            'position_multiplier': 1.0,
            'reasoning': [],
            'civilizations_bullish': 0,
            'civilizations_bearish': 0,
        }
        
        if not self._brain_wisdom:
            rec['reasoning'].append("No brain wisdom available")
            return rec
        
        # Count civilization votes
        bullish_signals = ['ACCUMULATE', 'ATTACK', 'BUY', 'PLANT_SEEDS', 'RESURRECTION_BUY', 
                          'DECISIVE_ACTION', 'BUILD', 'GROW', 'RIDE_THE_SUN']
        bearish_signals = ['RETREAT', 'PROTECT', 'CAUTION', 'RELEASE', 'EXIT']
        
        bullish_count = sum(1 for s in self._civilization_signals.values() 
                          if any(b in s.upper() for b in bullish_signals))
        bearish_count = sum(1 for s in self._civilization_signals.values() 
                          if any(b in s.upper() for b in bearish_signals))
        
        rec['civilizations_bullish'] = bullish_count
        rec['civilizations_bearish'] = bearish_count
        
        # Determine action based on consensus
        if self._brain_consensus == 'BULLISH':
            rec['action'] = 'BUY'
            rec['confidence'] = self._brain_confidence
            rec['position_multiplier'] = 1.0 + (self._brain_confidence * 0.5)  # Up to 1.5x
            rec['reasoning'].append(f"7 Civilizations: {bullish_count}/7 bullish")
            rec['reasoning'].append(f"Unified Consensus: {self._brain_consensus}")
            
            # Extra boost if fear is extreme
            if self._fear_greed < 25:
                rec['position_multiplier'] *= 1.2
                rec['reasoning'].append(f"Extreme Fear ({self._fear_greed}) = Contrarian Opportunity")
                
        elif self._brain_consensus == 'BEARISH':
            rec['action'] = 'REDUCE'
            rec['confidence'] = self._brain_confidence
            rec['position_multiplier'] = max(0.5, 1.0 - (self._brain_confidence * 0.3))  # Down to 0.7x
            rec['reasoning'].append(f"7 Civilizations: {bearish_count}/7 bearish")
            rec['reasoning'].append(f"Unified Consensus: {self._brain_consensus}")
            
            # Extra caution if manipulation risk is high
            if self._manipulation_risk > 0.3:
                rec['position_multiplier'] *= 0.8
                rec['reasoning'].append(f"High Manipulation Risk ({self._manipulation_risk:.0%})")
                
        else:
            rec['action'] = 'HOLD'
            rec['confidence'] = 0.5
            rec['reasoning'].append("Civilizations divided - waiting for clarity")
        
        # Lighthouse bonus
        if self._is_lighthouse:
            rec['position_multiplier'] *= 1.15
            rec['reasoning'].append("üóº Lighthouse Window Active")
        
        # üî∑ DIAMOND LATTICE BOOST - Sacred Geometry Amplification
        if self._diamond_boost > 1.3:
            diamond_mult = 1.0 + (self._diamond_boost - 1.0) * 0.2  # Up to 1.28x extra
            rec['position_multiplier'] *= diamond_mult
            rec['reasoning'].append(f"üî∑ Diamond Boost: {self._diamond_boost:.2f}x (œÜ={self._diamond_phi_alignment:.2f})")
            
            # If diamond coherence is very high, boost confidence too
            if self._diamond_coherence > 0.8:
                rec['confidence'] = min(1.0, rec['confidence'] + 0.1)
                rec['reasoning'].append(f"üî∑ Diamond Coherence Peak: Œ®={self._diamond_coherence:.2f}")
        
        return rec
    
    def get_signal_boost(self, base_score: float) -> float:
        """
        Get brain-boosted signal score for trading decisions.
        
        Applies 7-civilization wisdom to amplify or dampen signals.
        """
        boost = 1.0
        
        # Brain consensus boost
        if self._brain_consensus == 'BULLISH':
            boost *= 1.0 + (self._brain_confidence * 0.2)  # Up to +20%
        elif self._brain_consensus == 'BEARISH':
            boost *= 1.0 - (self._brain_confidence * 0.1)  # Down to -10%
        
        # Quantum coherence boost
        if self._quantum_coherence > 0.7:
            boost *= 1.0 + (self._quantum_coherence - 0.7) * 0.33  # Up to +10%
        
        # Planetary alignment boost
        if self._planetary_gamma > 0.8:
            boost *= 1.1  # +10% during strong alignment
        
        # Fear/Greed contrarian adjustment
        if self._fear_greed < 25:  # Extreme fear
            boost *= 1.15  # +15% contrarian
        elif self._fear_greed > 75:  # Extreme greed
            boost *= 0.90  # -10% caution
        
        return base_score * boost
    
    def display_status(self):
        """Display current brain bridge status."""
        if not self._brain_wisdom:
            print("   üß†üåç BRAIN: Awaiting first cycle...")
            return
        
        consensus_icon = "üìà" if self._brain_consensus == "BULLISH" else "üìâ" if self._brain_consensus == "BEARISH" else "‚öñÔ∏è"
        bullish = sum(1 for s in self._civilization_signals.values() 
                     if 'ACCUMULATE' in s or 'BUY' in s or 'ATTACK' in s or 'BUILD' in s)
        
        print(f"   üß†üåç BRAIN: {consensus_icon} {self._brain_consensus} | "
              f"Conf: {self._brain_confidence:.0%} | "
              f"Votes: {bullish}/7 üìà | "
              f"F&G: {self._fear_greed} | "
              f"Œì: {self._planetary_gamma:.2f}")


# Global Ecosystem Brain Bridge instance
ECOSYSTEM_BRAIN = EcosystemBrainBridge()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üåê SMART ORDER ROUTER - Best execution across exchanges
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class SmartOrderRouter:
    """
    Routes orders to the best exchange based on price, liquidity, and fees.
    Compares quotes across Binance, Kraken, and Capital.com in real-time.
    """
    
    def __init__(self, multi_client, get_cash_balance=None, battlefields: Optional[Dict[str, Any]] = None,
                 default_min_order_usd: float = 10.0):
        self.client = multi_client
        # Optional callback for liquid cash on a specific venue.
        # Signature: fn(exchange: str) -> float
        self.get_cash_balance = get_cash_balance
        self.battlefields = battlefields or {}
        self.default_min_order_usd = float(default_min_order_usd or 10.0)
        self.exchange_fees = {
            'binance': 0.001,   # 0.10% taker
            'kraken': 0.0026,   # 0.26% taker
            'capital': 0.001,   # ~0.1% spread
            'alpaca': 0.0       # Commission-free
        }
        # Prefer crypto-native venues first, but still consider all.
        self.exchange_priority = ['binance', 'kraken', 'alpaca', 'capital']
        self.route_history: List[Dict] = []
        
    def get_best_quote(self, symbol: str, side: str, quantity: float = None) -> Dict[str, Any]:
        """
        Get best quote across all exchanges for a symbol.
        Returns: {'exchange': str, 'price': float, 'effective_price': float, 'savings': float}
        """
        quotes = []
        base_symbol = symbol.replace('/', '').upper()
        
        for exchange in self.exchange_priority:
            try:
                # Normalize canonical symbol to exchange-specific if supported
                ex_symbol = base_symbol
                if hasattr(self.client, 'normalize_symbol'):
                    ex_symbol = self.client.normalize_symbol(exchange, symbol)
                ticker = self.client.get_ticker(exchange, ex_symbol)
                if not ticker or ticker.get('price', 0) <= 0:
                    continue
                    
                price = float(ticker.get('price', 0))
                bid = float(ticker.get('bid', price))
                ask = float(ticker.get('ask', price))
                
                # Calculate effective price including fees
                fee_rate = self.exchange_fees.get(exchange, 0.002)
                if side.upper() == 'BUY':
                    exec_price = ask * (1 + fee_rate)
                else:
                    exec_price = bid * (1 - fee_rate)
                    
                quotes.append({
                    'exchange': exchange,
                    'symbol': ex_symbol,
                    'price': price,
                    'bid': bid,
                    'ask': ask,
                    'effective_price': exec_price,
                    'fee_rate': fee_rate
                })
            except Exception as e:
                logger.debug(f"Quote error for {exchange}/{symbol}: {e}")
                continue
                
        if not quotes:
            return None
            
        # Sort by effective price (lowest for BUY, highest for SELL)
        if side.upper() == 'BUY':
            quotes.sort(key=lambda x: x['effective_price'])
        else:
            quotes.sort(key=lambda x: -x['effective_price'])
            
        best = quotes[0]
        
        # Calculate savings vs worst quote
        if len(quotes) > 1:
            worst = quotes[-1]
            if side.upper() == 'BUY':
                savings_pct = (worst['effective_price'] - best['effective_price']) / worst['effective_price'] * 100
            else:
                savings_pct = (best['effective_price'] - worst['effective_price']) / best['effective_price'] * 100
            best['savings_pct'] = savings_pct
            best['alternatives'] = quotes[1:]
        else:
            best['savings_pct'] = 0
            best['alternatives'] = []
            
        return best
        
    def route_order(self, symbol: str, side: str, quantity: float = None, quote_qty: float = None,
                    preferred_exchange: str = None) -> Dict[str, Any]:
        """
        Route and execute order on best exchange.
        Returns order result with routing metadata.
        """
        # Get best quote
        best = self.get_best_quote(symbol, side, quantity)
        if not best:
            return {'error': 'No quotes available', 'symbol': symbol}
            
        # Override if preferred exchange specified and available
        if preferred_exchange and preferred_exchange in [q['exchange'] for q in [best] + best.get('alternatives', [])]:
            for q in [best] + best.get('alternatives', []):
                if q['exchange'] == preferred_exchange:
                    best = q
                    break
                    
        # Execute order
        exchange = best['exchange']
        ex_symbol = best['symbol']

        # üí∞ ADDITIVE BUYING (SMART ROUTER): scale to available cash on the routed venue.
        if side.upper() == 'BUY' and callable(self.get_cash_balance):
            bf = (self.battlefields.get(exchange) or {})
            min_order = float(bf.get('min_trade_usd', self.default_min_order_usd) or self.default_min_order_usd)
            try:
                available_cash = float(self.get_cash_balance(exchange))
            except Exception:
                available_cash = 0.0

            available_cash *= 0.995

            if available_cash < min_order:
                # Try alternatives in order (already sorted by best effective price)
                for alt in best.get('alternatives', []):
                    alt_ex = alt.get('exchange')
                    if not alt_ex:
                        continue
                    bf = (self.battlefields.get(alt_ex) or {})
                    alt_min = float(bf.get('min_trade_usd', self.default_min_order_usd) or self.default_min_order_usd)
                    try:
                        alt_cash = float(self.get_cash_balance(alt_ex)) * 0.995
                    except Exception:
                        alt_cash = 0.0
                    if alt_cash >= alt_min:
                        exchange = alt_ex
                        ex_symbol = alt.get('symbol', ex_symbol)
                        best = alt
                        available_cash = alt_cash
                        min_order = alt_min
                        break

            if available_cash >= min_order and quote_qty is not None:
                try:
                    if float(quote_qty) > available_cash:
                        quote_qty = available_cash
                except Exception:
                    pass
        
        try:
            result = self.client.place_market_order(
                exchange, ex_symbol, side,
                quantity=quantity, quote_qty=quote_qty
            )
            
            # Add routing metadata
            result['routed_to'] = exchange
            result['symbol'] = ex_symbol
            result['effective_price'] = best['effective_price']
            result['savings_pct'] = best.get('savings_pct', 0)
            
            # Record route
            self.route_history.append({
                'timestamp': time.time(),
                'symbol': symbol,
                'side': side,
                'exchange': exchange,
                'price': best['price'],
                'savings_pct': best.get('savings_pct', 0)
            })
            
            return result
        except Exception as e:
            return {'error': str(e), 'exchange': exchange, 'symbol': ex_symbol}
            
    def get_routing_stats(self) -> Dict[str, Any]:
        """Get routing performance statistics."""
        if not self.route_history:
            return {'total_routes': 0}
            
        by_exchange = {}
        total_savings = 0
        
        for route in self.route_history:
            ex = route['exchange']
            by_exchange[ex] = by_exchange.get(ex, 0) + 1
            total_savings += route.get('savings_pct', 0)
            
        return {
            'total_routes': len(self.route_history),
            'by_exchange': by_exchange,
            'avg_savings_pct': total_savings / len(self.route_history) if self.route_history else 0
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚ö° CROSS-EXCHANGE ARBITRAGE SCANNER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class CrossExchangeArbitrageScanner:
    """
    Detects price discrepancies across Binance, Kraken, and Capital.com.
    Identifies triangular and direct arbitrage opportunities.
    """
    
    def __init__(self, multi_client):
        self.client = multi_client
        self.min_spread_pct = 0.3  # Minimum 0.3% spread to consider
        self.fee_buffer = 0.2     # 0.2% buffer for fees
        self.opportunities: List[Dict] = []
        self.last_scan = 0
        self.scan_interval = 30   # Seconds between scans
        
    def scan_direct_arbitrage(self, symbols: List[str] = None) -> List[Dict]:
        """
        Scan for direct arbitrage: buy on exchange A, sell on exchange B.
        """
        opportunities = []
        brain_mult = get_brain_multiplier()
        
        # Default symbols to scan
        if not symbols:
            symbols = ['BTCUSD', 'ETHUSD', 'XRPUSD', 'ADAUSD', 'SOLUSD', 
                      'DOTUSD', 'LINKUSD', 'AVAXUSD', 'DOGEUSD']
        
        exchanges = ['binance', 'kraken']
        
        for symbol in symbols:
            prices = {}
            
            # Get prices from each exchange
            for exchange in exchanges:
                try:
                    # Normalize canonical symbol to exchange-specific
                    ex_symbol = self.client.normalize_symbol(exchange, symbol)
                    ticker = self.client.get_ticker(exchange, ex_symbol)
                    if ticker and ticker.get('bid', 0) > 0:
                        prices[exchange] = {
                            'bid': float(ticker.get('bid', 0)),
                            'ask': float(ticker.get('ask', 0)),
                            'symbol': ex_symbol
                        }
                except Exception:
                    continue
                    
            # Check for arbitrage between each pair
            if len(prices) < 2:
                continue
                
            exchange_list = list(prices.keys())
            for i, buy_ex in enumerate(exchange_list):
                for sell_ex in exchange_list[i+1:]:
                    buy_price = prices[buy_ex]['ask']
                    sell_price = prices[sell_ex]['bid']
                    
                    # Check both directions
                    spread_1 = (sell_price - buy_price) / buy_price * 100
                    spread_2 = (prices[buy_ex]['bid'] - prices[sell_ex]['ask']) / prices[sell_ex]['ask'] * 100
                    
                    # Apply CASCADE amplification to profit confidence
                    cascaded_1 = min(spread_1 * CASCADE_FACTOR, 95.0)
                    if cascaded_1 > self.min_spread_pct + self.fee_buffer:
                        net_profit = (cascaded_1 - self.fee_buffer)
                        opportunities.append({
                            'type': 'direct',
                            'symbol': symbol,
                            'buy_exchange': buy_ex,
                            'sell_exchange': sell_ex,
                            'buy_price': buy_price,
                            'sell_price': sell_price,
                            'spread_pct': spread_1,
                            'cascaded_confidence_pct': cascaded_1,
                            'net_profit_pct': net_profit,
                            'brain_mult': brain_mult,
                            'timestamp': time.time()
                        })
                    
                    cascaded_2 = min(spread_2 * CASCADE_FACTOR, 95.0)
                    if cascaded_2 > self.min_spread_pct + self.fee_buffer:
                        net_profit = (cascaded_2 - self.fee_buffer)
                        opportunities.append({
                            'type': 'direct',
                            'symbol': symbol,
                            'buy_exchange': sell_ex,
                            'sell_exchange': buy_ex,
                            'buy_price': prices[sell_ex]['ask'],
                            'sell_price': prices[buy_ex]['bid'],
                            'spread_pct': spread_2,
                            'cascaded_confidence_pct': cascaded_2,
                            'net_profit_pct': net_profit,
                            'brain_mult': brain_mult,
                            'timestamp': time.time()
                        })
        
        # Sort by profit potential
        # Apply Œ® minimization: keep only top 3.7% by cascaded confidence
        opportunities.sort(key=lambda x: -(x.get('cascaded_confidence_pct', 0)))
        top_count = max(1, int(len(opportunities) * PSI_FILTER))
        opportunities = opportunities[:top_count]
        self.opportunities = opportunities
        self.last_scan = time.time()
        
        return opportunities
        
    def get_top_opportunities(self, limit: int = 5) -> List[Dict]:
        """Get top arbitrage opportunities."""
        # Refresh if stale
        if time.time() - self.last_scan > self.scan_interval:
            self.scan_direct_arbitrage()
        return self.opportunities[:limit]
        
    def execute_arbitrage(self, opportunity: Dict, amount_usd: float = 10.0) -> Dict[str, Any]:
        """
        Execute an arbitrage opportunity.
        Returns: {'success': bool, 'profit': float, 'details': dict}
        """
        buy_ex = opportunity['buy_exchange']
        sell_ex = opportunity['sell_exchange']
        symbol = opportunity['symbol']
        
        # Calculate quantity
        buy_price = opportunity['buy_price']
        quantity = amount_usd / buy_price
        
        results = {'buy': None, 'sell': None, 'profit': 0, 'success': False}
        
        try:
            # Execute buy
            buy_symbol = self.client.normalize_symbol(buy_ex, symbol)
            buy_result = self.client.place_market_order(buy_ex, buy_symbol, 'BUY', quantity=quantity)
            results['buy'] = buy_result
            
            if not buy_result or buy_result.get('error'):
                return results
                
            # Execute sell
                sell_symbol = self.client.normalize_symbol(sell_ex, symbol)
                sell_result = self.client.place_market_order(sell_ex, sell_symbol, 'SELL', quantity=quantity)
            results['sell'] = sell_result
            
            if sell_result and not sell_result.get('error'):
                results['success'] = True
                results['profit'] = amount_usd * (opportunity['net_profit_pct'] / 100)
                
        except Exception as e:
            results['error'] = str(e)
            
        return results


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚úÖ UNIFIED TRADE CONFIRMATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class UnifiedTradeConfirmation:
    """
    Normalizes trade confirmations across all exchanges.
    Handles Binance orderId, Kraken txid, Capital.com dealReference.
    """
    
    def __init__(self, multi_client):
        self.client = multi_client
        self.pending_confirmations: Dict[str, Dict] = {}
        self.confirmed_trades: List[Dict] = []

    def normalize_order_result(self, exchange: str, symbol: str, side: str,
                               quantity: float, quote_qty: float,
                               result: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize an already-executed order response into a unified confirmation."""
        if not result:
            return {'status': 'FAILED', 'error': 'No response'}

        # ‚ö†Ô∏è Check for error response BEFORE normalizing (e.g., min_notional blocked)
        if isinstance(result, dict) and ('error' in result):
            return {
                'status': 'BLOCKED',
                'error': result.get('error'),
                'exchange': result.get('exchange', exchange),
                'symbol': symbol,
                'side': side,
            }

        exchange_l = (exchange or '').lower()
        confirmation = {
            'exchange': exchange_l,
            'symbol': symbol,
            'side': side,
            'quantity': quantity,
            'quote_qty': quote_qty,
            'timestamp': time.time(),
            'raw_response': result,
        }

        if exchange_l == 'binance':
            confirmation.update(self._parse_binance_response(result))
        elif exchange_l == 'kraken':
            confirmation.update(self._parse_kraken_response(result))
        elif exchange_l == 'capital':
            confirmation.update(self._parse_capital_response(result))
        elif exchange_l == 'alpaca':
            confirmation.update(self._parse_alpaca_response(result))
        else:
            confirmation['status'] = 'UNKNOWN'
            confirmation['order_id'] = str(result.get('orderId', result.get('id', 'unknown')))

        if confirmation.get('status') in ['FILLED', 'ACCEPTED', 'OPEN', 'NEW', 'PENDING_NEW']:
            self.confirmed_trades.append(confirmation)

        return confirmation
        
    def submit_order(self, exchange: str, symbol: str, side: str, 
                    quantity: float = None, quote_qty: float = None) -> Dict[str, Any]:
        """
        Submit order and return unified confirmation.
        Validates lot sizes and minimum notional before submission.
        """
        # Normalize symbol per exchange to ensure BUY/SELL works across venues
        # (e.g. BTCUSD ‚Üí BTCUSDT on Binance, BTC/USD on Alpaca, XBTUSD on Kraken).
        original_symbol = symbol
        try:
            if hasattr(self.client, 'normalize_symbol'):
                normalized = self.client.normalize_symbol(exchange, symbol)
                if isinstance(normalized, str) and normalized.strip():
                    symbol = normalized.strip()
        except Exception:
            symbol = original_symbol

        # Validate quantity for SELL orders (lot size + notional)
        if side.upper() == 'SELL' and quantity is not None:
            # Get current price for notional check
            price = 0
            try:
                ticker = self.client.get_ticker(exchange, symbol)
                if ticker:
                    price = float(ticker.get('price', ticker.get('lastPrice', 0)))
            except Exception:
                pass
                
            adjusted_qty, error = validate_order_quantity(exchange, symbol, quantity, price, self.client)
            if error:
                print(f"   üö´ Order rejected pre-flight: {symbol} on {exchange}: {error}")
                return {'status': 'REJECTED', 'error': error, 'pre_flight': True}
            quantity = adjusted_qty
            
        # Safety: never submit an order with no size.
        if (quantity is None or float(quantity) <= 0.0) and (quote_qty is None or float(quote_qty) <= 0.0):
            return {
                'status': 'REJECTED',
                'error': 'Must provide quantity or quote_qty',
                'exchange': exchange,
                'symbol': symbol,
                'side': side,
                'pre_flight': True
            }

        result = self.client.place_market_order(
            exchange, symbol, side,
            quantity=quantity, quote_qty=quote_qty
        )

        return self.normalize_order_result(exchange, symbol, side, quantity, quote_qty, result)
        
    def _parse_binance_response(self, result: Dict) -> Dict:
        """Parse Binance order response."""
        if result.get('rejected') or result.get('uk_restricted'):
            return {
                'status': 'REJECTED',
                'order_id': None,
                'error': result.get('reason', 'UK restricted')
            }
            
        status = result.get('status', 'UNKNOWN')
        return {
            'status': status,
            'order_id': str(result.get('orderId', '')),
            'executed_qty': float(result.get('executedQty', 0)),
            'executed_quote_qty': float(result.get('cummulativeQuoteQty', 0)),
            'avg_price': float(result.get('price', 0)) if result.get('price') else None,
            'fills': result.get('fills', [])
        }
        
    def _parse_kraken_response(self, result: Dict) -> Dict:
        """Parse Kraken order response."""
        txid = result.get('txid', [])
        if isinstance(txid, list) and txid:
            order_id = txid[0]
            status = 'FILLED'  # Kraken market orders fill immediately
        else:
            order_id = str(result.get('orderId', result.get('id', '')))
            status = result.get('status', 'UNKNOWN')
            
        return {
            'status': status,
            'order_id': order_id,
            'executed_qty': float(result.get('executedQty', result.get('vol_exec', 0))),
            'descr': result.get('descr', {})
        }
        
    def _parse_capital_response(self, result: Dict) -> Dict:
        """Parse Capital.com order response and confirm."""
        deal_ref = result.get('dealReference')
        deal_id = result.get('dealId')
        
        if deal_id:
            return {
                'status': 'ACCEPTED',
                'order_id': deal_id,
                'deal_reference': deal_ref
            }
            
        # Need to confirm via API
        if deal_ref:
            try:
                capital_client = self.client.clients.get('capital')
                if capital_client and hasattr(capital_client.client, 'confirm_order'):
                    confirm = capital_client.client.confirm_order(deal_ref)
                    status = confirm.get('dealStatus', 'UNKNOWN')
                    return {
                        'status': status,
                        'order_id': confirm.get('dealId', deal_ref),
                        'deal_reference': deal_ref,
                        'level': confirm.get('level'),
                        'size': confirm.get('size'),
                        'direction': confirm.get('direction'),
                        'affected_deals': confirm.get('affectedDeals', [])
                    }
            except Exception as e:
                logger.error(f"Capital.com confirm error: {e}")
                
        return {
            'status': 'PENDING',
            'order_id': deal_ref,
            'deal_reference': deal_ref
        }
    
    def _parse_alpaca_response(self, result: Dict) -> Dict:
        """
        Parse Alpaca order response.
        
        Alpaca returns:
        - id: Order ID
        - status: 'new', 'accepted', 'pending_new', 'filled', 'canceled', 'rejected'
        - filled_qty: Quantity filled
        - filled_avg_price: Average fill price
        - symbol: Symbol traded
        """
        if not result:
            return {'status': 'FAILED', 'error': 'Empty response'}
        
        # Handle dry run
        if result.get('id') == 'dry_run_id':
            return {
                'status': 'SIMULATED',
                'order_id': 'dry_run_id',
                'dry_run': True
            }
        
        # Map Alpaca status to our standard format
        alpaca_status = result.get('status', 'unknown').lower()
        status_map = {
            'new': 'NEW',
            'accepted': 'ACCEPTED',
            'pending_new': 'PENDING_NEW',
            'filled': 'FILLED',
            'partially_filled': 'PARTIAL',
            'canceled': 'CANCELED',
            'rejected': 'REJECTED',
            'expired': 'EXPIRED',
        }
        status = status_map.get(alpaca_status, 'UNKNOWN')
        
        return {
            'status': status,
            'order_id': str(result.get('id', '')),
            'client_order_id': result.get('client_order_id'),
            'executed_qty': float(result.get('filled_qty', 0)),
            'avg_price': float(result.get('filled_avg_price', 0)) if result.get('filled_avg_price') else None,
            'symbol': result.get('symbol'),
            'side': result.get('side'),
            'order_type': result.get('type'),
            'created_at': result.get('created_at'),
            'filled_at': result.get('filled_at'),
        }
        
    def get_trade_history(self, exchange: str = None, limit: int = 50) -> List[Dict]:
        """Get confirmed trade history."""
        trades = self.confirmed_trades
        if exchange:
            trades = [t for t in trades if t['exchange'] == exchange.lower()]
        return trades[-limit:]
        
    def get_statistics(self) -> Dict[str, Any]:
        """Get trade confirmation statistics."""
        if not self.confirmed_trades:
            return {'total': 0}
            
        by_exchange = {}
        by_status = {}
        
        for trade in self.confirmed_trades:
            ex = trade['exchange']
            status = trade['status']
            by_exchange[ex] = by_exchange.get(ex, 0) + 1
            by_status[status] = by_status.get(status, 0) + 1
            
        return {
            'total': len(self.confirmed_trades),
            'by_exchange': by_exchange,
            'by_status': by_status
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚öñÔ∏è PORTFOLIO REBALANCER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class PortfolioRebalancer:
    """
    Unified portfolio rebalancing across Binance, Kraken, and Capital.com.
    Optimizes asset allocation and can shift funds between exchanges.
    """
    
    def __init__(self, multi_client):
        self.client = multi_client
        self.target_allocations: Dict[str, float] = {}  # asset -> target %
        self.rebalance_threshold = 0.05  # 5% deviation triggers rebalance
        self.min_trade_value = 5.0  # Minimum $5 to avoid dust trades
        self.last_rebalance = 0
        self.rebalance_history: List[Dict] = []
        
    def set_target_allocation(self, allocations: Dict[str, float]):
        """
        Set target portfolio allocation.
        Example: {'BTC': 0.30, 'ETH': 0.25, 'USDT': 0.45}
        """
        total = sum(allocations.values())
        if abs(total - 1.0) > 0.01:
            logger.warning(f"Allocations sum to {total}, normalizing to 100%")
            allocations = {k: v/total for k, v in allocations.items()}
        self.target_allocations = allocations
        
    def get_current_allocation(self) -> Dict[str, Dict]:
        """
        Get current portfolio allocation across all exchanges.
        Returns: {asset: {'amount': float, 'value_usd': float, 'pct': float, 'exchanges': dict}}
        """
        allocations = {}
        total_value = 0.0
        
        # Gather balances from all exchanges
        all_balances = self.client.get_all_balances()
        
        for exchange, balances in all_balances.items():
            for asset, amount in balances.items():
                try:
                    amount = float(amount)
                except:
                    continue
                if amount <= 0:
                    continue
                    
                # Normalize asset name
                asset_clean = asset.replace('Z', '').replace('X', '').upper()
                if asset_clean.startswith('LD'):  # Binance Earn
                    asset_clean = asset_clean[2:]
                    
                # Get USD value
                try:
                    if asset_clean in ['USD', 'USDT', 'USDC']:
                        value_usd = amount
                    else:
                        value_usd = self.client.convert_to_quote(exchange, asset_clean, amount, 'USDT')
                except:
                    value_usd = 0
                    
                if asset_clean not in allocations:
                    allocations[asset_clean] = {
                        'amount': 0.0,
                        'value_usd': 0.0,
                        'exchanges': {}
                    }
                    
                allocations[asset_clean]['amount'] += amount
                allocations[asset_clean]['value_usd'] += value_usd
                allocations[asset_clean]['exchanges'][exchange] = {
                    'amount': amount,
                    'value_usd': value_usd
                }
                total_value += value_usd
                
        # Calculate percentages
        for asset in allocations:
            if total_value > 0:
                allocations[asset]['pct'] = allocations[asset]['value_usd'] / total_value
            else:
                allocations[asset]['pct'] = 0.0
                
        return {'assets': allocations, 'total_value_usd': total_value}
        
    def calculate_rebalance_trades(self) -> List[Dict]:
        """
        Calculate trades needed to rebalance portfolio to target allocation.
        Returns list of trades: [{'asset': str, 'action': 'BUY'|'SELL', 'amount_usd': float, 'exchange': str}]
        """
        if not self.target_allocations:
            return []
            
        current = self.get_current_allocation()
        total_value = current['total_value_usd']
        assets = current['assets']
        
        trades = []
        
        for asset, target_pct in self.target_allocations.items():
            current_pct = assets.get(asset, {}).get('pct', 0.0)
            current_value = assets.get(asset, {}).get('value_usd', 0.0)
            target_value = total_value * target_pct
            
            deviation = abs(current_pct - target_pct)
            
            if deviation < self.rebalance_threshold:
                continue  # Within tolerance
                
            diff_usd = target_value - current_value
            
            if abs(diff_usd) < self.min_trade_value:
                continue  # Too small
                
            # Determine best exchange for this trade
            exchanges = assets.get(asset, {}).get('exchanges', {})
            
            if diff_usd > 0:  # Need to BUY
                # Pick exchange with most quote currency
                best_exchange = 'binance'  # Default
                trade = {
                    'asset': asset,
                    'action': 'BUY',
                    'amount_usd': abs(diff_usd),
                    'exchange': best_exchange,
                    'current_pct': current_pct,
                    'target_pct': target_pct
                }
            else:  # Need to SELL
                # Pick exchange with most of this asset
                best_exchange = max(exchanges.keys(), key=lambda e: exchanges[e]['amount']) if exchanges else 'binance'
                trade = {
                    'asset': asset,
                    'action': 'SELL',
                    'amount_usd': abs(diff_usd),
                    'exchange': best_exchange,
                    'current_pct': current_pct,
                    'target_pct': target_pct
                }
                
            trades.append(trade)
            
        # Sort: SELL first (to free up capital), then BUY
        trades.sort(key=lambda t: 0 if t['action'] == 'SELL' else 1)
        
        return trades
        
    def execute_rebalance(self, dry_run: bool = True) -> Dict[str, Any]:
        """
        Execute portfolio rebalance.
        Returns: {'success': bool, 'trades_executed': int, 'trades': list}
        """
        trades = self.calculate_rebalance_trades()
        
        if not trades:
            return {'success': True, 'trades_executed': 0, 'message': 'Portfolio within tolerance'}
            
        results = {
            'success': True,
            'trades_executed': 0,
            'trades': [],
            'dry_run': dry_run
        }
        
        for trade in trades:
            asset = trade['asset']
            action = trade['action']
            amount_usd = trade['amount_usd']
            exchange = trade['exchange']
            
            # Build symbol
            symbol = f"{asset}USDT" if exchange == 'binance' else f"{asset}USD"
            
            if dry_run:
                result = {'status': 'DRY_RUN', 'would_execute': trade}
            else:
                try:
                    if action == 'BUY':
                        result = self.client.place_market_order(
                            exchange, symbol, 'BUY', quote_qty=amount_usd
                        )
                    else:
                        # Calculate quantity from USD value
                        ticker = self.client.get_ticker(exchange, symbol)
                        price = float(ticker.get('price', 1))
                        quantity = amount_usd / price
                        result = self.client.place_market_order(
                            exchange, symbol, 'SELL', quantity=quantity
                        )
                    results['trades_executed'] += 1
                except Exception as e:
                    result = {'error': str(e)}
                    results['success'] = False
                    
            results['trades'].append({
                'trade': trade,
                'result': result
            })
            
        self.last_rebalance = time.time()
        self.rebalance_history.append({
            'timestamp': time.time(),
            'trades': len(trades),
            'success': results['success']
        })
        
        return results
        
    def get_rebalance_summary(self) -> str:
        """Get human-readable rebalance summary."""
        current = self.get_current_allocation()
        trades = self.calculate_rebalance_trades()
        
        lines = [
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            "‚öñÔ∏è PORTFOLIO REBALANCE SUMMARY",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            f"Total Portfolio Value: ${current['total_value_usd']:.2f}",
            "",
            "Current vs Target Allocation:"
        ]
        
        for asset, target in self.target_allocations.items():
            current_pct = current['assets'].get(asset, {}).get('pct', 0) * 100
            target_pct = target * 100
            diff = current_pct - target_pct
            indicator = "‚úÖ" if abs(diff) < 5 else "‚ö†Ô∏è"
            lines.append(f"  {indicator} {asset}: {current_pct:.1f}% ‚Üí {target_pct:.1f}% ({diff:+.1f}%)")
            
        if trades:
            lines.append("")
            lines.append("Recommended Trades:")
            for trade in trades:
                lines.append(f"  ‚Ä¢ {trade['action']} ${trade['amount_usd']:.2f} of {trade['asset']} on {trade['exchange']}")
        else:
            lines.append("")
            lines.append("‚úÖ Portfolio is balanced within tolerance")
            
        return "\n".join(lines)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîÆ PREDICTION VALIDATOR - Peer Review & Accuracy Tracking
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class PredictionValidator:
    """
    üîÆ PREDICTION VALIDATION SYSTEM
    
    Tracks prediction accuracy over time:
    - Logs predictions with timestamps: "At 10:00 predicted BTCUSDC +0.5% by 10:01"
    - Validates actual prices at predicted times
    - Scores accuracy: how close was prediction to reality?
    - Feeds accuracy back into confidence scores
    - Maintains historical hit rate for peer review
    
    This creates an auditable trail of "did the probability matrix get it right?"
    """
    
    def __init__(self, validation_window_seconds: int = 60):
        self.validation_window = validation_window_seconds  # Default 1 minute predictions
        self.pending_predictions: List[Dict] = []  # Predictions awaiting validation
        self.validated_predictions: List[Dict] = []  # Historical validated predictions
        self.max_history = 1000  # Keep last 1000 validated predictions
        
        # Accuracy metrics by various dimensions
        self.accuracy_metrics = {
            'total_predictions': 0,
            'validated': 0,
            'accurate': 0,  # Within 0.5% of predicted
            'close': 0,     # Within 1% of predicted
            'direction_correct': 0,  # Got the direction right (up/down)
            'by_exchange': {},
            'by_asset_class': {},
            'by_frequency_band': {},
            'by_coherence_level': {},
            'recent_accuracy': []  # Rolling window for recent accuracy
        }
        
        self.last_validation_check = time.time()
        logger.info("üîÆ PredictionValidator initialized - Tracking prediction accuracy")
    
    def log_prediction(self, exchange: str, symbol: str, current_price: float,
                       predicted_direction: str, predicted_change_pct: float,
                       probability: float, coherence: float, frequency: float,
                       asset_class: str = 'crypto') -> str:
        """
        Log a new prediction for future validation.
        
        Args:
            exchange: Exchange name (binance, kraken, etc.)
            symbol: Trading pair (BTCUSDC, etc.)
            current_price: Current price at prediction time
            predicted_direction: 'up', 'down', or 'neutral'
            predicted_change_pct: Expected % change
            probability: Confidence probability (0-1)
            coherence: HNC coherence at prediction time
            frequency: HNC frequency at prediction time
            asset_class: crypto, forex, stocks, etc.
            
        Returns:
            Prediction ID for tracking
        """
        prediction_id = f"{exchange}_{symbol}_{int(time.time()*1000)}"
        prediction_time = time.time()
        validation_time = prediction_time + self.validation_window
        
        # Calculate expected price
        if predicted_direction == 'up':
            expected_price = current_price * (1 + predicted_change_pct / 100)
        elif predicted_direction == 'down':
            expected_price = current_price * (1 - predicted_change_pct / 100)
        else:
            expected_price = current_price
        
        prediction = {
            'id': prediction_id,
            'exchange': exchange,
            'symbol': symbol,
            'asset_class': asset_class,
            'prediction_time': prediction_time,
            'prediction_time_str': datetime.now().strftime('%H:%M:%S'),
            'validation_time': validation_time,
            'validation_time_str': datetime.fromtimestamp(validation_time).strftime('%H:%M:%S'),
            'current_price': current_price,
            'predicted_direction': predicted_direction,
            'predicted_change_pct': predicted_change_pct,
            'expected_price': expected_price,
            'probability': probability,
            'coherence': coherence,
            'frequency': frequency,
            'freq_band': self._get_freq_band(frequency),
            'coherence_level': self._get_coherence_level(coherence),
            'status': 'pending'
        }
        
        self.pending_predictions.append(prediction)
        self.accuracy_metrics['total_predictions'] += 1
        
        logger.info(f"üîÆ PREDICTION LOGGED: {symbol} @ {prediction['prediction_time_str']}")
        logger.info(f"   üìä Current: ${current_price:.6f} ‚Üí Expected: ${expected_price:.6f} ({predicted_direction} {predicted_change_pct:.2f}%)")
        logger.info(f"   üéØ Probability: {probability:.1%} | Coherence: {coherence:.2f} | Freq: {frequency:.0f}Hz")
        logger.info(f"   ‚è∞ Will validate at: {prediction['validation_time_str']}")
        
        return prediction_id
    
    def validate_predictions(self, get_price_func) -> List[Dict]:
        """
        Check all pending predictions that are due for validation.
        
        Args:
            get_price_func: Function that takes (exchange, symbol) and returns current price
            
        Returns:
            List of newly validated predictions with results
        """
        now = time.time()
        newly_validated = []
        still_pending = []
        
        for prediction in self.pending_predictions:
            if now >= prediction['validation_time']:
                # Time to validate this prediction
                try:
                    actual_price = get_price_func(prediction['exchange'], prediction['symbol'])
                    if actual_price and actual_price > 0:
                        result = self._validate_single(prediction, actual_price)
                        newly_validated.append(result)
                        self._update_accuracy_metrics(result)
                        
                        # Log the validation result
                        self._log_validation_result(result)
                    else:
                        # Couldn't get price, keep pending for one more cycle
                        if now < prediction['validation_time'] + 60:  # Grace period
                            still_pending.append(prediction)
                        else:
                            prediction['status'] = 'expired'
                            logger.warning(f"‚ö†Ô∏è Prediction {prediction['id']} expired - couldn't get price")
                except Exception as e:
                    logger.error(f"Validation error for {prediction['id']}: {e}")
                    still_pending.append(prediction)
            else:
                still_pending.append(prediction)
        
        self.pending_predictions = still_pending
        
        # Add to historical validated predictions
        self.validated_predictions.extend(newly_validated)
        
        # Trim history if needed
        if len(self.validated_predictions) > self.max_history:
            self.validated_predictions = self.validated_predictions[-self.max_history:]
        
        self.last_validation_check = now
        return newly_validated
    
    def _validate_single(self, prediction: Dict, actual_price: float) -> Dict:
        """Validate a single prediction against actual price."""
        current_price = prediction['current_price']
        expected_price = prediction['expected_price']
        predicted_direction = prediction['predicted_direction']
        
        # Calculate actual change
        actual_change_pct = ((actual_price - current_price) / current_price) * 100
        actual_direction = 'up' if actual_change_pct > 0.01 else ('down' if actual_change_pct < -0.01 else 'neutral')
        
        # Calculate prediction error
        if expected_price > 0:
            price_error_pct = abs((actual_price - expected_price) / expected_price) * 100
        else:
            price_error_pct = 100
        
        # Determine accuracy levels
        is_accurate = price_error_pct <= 0.5  # Within 0.5% of predicted price
        is_close = price_error_pct <= 1.0     # Within 1% of predicted price
        direction_correct = (predicted_direction == actual_direction) or \
                           (predicted_direction in ['up', 'down'] and actual_direction == predicted_direction)
        
        # Calculate accuracy score (0-100)
        if is_accurate:
            accuracy_score = 100 - (price_error_pct * 20)  # 100 at 0%, 90 at 0.5%
        elif is_close:
            accuracy_score = 80 - ((price_error_pct - 0.5) * 40)  # 80 at 0.5%, 60 at 1%
        else:
            accuracy_score = max(0, 60 - (price_error_pct - 1) * 10)  # Decreases after 1%
        
        # Bonus for correct direction
        if direction_correct:
            accuracy_score = min(100, accuracy_score + 10)
        
        result = {
            **prediction,
            'status': 'validated',
            'validation_timestamp': time.time(),
            'validation_timestamp_str': datetime.now().strftime('%H:%M:%S'),
            'actual_price': actual_price,
            'actual_change_pct': actual_change_pct,
            'actual_direction': actual_direction,
            'price_error_pct': price_error_pct,
            'is_accurate': is_accurate,
            'is_close': is_close,
            'direction_correct': direction_correct,
            'accuracy_score': accuracy_score
        }
        
        return result
    
    def _update_accuracy_metrics(self, result: Dict):
        """Update accuracy metrics with validation result."""
        self.accuracy_metrics['validated'] += 1
        
        if result['is_accurate']:
            self.accuracy_metrics['accurate'] += 1
        if result['is_close']:
            self.accuracy_metrics['close'] += 1
        if result['direction_correct']:
            self.accuracy_metrics['direction_correct'] += 1
        
        # Update by exchange
        exchange = result['exchange']
        if exchange not in self.accuracy_metrics['by_exchange']:
            self.accuracy_metrics['by_exchange'][exchange] = {
                'total': 0, 'accurate': 0, 'close': 0, 'direction_correct': 0, 'avg_score': 0, 'scores': []
            }
        ex = self.accuracy_metrics['by_exchange'][exchange]
        ex['total'] += 1
        if result['is_accurate']:
            ex['accurate'] += 1
        if result['is_close']:
            ex['close'] += 1
        if result['direction_correct']:
            ex['direction_correct'] += 1
        ex['scores'].append(result['accuracy_score'])
        ex['scores'] = ex['scores'][-100:]  # Keep last 100
        ex['avg_score'] = sum(ex['scores']) / len(ex['scores'])
        
        # Update by asset class
        asset_class = result['asset_class']
        if asset_class not in self.accuracy_metrics['by_asset_class']:
            self.accuracy_metrics['by_asset_class'][asset_class] = {
                'total': 0, 'accurate': 0, 'close': 0, 'direction_correct': 0, 'avg_score': 0, 'scores': []
            }
        ac = self.accuracy_metrics['by_asset_class'][asset_class]
        ac['total'] += 1
        if result['is_accurate']:
            ac['accurate'] += 1
        if result['is_close']:
            ac['close'] += 1
        if result['direction_correct']:
            ac['direction_correct'] += 1
        ac['scores'].append(result['accuracy_score'])
        ac['scores'] = ac['scores'][-100:]
        ac['avg_score'] = sum(ac['scores']) / len(ac['scores'])
        
        # Update by frequency band
        freq_band = result.get('freq_band', 'unknown')
        if freq_band not in self.accuracy_metrics['by_frequency_band']:
            self.accuracy_metrics['by_frequency_band'][freq_band] = {
                'total': 0, 'accurate': 0, 'direction_correct': 0, 'avg_score': 0, 'scores': []
            }
        fb = self.accuracy_metrics['by_frequency_band'][freq_band]
        fb['total'] += 1
        if result['is_accurate']:
            fb['accurate'] += 1
        if result['direction_correct']:
            fb['direction_correct'] += 1
        fb['scores'].append(result['accuracy_score'])
        fb['scores'] = fb['scores'][-100:]
        fb['avg_score'] = sum(fb['scores']) / len(fb['scores'])
        
        # Update by coherence level
        coherence_level = result.get('coherence_level', 'unknown')
        if coherence_level not in self.accuracy_metrics['by_coherence_level']:
            self.accuracy_metrics['by_coherence_level'][coherence_level] = {
                'total': 0, 'accurate': 0, 'direction_correct': 0, 'avg_score': 0, 'scores': []
            }
        cl = self.accuracy_metrics['by_coherence_level'][coherence_level]
        cl['total'] += 1
        if result['is_accurate']:
            cl['accurate'] += 1
        if result['direction_correct']:
            cl['direction_correct'] += 1
        cl['scores'].append(result['accuracy_score'])
        cl['scores'] = cl['scores'][-100:]
        cl['avg_score'] = sum(cl['scores']) / len(cl['scores'])
        
        # Update recent accuracy (rolling window)
        self.accuracy_metrics['recent_accuracy'].append({
            'timestamp': time.time(),
            'score': result['accuracy_score'],
            'accurate': result['is_accurate'],
            'direction_correct': result['direction_correct']
        })
        self.accuracy_metrics['recent_accuracy'] = self.accuracy_metrics['recent_accuracy'][-100:]
    
    def _log_validation_result(self, result: Dict):
        """Log validation result with clear formatting."""
        symbol = result['symbol']
        prediction_time = result['prediction_time_str']
        validation_time = result['validation_timestamp_str']
        
        # Determine emoji based on accuracy
        if result['is_accurate']:
            emoji = "üéØ"
            status = "BANG ON!"
        elif result['is_close']:
            emoji = "‚úÖ"
            status = "CLOSE"
        elif result['direction_correct']:
            emoji = "üìà" if result['actual_direction'] == 'up' else "üìâ"
            status = "DIRECTION OK"
        else:
            emoji = "‚ùå"
            status = "MISSED"
        
        logger.info(f"")
        logger.info(f"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        logger.info(f"{emoji} PREDICTION VALIDATED: {symbol} | {status}")
        logger.info(f"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        logger.info(f"   ‚è∞ Predicted at {prediction_time} ‚Üí Checked at {validation_time}")
        logger.info(f"   üìä Expected: ${result['expected_price']:.6f} ({result['predicted_direction']} {result['predicted_change_pct']:.2f}%)")
        logger.info(f"   üìä Actual:   ${result['actual_price']:.6f} ({result['actual_direction']} {result['actual_change_pct']:.2f}%)")
        logger.info(f"   üéØ Accuracy Score: {result['accuracy_score']:.1f}/100 | Error: {result['price_error_pct']:.3f}%")
        logger.info(f"   üìà Direction: {'‚úÖ CORRECT' if result['direction_correct'] else '‚ùå WRONG'}")
        logger.info(f"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        logger.info(f"")
    
    def get_accuracy_boost(self, exchange: str, asset_class: str, 
                          frequency: float, coherence: float) -> float:
        """
        Get accuracy-based boost for probability calculations.
        
        If predictions at this frequency/coherence level have been historically accurate,
        boost the confidence. If they've been inaccurate, reduce confidence.
        
        Returns: Multiplier (0.8 to 1.2)
        """
        boosts = []
        
        # Exchange accuracy boost
        ex = self.accuracy_metrics['by_exchange'].get(exchange, {})
        if ex.get('total', 0) >= 10:  # Need at least 10 predictions
            ex_accuracy = ex.get('avg_score', 50) / 100
            boosts.append(0.8 + (ex_accuracy * 0.4))  # 0.8 to 1.2
        
        # Asset class accuracy boost
        ac = self.accuracy_metrics['by_asset_class'].get(asset_class, {})
        if ac.get('total', 0) >= 10:
            ac_accuracy = ac.get('avg_score', 50) / 100
            boosts.append(0.8 + (ac_accuracy * 0.4))
        
        # Frequency band accuracy boost
        freq_band = self._get_freq_band(frequency)
        fb = self.accuracy_metrics['by_frequency_band'].get(freq_band, {})
        if fb.get('total', 0) >= 10:
            fb_accuracy = fb.get('avg_score', 50) / 100
            boosts.append(0.8 + (fb_accuracy * 0.4))
        
        # Coherence level accuracy boost
        coherence_level = self._get_coherence_level(coherence)
        cl = self.accuracy_metrics['by_coherence_level'].get(coherence_level, {})
        if cl.get('total', 0) >= 10:
            cl_accuracy = cl.get('avg_score', 50) / 100
            boosts.append(0.8 + (cl_accuracy * 0.4))
        
        if boosts:
            return sum(boosts) / len(boosts)
        return 1.0  # Neutral if no history
    
    def get_accuracy_summary(self) -> str:
        """Get human-readable accuracy summary."""
        m = self.accuracy_metrics
        total = m['validated']
        
        if total == 0:
            return "üîÆ No predictions validated yet - collecting data..."
        
        accurate_pct = (m['accurate'] / total) * 100
        close_pct = (m['close'] / total) * 100
        direction_pct = (m['direction_correct'] / total) * 100
        
        # Calculate recent accuracy (last 20)
        recent = m['recent_accuracy'][-20:]
        if recent:
            recent_scores = [r['score'] for r in recent]
            recent_avg = sum(recent_scores) / len(recent_scores)
            recent_accurate = sum(1 for r in recent if r['accurate'])
            recent_direction = sum(1 for r in recent if r['direction_correct'])
        else:
            recent_avg = 0
            recent_accurate = 0
            recent_direction = 0
        
        lines = [
            "",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            "üîÆ PREDICTION ACCURACY REPORT",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            f"üìä Total Predictions: {m['total_predictions']} | Validated: {total}",
            f"",
            f"üéØ OVERALL ACCURACY:",
            f"   ‚Ä¢ Bang On (‚â§0.5% error): {m['accurate']}/{total} ({accurate_pct:.1f}%)",
            f"   ‚Ä¢ Close (‚â§1% error):     {m['close']}/{total} ({close_pct:.1f}%)",
            f"   ‚Ä¢ Direction Correct:     {m['direction_correct']}/{total} ({direction_pct:.1f}%)",
            f"",
            f"üìà RECENT (Last {len(recent)} predictions):",
            f"   ‚Ä¢ Average Score: {recent_avg:.1f}/100",
            f"   ‚Ä¢ Accurate: {recent_accurate}/{len(recent)}",
            f"   ‚Ä¢ Direction OK: {recent_direction}/{len(recent)}",
        ]
        
        # By exchange breakdown
        if m['by_exchange']:
            lines.append("")
            lines.append("üìç BY EXCHANGE:")
            for ex, data in m['by_exchange'].items():
                if data['total'] > 0:
                    acc_rate = (data['accurate'] / data['total']) * 100
                    lines.append(f"   ‚Ä¢ {ex}: {data['accurate']}/{data['total']} accurate ({acc_rate:.1f}%) | Avg Score: {data['avg_score']:.1f}")
        
        # By frequency band breakdown
        if m['by_frequency_band']:
            lines.append("")
            lines.append("üéµ BY FREQUENCY BAND:")
            for band, data in sorted(m['by_frequency_band'].items()):
                if data['total'] > 0:
                    acc_rate = (data['accurate'] / data['total']) * 100
                    lines.append(f"   ‚Ä¢ {band}: {data['accurate']}/{data['total']} ({acc_rate:.1f}%) | Avg: {data['avg_score']:.1f}")
        
        # By coherence level
        if m['by_coherence_level']:
            lines.append("")
            lines.append("üåä BY COHERENCE LEVEL:")
            for level, data in m['by_coherence_level'].items():
                if data['total'] > 0:
                    acc_rate = (data['accurate'] / data['total']) * 100
                    lines.append(f"   ‚Ä¢ {level}: {data['accurate']}/{data['total']} ({acc_rate:.1f}%) | Avg: {data['avg_score']:.1f}")
        
        lines.append("")
        lines.append("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        
        return "\n".join(lines)
    
    def _get_freq_band(self, freq: float) -> str:
        """Get frequency band name with sacred frequency mapping."""
        # Check for exact sacred frequency matches first (¬±5Hz tolerance)
        sacred_freqs = {
            7.83: "7.83Hz (Schumann)",
            136.1: "136Hz (OM/Earth)",
            174: "174Hz (Foundation)",
            285: "285Hz (Healing)",
            396: "396Hz (Liberation)",
            417: "417Hz (Change)",
            432: "432Hz (Cosmic)",
            440: "440Hz (Distortion!)",
            528: "528Hz (Love)",
            639: "639Hz (Connection)",
            741: "741Hz (Awakening)",
            852: "852Hz (Spiritual)",
            963: "963Hz (Unity)",
        }
        for sacred, name in sacred_freqs.items():
            if abs(freq - sacred) <= 5:
                return name
        
        # Fall back to band classification
        if freq < 200:
            return "Sub-200Hz (Deep Earth)"
        elif freq < 300:
            return "200-299Hz (Grounding)"
        elif freq < 400:
            return "300-399Hz (Activation)"
        elif freq < 500:
            return "400-499Hz (Transition)"
        elif freq < 600:
            return "500-599Hz (Heart)"
        elif freq < 700:
            return "600-699Hz (Expression)"
        elif freq < 800:
            return "700-799Hz (Intuition)"
        elif freq < 900:
            return "800-899Hz (Insight)"
        elif freq < 1000:
            return "900-999Hz (Crown)"
        else:
            return "1000+Hz (Transcendent)"
    
    def _get_coherence_level(self, coherence: float) -> str:
        """Get coherence level name."""
        if coherence < 0.3:
            return "Low (<0.3)"
        elif coherence < 0.5:
            return "Medium (0.3-0.5)"
        elif coherence < 0.7:
            return "Good (0.5-0.7)"
        elif coherence < 0.85:
            return "High (0.7-0.85)"
        else:
            return "Excellent (0.85+)"
    
    def get_pending_count(self) -> int:
        """Get number of predictions awaiting validation."""
        return len(self.pending_predictions)
    
    def get_validated_count(self) -> int:
        """Get total validated predictions."""
        return self.accuracy_metrics['validated']


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üåê MULTI-EXCHANGE ORCHESTRATOR - Unified Cross-Exchange Intelligence
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class MultiExchangeOrchestrator:
    """
    üåê MULTI-EXCHANGE ORCHESTRATOR
    
    Central nervous system for cross-exchange trading:
    - Unified opportunity scanning across Binance, Kraken, Capital.com, Alpaca
    - Cross-exchange learning: wins/losses inform all exchange decisions
    - Smart order routing to best execution venue
    - Arbitrage detection and execution
    - Coordinated position management
    
    ALL SYSTEMS TALK TO EACH OTHER through this orchestrator.
    """
    
    def __init__(self, multi_client):
        self.client = multi_client
        
        # Exchange-specific configuration
        self.exchange_config = {
            'binance': {
                'enabled': True,
                # ü§ë GREEDY HOE: ALL THE BINANCE PAIRS!
                'quote_currencies': ['USDC', 'USDT', 'BTC', 'ETH', 'BNB', 'FDUSD', 'EUR', 'GBP', 'TUSD'],
                'fee_rate': 0.001,
                'max_positions': 15,  # üî• BEAST MODE: 15 positions per exchange!
                'min_trade_usd': 10.0,
                'asset_class': 'crypto'
            },
            'kraken': {
                'enabled': True,  # ‚úÖ ENABLED - Trading on Kraken with GBP
                # ü§ë GREEDY HOE: ALL THE KRAKEN PAIRS!
                'quote_currencies': ['USD', 'EUR', 'GBP', 'USDT', 'USDC', 'BTC', 'ETH', 'AUD', 'CAD'],
                'fee_rate': 0.0026,
                'max_positions': 15,  # üî• BEAST MODE: 15 positions per exchange!
                'min_trade_usd': 5.0,
                'asset_class': 'crypto'
            },
            'capital': {
                'enabled': True,
                'quote_currencies': ['USD', 'GBP'],
                'fee_rate': 0.001,
                'max_positions': 10,  # üî• BEAST MODE: 10 CFD positions!
                'min_trade_usd': 10.0,
                'asset_class': 'cfd'  # forex, indices, commodities
            },
            'alpaca': {
                'enabled': CONFIG.get('ALPACA_ANALYTICS_ONLY', True) == False,  # Trading disabled by default
                'quote_currencies': ['USD'],
                'fee_rate': 0.0025,
                'max_positions': 10,  # üî• BEAST MODE: 10 stock positions!
                'min_trade_usd': 1.0,  # Fractional shares
                'asset_class': 'stocks'
            }
        }
        
        # Cross-exchange learning metrics
        self.learning_metrics = {
            'total_trades': 0,
            'wins': 0,
            'losses': 0,
            'total_pnl': 0.0,
            'by_exchange': {},
            'by_asset_class': {},
            'by_frequency_band': {},
            'cross_correlations': {}
        }
        
        # Unified ticker cache (all exchanges)
        self.unified_ticker_cache: Dict[str, Dict] = {}
        self.last_unified_scan = 0
        self.scan_interval = 10  # seconds
        
        # Cross-exchange signals
        self.cross_signals: List[Dict] = []
        self.signal_history: List[Dict] = []
        
        logger.info("üåê MultiExchangeOrchestrator initialized - All systems connected")

    def get_learning_metrics(self) -> Dict[str, Any]:
        """Expose cross-exchange learning metrics (wins, pnl, by exchange/class)."""
        return self.learning_metrics
        
    def get_enabled_exchanges(self) -> List[str]:
        """Get list of enabled exchanges."""
        return [ex for ex, cfg in self.exchange_config.items() if cfg['enabled']]
        
    def scan_all_exchanges(self) -> Dict[str, List[Dict]]:
        """
        Scan all enabled exchanges for opportunities.
        Returns opportunities organized by exchange.
        """
        all_opportunities = {}
        
        for exchange in self.get_enabled_exchanges():
            try:
                opps = self._scan_exchange(exchange)
                all_opportunities[exchange] = opps
                logger.debug(f"üîç {exchange}: Found {len(opps)} opportunities")
            except Exception as e:
                logger.error(f"‚ùå {exchange} scan error: {e}")
                all_opportunities[exchange] = []
                
        # Update unified cache
        self.last_unified_scan = time.time()
        return all_opportunities
        
    def _scan_exchange(self, exchange: str) -> List[Dict]:
        """Scan a single exchange for opportunities."""
        opportunities = []
        cfg = self.exchange_config.get(exchange, {})
        
        try:
            # Get tickers from the exchange client
            if hasattr(self.client, 'clients') and exchange in self.client.clients:
                client = self.client.clients[exchange]
                tickers = self._get_exchange_tickers(exchange, client, cfg)
                
                for symbol, ticker in tickers.items():
                    opp = self._evaluate_opportunity(exchange, symbol, ticker, cfg)
                    if opp:
                        opportunities.append(opp)
                        
        except Exception as e:
            logger.error(f"Scan error for {exchange}: {e}")
            
        # Sort by score
        opportunities.sort(key=lambda x: -x.get('score', 0))
        # üî• UNLEASHED: Return top 100 per exchange instead of 20!
        return opportunities[:100]  # Top 100 per exchange - TRADE EVERYTHING!
        
    def _get_exchange_tickers(self, exchange: str, client, cfg: Dict) -> Dict[str, Dict]:
        """Get tickers from an exchange."""
        tickers = {}
        quote_currencies = cfg.get('quote_currencies', ['USD'])
        
        try:
            if exchange == 'binance':
                raw = client.client.session.get(f"{client.client.base}/api/v3/ticker/24hr", timeout=10).json()
                for t in raw:
                    sym = t['symbol']
                    for q in quote_currencies:
                        if sym.endswith(q):
                            tickers[sym] = {
                                'price': float(t['lastPrice']),
                                'change': float(t['priceChangePercent']),
                                'volume': float(t['quoteVolume']),
                                'high': float(t['highPrice']),
                                'low': float(t['lowPrice']),
                                'exchange': 'binance',
                                'quote': q,
                            }
                            break
                            
            elif exchange == 'kraken':
                # Use existing Kraken ticker logic
                tickers = self._get_kraken_tickers(client, quote_currencies)
                
            elif exchange == 'capital':
                # CFD markets - simplified
                tickers = self._get_capital_tickers(client)
                
        except Exception as e:
            logger.error(f"Ticker fetch error for {exchange}: {e}")
            
        return tickers
        
    def _get_kraken_tickers(self, client, quote_currencies: List[str]) -> Dict[str, Dict]:
        """Get Kraken tickers."""
        tickers = {}
        try:
            if hasattr(client.client, 'get_24h_tickers'):
                raw_tickers = client.client.get_24h_tickers()
                for t in raw_tickers:
                    sym = t.get('symbol', '')
                    for q in quote_currencies:
                        if sym.endswith(q):
                            tickers[sym] = {
                                'price': float(t.get('price', 0)),
                                'change': float(t.get('change24h', 0)),
                                'volume': float(t.get('volume', 0)),
                                'high': float(t.get('high', t.get('price', 0))),
                                'low': float(t.get('low', t.get('price', 0))),
                                'exchange': 'kraken',
                                'quote': q,
                            }
                            break
        except Exception as e:
            logger.debug(f"Kraken ticker error: {e}")
        return tickers
        
    def _get_capital_tickers(self, client) -> Dict[str, Dict]:
        """Get Capital.com CFD tickers."""
        tickers = {}
        # Capital markets to scan
        markets = ['EURUSD', 'GBPUSD', 'GOLD', 'US500', 'UK100', 'OIL_CRUDE']
        
        try:
            for market in markets:
                # Simplified - actual implementation would use Capital API
                tickers[market] = {
                    'price': 0,  # Would be fetched from API
                    'change': 0,
                    'volume': 1000000,
                    'exchange': 'capital',
                    'quote': 'USD',
                    'asset_class': self._get_asset_class(market)
                }
        except Exception as e:
            logger.debug(f"Capital ticker error: {e}")
        return tickers
        
    def _get_asset_class(self, symbol: str) -> str:
        """Determine asset class from symbol."""
        sym = symbol.upper()
        if any(fx in sym for fx in ['USD', 'EUR', 'GBP', 'JPY', 'CHF']):
            if len(sym) <= 8:
                return 'forex'
        if any(idx in sym for idx in ['US500', 'US100', 'UK100', 'DE40']):
            return 'indices'
        if any(com in sym for com in ['GOLD', 'SILVER', 'OIL', 'NATGAS']):
            return 'commodities'
        return 'crypto'
        
    def _evaluate_opportunity(self, exchange: str, symbol: str, ticker: Dict, cfg: Dict) -> Optional[Dict]:
        """
        Evaluate a single opportunity.
        
        ü™ô PENNY PROFIT MODE: All gates are now ADVISORY only.
        The penny profit math (exact fee calculation) is the TRUE gate.
        We log warnings but don't block entries.
        """
        price = ticker.get('price', 0)
        change = ticker.get('change', 0)
        volume = ticker.get('volume', 0)
        
        if price <= 0:
            return None  # Can't trade without a price
            
        # Calculate coherence
        asset_class = ticker.get('asset_class', cfg.get('asset_class', 'crypto'))
        coherence = self._calculate_coherence(change, volume, ticker, asset_class)
        
        # ü™ô PENNY MODE: Coherence is advisory, only reject broken data
        if coherence < 0.05:
            logger.debug(f"  ‚ö†Ô∏è {symbol}: Coherence {coherence:.2f} too low (data error)")
            return None
            
        # Calculate frequency (advisory only)
        freq = max(256, min(963, 432 * ((1 + change/100) ** PHI)))
        in_avoid = 435 <= freq <= 445  # 440Hz distortion zone
        
        # ü™ô PENNY MODE: Frequency is advisory only, don't block
        if in_avoid:
            logger.debug(f"  ‚ö†Ô∏è {symbol}: Frequency {freq:.1f}Hz in distortion zone (advisory)")
            
        # Calculate probability
        probability = self._calculate_probability(coherence, change, freq, asset_class)
        
        # ü™ô PENNY MODE: Probability is advisory, very low threshold
        if probability < 0.15:  # Only skip truly hopeless signals
            logger.debug(f"  ‚ö†Ô∏è {symbol}: Probability {probability:.2f} below floor (advisory)")
            return None
            
        # Calculate score
        score = self._calculate_score(probability, coherence, volume, freq, change)
        
        # Apply cross-exchange learning boost
        score = self._apply_learning_boost(score, exchange, asset_class, freq)
        
        return {
            'exchange': exchange,
            'symbol': symbol,
            'price': price,
            'change': change,
            'volume': volume,
            'coherence': coherence,
            'frequency': freq,
            'probability': probability,
            'score': score,
            'asset_class': asset_class,
            'quote': ticker.get('quote', 'USD'),
            'timestamp': time.time()
        }
        
    def _calculate_coherence(self, change: float, volume: float, ticker: Dict, asset_class: str) -> float:
        """Calculate coherence with asset-class awareness."""
        high = ticker.get('high', ticker.get('price', 1))
        low = ticker.get('low', ticker.get('price', 1))
        price = ticker.get('price', 1)
        
        volatility = ((high - low) / low * 100) if low > 0 else 0
        
        if asset_class == 'forex':
            S = min(1.0, volume / 50.0)
            O = min(1.0, abs(change) / 0.3)
            E = min(1.0, volatility / 0.5)
            Lambda = (S + O + E) / 3.0
            return 1 / (1 + math.exp(-6 * (Lambda - 0.35)))
        elif asset_class == 'indices':
            S = min(1.0, volume / 50.0)
            O = min(1.0, abs(change) / 1.0)
            E = min(1.0, volatility / 2.0)
            Lambda = (S + O + E) / 3.0
            return 1 / (1 + math.exp(-6 * (Lambda - 0.35)))
        else:  # crypto
            S = min(1.0, volume / 50000.0)
            O = min(1.0, abs(change) / 15.0)
            E = min(1.0, volatility / 25.0)
            Lambda = (S + O + E) / 3.0
            return 1 / (1 + math.exp(-5 * (Lambda - 0.5)))
            
    def _calculate_probability(self, coherence: float, change: float, freq: float, asset_class: str) -> float:
        """Calculate trade probability with news/knowledge correlation."""
        base_prob = 0.50 + coherence * 0.30
        
        # Momentum adjustment
        if change > 0:
            base_prob += min(0.10, change / 50)
        else:
            base_prob -= min(0.05, abs(change) / 100)
            
        # Frequency adjustment - based on prediction accuracy data + sacred frequencies
        freq_modifier = self._get_sacred_frequency_modifier(freq)
        base_prob *= freq_modifier
        
        # üì∞ NEWS SENTIMENT MODIFIER - Learn from correlation data
        try:
            news_sentiment = getattr(self, '_last_news_sentiment', {})
            news_label = news_sentiment.get('label', 'neutral')
            news_confidence = news_sentiment.get('confidence', 0.0)
            
            # Get learned correlations from Adaptive Learner
            news_insights = ADAPTIVE_LEARNER.get_news_correlation_insights()
            
            if news_label == 'bullish' and news_confidence >= 0.5:
                # Boost probability in bullish news environments (if historically good)
                bullish_win_rate = news_insights.get('bullish', {}).get('win_rate', 0.5)
                if bullish_win_rate > 0.55:  # Only boost if bullish news historically good
                    news_boost = min(0.08, (bullish_win_rate - 0.5) * 0.4 * news_confidence)
                    base_prob += news_boost
            elif news_label == 'bearish' and news_confidence >= 0.5:
                # Reduce probability in bearish news (if historically bad)
                bearish_win_rate = news_insights.get('bearish', {}).get('win_rate', 0.5)
                if bearish_win_rate < 0.45:  # Only reduce if bearish news historically bad
                    news_penalty = min(0.08, (0.5 - bearish_win_rate) * 0.4 * news_confidence)
                    base_prob -= news_penalty
        except Exception:
            pass  # News correlation not critical
        
        # üìö KNOWLEDGE MODIFIER - Boost based on knowledge discovery performance
        try:
            knowledge_modifier = ADAPTIVE_LEARNER.get_knowledge_probability_modifier()
            base_prob *= knowledge_modifier  # Typically 0.97-1.03
        except Exception:
            pass  # Knowledge correlation not critical
            
        return max(0.0, min(CONFIG.get('PROB_CAP', 0.83), base_prob))
    
    def _get_sacred_frequency_modifier(self, freq: float) -> float:
        """
        üéµ SACRED FREQUENCY MODIFIER üéµ
        
        Maps market frequencies to sacred healing tones and returns
        appropriate probability modifiers based on harmonic resonance.
        
        SOLFEGGIO SCALE (Ancient healing frequencies):
        - 174 Hz: Foundation, pain relief
        - 285 Hz: Healing, tissue regeneration
        - 396 Hz: Liberation from fear/guilt (UT)
        - 417 Hz: Undoing situations, facilitating change (RE)
        - 528 Hz: Love frequency, DNA repair (MI) ‚≠ê OPTIMAL GREEN BORAX
        - 639 Hz: Connection, relationships (FA)
        - 741 Hz: Awakening intuition (SOL)
        - 852 Hz: Returning to spiritual order (LA)
        - 963 Hz: Unity, awakening (SI)
        
        EARTH FREQUENCIES:
        - 7.83 Hz: Schumann Resonance (Earth's heartbeat)
        - 136.1 Hz: OM frequency (Earth's year)
        - 432 Hz: Universal tuning (cosmic harmony)
        
        DISTORTION:
        - 440 Hz: Artificial concert pitch (dissonance)
        """
        # üü¢ Check SACRED SOLFEGGIO frequencies FIRST! 
        # 528Hz GREEN LOVE must be prioritized over Schumann harmonics!
        sacred_map = {
            (523, 533): CONFIG.get('FREQUENCY_BOOST_528HZ', 1.35),   # 528 Hz Love ‚≠ê GREEN BORAX
            (391, 401): CONFIG.get('FREQUENCY_BOOST_396HZ', 1.40),   # 396 Hz Liberation
            (427, 437): CONFIG.get('FREQUENCY_BOOST_432HZ', 1.30),   # 432 Hz Cosmic
            (169, 179): CONFIG.get('FREQUENCY_BOOST_174HZ', 1.20),   # 174 Hz Foundation
            (280, 290): CONFIG.get('FREQUENCY_BOOST_285HZ', 1.25),   # 285 Hz Healing
            (412, 422): CONFIG.get('FREQUENCY_BOOST_417HZ', 1.30),   # 417 Hz Change
            (435, 445): CONFIG.get('FREQUENCY_SUPPRESS_440HZ', 0.70),# 440 Hz Distortion!
            (634, 644): CONFIG.get('FREQUENCY_BOOST_639HZ', 1.25),   # 639 Hz Connection
            (736, 746): CONFIG.get('FREQUENCY_BOOST_741HZ', 1.15),   # 741 Hz Awakening
            (847, 857): CONFIG.get('FREQUENCY_BOOST_852HZ', 1.20),   # 852 Hz Spiritual
            (958, 968): CONFIG.get('FREQUENCY_SUPPRESS_963HZ', 0.60),# 963 Hz (poor data)
            (131, 141): CONFIG.get('FREQUENCY_BOOST_136HZ', 1.25),   # 136 Hz OM
        }
        
        for (low, high), modifier in sacred_map.items():
            if low <= freq <= high:
                return modifier
        
        # Check Schumann harmonics AFTER sacred frequencies (7.83Hz √ó n)
        schumann_base = 7.83
        for harmonic in range(1, 128):  # Up to 128th harmonic (~1000Hz)
            schumann_freq = schumann_base * harmonic
            if abs(freq - schumann_freq) <= 3:
                return CONFIG.get('FREQUENCY_BOOST_SCHUMANN', 1.45)
        
        # Band-based fallback
        if 300 <= freq <= 399:
            return CONFIG.get('FREQUENCY_BOOST_300HZ', 1.50)  # 98.8% accuracy!
        elif 600 <= freq <= 699:
            return CONFIG.get('FREQUENCY_SUPPRESS_600HZ', 0.75)  # 0% accuracy
        elif freq >= 1000:
            return CONFIG.get('FREQUENCY_SUPPRESS_HIGH_CHAOS', 0.50)
        
        # Neutral baseline for unclassified frequencies
        return CONFIG.get('FREQUENCY_NEUTRAL_BASELINE', 1.0)
        
    def _calculate_score(self, prob: float, coherence: float, volume: float, freq: float, change: float) -> float:
        """Calculate opportunity score."""
        base = prob * coherence * (1 + math.log10(max(1, volume/10000)))
        
        # Frequency bonus
        in_optimal = 520 <= freq <= 963
        freq_bonus = 1.0 if in_optimal else 0.5
        
        return base * (1 + freq_bonus)
        
    def _apply_learning_boost(self, score: float, exchange: str, asset_class: str, freq: float) -> float:
        """Apply cross-exchange learning boost to score."""
        boost = 1.0
        
        # Exchange performance boost
        ex_metrics = self.learning_metrics.get('by_exchange', {}).get(exchange, {})
        if ex_metrics.get('total_trades', 0) >= 10:
            ex_win_rate = ex_metrics.get('wins', 0) / max(1, ex_metrics.get('total_trades', 1))
            if ex_win_rate > 0.55:
                boost *= 1.0 + (ex_win_rate - 0.50) * 0.5
            elif ex_win_rate < 0.45:
                boost *= 0.8
                
        # Asset class performance boost
        ac_metrics = self.learning_metrics.get('by_asset_class', {}).get(asset_class, {})
        if ac_metrics.get('total_trades', 0) >= 10:
            ac_win_rate = ac_metrics.get('wins', 0) / max(1, ac_metrics.get('total_trades', 1))
            if ac_win_rate > 0.55:
                boost *= 1.0 + (ac_win_rate - 0.50) * 0.3
                
        return score * boost
        
    def record_trade_result(self, exchange: str, symbol: str, pnl: float, 
                           asset_class: str, frequency: float, coherence: float):
        """
        Record trade result for cross-exchange learning.
        ALL SYSTEMS LEARN FROM THIS.
        """
        is_win = pnl > 0
        
        # Update global metrics
        self.learning_metrics['total_trades'] += 1
        if is_win:
            self.learning_metrics['wins'] += 1
        else:
            self.learning_metrics['losses'] += 1
        self.learning_metrics['total_pnl'] += pnl
        
        # Update by exchange
        if exchange not in self.learning_metrics['by_exchange']:
            self.learning_metrics['by_exchange'][exchange] = {'total_trades': 0, 'wins': 0, 'losses': 0, 'pnl': 0}
        self.learning_metrics['by_exchange'][exchange]['total_trades'] += 1
        if is_win:
            self.learning_metrics['by_exchange'][exchange]['wins'] += 1
        else:
            self.learning_metrics['by_exchange'][exchange]['losses'] += 1
        self.learning_metrics['by_exchange'][exchange]['pnl'] += pnl
        
        # Update by asset class
        if asset_class not in self.learning_metrics['by_asset_class']:
            self.learning_metrics['by_asset_class'][asset_class] = {'total_trades': 0, 'wins': 0, 'losses': 0, 'pnl': 0}
        self.learning_metrics['by_asset_class'][asset_class]['total_trades'] += 1
        if is_win:
            self.learning_metrics['by_asset_class'][asset_class]['wins'] += 1
        else:
            self.learning_metrics['by_asset_class'][asset_class]['losses'] += 1
        self.learning_metrics['by_asset_class'][asset_class]['pnl'] += pnl
        
        # Update by frequency band
        freq_band = self._get_freq_band(frequency)
        if freq_band not in self.learning_metrics['by_frequency_band']:
            self.learning_metrics['by_frequency_band'][freq_band] = {'total_trades': 0, 'wins': 0, 'losses': 0, 'pnl': 0}
        self.learning_metrics['by_frequency_band'][freq_band]['total_trades'] += 1
        if is_win:
            self.learning_metrics['by_frequency_band'][freq_band]['wins'] += 1
        else:
            self.learning_metrics['by_frequency_band'][freq_band]['losses'] += 1
        self.learning_metrics['by_frequency_band'][freq_band]['pnl'] += pnl
        
        # Log cross-exchange insight
        total = self.learning_metrics['total_trades']
        wins = self.learning_metrics['wins']
        wr = wins / max(1, total) * 100
        logger.info(f"üåê Cross-Exchange Learning: {total} trades, {wr:.1f}% WR, ${self.learning_metrics['total_pnl']:.2f} PnL")
        
    def _get_freq_band(self, freq: float) -> str:
        """Get frequency band name."""
        if freq < 400:
            return 'LOW (<400Hz)'
        elif 400 <= freq < 500:
            return 'MID (400-500Hz)'
        elif 500 <= freq < 600:
            return 'SOLFEGGIO (500-600Hz)'
        elif 600 <= freq < 800:
            return 'HIGH (600-800Hz)'
        else:
            return 'ULTRA (>800Hz)'
            
    def get_best_opportunity(self) -> Optional[Dict]:
        """Get the single best opportunity across all exchanges."""
        all_opps = self.scan_all_exchanges()
        
        # Flatten and sort
        combined = []
        for exchange, opps in all_opps.items():
            combined.extend(opps)
            
        if not combined:
            return None
            
        combined.sort(key=lambda x: -x.get('score', 0))
        return combined[0]
        
    def get_learning_summary(self) -> str:
        """Get formatted learning summary."""
        m = self.learning_metrics
        lines = [
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            "üåê MULTI-EXCHANGE LEARNING SUMMARY",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            f"Total Trades: {m['total_trades']} | Wins: {m['wins']} | WR: {m['wins']/max(1,m['total_trades'])*100:.1f}%",
            f"Total PnL: ${m['total_pnl']:.2f}",
            "",
            "By Exchange:"
        ]
        
        for ex, metrics in m.get('by_exchange', {}).items():
            wr = metrics['wins'] / max(1, metrics['total_trades']) * 100
            lines.append(f"  {ex}: {metrics['total_trades']} trades, {wr:.1f}% WR, ${metrics['pnl']:.2f}")
            
        lines.append("")
        lines.append("By Asset Class:")
        for ac, metrics in m.get('by_asset_class', {}).items():
            wr = metrics['wins'] / max(1, metrics['total_trades']) * 100
            lines.append(f"  {ac}: {metrics['total_trades']} trades, {wr:.1f}% WR, ${metrics['pnl']:.2f}")
            
        lines.append("")
        lines.append("By Frequency Band:")
        for fb, metrics in m.get('by_frequency_band', {}).items():
            wr = metrics['wins'] / max(1, metrics['total_trades']) * 100
            lines.append(f"  {fb}: {metrics['total_trades']} trades, {wr:.1f}% WR")
            
        return "\n".join(lines)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä UNIFIED STATE AGGREGATOR - All JSON Feeds Into Ecosystem
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class UnifiedStateAggregator:
    """
    üìä UNIFIED STATE AGGREGATOR
    
    Consolidates ALL JSON data sources and feeds them into the main ecosystem:
    
    Data Sources:
    ‚îú‚îÄ aureon_kraken_state.json       - Main trading state (positions, balance, stats)
    ‚îú‚îÄ elephant_ultimate.json         - Symbol memory (hunts, wins, blacklist)
    ‚îú‚îÄ elephant_unified.json          - Unified elephant memory
    ‚îú‚îÄ adaptive_learning_history.json - Learning engine data
    ‚îú‚îÄ calibration_trades.json        - Calibration trade history
    ‚îú‚îÄ hnc_frequency_log.json         - HNC frequency readings
    ‚îú‚îÄ auris_runtime.json             - Auris configuration & targets
    ‚îî‚îÄ /tmp/aureon_trade_logs/*.jsonl - Trade logs for analysis
    
    ALL SYSTEMS FEED THE ECOSYSTEM through this aggregator.
    """
    
    # JSON file paths
    STATE_FILES = {
        'main_state': 'aureon_kraken_state.json',
        'elephant_ultimate': 'elephant_ultimate.json',
        'elephant_unified': 'elephant_unified.json',
        'elephant_live': 'elephant_live.json',
        'adaptive_learning': 'adaptive_learning_history.json',
        'calibration': 'calibration_trades.json',
        'hnc_frequency': 'hnc_frequency_log.json',
        'auris_runtime': 'auris_runtime.json',
        'multi_exchange_learning': 'multi_exchange_learning.json',
    }
    
    # JSONL logs
    LOG_FILES = {
        'thoughts': 'logs/aureon_thoughts.jsonl',
    }

    PROBABILITY_REPORTS = [
        'probability_all_markets_report.json',
        'probability_all_exchanges_report.json',
        'probability_kraken_report.json',
        'probability_full_market_report.json',
        'probability_batch_report.json',
        'probability_data.json',
        'probability_combined_report.json',
        'probability_4_exchanges_report.json',
        'probability_training_report.json',
    ]

    EXTRA_TRADE_HISTORY = [
        'paper_trade_history.json',  # Paper trade log
    ]

    ANALYTICS_REPORTS = [
        'multi_agent_results.json',
        'multi_agent_aggressive_results.json',
        'kelly_montecarlo_results.json',
        'montecarlo_results.json',
        'aureon_baseline_results.json',
        'hive_baseline.json',
        'harmonic_wave_data.json',
    ]

    POSITION_FILES = [
        'positions.json',
        'piano_positions.json',
    ]

    AUX_LOG_FILES = [
        'rejection_log.json',
        'smoke_test_results.json',
        'prediction_test_result.json',
    ]
    
    def __init__(self):
        self.aggregated_state = {
            'last_aggregation': 0,
            'sources_loaded': [],
            'total_historical_trades': 0,
            'combined_win_rate': 0.0,
            'symbol_insights': {},
            'probability_insights': {},
            'analytics_insights': {},
            'positions_snapshot': {},
            'aux_logs': {},
            'frequency_performance': {},
            'exchange_performance': {},
            'coherence_bands': {},
            'organism_health': {
                'status': 'UNKNOWN',
                'pulse': {},
                'recent_thoughts': []
            },
        }
        self.load_all_sources()
        
    def load_all_sources(self) -> Dict[str, Any]:
        """Load and aggregate data from all JSON sources."""
        self.aggregated_state['sources_loaded'] = []
        self.load_organism_thoughts()  # Load thoughts first
        all_trades = []
        symbol_data = {}
        frequency_data = {}
        probability_insights: Dict[str, Dict[str, Any]] = {}
        probability_freshness: Dict[str, Any] = {
            'report_ages_minutes': {},
            'newest_minutes': None,
            'oldest_minutes': None,
            'stale': False,
            'threshold_minutes': 120,
        }
        high_conviction: List[Dict[str, Any]] = []
        analytics_insights: Dict[str, Dict[str, Any]] = {}
        positions_snapshot: Dict[str, Any] = {}
        aux_logs: Dict[str, Any] = {}
        position_hygiene: Dict[str, Any] = {
            'flagged': [],
            'rules': {
                'max_cycles': 50,
                'min_momentum': -2.0,
            }
        }

        def _extract_pnl(trade: Dict[str, Any]) -> float:
            pnl = trade.get('pnl_usd')
            if pnl is None:
                pnl = trade.get('pnl')
            if pnl is None:
                return 0.0
            try:
                return float(pnl)
            except (TypeError, ValueError):
                return 0.0
        
        # 1. Load Main Trading State
        main_state = self._load_json(self.STATE_FILES['main_state'])
        if main_state:
            self.aggregated_state['sources_loaded'].append('main_state')
            self.aggregated_state['current_balance'] = main_state.get('balance', 0)
            self.aggregated_state['peak_balance'] = main_state.get('peak_balance', 0)
            self.aggregated_state['total_trades'] = main_state.get('total_trades', 0)
            self.aggregated_state['wins'] = main_state.get('wins', 0)
            self.aggregated_state['losses'] = main_state.get('losses', 0)
            self.aggregated_state['max_drawdown'] = main_state.get('max_drawdown', 0)
            
            # üéØ TRUE STARTING BALANCE - shared across all subsystems!
            self.aggregated_state['first_start_balance'] = main_state.get('first_start_balance', main_state.get('initial_balance', 0))
            self.aggregated_state['first_start_time'] = main_state.get('first_start_time', 0)
            self.aggregated_state['initial_balance'] = main_state.get('initial_balance', 0)

            # Position hygiene pass: flag long-running or losing positions
            positions = main_state.get('positions', {}) or {}
            for sym, pos in positions.items():
                try:
                    cycles = pos.get('cycles', 0)
                    momentum = pos.get('momentum', 0.0)
                    if cycles >= position_hygiene['rules']['max_cycles'] or momentum <= position_hygiene['rules']['min_momentum']:
                        position_hygiene['flagged'].append({
                            'symbol': sym,
                            'cycles': cycles,
                            'momentum': momentum,
                            'entry_price': pos.get('entry_price'),
                            'coherence': pos.get('coherence'),
                            'dominant_node': pos.get('dominant_node'),
                        })
                except Exception:
                    continue
            
        # 2. Load Elephant Memory files (symbol-level insights)
        for elephant_key in ['elephant_ultimate', 'elephant_unified', 'elephant_live']:
            elephant_data = self._load_json(self.STATE_FILES.get(elephant_key, ''))
            if elephant_data:
                self.aggregated_state['sources_loaded'].append(elephant_key)
                for symbol, data in elephant_data.items():
                    if symbol not in symbol_data:
                        symbol_data[symbol] = {
                            'total_hunts': 0, 'total_trades': 0, 'wins': 0, 
                            'losses': 0, 'profit': 0, 'blacklisted': False
                        }
                    symbol_data[symbol]['total_hunts'] += data.get('hunts', 0)
                    symbol_data[symbol]['total_trades'] += data.get('trades', 0)
                    symbol_data[symbol]['wins'] += data.get('wins', 0)
                    symbol_data[symbol]['losses'] += data.get('losses', 0)
                    symbol_data[symbol]['profit'] += data.get('profit', 0)
                    if data.get('blacklisted', False):
                        symbol_data[symbol]['blacklisted'] = True
                        
        self.aggregated_state['symbol_insights'] = symbol_data
        
        # 3. Load Calibration Trades (detailed trade history)
        calibration = self._load_json(self.STATE_FILES['calibration'])
        if calibration and isinstance(calibration, list):
            self.aggregated_state['sources_loaded'].append('calibration')
            all_trades.extend(calibration)
            
            # Extract frequency performance from calibration
            for trade in calibration:
                freq = trade.get('frequency', 0)
                freq_band = self._get_freq_band(freq)
                if freq_band not in frequency_data:
                    frequency_data[freq_band] = {'trades': 0, 'wins': 0, 'pnl': 0}
                frequency_data[freq_band]['trades'] += 1
                trade_pnl = _extract_pnl(trade)
                if trade_pnl > 0:
                    frequency_data[freq_band]['wins'] += 1
                frequency_data[freq_band]['pnl'] += trade_pnl
                
        self.aggregated_state['frequency_performance'] = frequency_data

        # 3b. Load extra trade history files (paper trading, etc.)
        for hist_file in self.EXTRA_TRADE_HISTORY:
            hist = self._load_json(hist_file)
            if hist and isinstance(hist, list):
                self.aggregated_state['sources_loaded'].append(f"history:{hist_file}")
                all_trades.extend(hist)
        
        # 4. Load HNC Frequency Log (frequency readings over time)
        hnc_log = self._load_json(self.STATE_FILES['hnc_frequency'])
        if hnc_log and isinstance(hnc_log, list):
            self.aggregated_state['sources_loaded'].append('hnc_frequency')
            # Get latest readings for each symbol
            latest_readings = {}
            for entry in hnc_log[-100:]:  # Last 100 entries
                for reading in entry.get('readings', []):
                    symbol = reading.get('symbol', '')
                    if symbol:
                        latest_readings[symbol] = {
                            'frequency': reading.get('frequency', 256),
                            'resonance': reading.get('resonance', 0.5),
                            'is_harmonic': reading.get('is_harmonic', False)
                        }
            self.aggregated_state['hnc_readings'] = latest_readings
            
        # 5. Load Adaptive Learning History
        adaptive = self._load_json(self.STATE_FILES['adaptive_learning'])
        if adaptive:
            self.aggregated_state['sources_loaded'].append('adaptive_learning')
            self.aggregated_state['learned_thresholds'] = adaptive.get('thresholds', {})
            adaptive_trades = adaptive.get('trades', [])
            all_trades.extend(adaptive_trades)
            
        # 6. Load Auris Runtime Config
        auris_config = self._load_json(self.STATE_FILES['auris_runtime'])
        if auris_config:
            self.aggregated_state['sources_loaded'].append('auris_runtime')
            self.aggregated_state['auris_targets'] = auris_config.get('targets_hz', {})
            self.aggregated_state['auris_identity'] = auris_config.get('identity', {})
            
        # 7. Load Multi-Exchange Learning (if exists)
        multi_ex = self._load_json(self.STATE_FILES['multi_exchange_learning'])
        if multi_ex:
            self.aggregated_state['sources_loaded'].append('multi_exchange_learning')
            self.aggregated_state['exchange_performance'] = multi_ex.get('by_exchange', {})

        # 7b. Load probability reports (market selection intelligence)
        for report in self.PROBABILITY_REPORTS:
            data = self._load_json(report)
            if not data:
                continue
            self.aggregated_state['sources_loaded'].append(f"probability:{report}")

            # Freshness tracking
            generated_ts = data.get('generated') or data.get('generated_at') if isinstance(data, dict) else None
            if generated_ts:
                try:
                    gen_dt = datetime.fromisoformat(generated_ts)
                    age_min = (datetime.now() - gen_dt).total_seconds() / 60
                    probability_freshness['report_ages_minutes'][report] = age_min
                except Exception:
                    pass

            entries = []
            for key in ('top_bullish', 'top_bearish', 'data', 'signals', 'items', 'predictions', 'data_points'):
                if isinstance(data, list) and key == 'data':
                    entries.extend(data)
                if isinstance(data.get(key, None), list):
                    entries.extend(data[key])
            if isinstance(data, list):
                entries.extend(data)

            for item in entries:
                if not isinstance(item, dict):
                    continue
                sym = item.get('symbol') or item.get('pair')
                if not sym:
                    continue
                try:
                    prob = float(item.get('probability', item.get('prob', 0)))
                except Exception:
                    prob = 0.0
                change = item.get('24h_change') or item.get('change') or item.get('pct_change') or 0
                state = item.get('state') or item.get('direction') or item.get('trend')

                current = probability_insights.get(sym, {})
                if not current or prob > current.get('probability', -1):
                    probability_insights[sym] = {
                        'probability': prob,
                        'state': state,
                        'change': change,
                        'source': report
                    }

                # Capture high-conviction signals for watchlist seeding
                confidence = item.get('confidence', item.get('conf', 0)) or 0.0
                if prob >= 0.80 and confidence >= 0.80:
                    high_conviction.append({
                        'symbol': sym,
                        'probability': prob,
                        'confidence': confidence,
                        'change': change,
                        'state': state,
                        'source': report,
                        'exchange': item.get('exchange'),
                    })
            
        # 8. Scan trade logs directory
        trade_logs = self._scan_trade_logs()
        if trade_logs:
            self.aggregated_state['sources_loaded'].append('trade_logs')
            all_trades.extend(trade_logs)

        # Save probability insights
        if probability_insights:
            self.aggregated_state['probability_insights'] = probability_insights

        # Probability freshness summary
        if probability_freshness['report_ages_minutes']:
            ages = list(probability_freshness['report_ages_minutes'].values())
            probability_freshness['newest_minutes'] = min(ages)
            probability_freshness['oldest_minutes'] = max(ages)
            probability_freshness['stale'] = probability_freshness['newest_minutes'] > probability_freshness['threshold_minutes']
            self.aggregated_state['probability_freshness'] = probability_freshness

        if high_conviction:
            self.aggregated_state['high_conviction_signals'] = high_conviction

        # 9. Load analytics reports (performance/forecast artifacts)
        for report in self.ANALYTICS_REPORTS:
            data = self._load_json(report)
            if not data:
                continue
            self.aggregated_state['sources_loaded'].append(f"analytics:{report}")
            entries = []
            if isinstance(data, list):
                entries = data
            elif isinstance(data, dict):
                for key in ('results', 'items', 'signals', 'data', 'top'):  # generic containers
                    if isinstance(data.get(key, None), list):
                        entries.extend(data[key])
                if not entries:
                    entries = [data]

            for item in entries:
                if not isinstance(item, dict):
                    continue
                sym = item.get('symbol') or item.get('pair') or item.get('asset')
                if not sym:
                    continue
                pnl = item.get('pnl') or item.get('pnl_usd') or item.get('profit') or 0
                wr = item.get('win_rate') or item.get('wr') or item.get('wins_ratio')
                prob = item.get('probability') or item.get('prob')
                score = item.get('score') or item.get('sharpe') or item.get('fitness')
                current = analytics_insights.get(sym, {})

                def _better(a, b):
                    # prefer higher prob/score/wr, then pnl
                    return (
                        (a.get('probability', 0) or 0) > (b.get('probability', 0) or 0) or
                        (a.get('score', 0) or 0) > (b.get('score', 0) or 0) or
                        (a.get('win_rate', 0) or 0) > (b.get('win_rate', 0) or 0) or
                        (a.get('pnl', 0) or 0) > (b.get('pnl', 0) or 0)
                    )

                candidate = {
                    'pnl': pnl,
                    'win_rate': wr,
                    'probability': prob,
                    'score': score,
                    'source': report,
                }

                if not current or _better(candidate, current):
                    analytics_insights[sym] = candidate

        if analytics_insights:
            self.aggregated_state['analytics_insights'] = analytics_insights

        # 10. Load positions files (current holdings snapshots)
        for pos_file in self.POSITION_FILES:
            pdata = self._load_json(pos_file)
            if not pdata:
                continue
            self.aggregated_state['sources_loaded'].append(f"positions:{pos_file}")
            if isinstance(pdata, dict):
                for sym, entry in pdata.items():
                    size = entry.get('quantity') or entry.get('qty') or entry.get('amount') or entry
                    positions_snapshot[sym] = size
            elif isinstance(pdata, list):
                for entry in pdata:
                    if not isinstance(entry, dict):
                        continue
                    sym = entry.get('symbol') or entry.get('pair')
                    if not sym:
                        continue
                    size = entry.get('quantity') or entry.get('qty') or entry.get('amount')
                    positions_snapshot[sym] = size

        if positions_snapshot:
            self.aggregated_state['positions_snapshot'] = positions_snapshot

        if position_hygiene['flagged']:
            self.aggregated_state['position_hygiene'] = position_hygiene

        # 11. Load auxiliary logs (diagnostic only)
        for log_file in self.AUX_LOG_FILES:
            ldata = self._load_json(log_file)
            if not ldata:
                continue
            self.aggregated_state['sources_loaded'].append(f"aux:{log_file}")
            try:
                count = len(ldata) if hasattr(ldata, '__len__') else 1
            except Exception:
                count = 1
            aux_logs[log_file] = {'entries': count}

        if aux_logs:
            self.aggregated_state['aux_logs'] = aux_logs
            
        # Calculate aggregated metrics
        self.aggregated_state['total_historical_trades'] = len(all_trades)
        if all_trades:
            wins = sum(1 for t in all_trades if _extract_pnl(t) > 0)
            self.aggregated_state['combined_win_rate'] = wins / len(all_trades) * 100
            
        # Calculate coherence bands performance
        coherence_bands = {'low': {'trades': 0, 'wins': 0}, 'mid': {'trades': 0, 'wins': 0}, 'high': {'trades': 0, 'wins': 0}}
        for trade in all_trades:
            coh = trade.get('coherence', 0.5)
            band = 'low' if coh < 0.5 else 'mid' if coh < 0.7 else 'high'
            coherence_bands[band]['trades'] += 1
            if _extract_pnl(trade) > 0:
                coherence_bands[band]['wins'] += 1
        self.aggregated_state['coherence_bands'] = coherence_bands
        
        self.aggregated_state['last_aggregation'] = time.time()
        
        logger.info(f"üìä State Aggregator: Loaded {len(self.aggregated_state['sources_loaded'])} sources, "
                   f"{self.aggregated_state['total_historical_trades']} historical trades")
        
        return self.aggregated_state
        
    def _load_json(self, filepath: str) -> Optional[Any]:
        """Safely load a JSON file."""
        if not filepath:
            return None
        try:
            full_path = os.path.join(ROOT_DIR, filepath)
            if os.path.exists(full_path):
                with open(full_path, 'r') as f:
                    return json.load(f)
        except Exception as e:
            logger.debug(f"Could not load {filepath}: {e}")
        return None
        
    def _scan_trade_logs(self) -> List[Dict]:
        """Scan /tmp/aureon_trade_logs for historical trades."""
        trades = []
        log_dir = '/tmp/aureon_trade_logs'
        if not os.path.exists(log_dir):
            return trades
            
        try:
            for filename in os.listdir(log_dir):
                if filename.endswith('.jsonl'):
                    filepath = os.path.join(log_dir, filename)
                    with open(filepath, 'r') as f:
                        for line in f:
                            try:
                                trade = json.loads(line.strip())
                                trades.append(trade)
                            except:
                                continue
        except Exception as e:
            logger.debug(f"Trade log scan error: {e}")
            
        return trades[-500:]  # Last 500 trades
        
    def _get_freq_band(self, freq: float) -> str:
        """Get frequency band name."""
        if freq < 300:
            return 'ROOT (174-256Hz)'
        elif freq < 450:
            return 'EARTH (396-432Hz)'
        elif freq < 550:
            return 'LOVE (528Hz)'
        elif freq < 700:
            return 'THROAT (639Hz)'
        elif freq < 850:
            return 'THIRD_EYE (741Hz)'
        else:
            return 'CROWN (852-963Hz)'
            
    def get_symbol_insight(self, symbol: str) -> Dict[str, Any]:
        """Get aggregated insight for a specific symbol."""
        base_symbol = symbol.replace('USDT', '').replace('USD', '').replace('GBP', '').replace('EUR', '')
        
        # Check all symbol variations
        insight = {'hunts': 0, 'trades': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'blacklisted': False, 'win_rate': 0.5}
        
        for sym, data in self.aggregated_state.get('symbol_insights', {}).items():
            if base_symbol in sym or sym in symbol:
                insight['hunts'] += data.get('total_hunts', 0)
                insight['trades'] += data.get('total_trades', 0)
                insight['wins'] += data.get('wins', 0)
                insight['losses'] += data.get('losses', 0)
                insight['profit'] += data.get('profit', 0)
                if data.get('blacklisted'):
                    insight['blacklisted'] = True
                    
        if insight['trades'] > 0:
            insight['win_rate'] = insight['wins'] / insight['trades']
            
        # Get HNC reading if available
        hnc = self.aggregated_state.get('hnc_readings', {}).get(symbol, {})
        if hnc:
            insight['frequency'] = hnc.get('frequency', 256)
            insight['resonance'] = hnc.get('resonance', 0.5)
            insight['is_harmonic'] = hnc.get('is_harmonic', False)

        # Probability signals (market selection intelligence)
        prob_insights = self.aggregated_state.get('probability_insights', {})
        for sym, pdata in prob_insights.items():
            base = sym.replace('USDT', '').replace('USD', '').replace('GBP', '').replace('EUR', '')
            if base_symbol == base or base in base_symbol:
                insight['probability_signal'] = pdata.get('probability', 0)
                insight['probability_state'] = pdata.get('state')
                insight['probability_change'] = pdata.get('change')
                insight['probability_source'] = pdata.get('source')
                break

        # Analytics signals (sim/backtest/agent metrics)
        analytics = self.aggregated_state.get('analytics_insights', {})
        for sym, adata in analytics.items():
            base = sym.replace('USDT', '').replace('USD', '').replace('GBP', '').replace('EUR', '')
            if base_symbol == base or base in base_symbol:
                insight['analytics_win_rate'] = adata.get('win_rate')
                insight['analytics_prob'] = adata.get('probability')
                insight['analytics_score'] = adata.get('score')
                insight['analytics_pnl'] = adata.get('pnl')
                insight['analytics_source'] = adata.get('source')
                break

        # Position snapshot (current holdings if available)
        positions = self.aggregated_state.get('positions_snapshot', {})
        for sym, qty in positions.items():
            base = sym.replace('USDT', '').replace('USD', '').replace('GBP', '').replace('EUR', '')
            if base_symbol == base or base in base_symbol:
                insight['position_quantity'] = qty
                break
            
        return insight
        
    def get_frequency_recommendation(self, freq: float) -> Dict[str, Any]:
        """Get recommendation based on historical frequency performance."""
        freq_band = self._get_freq_band(freq)
        perf = self.aggregated_state.get('frequency_performance', {}).get(freq_band, {})
        
        trades = perf.get('trades', 0)
        wins = perf.get('wins', 0)
        pnl = perf.get('pnl', 0)
        
        recommendation = {
            'band': freq_band,
            'historical_trades': trades,
            'historical_win_rate': wins / max(1, trades),
            'historical_pnl': pnl,
            'confidence': min(1.0, trades / 20),  # Full confidence after 20 trades
            'boost_factor': 1.0
        }
        
        # Calculate boost factor based on historical performance
        if trades >= 10:
            win_rate = wins / trades
            if win_rate > 0.60:
                recommendation['boost_factor'] = 1.0 + (win_rate - 0.50) * 0.5
            elif win_rate < 0.40:
                recommendation['boost_factor'] = 0.7
                
        return recommendation
        
    def get_coherence_recommendation(self, coherence: float) -> Dict[str, Any]:
        """Get recommendation based on historical coherence performance."""
        band = 'low' if coherence < 0.5 else 'mid' if coherence < 0.7 else 'high'
        perf = self.aggregated_state.get('coherence_bands', {}).get(band, {})
        
        trades = perf.get('trades', 0)
        wins = perf.get('wins', 0)
        
        return {
            'band': band,
            'historical_trades': trades,
            'historical_win_rate': wins / max(1, trades),
            'confidence': min(1.0, trades / 20),
            'recommended_min': 0.45 if band == 'low' else 0.50 if band == 'mid' else 0.55
        }

    def get_top_signals(self, n: int = 5) -> Dict[str, List[Tuple[str, Dict[str, Any]]]]:
        """Return top probability and analytics signals plus largest positions for visibility."""
        probs = sorted(
            self.aggregated_state.get('probability_insights', {}).items(),
            key=lambda kv: kv[1].get('probability', 0) or 0,
            reverse=True
        )[:n]

        def _analytic_key(item):
            data = item[1]
            return (
                data.get('score') or 0,
                data.get('win_rate') or 0,
                data.get('probability') or 0,
                data.get('pnl') or 0,
            )

        analytics = sorted(
            self.aggregated_state.get('analytics_insights', {}).items(),
            key=_analytic_key,
            reverse=True
        )[:n]

        positions = sorted(
            self.aggregated_state.get('positions_snapshot', {}).items(),
            key=lambda kv: abs(kv[1]) if isinstance(kv[1], (int, float)) else 0,
            reverse=True
        )[:n]

        return {
            'probability': probs,
            'analytics': analytics,
            'positions': positions,
        }
        
    def load_organism_thoughts(self, limit: int = 50):
        """Load recent thoughts to determine organism health."""
        try:
            filepath = os.path.join(ROOT_DIR, self.LOG_FILES['thoughts'])
            if not os.path.exists(filepath):
                return

            thoughts = []
            # Read last N lines efficiently
            with open(filepath, 'rb') as f:
                try:
                    f.seek(-10000, os.SEEK_END) # Go back ~10KB
                except OSError:
                    f.seek(0)
                
                lines = f.readlines()
                # Decode and parse last N lines
                for line in lines[-limit:]:
                    try:
                        thoughts.append(json.loads(line.decode('utf-8')))
                    except:
                        pass
            
            # Analyze health
            now = time.time()
            pulse = {
                'miner': {'last_seen': 0, 'status': 'OFFLINE'},
                'risk': {'last_seen': 0, 'status': 'OFFLINE'},
                'execution': {'last_seen': 0, 'status': 'OFFLINE'},
                'ecosystem': {'last_seen': 0, 'status': 'OFFLINE'},
            }
            
            for t in thoughts:
                src = t.get('source', 'unknown')
                ts = t.get('ts', 0)
                if src in pulse:
                    pulse[src]['last_seen'] = max(pulse[src]['last_seen'], ts)
            
            # Determine status based on recency (e.g. seen in last 60s)
            healthy_count = 0
            for src, data in pulse.items():
                age = now - data['last_seen']
                if age < 60:
                    data['status'] = 'ONLINE'
                    healthy_count += 1
                elif age < 300:
                    data['status'] = 'STALE'
                else:
                    data['status'] = 'OFFLINE'
            
            overall_status = 'HEALTHY' if healthy_count >= 3 else 'DEGRADED' if healthy_count > 0 else 'OFFLINE'
            
            self.aggregated_state['organism_health'] = {
                'status': overall_status,
                'pulse': pulse,
                'recent_thoughts': thoughts[-5:] # Keep last 5 for display
            }
            self.aggregated_state['sources_loaded'].append('organism_thoughts')
            
        except Exception as e:
            logger.debug(f"Failed to load organism thoughts: {e}")

    def save_aggregated_state(self):
        """Save multi-exchange learning state for persistence."""
        try:
            filepath = os.path.join(ROOT_DIR, self.STATE_FILES['multi_exchange_learning'])
            with open(filepath, 'w') as f:
                json.dump({
                    'by_exchange': self.aggregated_state.get('exchange_performance', {}),
                    'frequency_performance': self.aggregated_state.get('frequency_performance', {}),
                    'coherence_bands': self.aggregated_state.get('coherence_bands', {}),
                    'probability_insights': self.aggregated_state.get('probability_insights', {}),
                    'total_historical_trades': self.aggregated_state.get('total_historical_trades', 0),
                    'combined_win_rate': self.aggregated_state.get('combined_win_rate', 0),
                    'updated_at': datetime.now().isoformat()
                }, f, indent=2)
        except Exception as e:
            logger.warning(f"Could not save aggregated state: {e}")
            
    def get_summary(self) -> str:
        """Get formatted summary of aggregated state."""
        state = self.aggregated_state
        
        # Calculate TRUE P&L
        first_start = state.get('first_start_balance', 0)
        current = state.get('current_balance', 0)
        true_pnl = current - first_start if first_start > 0 else 0
        true_pct = (true_pnl / first_start * 100) if first_start > 0 else 0
        first_start_time = state.get('first_start_time', 0)
        start_str = time.strftime('%Y-%m-%d %H:%M', time.localtime(first_start_time)) if first_start_time > 0 else 'Unknown'
        
        lines = [
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            "üìä UNIFIED STATE AGGREGATOR SUMMARY",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            f"Sources Loaded: {', '.join(state.get('sources_loaded', []))}",
            f"Historical Trades: {state.get('total_historical_trades', 0)}",
            f"Combined Win Rate: {state.get('combined_win_rate', 0):.1f}%",
            "",
            "üíµ PORTFOLIO (TRUE from first run):",
            f"   First Started: {start_str}",
            f"   TRUE Starting: ¬£{first_start:.2f}",
            f"   Current: ¬£{current:.2f}",
            f"   TRUE P&L: ¬£{true_pnl:+.2f} ({true_pct:+.1f}%)",
            "",
            "Frequency Performance:"
        ]
        
        for band, perf in state.get('frequency_performance', {}).items():
            wr = perf['wins'] / max(1, perf['trades']) * 100
            lines.append(f"  {band}: {perf['trades']} trades, {wr:.1f}% WR, ${perf['pnl']:.2f}")
            
        lines.append("")
        lines.append("Coherence Bands:")
        for band, perf in state.get('coherence_bands', {}).items():
            wr = perf['wins'] / max(1, perf['trades']) * 100
            lines.append(f"  {band}: {perf['trades']} trades, {wr:.1f}% WR")
            
        health = state.get('organism_health', {})
        lines.append("")
        lines.append(f"üß† ORGANISM HEALTH: {health.get('status', 'UNKNOWN')}")
        pulse = health.get('pulse', {})
        lines.append(f"   Miner: {pulse.get('miner', {}).get('status')} | Risk: {pulse.get('risk', {}).get('status')} | Exec: {pulse.get('execution', {}).get('status')}")
            
        return "\n".join(lines)


# Global state aggregator instance
STATE_AGGREGATOR = UnifiedStateAggregator()


class CognitiveImmuneSystem:
    """
    üõ°Ô∏è Autonomous antivirus/immune layer with PROBABILITY MATRIX health prediction.
    
    Just like we predict trades using probability, we predict system health and auto-heal.
    
    Health Signals (23 total):
    - VITAL: memory, cpu, disk, uptime
    - NETWORK: websocket, api_latency, reconnects
    - DATA: price_freshness, probability_staleness, state_sync
    - LOGIC: kelly_validity, position_count, win_rate
    - TRADING: execution_success, bridge_sync, news_freshness
    
    Each signal contributes to overall health score (0-100).
    When health drops, system auto-heals before problems manifest.
    """

    # Health signal weights (PHI-based for harmonic balance)
    HEALTH_WEIGHTS = {
        # VITAL signs (most important)
        'memory_available': 1.618,
        'cpu_usage': 1.0,
        'disk_space': 1.0,
        'uptime_stability': 0.618,
        
        # NETWORK health
        'websocket_connected': 1.618,
        'websocket_freshness': 1.0,
        'api_latency': 0.618,
        'reconnect_rate': 0.618,
        
        # DATA integrity
        'price_freshness': 1.618,
        'probability_freshness': 1.0,
        'state_aggregator_sync': 0.618,
        'ticker_cache_hit': 0.382,
        
        # LOGIC consistency
        'kelly_positive': 1.618,
        'position_within_limits': 1.0,
        'win_rate_healthy': 0.618,
        'no_trading_halt': 1.0,
        
        # TRADING execution
        'execution_success_rate': 1.618,
        'bridge_sync_fresh': 0.618,
        'news_feed_active': 0.382,
        'knowledge_base_healthy': 0.382,
    }
    
    # Health thresholds for auto-healing
    HEALTH_THRESHOLDS = {
        'CRITICAL': 40,    # Immediate auto-heal
        'WARNING': 60,     # Monitor closely
        'WATCH': 75,       # Log but don't act
        'HEALTHY': 100,    # All good
    }

    def __init__(self, ecosystem: 'AureonKrakenEcosystem', thought_bus: Optional[ThoughtBus], state_aggregator: UnifiedStateAggregator):
        self.ecosystem = ecosystem
        self.bus = thought_bus
        self.aggregator = state_aggregator
        self.last_scan = 0.0
        self.scan_interval = 30.0
        self.fault_memory: Deque[Dict[str, Any]] = deque(maxlen=200)
        self.mycelium_event_dir = Path("data/mycelium_snapshots")
        self.mycelium_event_dir.mkdir(parents=True, exist_ok=True)
        self._mycelium_event_buffer: Deque[Dict[str, Any]] = deque(maxlen=200)
        
        # üß¨ PROBABILITY MATRIX - Health History for Prediction
        self.health_history: Deque[Dict[str, Any]] = deque(maxlen=1000)
        self.last_health_score = 100.0
        self.health_trend = 0.0  # Positive = improving, negative = degrading
        self.auto_heals_performed = 0
        self.predictions_made = 0
        self.predictions_correct = 0
        
        # üçÑ MYCELIUM CONNECTION - Neural network for immune signals
        self.mycelium = getattr(ecosystem, 'mycelium', None)
        self._mycelium_signal_strength = 1.0  # How strongly immune affects mycelium
        
        self.minds = {
            'Miner': self._miner_mind,
            'Risk': self._risk_mind,
            'Execution': self._execution_mind,
            'Bridge': self._bridge_mind,
            'NewsFeed': self._newsfeed_mind,
            'KnowledgeBase': self._knowledge_mind,
            'Mycelium': self._mycelium_mind,  # üçÑ NEW: Mycelium neural network mind
        }

        if self.bus:
            self.bus.subscribe("system.error", self._on_fault_thought)
            # üçÑ Subscribe to mycelium signals
            self.bus.subscribe("mycelium.coherence", self._on_mycelium_signal)
            self.bus.subscribe("mycelium.queen_decision", self._on_queen_decision)

    # ------------------------------------------------------------------
    # Event ingestion
    # ------------------------------------------------------------------
    def _on_fault_thought(self, thought: Thought) -> None:
        payload = thought.payload if isinstance(thought.payload, dict) else {}
        fault = {
            'ts': thought.ts,
            'source': payload.get('while_handling_topic', thought.topic),
            'error': payload.get('error', 'unknown fault'),
            'trace_id': thought.trace_id,
        }
        self.fault_memory.append(fault)

    # ------------------------------------------------------------------
    # üçÑ MYCELIUM SIGNAL HANDLERS - Neural network communication
    # ------------------------------------------------------------------
    def _on_mycelium_signal(self, thought: Thought) -> None:
        """Receive coherence signals from mycelium network."""
        payload = thought.payload if isinstance(thought.payload, dict) else {}
        coherence = payload.get('coherence', 0.5)
        
        # Low coherence might indicate network instability
        if coherence < 0.3:
            self.fault_memory.append({
                'ts': thought.ts,
                'source': 'mycelium',
                'error': f'Low network coherence: {coherence:.2f}',
                'trace_id': thought.trace_id,
            })
        
        if self.mycelium and hasattr(self.mycelium, "update_external_state"):
            self.mycelium.update_external_state(coherence=coherence, source="immune_system")
        if getattr(self.ecosystem, "gaia_reclaimer", None):
            self.ecosystem.gaia_reclaimer.update_signal(
                source="mycelium",
                coherence=coherence,
            )
        
        self._record_mycelium_event(
            event_type="coherence",
            data={
                "coherence": coherence,
                "trace_id": getattr(thought, "trace_id", None)
            }
        )
    
    def _on_queen_decision(self, thought: Thought) -> None:
        """Receive Queen Neuron decisions from mycelium."""
        payload = thought.payload if isinstance(thought.payload, dict) else {}
        queen_signal = payload.get('signal', 0.0)
        
        # Strong negative queen signal might indicate systemic risk
        if queen_signal < -0.7:
            self.fault_memory.append({
                'ts': thought.ts,
                'source': 'mycelium_queen',
                'error': f'Queen Neuron bearish alert: {queen_signal:.2f}',
                'trace_id': thought.trace_id,
            })
        
        self._record_mycelium_event(
            event_type="queen_decision",
            data={
                "queen_signal": queen_signal,
                "trace_id": getattr(thought, "trace_id", None)
            }
        )
    
    def _broadcast_health_to_mycelium(self, health_score: float, status: str) -> None:
        """
        üçÑ Send immune health signals INTO the mycelium network.
        This allows the neural network to factor system health into trading decisions.
        """
        if not self.mycelium:
            return
        
        try:
            # Convert health to signal strength (-1 to 1)
            # 100% health = +1.0 signal, 0% health = -1.0 signal
            health_signal = (health_score - 50) / 50  # Maps 0-100 to -1 to +1
            
            # Add immune signal to mycelium network
            self.mycelium.add_signal('IMMUNE_HEALTH', (health_signal + 1) / 2)  # Convert to 0-1
            
            # If we have full network, also notify hives
            if hasattr(self.mycelium, 'full_network') and self.mycelium.full_network:
                # Store immune state for queen neuron consideration
                self.mycelium.full_network.immune_health = health_score
                self.mycelium.full_network.immune_status = status
            
            # Publish to thought bus for other systems
            if self.bus:
                self.bus.publish(Thought(
                    source="immune_system",
                    topic="immune.health_broadcast",
                    payload={
                        'health_score': health_score,
                        'status': status,
                        'signal_strength': health_signal,
                        'trend': self.health_trend,
                    },
                ))
        except Exception as e:
            logger.debug(f"Mycelium health broadcast error: {e}")
        
        if hasattr(self.mycelium, "update_external_state"):
            self.mycelium.update_external_state(immune_health=health_score, source="immune_system")
        if getattr(self.ecosystem, "gaia_reclaimer", None):
            self.ecosystem.gaia_reclaimer.update_signal(
                source="immune_health",
                coherence=(health_signal + 1) / 2,
                risk_bias=health_signal * 0.1,
                payload={"status": status},
            )
        
        self._record_mycelium_event(
            event_type="immune_health",
            data={
                "health_score": health_score,
                "status": status,
                "signal_strength": (health_score - 50) / 50
            }
        )
    
    def _record_mycelium_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """Persist mycelium event telemetry to JSONL for downstream analysis."""
        try:
            snapshot = {
                "schema_version": "1.0",
                "timestamp": datetime.utcnow().isoformat(),
                "event_type": event_type,
                "data": data,
            }
            self._mycelium_event_buffer.append(snapshot)
            
            if len(self._mycelium_event_buffer) >= 10:
                self._flush_mycelium_events()
        except Exception as e:
            logger.debug(f"Mycelium event record error: {e}")
    
    def _flush_mycelium_events(self) -> None:
        """Flush buffered mycelium events to dated JSONL file."""
        if not self._mycelium_event_buffer:
            return
        try:
            date_str = datetime.utcnow().strftime("%Y-%m-%d")
            event_path = self.mycelium_event_dir / f"mycelium_events_{date_str}.jsonl"
            with event_path.open("a", encoding="utf-8") as f:
                for event in self._mycelium_event_buffer:
                    f.write(json.dumps(event) + "\n")
            self._mycelium_event_buffer.clear()
        except Exception as e:
            logger.debug(f"Mycelium event flush error: {e}")

    # ------------------------------------------------------------------
    # üß¨ PROBABILITY MATRIX - Health Prediction Engine
    # ------------------------------------------------------------------
    def calculate_health_score(self) -> Tuple[float, Dict[str, float]]:
        """
        Calculate overall system health using weighted probability matrix.
        Returns (overall_score, individual_scores) where scores are 0-100.
        """
        scores = {}
        now = time.time()
        
        # VITAL signs
        try:
            import psutil
            scores['memory_available'] = min(100, psutil.virtual_memory().available / (1024**3) * 10)  # 10GB = 100
            scores['cpu_usage'] = max(0, 100 - psutil.cpu_percent())
            scores['disk_space'] = psutil.disk_usage('/').percent
            scores['uptime_stability'] = min(100, (now - self.ecosystem.start_time) / 3600 * 10)  # 10h = 100
        except Exception:
            scores['memory_available'] = 80
            scores['cpu_usage'] = 80
            scores['disk_space'] = 80
            scores['uptime_stability'] = 80
        
        # NETWORK health
        scores['websocket_connected'] = 100 if getattr(self.ecosystem, 'ws_connected', False) else 0
        ws_age = now - getattr(self.ecosystem, 'ws_last_message', now)
        scores['websocket_freshness'] = max(0, 100 - (ws_age * 3.33))  # 30s = 0
        scores['api_latency'] = 80  # Default, could measure actual latency
        reconnects = getattr(self.ecosystem, 'ws_reconnect_count', 0)
        scores['reconnect_rate'] = max(0, 100 - (reconnects * 10))
        
        # DATA integrity
        ticker_cache = getattr(self.ecosystem, 'ticker_cache', {})
        scores['ticker_cache_hit'] = min(100, len(ticker_cache) * 5)  # 20 tickers = 100
        
        # Probability freshness from aggregator
        pfresh = self.aggregator.aggregated_state.get('probability_freshness', {}) if self.aggregator else {}
        scores['probability_freshness'] = 0 if pfresh.get('stale', False) else 100
        scores['price_freshness'] = scores['websocket_freshness']  # Use WS freshness as proxy
        scores['state_aggregator_sync'] = 100 if self.aggregator else 0
        
        # LOGIC consistency
        tracker = getattr(self.ecosystem, 'tracker', None)
        if tracker:
            win_rate = getattr(tracker, 'win_rate', 0.5)
            scores['win_rate_healthy'] = min(100, win_rate * 200)  # 50% = 100
            scores['no_trading_halt'] = 0 if getattr(tracker, 'trading_halted', False) else 100
        else:
            scores['win_rate_healthy'] = 50
            scores['no_trading_halt'] = 100
        
        positions = getattr(self.ecosystem, 'positions', {})
        max_pos = get_max_positions_limit() or 10
        scores['position_within_limits'] = max(0, 100 - (len(positions) / max_pos * 100)) if max_pos > 0 else 100
        
        # Kelly criterion health - is it returning sane values?
        test_kelly = kelly_criterion(0.50, 100, 100, 0.5)  # Standard test
        scores['kelly_positive'] = 100 if test_kelly > 0 else 50
        
        # TRADING execution
        scores['execution_success_rate'] = 80  # Default, could track actual
        
        bridge_age = now - getattr(self.ecosystem, 'last_bridge_sync', now)
        bridge_interval = getattr(self.ecosystem, 'bridge_sync_interval', 10.0)
        scores['bridge_sync_fresh'] = max(0, 100 - (bridge_age / bridge_interval * 25))
        
        news_feed = getattr(self.ecosystem, 'news_feed', None)
        scores['news_feed_active'] = 100 if news_feed else 50
        
        knowledge_base = getattr(self.ecosystem, 'knowledge_base', None)
        scores['knowledge_base_healthy'] = 100 if knowledge_base else 50
        
        # üçÑ MYCELIUM NETWORK health - Neural coherence is critical!
        if self.mycelium:
            try:
                network_coherence = self.mycelium.get_network_coherence()
                scores['mycelium_coherence'] = network_coherence * 100  # 0-1 to 0-100
                
                # Queen neuron health (if available)
                queen_signal = getattr(self.mycelium, 'queen_signal', 0.0)
                # Extreme signals (-1 or +1) are fine, but erratic swings are bad
                # For now, just check if queen exists and is responding
                scores['queen_neuron_health'] = 100 if abs(queen_signal) <= 1.0 else 50
                
                # Hive count - more hives = healthier network
                hive_count = getattr(self.mycelium, 'hive_count', 1)
                scores['hive_vitality'] = min(100, hive_count * 33)  # 3 hives = 100
            except Exception:
                scores['mycelium_coherence'] = 50
                scores['queen_neuron_health'] = 50
                scores['hive_vitality'] = 50
        else:
            scores['mycelium_coherence'] = 0
            scores['queen_neuron_health'] = 0
            scores['hive_vitality'] = 0
        
        # Calculate weighted average (add mycelium weights)
        mycelium_weights = {
            'mycelium_coherence': 1.618,  # PHI - neural coherence is vital
            'queen_neuron_health': 1.0,
            'hive_vitality': 0.618,
        }
        all_weights = {**self.HEALTH_WEIGHTS, **mycelium_weights}
        total_weight = sum(all_weights.values())
        weighted_sum = sum(scores.get(k, 50) * w for k, w in all_weights.items())
        overall = weighted_sum / total_weight if total_weight > 0 else 50
        
        return overall, scores
    
    def predict_health_trend(self) -> Tuple[str, float]:
        """
        Predict future health based on recent history (probability matrix style).
        Returns (prediction, confidence) where prediction is 'IMPROVING', 'STABLE', or 'DEGRADING'.
        """
        if len(self.health_history) < 5:
            return 'STABLE', 0.5
        
        # Get recent scores
        recent = list(self.health_history)[-10:]
        scores = [h['score'] for h in recent]
        
        # Calculate trend
        if len(scores) >= 2:
            trend = (scores[-1] - scores[0]) / max(len(scores), 1)
        else:
            trend = 0
        
        self.health_trend = trend
        
        # Predict based on trend
        if trend > 2:
            return 'IMPROVING', min(0.9, 0.5 + trend / 10)
        elif trend < -2:
            return 'DEGRADING', min(0.9, 0.5 - trend / 10)
        else:
            return 'STABLE', 0.7
    
    def get_health_status(self) -> str:
        """Get current health status level."""
        score = self.last_health_score
        for level, threshold in sorted(self.HEALTH_THRESHOLDS.items(), key=lambda x: x[1]):
            if score <= threshold:
                return level
        return 'HEALTHY'
    
    def get_immune_summary(self) -> Dict[str, Any]:
        """Get summary for display in status bar."""
        prediction, confidence = self.predict_health_trend()
        return {
            'health_score': round(self.last_health_score, 1),
            'status': self.get_health_status(),
            'trend': prediction,
            'trend_confidence': round(confidence, 2),
            'auto_heals': self.auto_heals_performed,
            'predictions_accuracy': round(self.predictions_correct / max(self.predictions_made, 1) * 100, 1),
        }

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def scan_and_heal(self, force: bool = False) -> None:
        """
        üõ°Ô∏è PROBABILITY MATRIX SCAN - Predict and prevent system issues.
        
        Unlike traditional reactive systems, we:
        1. Calculate overall health score (0-100)
        2. Predict health trend using historical data
        3. Auto-heal BEFORE problems become critical
        """
        now = time.time()
        if not force and (now - self.last_scan) < self.scan_interval:
            return
        self.last_scan = now
        
        # üß¨ STEP 1: Calculate current health score
        health_score, individual_scores = self.calculate_health_score()
        self.last_health_score = health_score
        
        # Record in history for trend prediction
        self.health_history.append({
            'ts': now,
            'score': health_score,
            'scores': individual_scores,
        })
        
        # üîÆ STEP 2: Predict health trend
        prediction, confidence = self.predict_health_trend()
        
        # Track prediction accuracy
        if len(self.health_history) >= 2:
            prev = list(self.health_history)[-2]
            was_degrading = self.health_trend < -2
            actually_degraded = health_score < prev['score']
            if was_degrading or actually_degraded:
                self.predictions_made += 1
                if was_degrading == actually_degraded:
                    self.predictions_correct += 1
        
        # üõ°Ô∏è STEP 3: Auto-heal based on health level
        status = self.get_health_status()
        
        if status == 'CRITICAL' or (status == 'WARNING' and prediction == 'DEGRADING'):
            # Collect faults and heal
            faults = self._collect_faults(now)
            
            # Add health-based faults
            for signal, score in individual_scores.items():
                if score < 30:
                    faults.append({'code': f'LOW_{signal.upper()}', 'detail': {'score': score}})
            
            healing_plan: List[Dict[str, Any]] = []
            for _, handler in self.minds.items():
                plan = handler(faults)
                if plan:
                    healing_plan.extend(plan)
            
            if healing_plan:
                self._execute_plan(healing_plan, faults)
                self.auto_heals_performed += 1
                
                self._emit_thought("immune.auto_heal", {
                    'health_score': health_score,
                    'status': status,
                    'prediction': prediction,
                    'confidence': confidence,
                    'heals': len(healing_plan),
                })
            else:
                self._emit_thought("immune.alert", {
                    'health_score': health_score,
                    'status': status,
                    'faults': faults,
                })
        
        elif status != 'HEALTHY':
            # Just monitor and collect faults
            faults = self._collect_faults(now)
            if faults:
                self._emit_thought("immune.watch", {
                    'health_score': health_score,
                    'status': status,
                    'faults': faults,
                })
        
        # üçÑ STEP 4: Broadcast health to mycelium network (every scan)
        # This allows the neural network to factor system health into trading
        self._broadcast_health_to_mycelium(health_score, status)

    # ------------------------------------------------------------------
    # Fault analysis helpers
    # ------------------------------------------------------------------
    def _collect_faults(self, now: float) -> List[Dict[str, Any]]:
        faults: List[Dict[str, Any]] = []

        # Organism status from aggregator
        health = self.aggregator.aggregated_state.get('organism_health', {}) if self.aggregator else {}
        status = health.get('status')
        if status in ('DEGRADED', 'OFFLINE'):
            faults.append({'code': f'ORGANISM_{status}', 'detail': health})

        # Probability freshness
        pfresh = self.aggregator.aggregated_state.get('probability_freshness', {}) if self.aggregator else {}
        if pfresh.get('stale'):
            faults.append({'code': 'PROBABILITY_STALE', 'detail': pfresh})

        # Websocket/liveness
        ws_age = now - getattr(self.ecosystem, 'ws_last_message', now)
        ws_timeout = CONFIG.get('WS_HEARTBEAT_TIMEOUT', 30)
        if ws_age > ws_timeout:
            faults.append({'code': 'WS_STALE', 'detail': {'age': ws_age, 'timeout': ws_timeout}})

        # Trading halt
        tracker = getattr(self.ecosystem, 'tracker', None)
        if tracker and getattr(tracker, 'trading_halted', False):
            faults.append({'code': 'TRADING_HALTED', 'detail': {'reason': tracker.halt_reason}})

        # Bridge sync
        if getattr(self.ecosystem, 'bridge_enabled', False):
            bridge_age = now - getattr(self.ecosystem, 'last_bridge_sync', 0.0)
            if bridge_age > getattr(self.ecosystem, 'bridge_sync_interval', 10.0) * 4:
                faults.append({'code': 'BRIDGE_STALE', 'detail': {'age': bridge_age}})

        # News feed staleness (if no news in 30+ minutes)
        news_feed = getattr(self.ecosystem, 'news_feed', None)
        if news_feed and hasattr(news_feed, 'last_poll_time') and news_feed.last_poll_time:
            try:
                from datetime import datetime
                news_age_seconds = (datetime.utcnow() - news_feed.last_poll_time).total_seconds()
                if news_age_seconds > 1800:  # 30 minutes
                    faults.append({'code': 'NEWS_STALE', 'detail': {'age_seconds': news_age_seconds}})
            except Exception:
                pass

        # News API errors accumulating
        if news_feed:
            news_metrics = getattr(news_feed, 'metrics', {})
            news_errors = news_metrics.get('errors', 0)
            if news_errors >= 5:
                faults.append({'code': 'NEWS_API_ERRORS', 'detail': {'errors': news_errors}})

        # Knowledge base errors
        knowledge_base = getattr(self.ecosystem, 'knowledge_base', None)
        if knowledge_base:
            kb_metrics = getattr(knowledge_base, 'metrics', {})
            kb_errors = kb_metrics.get('errors', 0)
            if kb_errors >= 10:
                faults.append({'code': 'KNOWLEDGE_API_ERRORS', 'detail': {'errors': kb_errors}})

        # üçÑ MYCELIUM NETWORK health checks
        if self.mycelium:
            try:
                # Network coherence check
                coherence = self.mycelium.get_network_coherence()
                if coherence < 0.3:
                    faults.append({'code': 'LOW_MYCELIUM_COHERENCE', 'detail': {'coherence': coherence}})
                
                # Queen neuron stability check
                queen_signal = getattr(self.mycelium, 'queen_signal', 0.0)
                # Check if queen is giving extreme or erratic signals
                if hasattr(self, '_last_queen_signal'):
                    signal_change = abs(queen_signal - self._last_queen_signal)
                    if signal_change > 1.5:  # Too much swing in one cycle
                        faults.append({'code': 'QUEEN_NEURON_UNSTABLE', 'detail': {
                            'current': queen_signal,
                            'previous': self._last_queen_signal,
                            'change': signal_change
                        }})
                self._last_queen_signal = queen_signal
                
                # Hive count check - if hives died, network is sick
                hive_count = getattr(self.mycelium, 'hive_count', 1)
                if hive_count == 0:
                    faults.append({'code': 'MYCELIUM_NO_HIVES', 'detail': {'hive_count': 0}})
            except Exception as e:
                logger.debug(f"Mycelium health check error: {e}")

        # Thought-level faults
        recent_faults = [f for f in self.fault_memory if now - f['ts'] < 120]
        for fault in recent_faults:
            faults.append({'code': 'THOUGHT_FAULT', 'detail': fault})

        return faults

    # ------------------------------------------------------------------
    # Mind protocols
    # ------------------------------------------------------------------
    def _miner_mind(self, faults: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        plan: List[Dict[str, Any]] = []
        if any(f['code'] in ('PROBABILITY_STALE', 'THOUGHT_FAULT') for f in faults):
            plan.append({
                'mind': 'Miner',
                'action': 'REFRESH_PROBABILITY_REPORTS',
                'description': 'Reload probability reports + aggregated state',
                'callable': self._heal_probability_reports,
                'auto_execute': True,
            })
        return plan

    def _risk_mind(self, faults: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        plan: List[Dict[str, Any]] = []
        if any(f['code'] in ('TRADING_HALTED', 'ORGANISM_DEGRADED') for f in faults):
            plan.append({
                'mind': 'Risk',
                'action': 'AUDIT_POSITIONS',
                'description': 'Run position/risk audit to release halts if conditions improve',
                'callable': self._heal_risk_controls,
                'auto_execute': True,
            })
        return plan

    def _execution_mind(self, faults: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        plan: List[Dict[str, Any]] = []
        if any(f['code'] == 'WS_STALE' for f in faults):
            plan.append({
                'mind': 'Execution',
                'action': 'RECHARGE_MARKET_DATA',
                'description': 'Refresh tickers and request websocket heartbeat',
                'callable': self._heal_market_data,
                'auto_execute': True,
            })
        return plan

    def _bridge_mind(self, faults: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        plan: List[Dict[str, Any]] = []
        if any(f['code'] == 'BRIDGE_STALE' for f in faults):
            plan.append({
                'mind': 'Bridge',
                'action': 'SYNC_BRIDGE',
                'description': 'Force a bridge sync so Ultimate/Unified share state',
                'callable': self._heal_bridge_link,
                'auto_execute': True,
            })
        return plan

    def _newsfeed_mind(self, faults: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """News Feed mind - handles news API staleness and errors."""
        plan: List[Dict[str, Any]] = []
        
        # Handle stale news
        if any(f['code'] == 'NEWS_STALE' for f in faults):
            plan.append({
                'mind': 'NewsFeed',
                'action': 'FORCE_NEWS_POLL',
                'description': 'Force refresh news feed from World News API',
                'callable': self._heal_news_feed,
                'auto_execute': True,
            })
        
        # Handle API errors accumulating
        if any(f['code'] == 'NEWS_API_ERRORS' for f in faults):
            plan.append({
                'mind': 'NewsFeed',
                'action': 'RESET_NEWS_METRICS',
                'description': 'Reset news API error counters and retry',
                'callable': self._heal_news_errors,
                'auto_execute': True,
            })
        
        return plan

    def _knowledge_mind(self, faults: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Knowledge Base mind - handles Wikipedia API errors."""
        plan: List[Dict[str, Any]] = []
        
        # Handle API errors accumulating
        if any(f['code'] == 'KNOWLEDGE_API_ERRORS' for f in faults):
            plan.append({
                'mind': 'KnowledgeBase',
                'action': 'RESET_KNOWLEDGE_METRICS',
                'description': 'Reset knowledge base error counters and clear stale cache',
                'callable': self._heal_knowledge_errors,
                'auto_execute': True,
            })
        
        return plan

    def _mycelium_mind(self, faults: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        üçÑ Mycelium Neural Network mind - handles network coherence issues.
        
        The mycelium is the neural backbone of Aureon. When it's unhealthy,
        trading decisions become unreliable.
        """
        plan: List[Dict[str, Any]] = []
        
        # Handle low network coherence
        low_coherence_faults = [f for f in faults if 'coherence' in f.get('error', '').lower()]
        if low_coherence_faults or any(f['code'] == 'LOW_MYCELIUM_COHERENCE' for f in faults):
            plan.append({
                'mind': 'Mycelium',
                'action': 'STRENGTHEN_SYNAPSES',
                'description': 'Reinforce mycelium neural connections to restore coherence',
                'callable': self._heal_mycelium_coherence,
                'auto_execute': True,
            })
        
        # Handle queen neuron issues
        queen_faults = [f for f in faults if 'queen' in f.get('source', '').lower()]
        if queen_faults or any(f['code'] == 'QUEEN_NEURON_UNSTABLE' for f in faults):
            plan.append({
                'mind': 'Mycelium',
                'action': 'STABILIZE_QUEEN',
                'description': 'Reset queen neuron bias to restore collective decision making',
                'callable': self._heal_queen_neuron,
                'auto_execute': True,
            })
        
        return plan

    # ------------------------------------------------------------------
    # Healing actions
    # ------------------------------------------------------------------
    def _heal_probability_reports(self) -> None:
        loader = getattr(self.ecosystem, 'probability_loader', None)
        if loader:
            loader.load_all_reports()
        self.aggregator.load_all_sources()

    def _heal_risk_controls(self) -> None:
        self.ecosystem.check_positions()
        self.ecosystem.refresh_equity()

    def _heal_market_data(self) -> None:
        try:
            self.ecosystem.refresh_tickers()
        finally:
            self.ecosystem.ws_last_message = time.time()

    def _heal_bridge_link(self) -> None:
        if getattr(self.ecosystem, 'bridge_enabled', False):
            self.ecosystem.sync_bridge()

    def _heal_news_feed(self) -> None:
        """Force a news poll to refresh market sentiment data."""
        news_feed = getattr(self.ecosystem, 'news_feed', None)
        if news_feed:
            try:
                import asyncio
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    loop.run_until_complete(news_feed.poll_and_publish())
                finally:
                    loop.close()
            except Exception as e:
                logger.warning(f"News feed heal failed: {e}")

    def _heal_news_errors(self) -> None:
        """Reset news API error counters."""
        news_feed = getattr(self.ecosystem, 'news_feed', None)
        if news_feed and hasattr(news_feed, 'metrics'):
            news_feed.metrics['errors'] = 0
            logger.info("News feed error counters reset")

    def _heal_knowledge_errors(self) -> None:
        """Reset knowledge base error counters and clear stale cache."""
        knowledge_base = getattr(self.ecosystem, 'knowledge_base', None)
        if knowledge_base:
            if hasattr(knowledge_base, 'metrics'):
                knowledge_base.metrics['errors'] = 0
            # Clear cache to force fresh lookups
            if hasattr(knowledge_base, 'cache'):
                knowledge_base.cache.clear()
            logger.info("Knowledge base error counters reset, cache cleared")

    def _heal_mycelium_coherence(self) -> None:
        """
        üçÑ Strengthen mycelium neural connections to restore coherence.
        
        When the network becomes fragmented, we reinforce all synapses
        with a small positive signal to rebuild connectivity.
        """
        if not self.mycelium:
            return
        
        try:
            # Strengthen all synapses with a small positive signal
            for symbol, synapses in self.mycelium.synapses.items():
                for synapse in synapses:
                    synapse.strengthen(0.05)  # Small positive reinforcement
            
            # If full network exists, also strengthen hive synapses
            if hasattr(self.mycelium, 'full_network') and self.mycelium.full_network:
                for synapse in self.mycelium.full_network.hive_synapses:
                    synapse.strengthen(0.05)
            
            logger.info("üçÑ Mycelium synapses strengthened - coherence healing applied")
            
            # Broadcast healing to thought bus
            if self.bus:
                self.bus.publish(Thought(
                    source="immune_system",
                    topic="mycelium.healed",
                    payload={'action': 'STRENGTHEN_SYNAPSES', 'strength': 0.05},
                ))
        except Exception as e:
            logger.warning(f"Mycelium healing error: {e}")

    def _heal_queen_neuron(self) -> None:
        """
        üçÑüëë Stabilize the Queen Neuron's collective decision making.
        
        When the queen becomes erratic, we reset her bias toward neutral
        to allow the hive to re-establish consensus.
        """
        if not self.mycelium:
            return
        
        try:
            if hasattr(self.mycelium, 'full_network') and self.mycelium.full_network:
                # Reset queen's aggregated signal toward neutral
                self.mycelium.queen_signal = 0.0
                
                # If the full network has a queen neuron, reset its bias
                if hasattr(self.mycelium.full_network, 'queen') and self.mycelium.full_network.queen:
                    self.mycelium.full_network.queen.bias = 0.0
                
                logger.info("üçÑüëë Queen Neuron stabilized - bias reset to neutral")
                
                # Broadcast healing
                if self.bus:
                    self.bus.publish(Thought(
                        source="immune_system",
                        topic="mycelium.queen_healed",
                        payload={'action': 'STABILIZE_QUEEN', 'new_bias': 0.0},
                    ))
        except Exception as e:
            logger.warning(f"Queen neuron healing error: {e}")

    # ------------------------------------------------------------------
    # Execution + telemetry
    # ------------------------------------------------------------------
    def _execute_plan(self, plan: List[Dict[str, Any]], faults: List[Dict[str, Any]]) -> None:
        executed = []
        for step in plan:
            callable_fn = step.get('callable')
            ok = False
            error = None
            if callable_fn:
                try:
                    callable_fn()
                    ok = True
                except Exception as exc:
                    error = str(exc)
            executed.append({
                'mind': step.get('mind'),
                'action': step.get('action'),
                'status': 'ok' if ok else 'error',
                'error': error,
            })

        self._emit_thought("immune.heal", {
            'executed': executed,
            'faults': faults,
        })

    def _emit_thought(self, topic: str, payload: Dict[str, Any]) -> None:
        if not self.bus:
            return
        self.bus.publish(Thought(
            source="immune_system",
            topic=topic,
            payload=payload,
        ))


def kelly_criterion(win_rate: float, avg_win: float, avg_loss: float, safety_factor: float = 0.5) -> float:
    """
    Calculate Kelly Criterion position size.
    
    Formula: f* = (p*b - (1-p)) / b
    Where:
        p = win probability
        b = win/loss ratio (avg_win / avg_loss)
    
    Returns: Position size as fraction of balance (with safety factor applied)
    
    üîß FIX: Returns minimum viable size (2%) when Kelly is negative/zero
    to prevent complete trading halt during losing streaks.
    """
    if avg_loss <= 0 or win_rate <= 0 or win_rate >= 1:
        return 0.10  # Fallback to 10%
    
    b = avg_win / avg_loss
    kelly_fraction = (win_rate * b - (1 - win_rate)) / b
    
    # Apply safety factor and bounds
    kelly_fraction = max(0, kelly_fraction) * safety_factor
    
    # üîß FIX: When Kelly says "don't trade" (win rate too low), use minimum viable size
    # This prevents complete trading halt - let penny math be the final gate
    if kelly_fraction <= 0.01:  # Kelly essentially says stop
        kelly_fraction = 0.02   # 2% minimum - tiny positions to recover
        
    return min(kelly_fraction, CONFIG['MAX_POSITION_SIZE'])


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß† ADAPTIVE LEARNING ENGINE - Self-Optimizing Parameters
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class AdaptiveLearningEngine:
    """
    Learns from past trades and dynamically adjusts system parameters.
    
    Key Optimizations:
    1. Win rate tracking by frequency band (432Hz vs 528Hz vs 440Hz)
    2. Coherence threshold optimization based on actual outcomes
    3. Score threshold calibration using rolling performance
    4. Time-of-day pattern detection
    5. Volume correlation analysis
    """
    
    def __init__(self, history_file: str = 'adaptive_learning_history.json'):
        self.history_file = history_file
        self.trade_history: List[Dict] = []
        self.max_history = 500  # Keep last 500 trades for analysis

        # Keep a pristine copy of defaults for easy reset when data is stale
        self.default_thresholds = {
            'min_coherence': CONFIG.get('ENTRY_COHERENCE', 0.45),
            'min_score': CONFIG.get('MIN_SCORE', 65),
            'min_probability': CONFIG.get('PROB_MIN_CONFIDENCE', 0.50),
            'harmonic_bonus': CONFIG.get('HNC_HARMONIC_BONUS', 1.15),
            'distortion_penalty': CONFIG.get('HNC_DISTORTION_PENALTY', 0.70),
        }
        self.optimized_thresholds = self.default_thresholds.copy()
        self.recency_window_days = 10  # Ignore trades older than this to avoid stale fear
        
        # Performance metrics by category
        self.metrics_by_frequency: Dict[str, Dict] = {}  # freq_band -> {wins, losses, total_pnl}
        self.metrics_by_coherence: Dict[str, Dict] = {}  # coherence_range -> {wins, losses}
        self.metrics_by_score: Dict[str, Dict] = {}      # score_range -> {wins, losses}
        self.metrics_by_hour: Dict[int, Dict] = {}       # hour -> {wins, losses}
        self.metrics_by_action: Dict[str, Dict] = {}     # HNC action -> {wins, losses}
        
        # Learning parameters
        self.learning_rate = 0.05  # How quickly to adapt
        self.min_samples_for_learning = 20  # Minimum trades before adjusting
        self.confidence_interval = 0.95  # Statistical confidence for changes

        self._maybe_auto_reset_on_startup()
        
        self._load_history()

    def _maybe_auto_reset_on_startup(self) -> None:
        """Optionally reset learned analytics at process startup.

        Controlled by env vars:
        - AUREON_AUTO_RESET_LEARNED_ANALYTICS=1
        - AUREON_AUTO_RESET_LEARNED_ANALYTICS_REASON=...
        - AUREON_LEARNED_ANALYTICS_REGIME_TAG=...
        - AUREON_AUTO_RESET_LEARNED_ANALYTICS_FORCE=1
        - AUREON_AUTO_RESET_LEARNED_ANALYTICS_NO_ARCHIVE=1
        """
        try:
            from learned_analytics_reset import auto_reset_config, reset_learned_analytics_if_needed
        except Exception:
            return

        cfg = auto_reset_config()
        if not cfg.get('enabled'):
            # Make it explicit in logs when auto-reset isn't active.
            # This is especially helpful on Windows when `.env` loading can vary.
            logger.info(
                "Adaptive Learning: startup auto-reset disabled (set AUREON_AUTO_RESET_LEARNED_ANALYTICS=1 to enable)"
            )
            return

        result = reset_learned_analytics_if_needed(
            history_path=self.history_file,
            reason=str(cfg.get('reason') or 'startup auto reset'),
            regime_tag=str(cfg.get('regime_tag') or 'penny_profit_v1'),
            force=bool(cfg.get('force')),
            archive=bool(cfg.get('archive', True)),
        )

        if result.error:
            logger.warning(f"Adaptive Learning: auto-reset failed: {result.error}")
            return

        if result.did_reset:
            if result.backup_path:
                logger.info(f"Adaptive Learning: auto-reset complete (archived ‚Üí {result.backup_path})")
            else:
                logger.info("Adaptive Learning: auto-reset complete")
        
    def _load_history(self):
        """Load historical trades from file."""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r') as f:
                    data = json.load(f)
                    self.trade_history = data.get('trades', [])[-self.max_history:]
                    self.optimized_thresholds = {
                        **self.default_thresholds,
                        **data.get('thresholds', {})
                    }

                    stale_removed = self._filter_recent_trades()
                    if stale_removed:
                        logger.info(f"Adaptive Learning: dropped {stale_removed} stale trades (> {self.recency_window_days}d) to stay active")

                    self._clamp_thresholds()
                    self._rebuild_metrics()
                    
                    if not self.trade_history:
                        # If everything was stale, reset to defaults so the system will trade
                        self.optimized_thresholds = self.default_thresholds.copy()
                        logger.info("Adaptive Learning: no recent trades found, resetting thresholds to defaults")
        except Exception as e:
            logger.warning(f"Could not load learning history: {e}")
            
    def _save_history(self):
        """Save trade history and learned thresholds."""
        try:
            with open(self.history_file, 'w') as f:
                json.dump({
                    'trades': self.trade_history[-self.max_history:],
                    'thresholds': self.optimized_thresholds,
                    'updated_at': datetime.now().isoformat()
                }, f, indent=2)
        except Exception as e:
            logger.warning(f"Could not save learning history: {e}")
            
    def _rebuild_metrics(self):
        """Rebuild performance metrics from trade history."""
        self.metrics_by_frequency = {}
        self.metrics_by_coherence = {}
        self.metrics_by_score = {}
        self.metrics_by_hour = {}
        self.metrics_by_action = {}
        
        for trade in self.trade_history:
            self._update_metrics(trade)
            
    def _get_frequency_band(self, freq: float) -> str:
        """Map frequency to band name."""
        if freq <= 200:
            return '174_FOUNDATION'
        elif freq <= 300:
            return '256_ROOT'
        elif freq <= 410:
            return '396_LIBERATION'
        elif freq <= 438:
            return '432_NATURAL'
        elif freq <= 445:
            return '440_DISTORTION'
        elif freq <= 520:
            return '512_VISION'
        elif freq <= 580:
            return '528_LOVE'
        elif freq <= 700:
            return '639_CONNECTION'
        elif freq <= 800:
            return '741_AWAKENING'
        elif freq <= 900:
            return '852_INTUITION'
        else:
            return '963_UNITY'
            
    def _get_coherence_range(self, coherence: float) -> str:
        """Map coherence to range bucket."""
        if coherence < 0.3:
            return 'LOW_0-30'
        elif coherence < 0.5:
            return 'MED_30-50'
        elif coherence < 0.7:
            return 'HIGH_50-70'
        else:
            return 'VERY_HIGH_70+'
            
    def _get_score_range(self, score: float) -> str:
        """Map score to range bucket."""
        if score < 50:
            return 'LOW_0-50'
        elif score < 65:
            return 'MED_50-65'
        elif score < 80:
            return 'HIGH_65-80'
        else:
            return 'VERY_HIGH_80+'
            
    def _update_metrics(self, trade: Dict):
        """Update metrics with a single trade."""
        is_win = trade.get('pnl', 0) > 0
        pnl = trade.get('pnl', 0)
        
        # By frequency
        freq = trade.get('frequency', 256)
        band = self._get_frequency_band(freq)
        if band not in self.metrics_by_frequency:
            self.metrics_by_frequency[band] = {'wins': 0, 'losses': 0, 'total_pnl': 0, 'trades': []}
        self.metrics_by_frequency[band]['wins' if is_win else 'losses'] += 1
        self.metrics_by_frequency[band]['total_pnl'] += pnl
        self.metrics_by_frequency[band]['trades'].append(pnl)
        
        # By coherence
        coherence = trade.get('coherence', 0.5)
        coh_range = self._get_coherence_range(coherence)
        if coh_range not in self.metrics_by_coherence:
            self.metrics_by_coherence[coh_range] = {'wins': 0, 'losses': 0, 'trades': []}
        self.metrics_by_coherence[coh_range]['wins' if is_win else 'losses'] += 1
        self.metrics_by_coherence[coh_range]['trades'].append(pnl)
        
        # By score
        score = trade.get('score', 50)
        score_range = self._get_score_range(score)
        if score_range not in self.metrics_by_score:
            self.metrics_by_score[score_range] = {'wins': 0, 'losses': 0, 'trades': []}
        self.metrics_by_score[score_range]['wins' if is_win else 'losses'] += 1
        self.metrics_by_score[score_range]['trades'].append(pnl)
        
        # By hour of day
        entry_time = trade.get('entry_time', time.time())
        hour = datetime.fromtimestamp(entry_time).hour
        if hour not in self.metrics_by_hour:
            self.metrics_by_hour[hour] = {'wins': 0, 'losses': 0, 'trades': []}
        self.metrics_by_hour[hour]['wins' if is_win else 'losses'] += 1
        self.metrics_by_hour[hour]['trades'].append(pnl)
        
        # By HNC action
        action = trade.get('hnc_action', 'HOLD')
        if action not in self.metrics_by_action:
            self.metrics_by_action[action] = {'wins': 0, 'losses': 0, 'trades': []}
        self.metrics_by_action[action]['wins' if is_win else 'losses'] += 1
        self.metrics_by_action[action]['trades'].append(pnl)
        
    def record_trade(self, trade_data: Dict):
        """
        Record a completed trade for learning.
        
        trade_data should include:
        - symbol, entry_price, exit_price, pnl
        - frequency, coherence, score
        - entry_time, hnc_action, probability
        """
        self.trade_history.append(trade_data)
        if len(self.trade_history) > self.max_history:
            self.trade_history = self.trade_history[-self.max_history:]
            
        self._update_metrics(trade_data)
        
        # Periodically optimize thresholds
        if len(self.trade_history) % 10 == 0:
            self.optimize_thresholds()
            self._save_history()
            
    def optimize_thresholds(self):
        """
        Analyze trade history and optimize thresholds.
        Only adjusts if we have statistical confidence.
        """
        total_trades = len(self.trade_history)
        if total_trades < self.min_samples_for_learning:
            return  # Not enough data
            
        # 1. Optimize coherence threshold
        self._optimize_coherence_threshold()
        
        # 2. Optimize score threshold
        self._optimize_score_threshold()
        
        # 3. Optimize frequency bonuses/penalties
        self._optimize_frequency_modifiers()
        
        # 4. Optimize probability threshold
        self._optimize_probability_threshold()
        
        # Make sure nothing drifts into over-cautious territory
        self._clamp_thresholds()

        logger.info(f"üß† Adaptive Learning: Thresholds updated based on {total_trades} trades")

    def _filter_recent_trades(self) -> int:
        """Drop trades older than the recency window to avoid stale fear."""
        cutoff = time.time() - self.recency_window_days * 86400
        recent = [t for t in self.trade_history if t.get('entry_time', cutoff) >= cutoff]
        removed = len(self.trade_history) - len(recent)
        self.trade_history = recent
        return removed

    def _clamp_thresholds(self):
        """Clamp thresholds to sane ranges so stale data cannot freeze trading."""
        bounds = {
            'min_coherence': (0.30, 0.75),
            'min_score': (45, 75),
            'min_probability': (0.40, 0.65),
            'harmonic_bonus': (1.00, 1.30),
            'distortion_penalty': (0.50, 0.90),
        }
        for key, (low, high) in bounds.items():
            val = self.optimized_thresholds.get(key, self.default_thresholds.get(key, low))
            self.optimized_thresholds[key] = max(low, min(high, val))
        
    def _optimize_coherence_threshold(self):
        """Find optimal coherence threshold based on win rates."""
        best_threshold = self.optimized_thresholds['min_coherence']
        best_edge = 0
        
        # Test different coherence thresholds
        for threshold_name, metrics in self.metrics_by_coherence.items():
            total = metrics['wins'] + metrics['losses']
            if total < 5:
                continue
                
            win_rate = metrics['wins'] / total
            avg_pnl = sum(metrics['trades']) / len(metrics['trades']) if metrics['trades'] else 0
            
            # Edge = win_rate * avg_win - (1-win_rate) * avg_loss (simplified)
            edge = avg_pnl
            
            # Higher coherence ranges should have better edge
            if 'HIGH' in threshold_name or 'VERY_HIGH' in threshold_name:
                if edge > best_edge and win_rate > 0.50:
                    best_edge = edge
                    # Extract threshold from range name
                    if 'VERY_HIGH' in threshold_name:
                        best_threshold = 0.70
                    elif 'HIGH_50-70' in threshold_name:
                        best_threshold = 0.50
                        
        # Gradual adjustment
        current = self.optimized_thresholds['min_coherence']
        new_threshold = current + (best_threshold - current) * self.learning_rate
        self.optimized_thresholds['min_coherence'] = round(max(0.30, min(0.80, new_threshold)), 2)
        
    def _optimize_score_threshold(self):
        """Find optimal score threshold based on win rates."""
        best_threshold = self.optimized_thresholds['min_score']
        best_edge = 0
        
        for score_range, metrics in self.metrics_by_score.items():
            total = metrics['wins'] + metrics['losses']
            if total < 5:
                continue
                
            win_rate = metrics['wins'] / total
            avg_pnl = sum(metrics['trades']) / len(metrics['trades']) if metrics['trades'] else 0
            
            if 'HIGH' in score_range or 'VERY_HIGH' in score_range:
                if avg_pnl > best_edge and win_rate > 0.50:
                    best_edge = avg_pnl
                    if 'VERY_HIGH' in score_range:
                        best_threshold = 65  # Lowered from 80 to be less restrictive
                    elif 'HIGH' in score_range:
                        best_threshold = 50  # Lowered from 65
                        
        current = self.optimized_thresholds['min_score']
        new_threshold = current + (best_threshold - current) * self.learning_rate
        self.optimized_thresholds['min_score'] = int(max(40, min(70, new_threshold)))  # Lowered from 50-90
        
    def _optimize_frequency_modifiers(self):
        """Adjust harmonic bonus and distortion penalty based on actual performance."""
        # Check 528Hz (LOVE) performance
        love_metrics = self.metrics_by_frequency.get('528_LOVE', {})
        if love_metrics.get('wins', 0) + love_metrics.get('losses', 0) >= 5:
            love_win_rate = love_metrics['wins'] / (love_metrics['wins'] + love_metrics['losses'])
            if love_win_rate > 0.55:
                # Increase harmonic bonus
                current = self.optimized_thresholds['harmonic_bonus']
                self.optimized_thresholds['harmonic_bonus'] = min(1.30, current + 0.02)
            elif love_win_rate < 0.45:
                # Decrease harmonic bonus
                current = self.optimized_thresholds['harmonic_bonus']
                self.optimized_thresholds['harmonic_bonus'] = max(1.0, current - 0.02)
                
        # Check 440Hz (DISTORTION) performance
        distortion_metrics = self.metrics_by_frequency.get('440_DISTORTION', {})
        if distortion_metrics.get('wins', 0) + distortion_metrics.get('losses', 0) >= 5:
            distortion_win_rate = distortion_metrics['wins'] / (distortion_metrics['wins'] + distortion_metrics['losses'])
            if distortion_win_rate < 0.45:
                # Increase penalty (lower multiplier)
                current = self.optimized_thresholds['distortion_penalty']
                self.optimized_thresholds['distortion_penalty'] = max(0.50, current - 0.02)
            elif distortion_win_rate > 0.55:
                # Decrease penalty
                current = self.optimized_thresholds['distortion_penalty']
                self.optimized_thresholds['distortion_penalty'] = min(1.0, current + 0.02)
                
    def _optimize_probability_threshold(self):
        """Optimize probability confidence threshold."""
        # Analyze trades by probability outcome
        high_prob_trades = [t for t in self.trade_history if t.get('probability', 0.5) >= 0.65]
        low_prob_trades = [t for t in self.trade_history if t.get('probability', 0.5) < 0.40]
        
        if len(high_prob_trades) >= 10:
            high_prob_wins = sum(1 for t in high_prob_trades if t.get('pnl', 0) > 0)
            high_prob_wr = high_prob_wins / len(high_prob_trades)
            
            # If high probability trades are winning well, trust them more
            if high_prob_wr > 0.60:
                current = self.optimized_thresholds['min_probability']
                self.optimized_thresholds['min_probability'] = max(0.40, current - 0.02)
                
    def get_optimized_thresholds(self) -> Dict:
        """Return current optimized thresholds."""
        return self.optimized_thresholds.copy()
        
    def get_best_hours(self, top_n: int = 5) -> List[int]:
        """Return hours with best win rates."""
        hour_stats = []
        for hour, metrics in self.metrics_by_hour.items():
            total = metrics['wins'] + metrics['losses']
            if total >= 3:
                win_rate = metrics['wins'] / total
                hour_stats.append((hour, win_rate, total))
                
        hour_stats.sort(key=lambda x: x[1], reverse=True)
        return [h[0] for h in hour_stats[:top_n]]
        
    def get_best_frequency_bands(self) -> List[str]:
        """Return frequency bands with best performance."""
        band_stats = []
        for band, metrics in self.metrics_by_frequency.items():
            total = metrics['wins'] + metrics['losses']
            if total >= 5:
                win_rate = metrics['wins'] / total
                avg_pnl = metrics['total_pnl'] / total
                band_stats.append((band, win_rate, avg_pnl, total))
                
        band_stats.sort(key=lambda x: x[2], reverse=True)  # Sort by avg PnL
        return [b[0] for b in band_stats if b[1] > 0.50]  # Return profitable bands
        
    def get_learning_summary(self) -> str:
        """Get human-readable learning summary."""
        total = len(self.trade_history)
        wins = sum(1 for t in self.trade_history if t.get('pnl', 0) > 0)
        
        lines = [
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            "üß† ADAPTIVE LEARNING SUMMARY",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê",
            f"Total Trades Analyzed: {total}",
            f"Overall Win Rate: {wins/total*100:.1f}%" if total > 0 else "N/A",
            "",
            "Optimized Thresholds:",
            f"  ‚Ä¢ Min Coherence: {self.optimized_thresholds['min_coherence']:.2f}",
            f"  ‚Ä¢ Min Score: {self.optimized_thresholds['min_score']}",
            f"  ‚Ä¢ Min Probability: {self.optimized_thresholds['min_probability']:.2f}",
            f"  ‚Ä¢ Harmonic Bonus: {self.optimized_thresholds['harmonic_bonus']:.2f}x",
            f"  ‚Ä¢ Distortion Penalty: {self.optimized_thresholds['distortion_penalty']:.2f}x",
        ]
        
        best_bands = self.get_best_frequency_bands()
        if best_bands:
            lines.append("")
            lines.append("Best Frequency Bands:")
            for band in best_bands[:3]:
                metrics = self.metrics_by_frequency.get(band, {})
                total_b = metrics.get('wins', 0) + metrics.get('losses', 0)
                wr = metrics.get('wins', 0) / total_b * 100 if total_b > 0 else 0
                lines.append(f"  üéµ {band}: {wr:.0f}% WR ({total_b} trades)")
                
        best_hours = self.get_best_hours(3)
        if best_hours:
            lines.append("")
            lines.append("Best Trading Hours (UTC):")
            for hour in best_hours:
                metrics = self.metrics_by_hour.get(hour, {})
                total_h = metrics.get('wins', 0) + metrics.get('losses', 0)
                wr = metrics.get('wins', 0) / total_h * 100 if total_h > 0 else 0
                lines.append(f"  ‚è∞ {hour:02d}:00 - {wr:.0f}% WR ({total_h} trades)")
                
        return "\n".join(lines)
        
    def get_entry_recommendation(self, symbol: str, frequency: float, coherence: float, 
                                  score: int, probability: float, current_hour: int = None) -> Dict:
        """
        üéØ PROACTIVE ANALYTICS: Get recommendation BEFORE entering a trade.
        
        Returns learned insights based on historical performance for similar conditions.
        This is what was missing - the system now TELLS YOU what to expect.
        """
        if current_hour is None:
            current_hour = datetime.now().hour
            
        recommendation = {
            'should_trade': True,
            'confidence': 'low',
            'expected_win_rate': 0.50,
            'similar_trades': 0,
            'suggested_hold_cycles': CONFIG['MIN_HOLD_CYCLES'],
            'suggested_take_profit': CONFIG['TAKE_PROFIT_PCT'],
            'suggested_stop_loss': CONFIG['STOP_LOSS_PCT'],
            'warnings': [],
            'advantages': [],
            'frequency_insight': None,
            'hour_insight': None,
            'coherence_insight': None
        }
        
        # ‚ïê‚ïê‚ïê FREQUENCY BAND ANALYSIS ‚ïê‚ïê‚ïê
        band = self._get_frequency_band(frequency)
        freq_metrics = self.metrics_by_frequency.get(band, {'wins': 0, 'losses': 0, 'total_pnl': 0, 'trades': []})
        freq_total = freq_metrics.get('wins', 0) + freq_metrics.get('losses', 0)
        
        if freq_total >= 3:
            freq_wr = freq_metrics['wins'] / freq_total
            avg_pnl_per_trade = freq_metrics['total_pnl'] / freq_total if freq_total > 0 else 0
            
            recommendation['frequency_insight'] = {
                'band': band,
                'win_rate': freq_wr,
                'avg_pnl': avg_pnl_per_trade,
                'sample_size': freq_total
            }
            
            if freq_wr >= 0.60:
                recommendation['advantages'].append(f"üéµ {band} has {freq_wr*100:.0f}% WR ({freq_total} trades)")
                recommendation['expected_win_rate'] = max(recommendation['expected_win_rate'], freq_wr * 0.9)  # 10% confidence haircut
            elif freq_wr < 0.40:
                recommendation['warnings'].append(f"‚ö†Ô∏è {band} only {freq_wr*100:.0f}% WR - historically weak")
                recommendation['expected_win_rate'] = min(recommendation['expected_win_rate'], freq_wr * 1.1)
                
            # Adjust TP/SL based on historical PnL distribution
            if freq_metrics['trades']:
                winners = [p for p in freq_metrics['trades'] if p > 0]
                losers = [p for p in freq_metrics['trades'] if p < 0]
                if len(winners) >= 3:
                    avg_win = sum(winners) / len(winners)
                    # If winners average higher, we can afford tighter TP
                    if avg_win > 0.015:  # 1.5%
                        recommendation['suggested_take_profit'] = max(0.01, avg_win * 0.8)  # Take at 80% of avg win
                if len(losers) >= 3:
                    avg_loss = abs(sum(losers) / len(losers))
                    # If losses are typically small, we can tighten stop loss
                    if avg_loss < 0.01:  # <1%
                        recommendation['suggested_stop_loss'] = max(0.005, avg_loss * 1.2)
        
        # ‚ïê‚ïê‚ïê HOUR OF DAY ANALYSIS ‚ïê‚ïê‚ïê
        hour_metrics = self.metrics_by_hour.get(current_hour, {'wins': 0, 'losses': 0, 'trades': []})
        hour_total = hour_metrics.get('wins', 0) + hour_metrics.get('losses', 0)
        
        if hour_total >= 3:
            hour_wr = hour_metrics['wins'] / hour_total
            
            recommendation['hour_insight'] = {
                'hour': current_hour,
                'win_rate': hour_wr,
                'sample_size': hour_total
            }
            
            if hour_wr >= 0.65:
                recommendation['advantages'].append(f"‚è∞ {current_hour:02d}:00 is historically strong ({hour_wr*100:.0f}% WR)")
            elif hour_wr < 0.35:
                recommendation['warnings'].append(f"‚ö†Ô∏è {current_hour:02d}:00 is historically weak ({hour_wr*100:.0f}% WR)")
                
        # ‚ïê‚ïê‚ïê COHERENCE RANGE ANALYSIS ‚ïê‚ïê‚ïê  
        coh_range = self._get_coherence_range(coherence)
        coh_metrics = self.metrics_by_coherence.get(coh_range, {'wins': 0, 'losses': 0, 'trades': []})
        coh_total = coh_metrics.get('wins', 0) + coh_metrics.get('losses', 0)
        
        if coh_total >= 3:
            coh_wr = coh_metrics['wins'] / coh_total
            
            recommendation['coherence_insight'] = {
                'range': coh_range,
                'win_rate': coh_wr,
                'sample_size': coh_total
            }
            
            if coh_wr >= 0.60:
                recommendation['advantages'].append(f"‚ú® Coherence {coh_range} = {coh_wr*100:.0f}% WR historically")
            elif coh_wr < 0.40:
                recommendation['warnings'].append(f"‚ö†Ô∏è Coherence {coh_range} underperforms ({coh_wr*100:.0f}% WR)")
                
        # ‚ïê‚ïê‚ïê CALCULATE COMBINED EXPECTED WIN RATE ‚ïê‚ïê‚ïê
        contributing_factors = []
        if freq_total >= 3:
            contributing_factors.append(('frequency', freq_wr, freq_total))
        if hour_total >= 3:
            contributing_factors.append(('hour', hour_wr, hour_total))
        if coh_total >= 3:
            contributing_factors.append(('coherence', coh_wr, coh_total))
            
        if contributing_factors:
            # Weighted average by sample size
            total_weight = sum(f[2] for f in contributing_factors)
            weighted_wr = sum(f[1] * f[2] for f in contributing_factors) / total_weight
            recommendation['expected_win_rate'] = weighted_wr
            recommendation['similar_trades'] = total_weight
            
        # ‚ïê‚ïê‚ïê SET CONFIDENCE LEVEL ‚ïê‚ïê‚ïê
        total_similar = freq_total + hour_total + coh_total
        if total_similar >= 30 and len(contributing_factors) >= 2:
            recommendation['confidence'] = 'high'
        elif total_similar >= 10:
            recommendation['confidence'] = 'medium'
        else:
            recommendation['confidence'] = 'low'
            
        # ‚ïê‚ïê‚ïê DETERMINE TRADE RECOMMENDATION ‚ïê‚ïê‚ïê
        # CRITICAL: Use the actual historical data to make decisions!
        # Historical evidence: 256_ROOT = 100% WR, 432_NATURAL = 18% WR
        # Historical evidence: Hour 14-15 = 90%+ WR, Hour 16-17 = 8% WR
        
        # Hard block on proven losing patterns
        if band == '432_NATURAL' and freq_total >= 5:
            freq_wr = freq_metrics.get('wins', 0) / freq_total
            if freq_wr < 0.30:  # 432 historically loses - BLOCK
                recommendation['should_trade'] = False
                recommendation['warnings'].append(f"‚ùå BLOCKED: {band} = {freq_wr*100:.0f}% WR historically")
                
        # Hard block on losing hours
        # IMPORTANT: hour-of-day is a noisy feature with small sample sizes.
        # Only hard-block when we have enough hour-specific observations.
        if hour_total >= 3:
            hour_wr = hour_metrics.get('wins', 0) / hour_total
            # With small n, warn but don't hard-block.
            if hour_total < 10:
                if hour_wr < 0.25:
                    recommendation['warnings'].append(
                        f"‚ö†Ô∏è Hour {current_hour}:00 looks weak ({hour_wr*100:.0f}% WR on {hour_total} trades)"
                    )
            else:
                if hour_wr < 0.25:  # This hour loses - BLOCK
                    recommendation['should_trade'] = False
                    recommendation['warnings'].append(f"‚ùå BLOCKED: Hour {current_hour}:00 = {hour_wr*100:.0f}% WR")
                
        # Block on very low expected win rate (with confidence)
        if recommendation['expected_win_rate'] < 0.40 and recommendation['confidence'] in ['high', 'medium']:
            recommendation['should_trade'] = False
            recommendation['warnings'].append(f"‚ùå Expected WR {recommendation['expected_win_rate']*100:.0f}% too low")
            
        # Block on multiple warnings
        if len([w for w in recommendation['warnings'] if '‚ùå' in w]) >= 2:
            recommendation['should_trade'] = False
            recommendation['warnings'].append("‚ùå Multiple blocking factors")
            
        # ‚ïê‚ïê‚ïê HOLD TIME SUGGESTION ‚ïê‚ïê‚ïê
        # If frequency band has high variance, suggest longer hold
        if freq_metrics['trades']:
            pnl_variance = sum((p - (freq_metrics['total_pnl']/max(1,freq_total)))**2 for p in freq_metrics['trades']) / max(1, freq_total)
            if pnl_variance > 0.001:  # High variance
                recommendation['suggested_hold_cycles'] = min(20, CONFIG['MIN_HOLD_CYCLES'] + 5)
                recommendation['advantages'].append("üìä High variance band - extended hold suggested")
                
        return recommendation
        
    def get_recommendation_summary(self, recommendation: Dict) -> str:
        """Format recommendation as human-readable summary for logging."""
        lines = []
        
        conf_emoji = {'high': 'üü¢', 'medium': 'üü°', 'low': '‚ö™'}.get(recommendation['confidence'], '‚ö™')
        trade_emoji = '‚úÖ' if recommendation['should_trade'] else '‚ùå'
        
        lines.append(f"  {trade_emoji} Trade: {'RECOMMENDED' if recommendation['should_trade'] else 'SKIP'}")
        lines.append(f"  {conf_emoji} Confidence: {recommendation['confidence'].upper()} ({recommendation['similar_trades']} similar trades)")
        lines.append(f"  üìà Expected WR: {recommendation['expected_win_rate']*100:.0f}%")
        
        if recommendation['advantages']:
            for adv in recommendation['advantages'][:2]:
                lines.append(f"    {adv}")
                
        if recommendation['warnings']:
            for warn in recommendation['warnings'][:2]:
                lines.append(f"    {warn}")
                
        lines.append(f"  üí° Suggested: TP {recommendation['suggested_take_profit']*100:.1f}% / SL {recommendation['suggested_stop_loss']*100:.1f}% / Hold {recommendation['suggested_hold_cycles']} cycles")
        
        return "\n".join(lines)
    
    def record_brain_state(self, brain_feature: Dict):
        """
        üß† Record brain state for correlation with trade outcomes.
        
        Called by EcosystemBrainBridge after each wisdom cycle.
        Allows learning correlation between brain signals and trade success.
        
        Args:
            brain_feature: Dict with keys like:
                - brain_consensus (BULLISH/BEARISH/NEUTRAL)
                - brain_confidence (0-1)
                - fear_greed (0-100)
                - manipulation_risk (0-1)
                - civilization_agreement (0-1)
        """
        if not hasattr(self, 'brain_state_history'):
            self.brain_state_history = []
            
        # Add timestamp
        brain_feature['timestamp'] = time.time()
        
        self.brain_state_history.append(brain_feature)
        
        # Keep last 100 brain states
        if len(self.brain_state_history) > 100:
            self.brain_state_history = self.brain_state_history[-100:]
        
        # Log significant brain states
        if brain_feature.get('brain_confidence', 0) > 0.8:
            logger.debug(f"üß† High confidence brain state: {brain_feature['brain_consensus']} ({brain_feature['brain_confidence']:.0%})")
    
    def get_brain_correlation(self) -> Dict:
        """
        Analyze correlation between brain states and trade outcomes.
        
        Returns insights about which brain states lead to winning trades.
        """
        if not hasattr(self, 'brain_state_history') or not self.brain_state_history:
            return {'status': 'no_data'}
        
        # Match brain states to trades by timestamp
        correlations = {
            'bullish_win_rate': 0.0,
            'bearish_win_rate': 0.0,
            'high_confidence_win_rate': 0.0,
            'extreme_fear_win_rate': 0.0,
            'samples': 0
        }
        
        bullish_trades = [t for t in self.trade_history 
                        if self._brain_at_time(t.get('entry_time', 0)) == 'BULLISH']
        bearish_trades = [t for t in self.trade_history 
                        if self._brain_at_time(t.get('entry_time', 0)) == 'BEARISH']
        
        if bullish_trades:
            wins = sum(1 for t in bullish_trades if t.get('pnl', 0) > 0)
            correlations['bullish_win_rate'] = wins / len(bullish_trades)
            
        if bearish_trades:
            wins = sum(1 for t in bearish_trades if t.get('pnl', 0) > 0)
            correlations['bearish_win_rate'] = wins / len(bearish_trades)
            
        correlations['samples'] = len(self.brain_state_history)
        
        return correlations
    
    def _brain_at_time(self, timestamp: float) -> str:
        """Find brain consensus closest to a given timestamp."""
        if not hasattr(self, 'brain_state_history') or not self.brain_state_history:
            return 'NEUTRAL'
        
        closest = min(self.brain_state_history, 
                     key=lambda x: abs(x.get('timestamp', 0) - timestamp))
        return closest.get('brain_consensus', 'NEUTRAL')

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìöüì∞ KNOWLEDGE & NEWS LEARNING INTEGRATION
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def record_knowledge_event(self, event: Dict):
        """
        üìö Record knowledge discovery event for correlation analysis.
        
        Called when the KnowledgeBase discovers relevant information.
        Tracks:
        - What was researched (topic, articles found)
        - When it was discovered
        - Market conditions at discovery time
        
        Later correlated with trade outcomes to learn which knowledge
        topics are predictive of profitable trades.
        
        Args:
            event: Dict with keys like:
                - topic: What was researched
                - articles_found: Number of articles
                - key_concepts: List of discovered concepts
                - timestamp: When discovered
                - market_context: Optional market state at time
        """
        if not hasattr(self, 'knowledge_event_history'):
            self.knowledge_event_history = []
            
        event['recorded_at'] = time.time()
        self.knowledge_event_history.append(event)
        
        # Keep last 200 knowledge events
        if len(self.knowledge_event_history) > 200:
            self.knowledge_event_history = self.knowledge_event_history[-200:]
        
        logger.debug(f"üìö Knowledge event recorded: {event.get('topic', 'unknown')}")
    
    def record_news_sentiment(self, sentiment_data: Dict):
        """
        üì∞ Record news sentiment for correlation with trade outcomes.
        
        Called when the NewsFeed publishes sentiment analysis.
        Tracks:
        - Overall sentiment (bullish/bearish/neutral)
        - Confidence level
        - Domain-specific sentiments (crypto, stocks)
        - Risk level from news
        
        Args:
            sentiment_data: Dict with keys like:
                - sentiment: float [-1, 1]
                - label: bullish/bearish/neutral
                - confidence: 0-1
                - crypto_sentiment: float
                - stock_sentiment: float
                - risk_level: normal/elevated/high
        """
        if not hasattr(self, 'news_sentiment_history'):
            self.news_sentiment_history = []
            
        sentiment_data['recorded_at'] = time.time()
        self.news_sentiment_history.append(sentiment_data)
        
        # Keep last 100 sentiment snapshots
        if len(self.news_sentiment_history) > 100:
            self.news_sentiment_history = self.news_sentiment_history[-100:]
        
        # Track metrics by sentiment label for learning
        if not hasattr(self, 'metrics_by_news_sentiment'):
            self.metrics_by_news_sentiment = {}
        
        label = sentiment_data.get('label', 'neutral')
        if label not in self.metrics_by_news_sentiment:
            self.metrics_by_news_sentiment[label] = {'trades': 0, 'wins': 0, 'total_pnl': 0}
        
        logger.debug(f"üì∞ News sentiment recorded: {label} ({sentiment_data.get('sentiment', 0):.3f})")
    
    def get_news_sentiment_at_time(self, timestamp: float) -> Dict:
        """Get the news sentiment closest to a given timestamp."""
        if not hasattr(self, 'news_sentiment_history') or not self.news_sentiment_history:
            return {'label': 'neutral', 'sentiment': 0.0, 'confidence': 0.0}
        
        closest = min(self.news_sentiment_history,
                     key=lambda x: abs(x.get('recorded_at', 0) - timestamp))
        return closest
    
    def correlate_trade_with_news(self, trade_data: Dict):
        """
        Correlate a completed trade with the news sentiment at entry time.
        Updates metrics to learn which news states lead to winning trades.
        """
        if not hasattr(self, 'metrics_by_news_sentiment'):
            self.metrics_by_news_sentiment = {}
        
        entry_time = trade_data.get('entry_time', time.time())
        news_at_entry = self.get_news_sentiment_at_time(entry_time)
        
        label = news_at_entry.get('label', 'neutral')
        is_win = trade_data.get('pnl', 0) > 0
        pnl = trade_data.get('pnl', 0)
        
        if label not in self.metrics_by_news_sentiment:
            self.metrics_by_news_sentiment[label] = {'trades': 0, 'wins': 0, 'total_pnl': 0}
        
        self.metrics_by_news_sentiment[label]['trades'] += 1
        if is_win:
            self.metrics_by_news_sentiment[label]['wins'] += 1
        self.metrics_by_news_sentiment[label]['total_pnl'] += pnl
        
        # Store correlation for this trade
        trade_data['news_sentiment_at_entry'] = news_at_entry.get('label', 'neutral')
        trade_data['news_confidence_at_entry'] = news_at_entry.get('confidence', 0.0)
    
    def get_news_correlation_insights(self) -> Dict:
        """
        Get insights about correlation between news sentiment and trade outcomes.
        
        Returns:
            Dict with win rates by news sentiment type
        """
        insights = {
            'status': 'analyzing',
            'by_sentiment': {},
            'recommendation': 'neutral',
            'total_samples': 0
        }
        
        if not hasattr(self, 'metrics_by_news_sentiment'):
            insights['status'] = 'no_data'
            return insights
        
        for label, metrics in self.metrics_by_news_sentiment.items():
            trades = metrics.get('trades', 0)
            wins = metrics.get('wins', 0)
            total_pnl = metrics.get('total_pnl', 0)
            
            if trades >= 3:  # Minimum sample for statistical relevance
                win_rate = wins / trades
                avg_pnl = total_pnl / trades
                
                insights['by_sentiment'][label] = {
                    'win_rate': win_rate,
                    'avg_pnl': avg_pnl,
                    'trades': trades
                }
                insights['total_samples'] += trades
        
        # Generate recommendation
        if insights['by_sentiment']:
            best_sentiment = max(insights['by_sentiment'].items(),
                               key=lambda x: x[1]['win_rate'])
            worst_sentiment = min(insights['by_sentiment'].items(),
                                key=lambda x: x[1]['win_rate'])
            
            if best_sentiment[1]['win_rate'] > 0.55:
                insights['recommendation'] = f"Trade MORE during {best_sentiment[0]} news"
            if worst_sentiment[1]['win_rate'] < 0.40:
                insights['recommendation'] += f", AVOID {worst_sentiment[0]} news"
        
        insights['status'] = 'complete'
        return insights
    
    def get_knowledge_probability_modifier(self, topic: str) -> float:
        """
        Get a probability modifier based on what knowledge we've learned.
        
        If we've researched a topic and trades in that area performed well,
        boost the probability. If they performed poorly, reduce it.
        
        Args:
            topic: The topic/symbol being traded
            
        Returns:
            float modifier (1.0 = neutral, >1 = boost, <1 = penalize)
        """
        if not hasattr(self, 'knowledge_event_history'):
            return 1.0
        
        # Find knowledge events related to this topic
        related_events = [e for e in self.knowledge_event_history
                        if topic.lower() in str(e.get('topic', '')).lower() or
                           topic.lower() in str(e.get('key_concepts', [])).lower()]
        
        if not related_events:
            return 1.0
        
        # Check trades made after knowledge discovery
        modifier = 1.0
        for event in related_events[-5:]:  # Last 5 related events
            event_time = event.get('recorded_at', 0)
            # Find trades made within 1 hour of knowledge discovery
            related_trades = [t for t in self.trade_history
                            if event_time <= t.get('entry_time', 0) <= event_time + 3600]
            
            if related_trades:
                win_rate = sum(1 for t in related_trades if t.get('pnl', 0) > 0) / len(related_trades)
                # Adjust modifier based on performance
                if win_rate >= 0.6:
                    modifier = min(modifier * 1.1, 1.3)  # Boost up to 30%
                elif win_rate <= 0.4:
                    modifier = max(modifier * 0.9, 0.7)  # Penalize down to 30%
        
        return modifier
    
    def enhanced_record_trade(self, trade_data: Dict):
        """
        Enhanced trade recording that includes news/knowledge correlation.
        
        Call this instead of record_trade to get full learning integration.
        """
        # Correlate with news sentiment
        self.correlate_trade_with_news(trade_data)
        
        # Get knowledge modifier that was active during entry
        entry_time = trade_data.get('entry_time', time.time())
        
        # Find what knowledge was recently discovered
        if hasattr(self, 'knowledge_event_history'):
            recent_knowledge = [e for e in self.knowledge_event_history
                              if entry_time - 3600 <= e.get('recorded_at', 0) <= entry_time]
            if recent_knowledge:
                trade_data['knowledge_context'] = [e.get('topic') for e in recent_knowledge[:3]]
        
        # Record the trade with all enrichments
        self.record_trade(trade_data)
        
        # Save enhanced history
        self._save_enhanced_history()
    
    def _save_enhanced_history(self):
        """Save enhanced learning history including knowledge/news data."""
        try:
            enhanced_data = {
                'trades': self.trade_history[-self.max_history:],
                'thresholds': self.optimized_thresholds,
                'updated_at': datetime.now().isoformat(),
                'news_metrics': getattr(self, 'metrics_by_news_sentiment', {}),
                'knowledge_events': getattr(self, 'knowledge_event_history', [])[-50:],
                'news_history': getattr(self, 'news_sentiment_history', [])[-50:]
            }
            with open(self.history_file, 'w') as f:
                json.dump(enhanced_data, f, indent=2)
        except Exception as e:
            logger.warning(f"Could not save enhanced history: {e}")
    
    def get_learning_summary_enhanced(self) -> str:
        """Get enhanced learning summary including knowledge/news insights."""
        base_summary = self.get_learning_summary()
        
        # Add news insights
        news_insights = self.get_news_correlation_insights()
        if news_insights['status'] == 'complete' and news_insights['total_samples'] >= 5:
            base_summary += "\n\n   üì∞ NEWS CORRELATION:"
            for label, metrics in news_insights['by_sentiment'].items():
                emoji = 'üêÇ' if label == 'bullish' else 'üêª' if label == 'bearish' else 'üìä'
                base_summary += f"\n      {emoji} {label.upper()}: {metrics['win_rate']*100:.0f}% WR ({metrics['trades']} trades)"
            if news_insights['recommendation']:
                base_summary += f"\n      üí° {news_insights['recommendation']}"
        
        # Add knowledge insights
        if hasattr(self, 'knowledge_event_history') and self.knowledge_event_history:
            base_summary += f"\n\n   üìö KNOWLEDGE BASE: {len(self.knowledge_event_history)} research events tracked"
        
        return base_summary


# Global adaptive learning instance
ADAPTIVE_LEARNER = AdaptiveLearningEngine()

# üçÑ Register ADAPTIVE_LEARNER with Mycelium Network
try:
    register_to_mycelium('learner', ADAPTIVE_LEARNER)
except Exception as e:
    print(f"   ‚ö†Ô∏è Could not register learner to mycelium: {e}")


def sync_exchange_trades_to_brain():
    """
    üß†üìà SYNC EXCHANGE TRADE HISTORY TO ADAPTIVE LEARNER
    
    Pulls real trade history from ALL exchanges (Kraken + Binance) and feeds 
    it to the brain so it can learn from actual wins/losses.
    
    This provides:
    - Real P&L data from actual trades
    - Entry/exit timestamps for time-of-day analysis
    - Pair performance tracking
    - Running balance history for drawdown analysis
    - Cross-exchange learning (what works on Kraken vs Binance)
    """
    from datetime import datetime
    
    total_synced = 0
    total_wins = 0
    total_losses = 0
    exchange_results = {}
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ü¶ë KRAKEN TRADE SYNC
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    try:
        import krakenex
        
        kraken = krakenex.API()
        kraken.key = os.getenv('KRAKEN_API_KEY')
        kraken.secret = os.getenv('KRAKEN_API_SECRET')
        
        if kraken.key and kraken.secret:
            result = kraken.query_private('TradesHistory', {'trades': True})
            
            if not result.get('error'):
                trades = result.get('result', {}).get('trades', {})
                
                if trades:
                    trade_list = sorted(trades.values(), key=lambda x: float(x.get('time', 0)))
                    pair_holdings = {}
                    kraken_synced = 0
                    kraken_wins = 0
                    kraken_losses = 0
                    
                    for trade in trade_list:
                        pair = trade.get('pair', '')
                        side = trade.get('type', '').upper()
                        price = float(trade.get('price', 0))
                        vol = float(trade.get('vol', 0))
                        cost = float(trade.get('cost', 0))
                        fee = float(trade.get('fee', 0))
                        trade_time = float(trade.get('time', 0))
                        
                        if side == 'BUY':
                            if pair not in pair_holdings:
                                pair_holdings[pair] = {'qty': 0, 'cost_basis': 0, 'entry_time': trade_time}
                            pair_holdings[pair]['qty'] += vol
                            pair_holdings[pair]['cost_basis'] += cost + fee
                            pair_holdings[pair]['entry_time'] = trade_time
                            
                        elif side == 'SELL':
                            realized_pnl = 0
                            cost_of_sold = 0
                            avg_cost = price
                            if pair in pair_holdings and pair_holdings[pair]['qty'] > 0:
                                avg_cost = pair_holdings[pair]['cost_basis'] / pair_holdings[pair]['qty']
                                cost_of_sold = avg_cost * vol
                                proceeds = cost - fee
                                realized_pnl = proceeds - cost_of_sold
                                pair_holdings[pair]['qty'] -= vol
                                pair_holdings[pair]['cost_basis'] -= cost_of_sold
                            
                            trade_record = {
                                'symbol': pair,
                                'entry_price': avg_cost / vol if vol > 0 else price,
                                'exit_price': price,
                                'pnl': realized_pnl,
                                'pnl_pct': (realized_pnl / cost_of_sold * 100) if cost_of_sold > 0 else 0,
                                'entry_time': pair_holdings.get(pair, {}).get('entry_time', trade_time),
                                'exit_time': trade_time,
                                'quantity': vol,
                                'frequency': 432,
                                'coherence': 0.5,
                                'score': 70,
                                'probability': 0.6,
                                'hnc_action': 'HOLD',
                                'source': 'kraken',
                                'exchange': 'kraken'
                            }
                            
                            ADAPTIVE_LEARNER.record_trade(trade_record)
                            kraken_synced += 1
                            if realized_pnl > 0:
                                kraken_wins += 1
                            else:
                                kraken_losses += 1
                    
                    total_synced += kraken_synced
                    total_wins += kraken_wins
                    total_losses += kraken_losses
                    exchange_results['kraken'] = {'synced': kraken_synced, 'wins': kraken_wins, 'losses': kraken_losses}
                    logger.info(f"ü¶ë Kraken: Synced {kraken_synced} trades | W:{kraken_wins} L:{kraken_losses}")
            else:
                logger.warning(f"ü¶ë Kraken API error: {result.get('error')}")
        else:
            logger.debug("ü¶ë Kraken API keys not configured - skipping")
            
    except Exception as e:
        logger.warning(f"ü¶ë Kraken sync error: {e}")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üü° BINANCE TRADE SYNC
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    try:
        from binance_client import BinanceClient
        
        binance_key = os.getenv('BINANCE_API_KEY')
        binance_secret = os.getenv('BINANCE_API_SECRET')
        
        if binance_key and binance_secret:
            binance = BinanceClient()
            
            # Get all trades from Binance
            all_trades = binance.get_all_my_trades()
            
            if all_trades:
                binance_synced = 0
                binance_wins = 0
                binance_losses = 0
                pair_holdings = {}
                
                # Flatten and sort all trades by time
                all_trade_list = []
                for symbol, trades in all_trades.items():
                    for trade in trades:
                        trade['_symbol'] = symbol
                        all_trade_list.append(trade)
                
                all_trade_list.sort(key=lambda x: x.get('time', 0))
                
                for trade in all_trade_list:
                    symbol = trade.get('_symbol', '')
                    is_buyer = trade.get('isBuyer', False)
                    price = float(trade.get('price', 0))
                    qty = float(trade.get('qty', 0))
                    quote_qty = float(trade.get('quoteQty', price * qty))
                    commission = float(trade.get('commission', 0))
                    trade_time = trade.get('time', 0) / 1000  # Binance uses milliseconds
                    
                    if is_buyer:
                        if symbol not in pair_holdings:
                            pair_holdings[symbol] = {'qty': 0, 'cost_basis': 0, 'entry_time': trade_time}
                        pair_holdings[symbol]['qty'] += qty
                        pair_holdings[symbol]['cost_basis'] += quote_qty + commission
                        pair_holdings[symbol]['entry_time'] = trade_time
                        
                    else:  # SELL
                        realized_pnl = 0
                        cost_of_sold = 0
                        avg_cost = price
                        if symbol in pair_holdings and pair_holdings[symbol]['qty'] > 0:
                            avg_cost = pair_holdings[symbol]['cost_basis'] / pair_holdings[symbol]['qty']
                            cost_of_sold = avg_cost * qty
                            proceeds = quote_qty - commission
                            realized_pnl = proceeds - cost_of_sold
                            pair_holdings[symbol]['qty'] -= qty
                            pair_holdings[symbol]['cost_basis'] -= cost_of_sold
                        
                        trade_record = {
                            'symbol': symbol,
                            'entry_price': avg_cost / qty if qty > 0 else price,
                            'exit_price': price,
                            'pnl': realized_pnl,
                            'pnl_pct': (realized_pnl / cost_of_sold * 100) if cost_of_sold > 0 else 0,
                            'entry_time': pair_holdings.get(symbol, {}).get('entry_time', trade_time),
                            'exit_time': trade_time,
                            'quantity': qty,
                            'frequency': 432,
                            'coherence': 0.5,
                            'score': 70,
                            'probability': 0.6,
                            'hnc_action': 'HOLD',
                            'source': 'binance',
                            'exchange': 'binance'
                        }
                        
                        ADAPTIVE_LEARNER.record_trade(trade_record)
                        binance_synced += 1
                        if realized_pnl > 0:
                            binance_wins += 1
                        else:
                            binance_losses += 1
                
                total_synced += binance_synced
                total_wins += binance_wins
                total_losses += binance_losses
                exchange_results['binance'] = {'synced': binance_synced, 'wins': binance_wins, 'losses': binance_losses}
                logger.info(f"üü° Binance: Synced {binance_synced} trades | W:{binance_wins} L:{binance_losses}")
        else:
            logger.debug("üü° Binance API keys not configured - skipping")
            
    except Exception as e:
        logger.warning(f"üü° Binance sync error: {e}")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìä FINAL SUMMARY
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # Save updated learning history
    ADAPTIVE_LEARNER._save_history()
    
    total = total_wins + total_losses
    win_rate = (total_wins / total * 100) if total > 0 else 0
    
    logger.info(f"üß†üìà TOTAL: Synced {total_synced} trades from {len(exchange_results)} exchanges | WR: {win_rate:.1f}%")
    
    return {
        'status': 'success',
        'trades_synced': total_synced,
        'wins': total_wins,
        'losses': total_losses,
        'win_rate': win_rate,
        'exchanges': exchange_results
    }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä PROBABILITY REPORT GENERATOR - Auto-Regenerates Every 15 Seconds
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ProbabilityReportGenerator:
    """
    Automatic probability report generator that runs in background thread.
    
    Features:
    - Generates fresh probability reports every 15 seconds
    - Supports multiple exchanges (Binance, Kraken, Alpaca)
    - Feeds into AdaptiveLearningEngine for continuous learning
    - Updates JSON files consumed by ProbabilityLoader
    - Lightweight - uses cached tickers to minimize API calls
    """
    
    # Symbols to analyze per exchange
    # ü§ë EXPANDED LIST - includes many altcoins and meme coins!
    BINANCE_SYMBOLS = [
        # Major coins
        'BTCUSDC', 'ETHUSDC', 'BNBUSDC', 'SOLUSDC', 'XRPUSDC', 'ADAUSDC', 'AVAXUSDC', 'DOGEUSDC', 'LINKUSDC',
        'MATICUSDC', 'DOTUSDC', 'ATOMUSDC', 'FILUSDC', 'LTCUSDC', 'SUIUSDC', 'APTUSDC', 'ARBUSDC',
        'OPUSDC', 'NEARUSDC', 'UNIUSDC', 'INJUSDC', 'FETUSDC', 'PEPEUSDC', 'SHIBUSDC',
        # Additional altcoins you hold
        'XLMUSDC', 'TWTUSDC', 'HMSTRUSDC', 'PENGUUSDC', 'ALTUSDC', 'HBARUSDC', 'CHZUSDC',
        'TURBOUSDC', 'MEMEUSDC', 'DOGSUSDC', 'WLDUSDC', 'SEIUSDC', 'TIAUSDC', 'WIFUSDC',
        'RAYUSDC', 'RUNEUSDC', 'ENAENAUSDC', 'ORDIUSDC', 'ICPUSDC', 'STRKUSDC', 'RENDERUSDC',
        'ARUSDC', 'MOVEUSDC', 'BERABERUSDC', 'TRUMPUSDC',
        # Also try USDT pairs for more liquidity
        'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT', 'ADAUSDT', 'AVAXUSDT', 'DOGEUSDT',
        'XLMUSDT', 'TWTUSDT', 'HMSTRUSDT', 'PENGUUSDT', 'HBARUSDT', 'CHZUSDT', 'PEPEUSDT',
        'SHIBUSDT', 'TURBOUSDT', 'MEMEUSDT', 'WLDUSDT', 'NEARUSDT', 'SUIUSDT', 'APTUSDT',
        'ARBUSDT', 'OPUSDT', 'INJUSDT', 'FETUSDT', 'LINKUSDT', 'DOTUSDT', 'ATOMUSDT',
    ]
    
    # üêô KRAKEN SYMBOLS - Comprehensive list of 70+ tradeable pairs
    KRAKEN_SYMBOLS = [
        # === TOP TIER (BTC, ETH, Major L1s) ===
        'XXBTZUSD', 'XETHZUSD', 'SOLUSD', 'XRPUSD', 'ADAUSD', 'AVAXUSD', 'DOTUSD', 
        'ATOMUSD', 'NEARUSD', 'ICPUSD', 'APTUSD', 'SUIUSD', 'SEIUSD', 'TIAUSD',
        
        # === LAYER 2s & SCALING ===
        'ARBUSD', 'OPUSD', 'MATICUSD', 'STXUSD', 'IMXUSD', 'LPTUSD',
        
        # === DEFI BLUE CHIPS ===
        'UNIUSD', 'AAVEUSD', 'LINKUSD', 'MKRUSD', 'CRVUSD', 'COMPUSD', 'SNXUSD',
        'SUSHIUSD', 'YFIUSD', 'DYDXUSD', 'GRTUSD', 'ENSUSD', 'LDOUSD', 'PENDLEUSD',
        
        # === AI & DATA ===
        'FETUSD', 'RENDERUSD', 'INJUSD', 'WLDUSD', 'PYTHUSD', 'JTOUSD', 'ONDOUSD',
        
        # === GAMING & METAVERSE ===
        'AXSUSD', 'MANAUSD', 'SANDUSD', 'GALAUSD', 'FLOWUSD', 'GMTUSD', 'ORCAUSD',
        
        # === MEMECOINS (High volatility = opportunity) ===
        'DOGEUSD', 'SHIBUSD', 'PEPEUSD', 'BONKUSD', 'FLOKIUSD', 'WIFUSD', 'MOGUSD',
        'PENGUUSD', 'TRUMPUSD', 'MELANIAUSD', 'WENUSD',
        
        # === MID CAPS ===
        'LTCUSD', 'ETCUSD', 'FILUSD', 'ALGOUSD', 'XLMUSD', 'ZECUSD', 'TRXUSD',
        'HBARUSD', 'QNTUSD', 'KAVAUSD', 'RUNEUSD', 'MOVEUSD', 'JUPUSD',
        
        # === EMERGING & SPECULATIVE ===
        'APEUSD', 'CHZUSD', 'MASKUSD', 'JASMYUSD', 'ZRXUSD',
        
        # === USDC PAIRS (Kraken has limited USDC support - using USD pairs instead) ===
        # NOTE: DOGEUSDC is NOT available on Kraken - use DOGEUSD instead
        'XXBTUSDC', 'XETHUSDC', 'SOLUSDC', 'XLMUSDC', 'ADAUSDC', 'XRPUSDC',
    ]
    
    def __init__(self, report_dir: str = '.', interval_seconds: float = 15.0):
        self.report_dir = report_dir
        self.interval = interval_seconds
        self._running = False
        self._thread: Optional[threading.Thread] = None
        self._lock = threading.Lock()
        
        # Initialize HNC integration if available
        self.hnc_integration = None
        if PROB_MATRIX_AVAILABLE:
            try:
                self.hnc_integration = HNCProbabilityIntegration()
            except Exception as e:
                logger.warning(f"Could not initialize HNC integration: {e}")
        
        # Price cache for momentum calculations
        self._price_history: Dict[str, List[Tuple[float, float]]] = {}  # symbol -> [(timestamp, price), ...]
        self._max_price_history = 10  # Keep last 10 prices for momentum
        
        # üáÆüá™üéØ IRA SNIPER MODE INTEGRATION
        self._sniper_coverage: Dict[str, Any] = {}
        self._sniper_brain = None
        self._celtic_sniper = None
        if CELTIC_SNIPER_AVAILABLE:
            try:
                self._celtic_sniper = get_celtic_sniper()
                logger.info("   üéØ Celtic Sniper linked to Probability Generator")
            except Exception as e:
                logger.debug(f"Celtic sniper not available: {e}")
        if SNIPER_BRAIN_AVAILABLE:
            try:
                self._sniper_brain = get_unified_brain('probability', position_size=10.0)
                logger.info("   üß† Sniper Brain linked to Probability Generator")
            except Exception as e:
                logger.debug(f"Sniper brain not available: {e}")
        
        # Generation stats
        self.last_generation = 0.0
        self.generation_count = 0
        self.last_results: Dict[str, List[Dict]] = {}
        
        logger.info(f"üìä ProbabilityReportGenerator initialized (interval={interval_seconds}s)")
    
    def start(self, ecosystem: 'AureonKrakenEcosystem' = None):
        """Start background probability generation."""
        if self._running:
            return
        
        self._running = True
        self._ecosystem = ecosystem
        
        # üéØ Sync sniper coverage from ecosystem
        if ecosystem and hasattr(ecosystem, 'sniper_coverage'):
            self._sniper_coverage = ecosystem.sniper_coverage or {}
        if ecosystem and hasattr(ecosystem, 'sniper_brain'):
            self._sniper_brain = ecosystem.sniper_brain
        
        self._thread = threading.Thread(target=self._generation_loop, daemon=True)
        self._thread.start()
        logger.info("üìä Probability Report Generator STARTED (background thread)")
    
    def stop(self):
        """Stop background generation."""
        self._running = False
        if self._thread:
            self._thread.join(timeout=5.0)
        logger.info("üìä Probability Report Generator STOPPED")
    
    def _generation_loop(self):
        """Main generation loop - runs every interval_seconds."""
        while self._running:
            try:
                self._generate_all_reports()
            except Exception as e:
                logger.error(f"Probability generation error: {e}")
            
            # Sleep in small chunks to allow quick shutdown
            for _ in range(int(self.interval * 2)):
                if not self._running:
                    break
                time.sleep(0.5)
    
    def _generate_all_reports(self):
        """Generate probability reports for all exchanges."""
        start_time = time.time()
        all_results = []
        
        # Get tickers from ecosystem cache if available
        ticker_cache = {}
        if hasattr(self, '_ecosystem') and self._ecosystem:
            ticker_cache = getattr(self._ecosystem, 'ticker_cache', {})
        
        # Generate for Binance symbols
        binance_results = self._generate_exchange_report('binance', self.BINANCE_SYMBOLS, ticker_cache)
        all_results.extend(binance_results)
        
        # Generate for Kraken symbols  
        kraken_results = self._generate_exchange_report('kraken', self.KRAKEN_SYMBOLS, ticker_cache)
        all_results.extend(kraken_results)
        
        # üéØ Sort by probability + sniper boost (Celtic-aligned signals get priority)
        all_results.sort(
            key=lambda r: (
                r.get('probability', 0) + r.get('sniper_boost', 0),  # Boosted probability
                1 if r.get('celtic_aligned') else 0,  # Celtic alignment bonus
                r.get('confidence', 0)
            ), 
            reverse=True
        )
        
        # Count Celtic-aligned signals
        celtic_count = sum(1 for r in all_results if r.get('celtic_aligned'))
        sniper_boosted = sum(1 for r in all_results if r.get('sniper_boost', 0) > 0)
        
        # Save combined report
        report = {
            'generated_at': datetime.now().isoformat(),
            'generator': 'ProbabilityReportGenerator',
            'interval_seconds': self.interval,
            'generation_count': self.generation_count + 1,
            'count': len(all_results),
            'celtic_aligned_count': celtic_count,
            'sniper_boosted_count': sniper_boosted,
            'top_10': all_results[:10],
            'high_conviction': [r for r in all_results if r.get('probability', 0) >= 0.75],
            'celtic_picks': [r for r in all_results if r.get('celtic_aligned')][:10],
            'all': all_results,
        }
        
        # Write to files
        with self._lock:
            try:
                # Main batch report (consumed by ecosystem)
                batch_path = os.path.join(self.report_dir, 'probability_batch_report.json')
                with open(batch_path, 'w') as f:
                    json.dump(report, f, indent=2)
                
                # Also update kraken report for backward compatibility
                kraken_report = {
                    'generated_at': report['generated_at'],
                    'count': len(kraken_results),
                    'all': kraken_results,
                }
                kraken_path = os.path.join(self.report_dir, 'probability_kraken_report.json')
                with open(kraken_path, 'w') as f:
                    json.dump(kraken_report, f, indent=2)
                
                # Combined all-exchanges report
                combined_path = os.path.join(self.report_dir, 'probability_all_exchanges_report.json')
                with open(combined_path, 'w') as f:
                    json.dump(report, f, indent=2)
                    
            except Exception as e:
                logger.error(f"Failed to write probability report: {e}")
        
        # Update stats
        self.last_generation = time.time()
        self.generation_count += 1
        self.last_results = {'all': all_results, 'binance': binance_results, 'kraken': kraken_results}
        
        # Feed top signals to AdaptiveLearningEngine
        self._feed_to_adaptive_learning(all_results[:10])
        
        # Notify ecosystem to reload
        if hasattr(self, '_ecosystem') and self._ecosystem:
            loader = getattr(self._ecosystem, 'probability_loader', None)
            if loader:
                try:
                    loader.load_all_reports()
                except Exception:
                    pass
        
        elapsed = time.time() - start_time
        if self.generation_count % 4 == 0:  # Log every minute (4 * 15s)
            celtic_flag = f" | üáÆüá™ Celtic: {celtic_count}" if celtic_count > 0 else ""
            sniper_flag = f" | üéØ Sniper: {sniper_boosted}" if sniper_boosted > 0 else ""
            logger.info(f"üìä Probability reports regenerated #{self.generation_count} ({len(all_results)} signals, {elapsed:.2f}s{celtic_flag}{sniper_flag})")
    
    def _generate_exchange_report(self, exchange: str, symbols: List[str], ticker_cache: Dict) -> List[Dict]:
        """Generate probability report for a specific exchange."""
        results = []
        
        for symbol in symbols:
            try:
                # Try to get price from cache first
                price = 0.0
                if symbol in ticker_cache:
                    cached = ticker_cache[symbol]
                    if isinstance(cached, dict):
                        price = float(cached.get('last', cached.get('c', cached.get('price', 0))))
                    else:
                        price = float(cached)
                
                if price <= 0:
                    continue  # Skip symbols without prices
                
                # Update price history for momentum calculation
                self._update_price_history(symbol, price)
                
                # Calculate momentum from price history
                momentum = self._calculate_momentum(symbol)
                
                # Calculate frequency and coherence (HNC physics)
                freq, coherence, is_harmonic = self._calculate_frequency_metrics(symbol, price, momentum)
                
                # Use HNC integration if available
                if self.hnc_integration:
                    try:
                        matrix = self.hnc_integration.update_and_analyze(
                            symbol, price, freq, momentum, coherence, is_harmonic
                        )
                        signal = self.hnc_integration.get_trading_signal(symbol)
                        
                        results.append({
                            'symbol': symbol,
                            'exchange': exchange,
                            'price': price,
                            'probability': float(signal.get('probability', 0.5)),
                            'confidence': float(signal.get('confidence', 0.5)),
                            'action': signal.get('action', 'HOLD'),
                            'modifier': signal.get('modifier', 1.0),
                            'reason': signal.get('reason', ''),
                            'frequency': float(matrix.hour_plus_1.avg_frequency) if matrix else freq,
                            'state': matrix.hour_plus_1.state.value if matrix else 'NEUTRAL',
                            'momentum': momentum,
                            'coherence': coherence,
                            'is_harmonic': is_harmonic,
                            'sniper_boost': self._calculate_sniper_boost(symbol, exchange),
                            'celtic_aligned': self._check_celtic_alignment(symbol, momentum),
                        })
                    except Exception as e:
                        logger.debug(f"HNC analysis failed for {symbol}: {e}")
                        # Fallback to simple calculation
                        prob, action = self._simple_probability(momentum, coherence, is_harmonic)
                        results.append({
                            'symbol': symbol,
                            'exchange': exchange,
                            'price': price,
                            'probability': prob,
                            'confidence': coherence,
                            'action': action,
                            'modifier': 1.0,
                            'reason': 'simple_calc',
                            'frequency': freq,
                            'state': 'NEUTRAL',
                            'momentum': momentum,
                            'coherence': coherence,
                            'is_harmonic': is_harmonic,
                            'sniper_boost': self._calculate_sniper_boost(symbol, exchange),
                            'celtic_aligned': self._check_celtic_alignment(symbol, momentum),
                        })
                else:
                    # Simple probability calculation without HNC
                    prob, action = self._simple_probability(momentum, coherence, is_harmonic)
                    results.append({
                        'symbol': symbol,
                        'exchange': exchange,
                        'price': price,
                        'probability': prob,
                        'confidence': coherence,
                        'action': action,
                        'modifier': 1.0,
                        'reason': 'simple_calc',
                        'frequency': freq,
                        'state': 'NEUTRAL',
                        'momentum': momentum,
                        'coherence': coherence,
                        'is_harmonic': is_harmonic,
                    })
                    
            except Exception as e:
                logger.debug(f"Error generating probability for {symbol}: {e}")
                continue
        
        return results
    
    def _update_price_history(self, symbol: str, price: float):
        """Update price history for momentum calculation."""
        now = time.time()
        if symbol not in self._price_history:
            self._price_history[symbol] = []
        
        self._price_history[symbol].append((now, price))
        
        # Keep only recent prices
        if len(self._price_history[symbol]) > self._max_price_history:
            self._price_history[symbol] = self._price_history[symbol][-self._max_price_history:]
    
    def _calculate_momentum(self, symbol: str) -> float:
        """Calculate price momentum from history."""
        history = self._price_history.get(symbol, [])
        if len(history) < 2:
            return 0.0
        
        start_price = history[0][1]
        end_price = history[-1][1]
        
        if start_price <= 0:
            return 0.0
        
        return ((end_price - start_price) / start_price) * 100
    
    def _calculate_frequency_metrics(self, symbol: str, price: float, momentum: float) -> Tuple[float, float, bool]:
        """Calculate HNC frequency metrics."""
        import numpy as np
        
        # PHI-based frequency calculation
        phi = (1 + 5 ** 0.5) / 2
        
        # Base frequency from price ratio (normalized)
        history = self._price_history.get(symbol, [])
        if len(history) >= 2:
            ratio = price / history[0][1] if history[0][1] > 0 else 1.0
            freq = max(256.0, min(963.0, 432.0 * (ratio ** phi)))
        else:
            freq = 432.0  # Default natural frequency
        
        # Coherence from price stability
        if len(history) >= 3:
            prices = [p[1] for p in history]
            std = float(np.std(prices)) if prices else 0
            coherence = max(0.2, min(0.95, 1.0 / (1.0 + std / max(1.0, price))))
        else:
            coherence = 0.5
        
        # Harmonic check (near 432Hz or 528Hz)
        is_harmonic = abs(freq - 432) < 25 or abs(freq - 528) < 25
        
        return freq, coherence, is_harmonic
    
    def _simple_probability(self, momentum: float, coherence: float, is_harmonic: bool) -> Tuple[float, str]:
        """Simple probability calculation without full HNC."""
        # Base probability
        prob = 0.5
        
        # Momentum contribution
        if momentum > 1.0:
            prob += min(0.15, momentum * 0.05)
        elif momentum < -1.0:
            prob -= min(0.15, abs(momentum) * 0.05)
        
        # Coherence contribution  
        prob += (coherence - 0.5) * 0.2
        
        # Harmonic bonus
        if is_harmonic:
            prob += 0.05
        
        # Clamp to valid range
        prob = max(0.3, min(0.8, prob))
        
        # Determine action
        if prob >= 0.65:
            action = 'BUY' if momentum > 0 else 'HOLD'
        elif prob <= 0.35:
            action = 'SELL' if momentum < 0 else 'HOLD'
        else:
            action = 'HOLD'
        
        return prob, action
    
    def _calculate_sniper_boost(self, symbol: str, exchange: str) -> float:
        """
        üéØ Calculate sniper boost for symbol based on coverage and brain readiness.
        
        Returns boost factor 0.0 to 0.2 that can be added to probability.
        """
        boost = 0.0
        
        # Check if exchange is in sniper coverage
        platforms = self._sniper_coverage.get('platforms', {})
        if exchange.lower() in platforms:
            boost += 0.05  # Exchange is sniper-ready
            
            # Check if symbol's base asset is in sellable assets
            sellable = platforms.get(exchange.lower(), {}).get('sellable_assets', [])
            base = symbol.replace('USD', '').replace('USDC', '').replace('USDT', '').replace('/', '')
            if base in sellable or base.upper() in [a.upper() for a in sellable]:
                boost += 0.05  # Asset is sellable (can execute sniper exit)
        
        # Bonus if sniper brain is active and winning
        if self._sniper_brain:
            try:
                status = self._sniper_brain.get_status()
                win_rate = status.get('win_rate', 0.5)
                if win_rate > 0.6:
                    boost += 0.05  # Brain is performing well
                if status.get('kills_today', 0) > 0:
                    boost += 0.02  # Brain has recent activity
            except:
                pass
        
        return min(0.2, boost)  # Cap at 0.2 boost
    
    def _check_celtic_alignment(self, symbol: str, momentum: float) -> bool:
        """
        üáÆüá™ Check if signal aligns with Celtic sniper training model.
        
        Returns True if the signal matches IRA training patterns.
        """
        if not self._celtic_sniper:
            return False
        
        try:
            # Check if Celtic sniper would approve this entry
            # Positive momentum + sniper active = aligned
            sniper_config = get_sniper_config() if CELTIC_SNIPER_AVAILABLE else {}
            if not sniper_config.get('ACTIVE', False):
                return False
            
            # Celtic alignment requires:
            # 1. Positive momentum (buying into strength)
            # 2. Not in "WAIT" mode from training model
            if momentum <= 0:
                return False
            
            # If we have a Celtic sniper instance, check its recommendation
            if hasattr(self._celtic_sniper, 'should_enter'):
                return self._celtic_sniper.should_enter(symbol, momentum)
            
            return momentum > 0.5  # Default: aligned if momentum > 0.5%
            
        except Exception:
            return False
    
    def _feed_sniper_telemetry(self, top_signals: List[Dict]):
        """üß† Feed top signals to sniper brain for pattern learning."""
        if not self._sniper_brain:
            return
        
        try:
            for signal in top_signals[:5]:  # Top 5 only
                if signal.get('celtic_aligned') and signal.get('sniper_boost', 0) > 0:
                    # This is a high-quality Celtic-aligned signal
                    self._sniper_brain.record_signal(
                        symbol=signal['symbol'],
                        exchange=signal.get('exchange', 'unknown'),
                        probability=signal.get('probability', 0.5),
                        momentum=signal.get('momentum', 0),
                        sniper_boost=signal.get('sniper_boost', 0)
                    )
        except Exception as e:
            logger.debug(f"Sniper telemetry feed failed: {e}")

    def _feed_to_adaptive_learning(self, top_signals: List[Dict]):
        """Feed top signals to AdaptiveLearningEngine for continuous learning."""
        # üéØ Also feed to sniper brain
        self._feed_sniper_telemetry(top_signals)
        
        try:
            for signal in top_signals:
                if signal.get('probability', 0) >= 0.70:
                    # Create a learning record
                    learning_record = {
                        'symbol': signal['symbol'],
                        'exchange': signal.get('exchange', 'unknown'),
                        'probability': signal['probability'],
                        'frequency': signal.get('frequency', 432),
                        'coherence': signal.get('coherence', 0.5),
                        'is_harmonic': signal.get('is_harmonic', False),
                        'action': signal.get('action', 'HOLD'),
                        'timestamp': datetime.now().isoformat(),
                        'sniper_boost': signal.get('sniper_boost', 0),
                        'celtic_aligned': signal.get('celtic_aligned', False),
                    }
                    
                    # Feed to adaptive learner for frequency band analysis
                    freq_band = ADAPTIVE_LEARNER._get_frequency_band(signal.get('frequency', 432))
                    if freq_band not in ADAPTIVE_LEARNER.metrics_by_frequency:
                        ADAPTIVE_LEARNER.metrics_by_frequency[freq_band] = {
                            'signals': 0, 'wins': 0, 'losses': 0
                        }
                    ADAPTIVE_LEARNER.metrics_by_frequency[freq_band]['signals'] = \
                        ADAPTIVE_LEARNER.metrics_by_frequency[freq_band].get('signals', 0) + 1
                    
        except Exception as e:
            logger.debug(f"Could not feed to adaptive learning: {e}")
    
    def get_top_signals(self, min_probability: float = 0.70, limit: int = 10) -> List[Dict]:
        """Get current top signals above threshold."""
        with self._lock:
            all_results = self.last_results.get('all', [])
            filtered = [r for r in all_results if r.get('probability', 0) >= min_probability]
            return filtered[:limit]
    
    def get_freshness_minutes(self) -> float:
        """Get minutes since last generation."""
        if self.last_generation == 0:
            return float('inf')
        return (time.time() - self.last_generation) / 60.0


# Global probability report generator instance
PROBABILITY_GENERATOR: Optional[ProbabilityReportGenerator] = None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üåä CASCADE AMPLIFIER - 546x Miner-Validated Signal Amplification
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class CascadeAmplifier:
    """
    Cascade Amplification System - Direct port from aureon_miner.py 546x optimization.
    
    Applies proven miner optimizations to trading signals:
    1. CASCADE AMPLIFICATION (up to 10x) - Compounds successive wins
    2. Œ∫t EFFICIENCY (up to 2.49x) - Extracts more value from same capital
    3. LIGHTHOUSE Œì=1.000 - Perfect entry timing via planetary coherence
    4. MIRROR RESONANCE - 50-minute stability holding
    
    The miner proved these techniques achieve 546x amplification.
    Now applied to trading for win rate and profit optimization.
    """
    
    def __init__(self):
        # Cascade state
        self.cascade_factor = 1.0
        self.cascade_max = 10.0
        self.cascade_decay = 0.95  # Decay per cycle without win
        self.cascade_boost = 1.15  # Boost per win
        
        # Œ∫t efficiency (coupling coefficient from miner)
        self.kappa_t = 1.0
        self.kappa_max = 2.49  # Proven achievable in miner
        self.kappa_ramp = 0.05  # Ramp rate per successful trade
        
        # Lighthouse Œì (planetary coherence from miner)
        self.lighthouse_gamma = 0.5
        self.lighthouse_active = False
        
        # Mirror resonance state
        self.mirror_coherence = 0.5
        self.mirror_stability_seconds = 0
        self.min_hold_seconds = 50 * 60  # 50 minutes (proven in miner)
        
        # Win streak tracking
        self.consecutive_wins = 0
        self.total_cascade_trades = 0
        self.cascade_wins = 0
        
    def record_win(self, pnl_pct: float = 0.0):
        """Record a winning trade - boost cascade."""
        self.consecutive_wins += 1
        self.cascade_wins += 1
        self.total_cascade_trades += 1
        
        # Boost cascade factor
        boost = self.cascade_boost * (1 + pnl_pct * 0.5)  # Extra boost for big wins
        self.cascade_factor = min(self.cascade_max, self.cascade_factor * boost)
        
        # Ramp Œ∫t efficiency
        self.kappa_t = min(self.kappa_max, self.kappa_t + self.kappa_ramp)
        
        # Strengthen mirror coherence
        self.mirror_coherence = min(1.0, self.mirror_coherence + 0.05)
        
        logger.debug(f"üåä CASCADE WIN: streak={self.consecutive_wins}, "
                    f"cascade={self.cascade_factor:.2f}x, Œ∫t={self.kappa_t:.2f}")
        
    def record_loss(self, pnl_pct: float = 0.0):
        """Record a losing trade - decay cascade."""
        self.consecutive_wins = 0
        self.total_cascade_trades += 1
        
        # Decay cascade factor
        self.cascade_factor = max(1.0, self.cascade_factor * self.cascade_decay)
        
        # Slight Œ∫t decay
        self.kappa_t = max(1.0, self.kappa_t - self.kappa_ramp * 0.5)
        
        # Mirror coherence decay
        self.mirror_coherence = max(0.3, self.mirror_coherence - 0.02)
        
        logger.debug(f"üåä CASCADE LOSS: reset streak, cascade={self.cascade_factor:.2f}x")
        
    def update_lighthouse(self, gamma: float):
        """Update Lighthouse Œì from external source (brain/platypus)."""
        self.lighthouse_gamma = gamma
        self.lighthouse_active = gamma >= MIN_GAMMA_THRESHOLD  # Independent mode: 0.20 threshold from miner blueprint
        
    def get_signal_multiplier(self, base_coherence: float = 0.5) -> float:
        """
        Get combined cascade multiplier for trading signal strength.
        
        Formula: Total = CASCADE √ó Œ∫t √ó Lighthouse √ó Mirror
        
        Returns multiplier to apply to score/signal strength.
        """
        # Base cascade contribution
        cascade_mult = 1.0 + (self.cascade_factor - 1.0) * 0.3  # Max 3.7x from cascade
        
        # Œ∫t efficiency contribution
        kappa_mult = 1.0 + (self.kappa_t - 1.0) * 0.2  # Max 1.3x from Œ∫t
        
        # Lighthouse contribution (when aligned)
        lighthouse_mult = 1.0
        if self.lighthouse_active:
            lighthouse_mult = 1.0 + (self.lighthouse_gamma - 0.75) * 0.4  # Up to 1.1x
            
        # Mirror stability contribution
        mirror_mult = 1.0 + (self.mirror_coherence - 0.5) * 0.2  # Up to 1.1x
        
        # Coherence synergy
        coherence_mult = 1.0 + max(0, base_coherence - 0.5) * 0.3
        
        total = cascade_mult * kappa_mult * lighthouse_mult * mirror_mult * coherence_mult
        
        return min(5.0, max(1.0, total))  # Cap at 5x for safety
        
    def get_position_size_multiplier(self) -> float:
        """
        Get position size multiplier based on cascade state.
        Higher cascade = can take larger positions.
        """
        if self.consecutive_wins >= 5:
            return min(2.0, 1.0 + self.consecutive_wins * 0.1)
        return 1.0
        
    def get_min_hold_time(self) -> float:
        """
        Get minimum hold time in seconds based on mirror resonance.
        Higher mirror coherence = longer optimal hold for stability.
        """
        if self.mirror_coherence >= 0.8:
            return self.min_hold_seconds  # Full 50 minutes
        elif self.mirror_coherence >= 0.6:
            return self.min_hold_seconds * 0.5  # 25 minutes
        else:
            return 60  # 1 minute minimum
            
    def get_stats(self) -> Dict:
        """Get current cascade amplifier statistics."""
        win_rate = self.cascade_wins / self.total_cascade_trades if self.total_cascade_trades > 0 else 0
        return {
            'cascade_factor': self.cascade_factor,
            'kappa_t': self.kappa_t,
            'lighthouse_gamma': self.lighthouse_gamma,
            'lighthouse_active': self.lighthouse_active,
            'mirror_coherence': self.mirror_coherence,
            'consecutive_wins': self.consecutive_wins,
            'total_trades': self.total_cascade_trades,
            'cascade_win_rate': win_rate,
            'signal_multiplier': self.get_signal_multiplier(),
            'position_multiplier': self.get_position_size_multiplier(),
            'min_hold_seconds': self.get_min_hold_time()
        }
        
    def display_status(self):
        """Display cascade amplifier status."""
        stats = self.get_stats()
        lighthouse_icon = "üóº‚úÖ" if stats['lighthouse_active'] else "üóº‚ö™"
        print(f"   üåä CASCADE: {stats['cascade_factor']:.2f}x | "
              f"Œ∫t={stats['kappa_t']:.2f} | {lighthouse_icon} Œì={stats['lighthouse_gamma']:.3f} | "
              f"Mirror={stats['mirror_coherence']:.2f} | "
              f"Signal={stats['signal_multiplier']:.2f}x")


# Global cascade amplifier instance
CASCADE_AMPLIFIER = CascadeAmplifier()

# üçÑ Register CASCADE_AMPLIFIER with Mycelium Network
try:
    register_to_mycelium('cascade', CASCADE_AMPLIFIER)
except Exception as e:
    print(f"   ‚ö†Ô∏è Could not register cascade to mycelium: {e}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä ATR CALCULATOR - Dynamic TP/SL
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ATRCalculator:
    """
    Average True Range calculator for dynamic TP/SL scaling.
    Implements volatility-adjusted position management.
    """
    
    def __init__(self, period: int = 14):
        self.period = period
        self.price_history: Dict[str, List[Dict]] = {}  # symbol -> [{high, low, close}]
        self.atr_cache: Dict[str, float] = {}
        self.last_update: Dict[str, float] = {}
        
    def update(self, symbol: str, high: float, low: float, close: float):
        """Add new price data for ATR calculation."""
        if symbol not in self.price_history:
            self.price_history[symbol] = []
            
        self.price_history[symbol].append({
            'high': high,
            'low': low,
            'close': close,
            'timestamp': time.time()
        })
        
        # Keep only last period * 2 candles
        if len(self.price_history[symbol]) > self.period * 2:
            self.price_history[symbol] = self.price_history[symbol][-self.period * 2:]
            
        self.last_update[symbol] = time.time()
        
    def calculate_atr(self, symbol: str) -> float:
        """Calculate ATR for a symbol."""
        if symbol not in self.price_history or len(self.price_history[symbol]) < 2:
            return 0.0
            
        history = self.price_history[symbol]
        true_ranges = []
        
        for i in range(1, min(len(history), self.period + 1)):
            current = history[-i]
            previous = history[-i - 1] if i < len(history) else current
            
            # True Range = max(H-L, |H-Prev Close|, |L-Prev Close|)
            tr1 = current['high'] - current['low']
            tr2 = abs(current['high'] - previous['close'])
            tr3 = abs(current['low'] - previous['close'])
            true_ranges.append(max(tr1, tr2, tr3))
            
        if not true_ranges:
            return 0.0
            
        atr = sum(true_ranges) / len(true_ranges)
        self.atr_cache[symbol] = atr
        return atr
        
    def get_dynamic_tp_sl(self, symbol: str, base_tp: float = 2.0, base_sl: float = 0.8,
                          atr_tp_mult: float = 2.0, atr_sl_mult: float = 1.5) -> Dict[str, float]:
        """
        Calculate dynamic TP/SL based on ATR.
        
        Args:
            symbol: Trading symbol
            base_tp: Base take profit % (used if no ATR data)
            base_sl: Base stop loss % (used if no ATR data)
            atr_tp_mult: ATR multiplier for take profit
            atr_sl_mult: ATR multiplier for stop loss
            
        Returns:
            {'tp_pct': float, 'sl_pct': float, 'atr': float, 'is_dynamic': bool}
        """
        atr = self.calculate_atr(symbol)
        
        if atr <= 0 or symbol not in self.price_history:
            return {
                'tp_pct': base_tp,
                'sl_pct': base_sl,
                'atr': 0,
                'is_dynamic': False
            }
            
        # Get current price from latest candle
        current_price = self.price_history[symbol][-1]['close']
        if current_price <= 0:
            return {'tp_pct': base_tp, 'sl_pct': base_sl, 'atr': atr, 'is_dynamic': False}
            
        # ATR as percentage of price
        atr_pct = (atr / current_price) * 100
        
        # Scale TP/SL by ATR
        dynamic_tp = min(atr_pct * atr_tp_mult, 10.0)  # Cap at 10%
        dynamic_sl = min(atr_pct * atr_sl_mult, 5.0)   # Cap at 5%
        
        # Ensure minimum values
        dynamic_tp = max(dynamic_tp, base_tp * 0.5)
        dynamic_sl = max(dynamic_sl, base_sl * 0.5)
        
        return {
            'tp_pct': round(dynamic_tp, 2),
            'sl_pct': round(dynamic_sl, 2),
            'atr': round(atr, 6),
            'atr_pct': round(atr_pct, 2),
            'is_dynamic': True
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî• PORTFOLIO HEAT MANAGER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class PortfolioHeatManager:
    """
    Tracks total portfolio risk across all positions.
    Implements correlation-adjusted position sizing and heat limits.
    """
    
    def __init__(self, max_heat: float = 0.60, heat_decay: float = 0.95):
        self.max_heat = max_heat  # Maximum 60% portfolio at risk
        self.heat_decay = heat_decay  # Heat decays 5% per cycle
        self.current_heat = 0.0
        self.position_heat: Dict[str, float] = {}  # symbol -> heat contribution
        self.correlation_matrix: Dict[str, Dict[str, float]] = {}
        self.heat_history: List[float] = []
        
    def add_position_heat(self, symbol: str, position_pct: float, risk_pct: float = 1.0):
        """
        Add heat from a new position.
        
        Args:
            symbol: Trading symbol
            position_pct: Position size as % of portfolio
            risk_pct: Risk adjustment (1.0 = full risk, 0.5 = hedged)
        """
        heat = position_pct * risk_pct
        
        # Apply correlation adjustment (correlated assets add more heat)
        correlation_mult = self._get_correlation_multiplier(symbol)
        heat *= correlation_mult
        
        self.position_heat[symbol] = heat
        self._recalculate_total_heat()
        
    def remove_position_heat(self, symbol: str):
        """Remove heat when position is closed."""
        if symbol in self.position_heat:
            del self.position_heat[symbol]
        self._recalculate_total_heat()
        
    def _recalculate_total_heat(self):
        """Recalculate total portfolio heat."""
        self.current_heat = sum(self.position_heat.values())
        self.heat_history.append(self.current_heat)
        if len(self.heat_history) > 100:
            self.heat_history = self.heat_history[-100:]
            
    def _get_correlation_multiplier(self, symbol: str) -> float:
        """
        Get correlation multiplier for a symbol.
        Highly correlated assets with existing positions add more heat.
        """
        if not self.position_heat:
            return 1.0
            
        # Simple heuristic: same-category assets have higher correlation
        # BTC-related: BTC, WBTC, etc.
        # ETH-related: ETH, STETH, etc.
        btc_related = ['BTC', 'XBT', 'WBTC', 'BTCUSD', 'XBTUSD']
        eth_related = ['ETH', 'STETH', 'ETHUSD', 'XETHUSD']
        
        symbol_upper = symbol.upper()
        correlation_boost = 0.0
        
        for existing in self.position_heat:
            existing_upper = existing.upper()
            
            # Check BTC correlation
            if any(b in symbol_upper for b in btc_related) and any(b in existing_upper for b in btc_related):
                correlation_boost += 0.3
            # Check ETH correlation
            elif any(e in symbol_upper for e in eth_related) and any(e in existing_upper for e in eth_related):
                correlation_boost += 0.3
            # General crypto correlation
            elif 'USD' in symbol_upper and 'USD' in existing_upper:
                correlation_boost += 0.1
                
        return 1.0 + min(correlation_boost, 0.5)  # Cap at 1.5x
        
    def can_add_position(self, position_pct: float) -> Tuple[bool, str]:
        """
        Check if adding a position would exceed heat limits.
        
        Returns:
            (can_add: bool, reason: str)
        """
        projected_heat = self.current_heat + position_pct
        
        if projected_heat > self.max_heat:
            return False, f"Heat limit: {self.current_heat:.1%} + {position_pct:.1%} > {self.max_heat:.1%}"
            
        return True, "OK"
        
    def get_max_position_size(self) -> float:
        """Get maximum position size allowed given current heat."""
        available_heat = max(0, self.max_heat - self.current_heat)
        return available_heat
        
    def decay_heat(self):
        """Apply heat decay (called each cycle)."""
        for symbol in self.position_heat:
            self.position_heat[symbol] *= self.heat_decay
        self._recalculate_total_heat()
        
    def get_heat_status(self) -> Dict[str, Any]:
        """Get current heat status."""
        return {
            'current_heat': round(self.current_heat, 3),
            'max_heat': self.max_heat,
            'available': round(self.max_heat - self.current_heat, 3),
            'utilization': round(self.current_heat / self.max_heat, 3) if self.max_heat > 0 else 0,
            'position_count': len(self.position_heat),
            'positions': dict(self.position_heat)
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ÔøΩ UNIVERSAL MARKET INTELLIGENCE - SCANS ALL ASSETS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class UniversalMarketIntelligence:
    """
    üåê Scans ALL trading assets across ALL exchanges and feeds aggregated
    intelligence back to the brain for decision-making.
    
    Unlike the opportunity scanner which filters aggressively, this
    component analyzes EVERY asset to build a complete market picture.
    
    Feeds to Brain:
    - Sector momentum (which sectors are moving)
    - Exchange health (which exchanges have most activity)
    - Correlation clusters (which assets move together)
    - Liquidity distribution (where the money is flowing)
    - Anomaly detection (unusual patterns across all assets)
    - Global sentiment (aggregate bullish/bearish across market)
    """
    
    UNIVERSAL_AVAILABLE = True  # Flag for system interconnection
    
    def __init__(self, thought_bus: Optional['ThoughtBus'] = None):
        self.bus = thought_bus
        self.last_scan_time = 0.0
        self.scan_interval = 30.0  # Full scan every 30 seconds
        
        # Aggregated market intelligence
        self.market_intelligence: Dict[str, Any] = {
            'total_assets_scanned': 0,
            'exchange_health': {},
            'sector_momentum': {},
            'liquidity_distribution': {},
            'global_sentiment': 0.5,  # 0=bearish, 1=bullish
            'correlation_clusters': [],
            'anomalies_detected': [],
            'top_movers': [],
            'bottom_movers': [],
            'volume_leaders': [],
            'timestamp': 0,
        }
        
        # Connect to thought bus
        if self.bus:
            # Subscribe to relevant topics
            self.bus.subscribe('brain.*', self._on_thought_wrapper)
            self.bus.subscribe('immune.*', self._on_thought_wrapper)
            
        logger.info("üåê Universal Market Intelligence initialized - Scans ALL assets")
    
    def _on_thought_wrapper(self, thought):
        """Wrapper to handle Thought objects from the bus."""
        try:
            topic = thought.topic if hasattr(thought, 'topic') else thought.get('topic', '')
            payload = thought.payload if hasattr(thought, 'payload') else thought.get('data', {})
            self._on_thought({'topic': topic, 'data': payload})
        except Exception:
            pass
        
    def _on_thought(self, thought: Dict[str, Any]):
        """Receive thoughts from other components."""
        pass  # We mainly emit, don't need to receive
        
    def _emit_thought(self, topic: str, data: Dict[str, Any]):
        """Emit a thought to the bus."""
        if self.bus:
            try:
                from aureon_thought_bus import Thought
                thought = Thought(
                    source='universal_intel',
                    topic=f'universal_intel.{topic}',
                    payload=data
                )
                self.bus.publish(thought)
            except Exception:
                pass
        
    def scan_all_assets(self, ticker_cache: Dict[str, Dict]) -> Dict[str, Any]:
        """
        Scan ALL assets in the ticker cache without filtering.
        
        Args:
            ticker_cache: Complete ticker cache from all exchanges
            
        Returns:
            Comprehensive market intelligence dict
        """
        now = time.time()
        if (now - self.last_scan_time) < self.scan_interval and self.market_intelligence['total_assets_scanned'] > 0:
            return self.market_intelligence  # Return cached
            
        self.last_scan_time = now
        
        if not ticker_cache:
            return self.market_intelligence
            
        # Reset counters
        exchange_counts: Dict[str, int] = {}
        exchange_volumes: Dict[str, float] = {}
        exchange_avg_change: Dict[str, List[float]] = {}
        
        all_changes: List[float] = []
        all_volumes: List[Tuple[str, float]] = []
        all_movers: List[Tuple[str, float]] = []
        
        # Sector detection (by symbol suffix)
        sector_momentum: Dict[str, List[float]] = {
            'USD_PAIRS': [],    # Pairs ending in USD/USDT/USDC
            'BTC_PAIRS': [],    # Pairs ending in BTC
            'ETH_PAIRS': [],    # Pairs ending in ETH
            'FOREX': [],        # GBP, EUR, JPY pairs
            'STOCKS': [],       # From Capital.com/Alpaca
            'OTHER': [],
        }
        
        bullish_count = 0
        bearish_count = 0
        anomalies = []
        
        # Scan EVERY asset
        for symbol, data in ticker_cache.items():
            try:
                source = data.get('source', 'unknown')
                change = float(data.get('change24h', 0))
                volume = float(data.get('volume', 0))
                price = float(data.get('price', 0))
                
                # Track per exchange
                exchange_counts[source] = exchange_counts.get(source, 0) + 1
                exchange_volumes[source] = exchange_volumes.get(source, 0) + volume
                if source not in exchange_avg_change:
                    exchange_avg_change[source] = []
                exchange_avg_change[source].append(change)
                
                # Track overall
                all_changes.append(change)
                all_volumes.append((symbol, volume))
                all_movers.append((symbol, change))
                
                # Categorize by sector
                if any(symbol.endswith(s) for s in ['USD', 'USDT', 'USDC', 'FDUSD', 'BUSD', 'TUSD']):
                    sector_momentum['USD_PAIRS'].append(change)
                elif symbol.endswith('BTC'):
                    sector_momentum['BTC_PAIRS'].append(change)
                elif symbol.endswith('ETH'):
                    sector_momentum['ETH_PAIRS'].append(change)
                elif any(symbol.endswith(s) for s in ['GBP', 'EUR', 'JPY', 'CHF', 'AUD', 'CAD']):
                    sector_momentum['FOREX'].append(change)
                elif source in ['capital', 'alpaca']:
                    sector_momentum['STOCKS'].append(change)
                else:
                    sector_momentum['OTHER'].append(change)
                    
                # Sentiment tracking
                if change > 0.5:
                    bullish_count += 1
                elif change < -0.5:
                    bearish_count += 1
                    
                # Anomaly detection (extreme moves)
                if abs(change) > 15:
                    anomalies.append({
                        'symbol': symbol,
                        'change': change,
                        'source': source,
                        'type': 'extreme_move'
                    })
                    
            except Exception:
                continue
                
        # Calculate aggregates
        total_scanned = len(ticker_cache)
        
        # Exchange health
        exchange_health = {}
        for ex in exchange_counts:
            avg_ch = sum(exchange_avg_change.get(ex, [0])) / max(1, len(exchange_avg_change.get(ex, [1])))
            exchange_health[ex] = {
                'count': exchange_counts.get(ex, 0),
                'total_volume': exchange_volumes.get(ex, 0),
                'avg_change': round(avg_ch, 2),
                'health': 'ACTIVE' if exchange_counts.get(ex, 0) > 100 else 'LIMITED'
            }
            
        # Sector momentum aggregates
        sector_agg = {}
        for sector, changes in sector_momentum.items():
            if changes:
                sector_agg[sector] = {
                    'count': len(changes),
                    'avg_change': round(sum(changes) / len(changes), 2),
                    'trend': 'BULLISH' if sum(changes) / len(changes) > 0.5 else 'BEARISH' if sum(changes) / len(changes) < -0.5 else 'NEUTRAL'
                }
                
        # Global sentiment (0-1 scale)
        total_with_sentiment = bullish_count + bearish_count
        global_sentiment = bullish_count / max(1, total_with_sentiment)
        
        # Top/Bottom movers
        sorted_movers = sorted(all_movers, key=lambda x: x[1], reverse=True)
        top_movers = sorted_movers[:10]
        bottom_movers = sorted_movers[-10:]
        
        # Volume leaders
        sorted_volumes = sorted(all_volumes, key=lambda x: x[1], reverse=True)
        volume_leaders = sorted_volumes[:10]
        
        # Liquidity distribution
        total_vol = sum(v for _, v in all_volumes)
        liquidity_dist = {}
        for ex in exchange_volumes:
            liquidity_dist[ex] = round(exchange_volumes[ex] / max(1, total_vol) * 100, 1)
            
        # Update market intelligence
        self.market_intelligence = {
            'total_assets_scanned': total_scanned,
            'exchange_health': exchange_health,
            'sector_momentum': sector_agg,
            'liquidity_distribution': liquidity_dist,
            'global_sentiment': round(global_sentiment, 3),
            'sentiment_label': 'BULLISH' if global_sentiment > 0.55 else 'BEARISH' if global_sentiment < 0.45 else 'NEUTRAL',
            'anomalies_detected': anomalies[:5],  # Top 5 anomalies
            'top_movers': [{'symbol': s, 'change': round(c, 2)} for s, c in top_movers],
            'bottom_movers': [{'symbol': s, 'change': round(c, 2)} for s, c in bottom_movers],
            'volume_leaders': [{'symbol': s, 'volume': round(v, 2)} for s, v in volume_leaders],
            'timestamp': now,
        }
        
        # Emit to thought bus
        self._emit_thought('universal_scan_complete', {
            'total_assets': total_scanned,
            'sentiment': self.market_intelligence['sentiment_label'],
            'anomalies': len(anomalies)
        })
            
        return self.market_intelligence
        
    def get_brain_context(self) -> Dict[str, Any]:
        """
        Get market intelligence formatted for brain consumption.
        
        Returns:
            Dict with brain-ready market context
        """
        intel = self.market_intelligence
        
        return {
            'universal_market_scanned': intel['total_assets_scanned'],
            'market_sentiment': intel.get('global_sentiment', 0.5),
            'market_sentiment_label': intel.get('sentiment_label', 'NEUTRAL'),
            'dominant_exchange': max(intel.get('exchange_health', {}).items(), key=lambda x: x[1].get('count', 0), default=('none', {}))[0],
            'liquidity_concentration': intel.get('liquidity_distribution', {}),
            'sector_trends': {k: v.get('trend', 'NEUTRAL') for k, v in intel.get('sector_momentum', {}).items()},
            'anomaly_count': len(intel.get('anomalies_detected', [])),
            'top_mover': intel.get('top_movers', [{}])[0].get('symbol', 'N/A'),
            'scan_fresh': (time.time() - intel.get('timestamp', 0)) < 60,
        }
        
    def get_status(self) -> Dict[str, Any]:
        """Get current scanner status."""
        return {
            'available': self.UNIVERSAL_AVAILABLE,
            'last_scan': self.last_scan_time,
            'total_scanned': self.market_intelligence['total_assets_scanned'],
            'sentiment': self.market_intelligence.get('sentiment_label', 'UNKNOWN'),
            'exchanges_active': list(self.market_intelligence.get('exchange_health', {}).keys()),
        }


# Global instance
UNIVERSAL_MARKET_INTEL: Optional[UniversalMarketIntelligence] = None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ÔøΩüéõÔ∏è ADAPTIVE FILTER THRESHOLDS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class AdaptiveFilterThresholds:
    """
    Auto-adjusts MIN_MOMENTUM, MIN_VOLUME based on market conditions.
    Learns optimal thresholds from historical performance.
    """
    
    def __init__(self):
        # Base thresholds
        self.base_momentum = CONFIG.get('MIN_MOMENTUM', 0.5)
        self.base_volume = CONFIG.get('MIN_VOLUME', 50000)
        self.base_coherence = CONFIG.get('MIN_COHERENCE', 0.45)
        
        # Current adaptive thresholds
        self.momentum_threshold = self.base_momentum
        self.volume_threshold = self.base_volume
        self.coherence_threshold = self.base_coherence
        
        # Performance tracking
        self.trades_by_threshold: Dict[str, List[Dict]] = {
            'momentum': [],
            'volume': [],
            'coherence': []
        }
        
        # Market regime
        self.market_regime = 'NORMAL'  # NORMAL, TRENDING, RANGING, VOLATILE
        self.regime_history: List[str] = []
        
    def detect_market_regime(self, recent_changes: List[float]) -> str:
        """
        Detect current market regime from recent price changes.
        
        Args:
            recent_changes: List of recent 24h % changes across symbols
        """
        if not recent_changes:
            return 'NORMAL'
            
        avg_change = sum(recent_changes) / len(recent_changes)
        volatility = sum(abs(c - avg_change) for c in recent_changes) / len(recent_changes)
        
        # Count direction consistency
        positive = sum(1 for c in recent_changes if c > 0)
        negative = len(recent_changes) - positive
        direction_ratio = max(positive, negative) / len(recent_changes)
        
        # Determine regime
        if volatility > 5.0:
            regime = 'VOLATILE'
        elif direction_ratio > 0.7 and abs(avg_change) > 2.0:
            regime = 'TRENDING'
        elif direction_ratio < 0.6 and volatility < 2.0:
            regime = 'RANGING'
        else:
            regime = 'NORMAL'
            
        self.market_regime = regime
        self.regime_history.append(regime)
        if len(self.regime_history) > 50:
            self.regime_history = self.regime_history[-50:]
            
        return regime
        
    def adjust_thresholds(self, regime: str = None):
        """
        Adjust thresholds based on market regime.
        """
        regime = regime or self.market_regime
        
        if regime == 'TRENDING':
            # In trends, lower momentum threshold to catch moves early
            self.momentum_threshold = self.base_momentum * 0.7
            self.volume_threshold = self.base_volume * 0.8
            self.coherence_threshold = self.base_coherence * 0.9
            
        elif regime == 'VOLATILE':
            # In volatility, raise thresholds to filter noise
            self.momentum_threshold = self.base_momentum * 1.5
            self.volume_threshold = self.base_volume * 1.3
            self.coherence_threshold = self.base_coherence * 1.2
            
        elif regime == 'RANGING':
            # In ranging, require strong signals
            self.momentum_threshold = self.base_momentum * 1.2
            self.volume_threshold = self.base_volume * 1.1
            self.coherence_threshold = self.base_coherence * 1.1
            
        else:  # NORMAL
            self.momentum_threshold = self.base_momentum
            self.volume_threshold = self.base_volume
            self.coherence_threshold = self.base_coherence
            
    def record_trade_result(self, threshold_type: str, threshold_value: float, 
                           actual_value: float, profit: float):
        """Record trade result for learning."""
        self.trades_by_threshold[threshold_type].append({
            'threshold': threshold_value,
            'actual': actual_value,
            'profit': profit,
            'timestamp': time.time()
        })
        
        # Keep last 100 trades per type
        if len(self.trades_by_threshold[threshold_type]) > 100:
            self.trades_by_threshold[threshold_type] = \
                self.trades_by_threshold[threshold_type][-100:]
                
    def learn_optimal_thresholds(self):
        """
        Learn optimal thresholds from trade history.
        Adjusts base thresholds based on profitability patterns.
        """
        for threshold_type in ['momentum', 'volume', 'coherence']:
            trades = self.trades_by_threshold[threshold_type]
            if len(trades) < 20:
                continue
                
            # Group trades by threshold quartile
            sorted_trades = sorted(trades, key=lambda x: x['actual'])
            quartile_size = len(sorted_trades) // 4
            
            if quartile_size < 5:
                continue
                
            # Calculate profitability by quartile
            quartile_profits = []
            for i in range(4):
                start = i * quartile_size
                end = start + quartile_size if i < 3 else len(sorted_trades)
                q_trades = sorted_trades[start:end]
                avg_profit = sum(t['profit'] for t in q_trades) / len(q_trades)
                avg_value = sum(t['actual'] for t in q_trades) / len(q_trades)
                quartile_profits.append((avg_value, avg_profit))
                
            # Find most profitable quartile
            best_quartile = max(quartile_profits, key=lambda x: x[1])
            optimal_value = best_quartile[0]
            
            # Gradually adjust base threshold toward optimal
            if threshold_type == 'momentum':
                self.base_momentum = self.base_momentum * 0.9 + optimal_value * 0.1
            elif threshold_type == 'volume':
                self.base_volume = self.base_volume * 0.9 + optimal_value * 0.1
            elif threshold_type == 'coherence':
                self.base_coherence = self.base_coherence * 0.9 + optimal_value * 0.1
                
    def get_thresholds(self) -> Dict[str, float]:
        """Get current adaptive thresholds."""
        return {
            'momentum': round(self.momentum_threshold, 2),
            'volume': round(self.volume_threshold, 0),
            'coherence': round(self.coherence_threshold, 2),
            'regime': self.market_regime,
            'base_momentum': round(self.base_momentum, 2),
            'base_volume': round(self.base_volume, 0),
            'base_coherence': round(self.base_coherence, 2)
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéØ TRAILING STOP MANAGER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class TrailingStopManager:
    """
    Manages trailing stops for all positions.
    Activates trailing stop once position is in profit, then trails behind price.
    """
    
    def __init__(self):
        # Configuration
        self.activation_profit_pct = CONFIG.get('TRAILING_ACTIVATION_PCT', 0.5)  # Activate at 0.5% profit
        self.trail_distance_pct = CONFIG.get('TRAILING_DISTANCE_PCT', 0.3)  # Trail 0.3% behind peak
        self.use_atr_trailing = CONFIG.get('USE_ATR_TRAILING', True)  # Use ATR for dynamic trailing
        self.atr_trail_multiplier = CONFIG.get('ATR_TRAIL_MULTIPLIER', 1.5)  # Trail at 1.5x ATR
        
        # Statistics
        self.trailing_stops_triggered = 0
        self.trailing_profits_locked = 0.0
        
    def update_position(self, pos, current_price: float, atr: float = 0.0) -> Dict[str, Any]:
        """
        Update trailing stop for a position.
        
        Args:
            pos: Position object
            current_price: Current market price
            atr: Average True Range (optional, for dynamic trailing)
            
        Returns:
            {'should_exit': bool, 'reason': str, 'stop_price': float}
        """
        result = {
            'should_exit': False,
            'reason': '',
            'stop_price': pos.trailing_stop_price,
            'highest_price': pos.highest_price,
            'pnl_pct': 0.0
        }
        
        # Update highest price tracking
        if current_price > pos.highest_price:
            pos.highest_price = current_price
            result['highest_price'] = current_price
            
        if current_price < pos.lowest_price:
            pos.lowest_price = current_price
            
        # Calculate current P&L percentage
        pnl_pct = ((current_price - pos.entry_price) / pos.entry_price) * 100 if pos.entry_price > 0 else 0.0
        result['pnl_pct'] = pnl_pct
        
        # Check if trailing stop should activate
        if not pos.trailing_stop_active:
            if pnl_pct >= self.activation_profit_pct:
                pos.trailing_stop_active = True
                # Set initial trailing stop
                pos.trailing_stop_price = self._calculate_stop_price(
                    pos.highest_price, pos.entry_price, atr
                )
                result['stop_price'] = pos.trailing_stop_price
                
        # Update trailing stop if active
        if pos.trailing_stop_active:
            new_stop = self._calculate_stop_price(pos.highest_price, pos.entry_price, atr)
            
            # Only raise the stop, never lower it
            if new_stop > pos.trailing_stop_price:
                pos.trailing_stop_price = new_stop
                result['stop_price'] = new_stop
                
            # Check if stop is triggered
            if current_price <= pos.trailing_stop_price:
                result['should_exit'] = True
                result['reason'] = f"TRAILING_STOP @ {pos.trailing_stop_price:.6f}"
                self.trailing_stops_triggered += 1
                
                # Calculate locked profit
                locked_pnl = ((pos.trailing_stop_price - pos.entry_price) / pos.entry_price) * 100 if pos.entry_price > 0 else 0.0
                self.trailing_profits_locked += locked_pnl
                
        return result
        
    def _calculate_stop_price(self, highest_price: float, entry_price: float, 
                              atr: float = 0.0) -> float:
        """Calculate trailing stop price."""
        if self.use_atr_trailing and atr > 0:
            # ATR-based trailing: trail at ATR * multiplier below peak
            stop_distance = atr * self.atr_trail_multiplier
            stop_price = highest_price - stop_distance
        else:
            # Percentage-based trailing
            stop_distance = highest_price * (self.trail_distance_pct / 100)
            stop_price = highest_price - stop_distance
            
        # Never set stop below entry (lock in breakeven minimum)
        return max(stop_price, entry_price * 1.001)  # At least 0.1% above entry
        
    def get_stats(self) -> Dict[str, Any]:
        """Get trailing stop statistics."""
        return {
            'stops_triggered': self.trailing_stops_triggered,
            'profits_locked_pct': round(self.trailing_profits_locked, 2),
            'activation_pct': self.activation_profit_pct,
            'trail_distance_pct': self.trail_distance_pct,
            'use_atr': self.use_atr_trailing
        }
        
    def reset_stats(self):
        """Reset statistics."""
        self.trailing_stops_triggered = 0
        self.trailing_profits_locked = 0.0


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üì¢ NOTIFICATION SYSTEM (Telegram/Discord/Webhook)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class NotificationManager:
    """
    Sends trade alerts and notifications to Telegram, Discord, or webhooks.
    Configurable via environment variables.
    """
    
    def __init__(self):
        # Telegram config
        self.telegram_token = os.getenv('TELEGRAM_BOT_TOKEN', '')
        self.telegram_chat_id = os.getenv('TELEGRAM_CHAT_ID', '')
        self.telegram_enabled = bool(self.telegram_token and self.telegram_chat_id)
        
        # Discord config
        self.discord_webhook = os.getenv('DISCORD_WEBHOOK_URL', '')
        self.discord_enabled = bool(self.discord_webhook)
        
        # Generic webhook config
        self.webhook_url = os.getenv('ALERT_WEBHOOK_URL', '')
        self.webhook_enabled = bool(self.webhook_url)
        
        # Rate limiting
        self.last_notification = 0
        self.min_interval = 60  # Minimum 60 seconds between notifications
        self.notification_history: List[Dict] = []
        
        # Alert levels
        self.alert_levels = {
            'TRADE': True,      # Trade executed
            'PROFIT': True,     # Position closed with profit
            'LOSS': True,       # Position closed with loss
            'CIRCUIT': True,    # Circuit breaker triggered
            'ARBITRAGE': True,  # Arbitrage opportunity
            'WARNING': True,    # System warnings
            'INFO': False       # General info (disabled by default)
        }
        
    def is_enabled(self) -> bool:
        """Check if any notification channel is enabled."""
        return self.telegram_enabled or self.discord_enabled or self.webhook_enabled
        
    def set_alert_level(self, level: str, enabled: bool):
        """Enable/disable specific alert types."""
        if level in self.alert_levels:
            self.alert_levels[level] = enabled
            
    def _can_send(self) -> bool:
        """Check rate limiting."""
        now = time.time()
        if now - self.last_notification < self.min_interval:
            return False
        return True
        
    def _send_telegram(self, message: str) -> bool:
        """Send message via Telegram."""
        if not self.telegram_enabled:
            return False
            
        try:
            import urllib.request
            import urllib.parse
            
            url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
            data = urllib.parse.urlencode({
                'chat_id': self.telegram_chat_id,
                'text': message,
                'parse_mode': 'HTML'
            }).encode()
            
            req = urllib.request.Request(url, data=data)
            with urllib.request.urlopen(req, timeout=10) as response:
                return response.status == 200
        except Exception as e:
            logger.error(f"Telegram send error: {e}")
            return False
            
    def _send_discord(self, message: str, title: str = "Aureon Alert") -> bool:
        """Send message via Discord webhook."""
        if not self.discord_enabled:
            return False
            
        try:
            import urllib.request
            import json
            
            payload = {
                "embeds": [{
                    "title": title,
                    "description": message,
                    "color": 0x00ff00  # Green
                }]
            }
            
            data = json.dumps(payload).encode()
            req = urllib.request.Request(
                self.discord_webhook,
                data=data,
                headers={'Content-Type': 'application/json'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as response:
                return response.status in [200, 204]
        except Exception as e:
            logger.error(f"Discord send error: {e}")
            return False
            
    def _send_webhook(self, payload: Dict) -> bool:
        """Send to generic webhook."""
        if not self.webhook_enabled:
            return False
            
        try:
            import urllib.request
            import json
            
            data = json.dumps(payload).encode()
            req = urllib.request.Request(
                self.webhook_url,
                data=data,
                headers={'Content-Type': 'application/json'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as response:
                return response.status == 200
        except Exception as e:
            logger.error(f"Webhook send error: {e}")
            return False
            
    def send_alert(self, level: str, title: str, message: str, 
                   data: Dict = None) -> bool:
        """
        Send alert to all enabled channels.
        
        Args:
            level: Alert level (TRADE, PROFIT, LOSS, CIRCUIT, ARBITRAGE, WARNING, INFO)
            title: Alert title
            message: Alert message
            data: Optional additional data for webhook
        """
        # Check if this alert level is enabled
        if not self.alert_levels.get(level, False):
            return False
            
        # Rate limiting
        if not self._can_send():
            return False
            
        self.last_notification = time.time()
        
        # Build formatted message
        emoji_map = {
            'TRADE': 'üìä',
            'PROFIT': 'üí∞',
            'LOSS': 'üìâ',
            'CIRCUIT': 'üö®',
            'ARBITRAGE': '‚ö°',
            'WARNING': '‚ö†Ô∏è',
            'INFO': '‚ÑπÔ∏è'
        }
        emoji = emoji_map.get(level, 'üì¢')
        
        formatted_msg = f"{emoji} <b>{title}</b>\n{message}"
        discord_msg = f"{emoji} **{title}**\n{message}"
        
        success = False
        
        # Send to all channels
        if self.telegram_enabled:
            success = self._send_telegram(formatted_msg) or success
            
        if self.discord_enabled:
            success = self._send_discord(discord_msg, f"{emoji} {title}") or success
            
        if self.webhook_enabled:
            webhook_payload = {
                'level': level,
                'title': title,
                'message': message,
                'timestamp': time.time(),
                'data': data or {}
            }
            success = self._send_webhook(webhook_payload) or success
            
        # Record notification
        self.notification_history.append({
            'level': level,
            'title': title,
            'timestamp': time.time(),
            'success': success
        })
        
        if len(self.notification_history) > 100:
            self.notification_history = self.notification_history[-100:]
            
        return success
        
    def notify_trade(self, symbol: str, side: str, price: float, 
                    quantity: float, exchange: str):
        """Send trade execution notification."""
        curr = "¬£" if CONFIG.get('BASE_CURRENCY') == 'GBP' else "$"
        value = price * quantity
        
        msg = (f"Symbol: {symbol}\n"
               f"Side: {side}\n"
               f"Price: {curr}{price:.6f}\n"
               f"Value: {curr}{value:.2f}\n"
               f"Exchange: {exchange.upper()}")
               
        self.send_alert('TRADE', f"{side} {symbol}", msg)
        
    def notify_close(self, symbol: str, pnl: float, pct: float, reason: str):
        """Send position close notification."""
        level = 'PROFIT' if pnl > 0 else 'LOSS'
        curr = "¬£" if CONFIG.get('BASE_CURRENCY') == 'GBP' else "$"
        
        msg = (f"Symbol: {symbol}\n"
               f"P&L: {curr}{pnl:+.2f} ({pct:+.1f}%)\n"
               f"Reason: {reason}")
               
        title = f"{'WIN' if pnl > 0 else 'LOSS'} {symbol}"
        self.send_alert(level, title, msg)
        
    def notify_circuit_breaker(self, reason: str, drawdown: float):
        """Send circuit breaker alert."""
        msg = (f"‚ö†Ô∏è TRADING HALTED\n"
               f"Reason: {reason}\n"
               f"Drawdown: {drawdown:.1f}%\n"
               f"Manual restart required!")
               
        self.send_alert('CIRCUIT', "CIRCUIT BREAKER", msg)
        
    def notify_arbitrage(self, opportunity: Dict):
        """Send arbitrage opportunity alert."""
        msg = (f"Symbol: {opportunity.get('symbol')}\n"
               f"Buy: {opportunity.get('buy_exchange')} @ {opportunity.get('buy_price'):.6f}\n"
               f"Sell: {opportunity.get('sell_exchange')} @ {opportunity.get('sell_price'):.6f}\n"
               f"Spread: {opportunity.get('spread_pct', 0):.2f}%\n"
               f"Net Profit: {opportunity.get('net_profit_pct', 0):.2f}%")
               
        self.send_alert('ARBITRAGE', "Arbitrage Found", msg)
        
    def get_status(self) -> Dict[str, Any]:
        """Get notification system status."""
        return {
            'telegram_enabled': self.telegram_enabled,
            'discord_enabled': self.discord_enabled,
            'webhook_enabled': self.webhook_enabled,
            'total_sent': len(self.notification_history),
            'recent_success_rate': self._calc_success_rate()
        }
        
    def _calc_success_rate(self) -> float:
        """Calculate recent notification success rate."""
        recent = self.notification_history[-20:]
        if not recent:
            return 0.0
        return sum(1 for n in recent if n['success']) / len(recent)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üåå NEXUS INTEGRATION - UNIFIED NEURAL TRADING ENGINE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class NexusIntegration:
    """
    Integrates the Aureon Nexus (Master Equation + Queen Hive) into the ecosystem.
    
    The Nexus provides:
    - Master Equation: Œõ(t) = S(t) + O(t) + E(t) for signal generation
    - Queen Hive: 10-9-1 compounding model for profit distribution
    - NexusBus: State management and signal propagation
    
    Coherence thresholds:
    - Entry: Œì > 0.75 (high confidence buy signal)
    - Exit: Œì < 0.70 (exit positions)
    """
    
    def __init__(self):
        self.enabled = NEXUS_AVAILABLE
        self.master_equation: Optional[Any] = None
        self.queen_hive: Optional[Any] = None
        self.nexus_bus = NEXUS_BUS
        
        # Coherence history for observer calculation
        self.coherence_history: List[float] = []
        
        # Performance tracking
        self.signals_generated = 0
        self.signals_followed = 0
        self.nexus_profits = 0.0
        
        if self.enabled:
            self._initialize_nexus()
        else:
            logger.warning("‚ö†Ô∏è Nexus not available - using fallback signals")
            
    def _initialize_nexus(self):
        """Initialize Nexus components."""
        try:
            from aureon_nexus import MasterEquation, QueenHive
            self.master_equation = MasterEquation()
            self.queen_hive = QueenHive(initial_capital=0.0)
            logger.info("üåå NEXUS Integration initialized")
            logger.info(f"   ‚îî‚îÄ Master Equation: Œõ(t) = S(t) + O(t) + E(t)")
            logger.info(f"   ‚îî‚îÄ Queen Hive: 10-9-1 compounding active")
            logger.info(f"   ‚îî‚îÄ Entry threshold: Œì > 0.75")
            logger.info(f"   ‚îî‚îÄ Exit threshold: Œì < 0.70")
        except Exception as e:
            logger.error(f"Failed to initialize Nexus: {e}")
            self.enabled = False
            
    def update_capital(self, capital: float):
        """Update Queen Hive with current capital."""
        if self.queen_hive:
            self.queen_hive.current_capital = capital
            if self.queen_hive.initial_capital == 0:
                self.queen_hive.initial_capital = capital
                
    def calculate_master_equation(self, market_data: Dict[str, float]) -> Dict[str, Any]:
        """
        Calculate the Master Equation and return signal.
        
        Market data should include:
        - volatility: 0.0 to 1.0
        - momentum: 0.0 to 1.0
        - sentiment: 0.0 to 1.0
        - trend_strength: 0.0 to 1.0
        - pattern_match: 0.0 to 1.0
        - harmony: 0.0 to 1.0
        - volume_ratio: 0.0 to 1.0
        - correlation: 0.0 to 1.0
        """
        if not self.enabled or not self.master_equation:
            return self._fallback_signal()
            
        try:
            # Update S(t) - Substrate from market data
            self.master_equation.update_substrate(market_data)
            
            # Update O(t) - Observer from coherence history
            self.master_equation.update_observer(self.coherence_history)
            
            # Update E(t) - Echo from momentum
            price_momentum = market_data.get('momentum', 0.5)
            self.master_equation.update_echo(price_momentum)
            
            # Calculate Œõ(t) and derive coherence Œì
            self.master_equation.calculate_lambda()
            
            # Store coherence in history
            self.coherence_history.append(self.master_equation.coherence)
            if len(self.coherence_history) > 100:
                self.coherence_history = self.coherence_history[-100:]
                
            # Get signal
            signal, confidence = self.master_equation.get_signal()
            self.signals_generated += 1
            
            return {
                'signal': signal,
                'confidence': confidence,
                'coherence': self.master_equation.coherence,
                'lambda': self.master_equation.lambda_value,
                'substrate': self.master_equation.substrate,
                'observer': self.master_equation.observer,
                'echo': self.master_equation.echo,
                'entry_threshold': self.master_equation.entry_threshold,
                'exit_threshold': self.master_equation.exit_threshold
            }
        except Exception as e:
            logger.error(f"Master Equation error: {e}")
            return self._fallback_signal()
            
    def _fallback_signal(self) -> Dict[str, Any]:
        """Fallback when Nexus is unavailable."""
        return {
            'signal': 'NEUTRAL',
            'confidence': 0.5,
            'coherence': 0.5,
            'lambda': 1.5,
            'substrate': 0.5,
            'observer': 0.5,
            'echo': 0.5,
            'entry_threshold': 0.75,
            'exit_threshold': 0.70
        }
        
    def record_trade_profit(self, profit: float, btc_price: float = 95000) -> Dict[str, float]:
        """
        Record profit through Queen Hive 10-9-1 model.
        
        Returns distribution:
        - compound: 90% goes back to capital
        - harvest: 10% for spawning new hives
        """
        if not self.queen_hive:
            return {'profit': profit, 'compound': profit * 0.9, 'harvest': profit * 0.1}
            
        result = self.queen_hive.record_profit(profit, btc_price)
        self.nexus_profits += profit
        
        if profit > 0:
            self.signals_followed += 1
            
        return result
        
    def get_hive_stats(self) -> Dict[str, Any]:
        """Get Queen Hive statistics."""
        if not self.queen_hive:
            return {}
            
        try:
            return self.queen_hive.get_stats()
        except:
            return {}
            
    def broadcast_signal(self, module: str, signal_type: str, data: Dict) -> bool:
        """Broadcast signal through NexusBus."""
        if not self.nexus_bus:
            return False
            
        try:
            self.nexus_bus.emit(module, signal_type, data)
            return True
        except Exception as e:
            logger.error(f"NexusBus broadcast error: {e}")
            return False
            
    def register_module(self, name: str, callback) -> bool:
        """Register a module to receive NexusBus signals."""
        if not self.nexus_bus:
            return False
            
        try:
            self.nexus_bus.register(name, callback)
            return True
        except Exception as e:
            logger.error(f"NexusBus registration error: {e}")
            return False
            
    def convert_klines_to_market_data(self, klines: List[Dict]) -> Dict[str, float]:
        """
        Convert kline data to market data format for Master Equation.
        
        Calculates volatility, momentum, trend_strength etc. from OHLCV data.
        """
        if not klines or len(klines) < 2:
            return {
                'volatility': 0.5,
                'momentum': 0.5,
                'sentiment': 0.5,
                'trend_strength': 0.5,
                'pattern_match': 0.5,
                'harmony': 0.5,
                'volume_ratio': 0.5,
                'correlation': 0.5
            }
            
        try:
            # Get recent prices
            closes = [float(k.get('close', k.get('c', 0))) for k in klines[-20:] if k]
            highs = [float(k.get('high', k.get('h', 0))) for k in klines[-20:] if k]
            lows = [float(k.get('low', k.get('l', 0))) for k in klines[-20:] if k]
            volumes = [float(k.get('volume', k.get('v', 0))) for k in klines[-20:] if k]
            
            if not closes:
                return self._default_market_data()
                
            current_price = closes[-1]
            
            # Volatility: Average true range normalized
            if len(highs) >= 2 and len(lows) >= 2:
                atr = sum(h - l for h, l in zip(highs[-14:], lows[-14:])) / min(14, len(highs))
                volatility = min(1.0, atr / current_price * 10)  # Normalize
            else:
                volatility = 0.5
                
            # Momentum: Price change over period
            if len(closes) >= 5:
                momentum_raw = (closes[-1] - closes[-5]) / closes[-5]
                momentum = 0.5 + (momentum_raw * 5)  # Scale to 0-1 range
                momentum = max(0.0, min(1.0, momentum))
            else:
                momentum = 0.5
                
            # Trend strength: Directional consistency
            if len(closes) >= 10:
                ups = sum(1 for i in range(1, len(closes)) if closes[i] > closes[i-1])
                trend_strength = ups / (len(closes) - 1)
            else:
                trend_strength = 0.5
                
            # Volume ratio: Current vs average
            if volumes and sum(volumes[:-1]) > 0:
                avg_vol = sum(volumes[:-1]) / len(volumes[:-1])
                volume_ratio = min(1.0, volumes[-1] / avg_vol) if avg_vol > 0 else 0.5
            else:
                volume_ratio = 0.5
                
            # Sentiment: Based on close position in range
            if len(highs) >= 1 and len(lows) >= 1:
                high_low_range = max(highs[-1] - lows[-1], 0.0001)
                sentiment = (current_price - lows[-1]) / high_low_range
                sentiment = max(0.0, min(1.0, sentiment))
            else:
                sentiment = 0.5
                
            # Harmony: Golden ratio alignment (0.618, 1.618)
            if len(closes) >= 5:
                ratio = closes[-1] / closes[-5] if closes[-5] > 0 else 1.0
                phi_distance = abs(ratio - 1.618)
                harmony = max(0.0, 1.0 - phi_distance)
            else:
                harmony = 0.5
                
            return {
                'volatility': volatility,
                'momentum': momentum,
                'sentiment': sentiment,
                'trend_strength': trend_strength,
                'pattern_match': 0.5,  # Requires pattern detection
                'harmony': harmony,
                'volume_ratio': volume_ratio,
                'correlation': 0.5  # Requires cross-asset analysis
            }
        except Exception as e:
            logger.error(f"Kline conversion error: {e}")
            return self._default_market_data()
            
    def _default_market_data(self) -> Dict[str, float]:
        """Default market data values."""
        return {
            'volatility': 0.5,
            'momentum': 0.5,
            'sentiment': 0.5,
            'trend_strength': 0.5,
            'pattern_match': 0.5,
            'harmony': 0.5,
            'volume_ratio': 0.5,
            'correlation': 0.5
        }
        
    def should_enter(self, coherence: float = None) -> bool:
        """Check if coherence meets entry threshold."""
        if coherence is None:
            coherence = self.master_equation.coherence if self.master_equation else 0.5
        return coherence >= 0.75
        
    def should_exit(self, coherence: float = None) -> bool:
        """Check if coherence falls below exit threshold."""
        if coherence is None:
            coherence = self.master_equation.coherence if self.master_equation else 0.5
        return coherence <= 0.70
        
    def get_stats(self) -> Dict[str, Any]:
        """Get Nexus integration statistics."""
        stats = {
            'enabled': self.enabled,
            'signals_generated': self.signals_generated,
            'signals_followed': self.signals_followed,
            'nexus_profits': self.nexus_profits,
            'current_coherence': self.master_equation.coherence if self.master_equation else 0.0,
            'coherence_avg': sum(self.coherence_history[-20:]) / max(1, len(self.coherence_history[-20:]))
        }
        
        # Add hive stats if available
        hive_stats = self.get_hive_stats()
        if hive_stats:
            stats['hive'] = hive_stats
            
        return stats
        
    def display_equation(self):
        """Display current Master Equation state."""
        if self.master_equation:
            self.master_equation.display()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üåü SWARM ORCHESTRATOR ENHANCEMENTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Prime numbers for dynamic sizing (from multi_agent_aggressive.ts)
PRIMES = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]
PRIME_SCALE = 0.05  # 5% per prime unit ‚Üí 10%, 15%, 25%, 35%, etc. (sensible position sizes)

# Fibonacci sequence for timing (from multi_agent_aggressive.ts)
FIBONACCI = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987]


@dataclass
class MarketSignal:
    """Signal broadcast from scout position (from swarmOrchestrator.ts)"""
    symbol: str
    direction: str  # 'BUY' or 'SELL'
    strength: float  # 0.0 to 1.0
    momentum: float  # % change
    coherence: float  # Gamma value
    timestamp: float
    scout_id: Optional[str] = None


@dataclass
class CapitalPool:
    """Central capital management (from swarmOrchestrator.ts - bee hive)"""
    total_equity: float = 0.0
    allocated: Dict[str, float] = field(default_factory=dict)  # {symbol: amount}
    reserved: float = 0.0  # Keep 10% reserved for opportunities
    profits_this_cycle: float = 0.0
    total_profits: float = 0.0
    sentiment_score: float = 0.0  # -10 to +10 (Neutral 0)
    
    def update_equity(self, new_equity: float):
        """Update total equity and recalculate reserves based on sentiment"""
        self.total_equity = new_equity
        
        # Dynamic Reserve:
        # Neutral (0): 10%
        # Bullish (>2): 5% (Aggressive)
        # Bearish (<-2): 20% (Defensive)
        reserve_pct = 0.10
        if self.sentiment_score > 2.0:
            reserve_pct = 0.05
        elif self.sentiment_score < -2.0:
            reserve_pct = 0.20
            
        self.reserved = new_equity * reserve_pct

    def update_sentiment(self, score: float):
        """Update market sentiment score to adjust risk parameters"""
        self.sentiment_score = score
        # Recalculate reserve with new sentiment
        self.update_equity(self.total_equity)

    def get_recommended_position_size(self, base_pct: float = 0.05) -> float:
        """
        Calculate recommended position size based on sentiment.
        base_pct: Base position size percentage (e.g., 0.05 for 5%)
        """
        # Adjust size based on sentiment
        adjusted_pct = base_pct
        if self.sentiment_score > 5.0: # Very Bullish
            adjusted_pct *= 1.5
        elif self.sentiment_score < -2.0: # Bearish
            adjusted_pct *= 0.5
            
        # Cap at 20% of total equity
        max_size = self.total_equity * 0.20
        
        # Calculate size
        size = self.total_equity * adjusted_pct
        return min(size, max_size)
        
    def allocate(self, symbol: str, amount: float) -> bool:
        """Allocate capital to a position"""
        available = self.total_equity - sum(self.allocated.values()) - self.reserved
        if available >= amount:
            self.allocated[symbol] = self.allocated.get(symbol, 0) + amount
            return True
        return False
        
    def deallocate(self, symbol: str, amount: float, profit: float = 0.0):
        """Return capital from closed position"""
        if symbol in self.allocated:
            self.allocated[symbol] = max(0, self.allocated[symbol] - amount)
            if self.allocated[symbol] == 0:
                del self.allocated[symbol]
        self.profits_this_cycle += profit
        self.total_profits += profit
        
    def get_available(self) -> float:
        """Get unallocated capital"""
        return max(0, self.total_equity - sum(self.allocated.values()) - self.reserved)


class SignalBroadcaster:
    """Manages signal broadcasting between positions (from swarmOrchestrator.ts - wolf scout)"""
    
    def __init__(self):
        self.latest_signal: Optional[MarketSignal] = None
        self.signal_history: deque = deque(maxlen=20)
        self.scout_positions: List[str] = []  # Positions that can act as scouts
        
    def broadcast_signal(self, signal: MarketSignal):
        """Broadcast a new signal from scout"""
        self.latest_signal = signal
        self.signal_history.append(signal)
        
    def get_latest_signal(self, max_age_seconds: float = 60.0) -> Optional[MarketSignal]:
        """Get latest signal if not too old"""
        if self.latest_signal:
            age = time.time() - self.latest_signal.timestamp
            if age <= max_age_seconds:
                return self.latest_signal
        return None
        
    def should_follow_signal(self, symbol: str, signal: MarketSignal) -> bool:
        """Determine if a position should follow the signal"""
        # Don't follow signals for the same symbol (avoid feedback loop)
        if symbol == signal.symbol:
            return False
        # Only follow strong signals (strength > 0.5)
        if signal.strength < 0.5:
            return False
        # Only follow if coherence is good
        if signal.coherence < 0.4:
            return False
        return True


class PositionSplitter:
    """Manages position splitting (from queen_hive.ts - hive splitting)"""
    
    def __init__(self):
        self.split_threshold = 2.0  # Split when position reaches 2x entry value
        self.max_generation = 5  # Max split depth
        self.split_history: List[Dict] = []
        
    def should_split(self, position_value: float, entry_value: float, generation: int) -> bool:
        """Check if position should split"""
        if generation >= self.max_generation:
            return False
        return position_value >= entry_value * self.split_threshold
        
    def execute_split(self, position: 'Position') -> Tuple['Position', 'Position']:
        """Split position into two child positions"""
        # Each child gets half the value
        split_value = position.size * position.current_price / 2
        split_size = position.size / 2
        
        # Create two children at next generation
        child1 = Position(
            symbol=position.symbol,
            size=split_size,
            entry_price=position.current_price,
            current_price=position.current_price,
            quote_asset=position.quote_asset,
            generation=position.generation + 1,
            parent_id=position.id
        )
        
        child2 = Position(
            symbol=position.symbol,
            size=split_size,
            entry_price=position.current_price,
            current_price=position.current_price,
            quote_asset=position.quote_asset,
            generation=position.generation + 1,
            parent_id=position.id
        )
        
        # Record split event
        self.split_history.append({
            'timestamp': time.time(),
            'parent_id': position.id,
            'parent_value': position.size * position.current_price,
            'generation': position.generation,
            'children': [child1.id, child2.id]
        })
        
        return child1, child2


class PrimeSizer:
    """Prime-based dynamic position sizing (from multi_agent_aggressive.ts)"""
    
    def __init__(self):
        self.prime_idx = 0
        self.fib_idx = 0
        
    def get_next_size(self, base_size: float) -> float:
        """Get next position size using prime scaling"""
        prime = PRIMES[self.prime_idx % len(PRIMES)]
        size = base_size * prime * PRIME_SCALE
        self.prime_idx += 1
        return size
        
    def get_fibonacci_timing(self) -> int:
        """Get next timing interval using Fibonacci"""
        fib = FIBONACCI[self.fib_idx % len(FIBONACCI)]
        self.fib_idx += 1
        return fib
        
    def reset(self):
        """Reset indices"""
        self.prime_idx = 0
        self.fib_idx = 0


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üêÖ AURIS NODES - 9 Nodes of Market Analysis
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class MarketState:
    """Complete market snapshot for analysis"""
    symbol: str
    price: float
    bid: float = 0.0
    ask: float = 0.0
    volume: float = 0.0
    change_24h: float = 0.0
    high_24h: float = 0.0
    low_24h: float = 0.0
    prices: List[float] = field(default_factory=list)
    timestamp: float = 0.0


class AurisNode:
    """Base class for all Auris nodes"""
    def __init__(self, name: str, freq: float, weight: float = 1.0):
        self.name = name
        self.freq = freq
        self.weight = weight
        self.response = 0.0
        
    def compute(self, state: MarketState) -> float:
        raise NotImplementedError


class TigerNode(AurisNode):
    """üêÖ Volatility & Spread - Cuts the noise"""
    def __init__(self):
        super().__init__("Tiger", CONFIG['FREQ_TIGER'], 1.2)
        
    def compute(self, state: MarketState) -> float:
        if state.ask <= 0 or state.bid <= 0:
            return 0.5
        spread = (state.ask - state.bid) / state.price if state.price > 0 else 0
        # Low spread = high coherence
        self.response = max(0, 1 - spread * 100)
        return self.response


class FalconNode(AurisNode):
    """ü¶Ö Speed & Momentum - Quick strikes"""
    def __init__(self):
        super().__init__("Falcon", CONFIG['FREQ_FALCON'], 1.35)  # BOOSTED: 75% win rate
        
    def compute(self, state: MarketState) -> float:
        # Positive momentum = high coherence
        if state.change_24h > 10:
            self.response = 0.9
        elif state.change_24h > 5:
            self.response = 0.75
        elif state.change_24h > 2:
            self.response = 0.6
        elif state.change_24h > 0:
            self.response = 0.5
        else:
            self.response = 0.3
        return self.response


class HummingbirdNode(AurisNode):
    """üê¶ Stability - High frequency lock"""
    def __init__(self):
        super().__init__("Hummingbird", CONFIG['FREQ_HUMMINGBIRD'], 1.0)
        
    def compute(self, state: MarketState) -> float:
        if len(state.prices) < 3:
            return 0.5
        # Low variance = stable = high coherence
        mean = sum(state.prices) / len(state.prices)
        variance = sum((p - mean) ** 2 for p in state.prices) / len(state.prices)
        std = math.sqrt(variance) if variance > 0 else 0
        cv = std / mean if mean > 0 else 0
        self.response = max(0, 1 - cv * 10)
        return self.response


class DolphinNode(AurisNode):
    """üê¨ Waveform - Emotional carrier"""
    def __init__(self):
        super().__init__("Dolphin", CONFIG['FREQ_DOLPHIN'], 0.6)  # REDUCED: 0% win rate in data (needs investigation)
        
    def compute(self, state: MarketState) -> float:
        if len(state.prices) < 5:
            return 0.5
        # Detect wave pattern (up-down-up)
        ups = sum(1 for i in range(1, len(state.prices)) if state.prices[i] > state.prices[i-1])
        ratio = ups / (len(state.prices) - 1)
        # Balanced waves = good
        self.response = 1 - abs(ratio - 0.6)  # Slight bullish bias
        return self.response


class DeerNode(AurisNode):
    """ü¶å Sensing - Micro-shifts detection"""
    def __init__(self):
        super().__init__("Deer", CONFIG['FREQ_DEER'], 1.25)  # BOOSTED: Highest profitability $+39.71
        
    def compute(self, state: MarketState) -> float:
        if len(state.prices) < 2:
            return 0.5
        # Recent micro-movement
        recent_change = (state.prices[-1] - state.prices[-2]) / state.prices[-2] if state.prices[-2] > 0 else 0
        self.response = 0.5 + recent_change * 50  # Scale micro moves
        self.response = max(0, min(1, self.response))
        return self.response


class OwlNode(AurisNode):
    """ü¶â Memory - Pattern recognition"""
    def __init__(self):
        super().__init__("Owl", CONFIG['FREQ_OWL'], 1.1)
        self.memory: Dict[str, List[float]] = {}
        
    def compute(self, state: MarketState) -> float:
        if state.symbol not in self.memory:
            self.memory[state.symbol] = []
        self.memory[state.symbol].append(state.change_24h)
        if len(self.memory[state.symbol]) > 100:
            self.memory[state.symbol] = self.memory[state.symbol][-100:]
            
        history = self.memory[state.symbol]
        if len(history) < 5:
            return 0.5
            
        # Pattern: was it bullish before?
        avg_momentum = sum(history[-10:]) / min(10, len(history))
        self.response = 0.5 + avg_momentum / 20
        self.response = max(0, min(1, self.response))
        return self.response


class PandaNode(AurisNode):
    """üêº Safety - Grounding and protection"""
    def __init__(self):
        super().__init__("Panda", CONFIG['FREQ_PANDA'], 1.20)  # BOOSTED: 60% win rate $+15.84
        
    def compute(self, state: MarketState) -> float:
        # Volume = safety (liquidity)
        if state.volume > 1000000:
            self.response = 0.9
        elif state.volume > 500000:
            self.response = 0.75
        elif state.volume > 100000:
            self.response = 0.6
        elif state.volume > 50000:
            self.response = 0.5
        else:
            self.response = 0.3
        return self.response


class CargoShipNode(AurisNode):
    """üö¢ Liquidity - Momentum buffer"""
    def __init__(self):
        super().__init__("CargoShip", CONFIG['FREQ_CARGOSHIP'], 0.8)
        
    def compute(self, state: MarketState) -> float:
        # High volume relative to price range = good liquidity
        if state.high_24h <= state.low_24h or state.volume <= 0:
            return 0.5
        range_pct = (state.high_24h - state.low_24h) / state.low_24h
        vol_per_range = state.volume / (range_pct * 100) if range_pct > 0 else 0
        self.response = min(1, vol_per_range / 100000)
        return self.response


class ClownfishNode(AurisNode):
    """üê† Symbiosis - Market connection"""
    def __init__(self):
        super().__init__("Clownfish", CONFIG['FREQ_CLOWNFISH'], 0.9)
        
    def compute(self, state: MarketState) -> float:
        # Connection = how well this coin moves with market sentiment
        # Positive momentum with good volume = connected
        if state.change_24h > 0 and state.volume > 100000:
            self.response = 0.7 + min(0.3, state.change_24h / 30)
        elif state.change_24h > 0:
            self.response = 0.5 + min(0.2, state.change_24h / 20)
        else:
            self.response = 0.4
        return self.response


class AurisEngine:
    """The complete 9-node Auris analysis engine with Lambda field + HNC frequency"""
    
    def __init__(self):
        self.nodes = [
            TigerNode(),
            FalconNode(),
            HummingbirdNode(),
            DolphinNode(),
            DeerNode(),
            OwlNode(),
            PandaNode(),
            CargoShipNode(),
            ClownfishNode(),
        ]
        # Lambda field components (Œõ = S + O + E + H)
        self.last_lambda = 0.5      # O(t) = Observer (self-reference)
        self.lambda_history = deque(maxlen=5)  # E(t) = Echo (memory)
        
        # üåç‚ö° HNC Frequency Integration ‚ö°üåç
        self.hnc = None
        self.hnc_bridge = None
        self.hnc_frequency = 256.0  # Default to ROOT frequency
        self.hnc_coherence = 0.0
        self.hnc_is_harmonic = False
        self.asset_frequencies: Dict[str, Dict[str, Any]] = {}  # Per-asset frequency tracking
        self.frequency_history: deque = deque(maxlen=100)  # Global frequency history
        if HNC_AVAILABLE and CONFIG.get('ENABLE_HNC_FREQUENCY', True):
            try:
                self.hnc = HarmonicNexusCore(guardian_id="02111991")
                self.hnc_bridge = HNCTradingBridge(self.hnc)
                print("   üåç‚ö° HNC Frequency Layer ACTIVE")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  HNC init failed: {e}")
        
        # üåç‚ö° Probability Matrix Integration ‚ö°üåç
        self.prob_matrix = None
        if PROB_MATRIX_AVAILABLE and CONFIG.get('ENABLE_PROB_MATRIX', True):
            try:
                self.prob_matrix = HNCProbabilityIntegration()
                print("   üìä Probability Matrix (2-Hour Window) ACTIVE")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Probability Matrix init failed: {e}")
        
        # üåç‚ö° Global Financial Ecosystem Feed ‚ö°üåç
        self.global_feed = None
        self.macro_snapshot = None
        if GLOBAL_FEED_AVAILABLE:
            try:
                self.global_feed = GlobalFinancialFeed()
                self.macro_snapshot = self.global_feed.get_snapshot()
                print("   üåç Global Financial Ecosystem ACTIVE")
                print(f"      Fear/Greed: {self.macro_snapshot.crypto_fear_greed} | Regime: {self.macro_snapshot.market_regime}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Global Feed init failed: {e}")
        
        # üìä Probability Validation Engine üìä
        self.probability_validator = None
        if VALIDATOR_AVAILABLE:
            try:
                self.probability_validator = get_validator()
                stats = self.probability_validator.stats
                if stats.validated_predictions > 0:
                    print(f"   üìä Probability Validator ACTIVE")
                    print(f"      Accuracy: {stats.direction_accuracy*100:.1f}% ({stats.validated_predictions} predictions)")
                else:
                    print("   üìä Probability Validator ACTIVE (collecting data)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Validator init failed: {e}")
        
        # üåç‚ö° CoinAPI Anomaly Detection ‚ö°üåç
        self.coinapi_detector = None
        self.anomaly_blacklist: Dict[str, float] = {}  # {symbol: unblock_timestamp}
        self.coherence_adjustments: Dict[str, float] = {}  # {symbol: adjustment_factor}
        self.last_anomaly_scan = 0
        if COINAPI_AVAILABLE:
            try:
                api_key = os.getenv('COINAPI_KEY', '')
                if api_key:
                    coinapi_client = CoinAPIClient(api_key)
                    self.coinapi_detector = AnomalyDetector(coinapi_client)
                    print("   üåê CoinAPI Anomaly Detection ACTIVE")
                else:
                    print("   ‚ö†Ô∏è  CoinAPI: No API key (anomaly detection disabled)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  CoinAPI init failed: {e}")
        
        # üåå‚ö° Imperial Predictability Engine ‚ö°üåå
        self.imperial = None
        self.cosmic_state = None
        self.imperial_yield = 0.0
        self.cosmic_phase = "UNKNOWN"
        if IMPERIAL_AVAILABLE and CONFIG.get('ENABLE_IMPERIAL', True):
            try:
                self.imperial = ImperialTradingIntegration()
                self.cosmic_state = self.imperial.update_cosmic_state()
                print("   üåå‚ö° Imperial Predictability Engine ACTIVE")
                print(f"      ‚îú‚îÄ Cosmic Phase: {self.cosmic_state.phase.value}")
                print(f"      ‚îú‚îÄ Coherence: {self.cosmic_state.coherence:.2%}")
                print(f"      ‚îî‚îÄ Planetary Torque: √ó{self.cosmic_state.planetary_torque:.2f}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Imperial Predictability init failed: {e}")
        
        # üåç‚ö° Earth Resonance Engine ‚ö°üåç
        self.earth_engine = None
        if EARTH_RESONANCE_AVAILABLE and CONFIG.get('ENABLE_EARTH_RESONANCE', True):
            try:
                self.earth_engine = get_earth_engine()
                # Apply CONFIG thresholds to Earth engine
                coherence_thresh = CONFIG.get('EARTH_COHERENCE_THRESHOLD', 0.55)
                phase_lock_thresh = CONFIG.get('EARTH_PHASE_LOCK_THRESHOLD', 0.65)
                self.earth_engine.set_thresholds(
                    coherence=coherence_thresh,
                    phase_lock=phase_lock_thresh
                )
                self.earth_engine.update_schumann_state()
                print("   üåç‚ö° Earth Resonance Engine ACTIVE")
                print(f"      ‚îú‚îÄ Schumann Mode 1: {self.earth_engine.schumann_state.mode1_power:.2f}")
                print(f"      ‚îú‚îÄ Field Coherence: {self.earth_engine.schumann_state.field_coherence:.2%}")
                print(f"      ‚îú‚îÄ Coherence Gate: {coherence_thresh:.0%} | Phase Gate: {phase_lock_thresh:.0%}")
                print(f"      ‚îî‚îÄ PHI Multiplier: √ó{self.earth_engine.get_phi_position_multiplier():.3f}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Earth Resonance Engine init failed: {e}")
        
        # üî≠ QUANTUM TELESCOPE & HARMONIC UNDERLAY üî≠
        self.telescope = None
        self.harmonic_engine = None
        if CONFIG.get('ENABLE_QUANTUM_TELESCOPE', True):
            try:
                self.telescope = QuantumTelescope()
                self.harmonic_engine = SixDimensionalHarmonicEngine()
                print("   üî≠ Quantum Telescope & Harmonic Engine ACTIVE")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Quantum Telescope init failed: {e}")
        
    def compute_coherence(self, state: MarketState) -> Tuple[float, str]:
        """Compute overall market coherence (Œì) with Lambda field + HNC frequency
        
        Œõ(t) = S(t) + O(t) + E(t) + H(t)
        Where:
            S(t) = Substrate (9 Auris nodes)
            O(t) = Observer (Œõ(t-1) √ó 0.3) - self-reference
            E(t) = Echo (avg(Œõ[t-5:t]) √ó 0.2) - memory
            H(t) = Harmonic (HNC frequency coherence √ó 0.25) - global frequency
        """
        total_weight = sum(n.weight for n in self.nodes)
        weighted_sum = 0
        
        dominant_node = None
        max_response = 0
        
        # S(t) = Substrate from 9 Auris nodes
        for node in self.nodes:
            response = node.compute(state)
            weighted_sum += response * node.weight
            if response > max_response:
                max_response = response
                dominant_node = node.name
                
        substrate = weighted_sum / total_weight if total_weight > 0 else 0
        
        # Full Lambda field if enabled
        if CONFIG['ENABLE_LAMBDA_FIELD']:
            # O(t) = Observer component (self-reference)
            observer = self.last_lambda * CONFIG['OBSERVER_WEIGHT']
            
            # E(t) = Echo component (memory)
            echo = 0.0
            if len(self.lambda_history) > 0:
                echo = (sum(self.lambda_history) / len(self.lambda_history)) * CONFIG['ECHO_WEIGHT']
            
            # H(t) = Harmonic component (HNC global frequency)
            harmonic = 0.0
            if self.hnc_bridge and CONFIG.get('ENABLE_HNC_FREQUENCY', True):
                harmonic = self.hnc_coherence * CONFIG.get('HNC_FREQUENCY_WEIGHT', 0.25)

            # H6D(t) = 6D Harmonic waveform ecosystem coherence
            harmonic6d = 0.0
            if self.harmonic_engine:
                try:
                    eco = self.harmonic_engine.get_ecosystem_state()
                    harmonic_coh = eco.get('ecosystem_coherence', 0.0)
                    if harmonic_coh >= CONFIG.get('HARMONIC_GATE', 0.45):
                        harmonic6d = harmonic_coh * CONFIG.get('HARMONIC_WEIGHT', 0.20)
                except Exception:
                    harmonic6d = 0.0
            
            # Q(t) = Quantum Telescope component (Geometric Coherence)
            quantum = 0.0
            if self.telescope:
                try:
                    beam = LightBeam(
                        symbol=state.symbol,
                        price=state.price,
                        volume=state.volume,
                        momentum=state.change_24h,
                        timestamp=state.timestamp
                    )
                    observation = self.telescope.observe(beam)
                    # Use Dodecahedron (Ether/Coherence) as the primary signal
                    quantum = observation.get(GeometricSolid.DODECAHEDRON, 0.5) * CONFIG.get('QUANTUM_WEIGHT', 0.20)
                except Exception:
                    quantum = 0.0

            # Œõ(t) = S(t) + O(t) + E(t) + H(t) + H6D(t) + Q(t)
            lambda_field = substrate + observer + echo + harmonic + harmonic6d + quantum
            lambda_field = max(0.0, min(1.0, lambda_field))  # Clamp to [0, 1]
            
            # Update history
            self.lambda_history.append(lambda_field)
            self.last_lambda = lambda_field
            
            coherence = lambda_field
        else:
            # Legacy mode: just use substrate
            coherence = substrate
                
        return coherence, dominant_node or "Unknown"
    
    def update_hnc_state(self, symbol: str, price: float, change_24h: float, coherence: float, score: float):
        """Update HNC frequency state for a symbol and get harmonic analysis"""
        if not self.hnc_bridge:
            return None
        
        try:
            opp = {
                'symbol': symbol,
                'price': price,
                'change24h': change_24h,
                'coherence': coherence,
                'score': score
            }
            enhanced = self.hnc_bridge.enhance_opportunity(opp)
            
            # Store latest HNC state
            self.hnc_frequency = enhanced.get('hnc_frequency', 256.0)
            self.hnc_coherence = enhanced.get('hnc_resonance', 0.0)
            self.hnc_is_harmonic = enhanced.get('hnc_is_harmonic', False)
            
            # üåç‚ö° Track per-asset frequency ‚ö°üåç
            self.asset_frequencies[symbol] = {
                'symbol': symbol,
                'frequency': enhanced.get('hnc_frequency', 256.0),
                'is_harmonic': enhanced.get('hnc_is_harmonic', False),
                'resonance': enhanced.get('hnc_resonance', 0.5),
                'change': change_24h,
                'coherence': coherence,
                'score': enhanced.get('score', score),
                'price': price,
                'timestamp': time.time()
            }
            
            # Store in frequency history for trend analysis
            self.frequency_history.append({
                'symbol': symbol,
                'frequency': enhanced.get('hnc_frequency', 256.0),
                'timestamp': time.time()
            })
            
            return enhanced
        except Exception as e:
            return None
    
    def get_hnc_position_modifier(self) -> float:
        """Get position size modifier based on HNC frequency state"""
        if not self.hnc_bridge or not CONFIG.get('ENABLE_HNC_FREQUENCY', True):
            return 1.0
        
        try:
            rec = self.hnc_bridge.get_trading_recommendation([])
            return rec.get('position_size_modifier', 1.0)
        except:
            return 1.0
    
    def get_hnc_status(self) -> Dict[str, Any]:
        """Get current HNC status for display"""
        if not self.hnc_bridge or not CONFIG.get('ENABLE_HNC_FREQUENCY', True):
            return {
                'composite_freq': 256.0,
                'phase': 'DISABLED',
                'triadic_coherence': 0.0,
                'lighthouse_aligned': False,
                'position_modifier': 1.0,
                'fear_state': 'NEUTRAL'
            }
        
        try:
            state = self.hnc.get_global_field_state()
            rec = self.hnc_bridge.get_trading_recommendation([])
            return {
                'composite_freq': state.get('composite_frequency', 256.0),
                'phase': state.get('phase', 'UNKNOWN'),
                'triadic_coherence': state.get('triadic_coherence', 0.0),
                'lighthouse_aligned': state.get('lighthouse_aligned', False),
                'position_modifier': rec.get('position_size_modifier', 1.0),
                'fear_state': state.get('fear_state', 'NEUTRAL')
            }
        except Exception as e:
            return {
                'composite_freq': self.hnc_frequency,
                'phase': 'ERROR',
                'triadic_coherence': self.hnc_coherence,
                'lighthouse_aligned': False,
                'position_modifier': 1.0,
                'fear_state': 'UNKNOWN'
            }

    def get_probability_signal(self, symbol: str, price: float, frequency: float,
                                momentum: float, coherence: float, 
                                is_harmonic: bool) -> Dict[str, Any]:
        """
        Get probability signal for an asset using the 2-hour probability matrix.
        Hour -1 (lookback) provides base signal.
        Hour +1 (forecast) is the primary trading window.
        Hour +2 fine-tunes Hour +1 predictions.
        """
        if not self.prob_matrix or not CONFIG.get('ENABLE_PROB_MATRIX', True):
            return {
                'probability': 0.5,
                'confidence': 0.0,
                'action': 'HOLD',
                'modifier': 1.0,
                'h1_state': 'DISABLED',
                'fine_tune': 0.0,
            }
        
        try:
            # Update and analyze
            matrix = self.prob_matrix.update_and_analyze(
                symbol=symbol,
                price=price,
                frequency=frequency,
                momentum=momentum,
                coherence=coherence,
                is_harmonic=is_harmonic,
            )
            
            # Get trading signal
            signal = self.prob_matrix.get_trading_signal(symbol)
            return signal
        except Exception as e:
            return {
                'probability': 0.5,
                'confidence': 0.0,
                'action': 'HOLD',
                'modifier': 1.0,
                'h1_state': 'ERROR',
                'fine_tune': 0.0,
            }
    
    def get_high_probability_assets(self, min_prob: float = 0.65) -> List[Dict]:
        """Get assets with high probability forecasts"""
        if not self.prob_matrix:
            return []
        return self.prob_matrix.get_high_probability_opportunities(
            min_probability=min_prob,
            min_confidence=CONFIG.get('PROB_MIN_CONFIDENCE', 0.50)
        )

    # üåå‚ö° IMPERIAL PREDICTABILITY METHODS ‚ö°üåå
    
    def get_imperial_prediction(self, symbol: str, price: float, 
                                momentum: float = 0.0) -> Dict[str, Any]:
        """
        Get Imperial Predictability forecast for a symbol.
        Uses cosmic synchronization + temporal forecasting.
        """
        if not self.imperial or not CONFIG.get('ENABLE_IMPERIAL', True):
            return {
                'probability': 0.5,
                'confidence': 0.0,
                'action': 'HOLD',
                'multiplier': 1.0,
                'cosmic_phase': 'DISABLED',
                'cosmic_boost': 1.0,
            }
        
        try:
            matrix = self.imperial.engine.generate_matrix(symbol, price, momentum)
            return {
                'probability': matrix.combined_probability,
                'confidence': matrix.imperial_confidence,
                'action': matrix.recommended_action,
                'multiplier': matrix.position_multiplier,
                'cosmic_phase': matrix.cosmic_state.phase.value,
                'cosmic_boost': matrix.cosmic_boost,
                'alignment_bonus': matrix.alignment_bonus,
                '1h_signal': matrix.window_1h.signal.value,
                '4h_signal': matrix.window_4h.signal.value,
                'btc_forecast': matrix.window_1h.btc_forecast,
                'imperial_yield': matrix.cosmic_state.imperial_yield,
                'planetary_torque': matrix.cosmic_state.planetary_torque,
            }
        except Exception as e:
            return {
                'probability': 0.5,
                'confidence': 0.0,
                'action': 'HOLD',
                'multiplier': 1.0,
                'cosmic_phase': 'ERROR',
                'cosmic_boost': 1.0,
            }
    
    def enhance_opportunity_imperial(self, opp: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enhance a trading opportunity with Imperial predictability.
        Adds cosmic-aware position sizing and probability forecasts.
        """
        if not self.imperial or not CONFIG.get('ENABLE_IMPERIAL', True):
            return opp
        
        try:
            return self.imperial.enhance_opportunity(opp)
        except Exception as e:
            return opp
    
    def get_imperial_position_modifier(self, symbol: str, 
                                       momentum: float = 0.0,
                                       price: float = 0.0) -> float:
        """
        Get Imperial position size modifier for a symbol.
        Returns multiplier (0.1 to 1.5) based on cosmic state.
        """
        if not self.imperial or not CONFIG.get('ENABLE_IMPERIAL', True):
            return 1.0
        
        try:
            return self.imperial.get_position_modifier(symbol, momentum, price)
        except:
            return 1.0
    
    def get_cosmic_status(self) -> Dict[str, Any]:
        """Get current cosmic state for display"""
        if not self.imperial or not CONFIG.get('ENABLE_IMPERIAL', True):
            return {
                'phase': 'DISABLED',
                'coherence': 0.0,
                'distortion': 0.0,
                'planetary_torque': 1.0,
                'imperial_yield': 0.0,
            }
        
        try:
            return self.imperial.get_cosmic_status()
        except:
            return {
                'phase': 'ERROR',
                'coherence': 0.0,
                'distortion': 0.0,
                'planetary_torque': 1.0,
                'imperial_yield': 0.0,
            }
    
    def should_trade_imperial(self) -> Tuple[bool, str]:
        """
        Check if cosmic state supports trading.
        Returns (should_trade, reason).
        """
        if not self.imperial or not CONFIG.get('ENABLE_IMPERIAL', True):
            return True, "Imperial disabled - trading allowed"
        
        try:
            return self.imperial.should_trade()
        except:
            return True, "Imperial check failed - trading allowed"
    
    def get_earth_resonance_status(self) -> Dict[str, Any]:
        """Get current Earth Resonance Engine status"""
        if not self.earth_engine or not CONFIG.get('ENABLE_EARTH_RESONANCE', True):
            return {'enabled': False, 'reason': 'Earth Resonance disabled'}
        
        try:
            gate_status = self.earth_engine.get_trading_gate_status_dict()
            return {
                'enabled': True,
                'gate_open': gate_status['gate_open'],
                'coherence': gate_status['coherence'],
                'phase_locked': gate_status['phase_locked'],
                'schumann_power': gate_status['schumann_power'],
                'dominant_mode': gate_status['dominant_mode'],
                'phi_multiplier': self.earth_engine.get_phi_position_multiplier(),
                'exit_urgency': self.earth_engine.get_exit_urgency(0)  # Default 0 P&L
            }
        except Exception as e:
            return {'enabled': False, 'reason': f'Earth Resonance error: {e}'}
    
    def should_trade_earth(self) -> Tuple[bool, str]:
        """
        Check if Earth Resonance supports trading.
        Returns (should_trade, reason).
        """
        if not self.earth_engine or not CONFIG.get('ENABLE_EARTH_RESONANCE', True):
            return True, "Earth Resonance disabled - trading allowed"
        
        try:
            # get_trading_gate_status returns (bool, str)
            gate_open, reason = self.earth_engine.get_trading_gate_status()
            
            if not gate_open:
                return False, f"Earth gate CLOSED: {reason}"
            
            return True, f"Earth gate OPEN: {reason}"
        except Exception as e:
            return True, f"Earth check failed ({e}) - trading allowed"
    
    def should_trade_brain(self) -> Tuple[bool, str]:
        """
        üß† BRAIN GATE: 7 Civilizations + Quantum Brain must approve trades.
        Returns (should_trade, reason).
        """
        if not hasattr(self, 'brain_bridge') or not self.brain_bridge:
            return True, "Brain Bridge not initialized - trading allowed"
        
        try:
            # Get brain recommendation
            rec = self.brain_bridge.get_trading_recommendation()
            action = rec.get('action', 'HOLD')
            civs_bullish = rec.get('civilizations_bullish', 0)
            civs_total = rec.get('civilizations_total', 7)
            confidence = rec.get('confidence', 0.5)
            reasoning = rec.get('reasoning', [])
            
            # HARD BLOCK: If brain says REDUCE with high confidence
            if action == 'REDUCE' and confidence > 0.65:
                return False, f"Brain says REDUCE (conf={confidence:.0%}, {civs_bullish}/{civs_total} bullish)"
            
            # SOFT GATE: If BEARISH with moderate confidence
            consensus = self._brain_consensus
            if consensus == 'BEARISH' and confidence > 0.6:
                return False, f"Brain BEARISH (conf={confidence:.0%}) - waiting for bullish signal"
            
            # APPROVED
            if action == 'BUY':
                return True, f"Brain APPROVED: {civs_bullish}/{civs_total} civilizations BULLISH"
            
            return True, f"Brain neutral - {consensus} (conf={confidence:.0%})"
            
        except Exception as e:
            return True, f"Brain check error ({e}) - trading allowed"
    
    def should_trade_all_gates(self) -> Tuple[bool, str]:
        """
        Combined gate check: Imperial + HNC + Earth Resonance + BRAIN.
        Returns (should_trade, reason).
        """
        reasons = []
        
        # Check Imperial gate
        imperial_ok, imperial_reason = self.should_trade_imperial()
        if not imperial_ok:
            reasons.append(f"Imperial: {imperial_reason}")
        
        # Check Earth Resonance gate
        earth_ok, earth_reason = self.should_trade_earth()
        if not earth_ok:
            reasons.append(f"Earth: {earth_reason}")
        
        # Check HNC frequency gate (if we have current frequency)
        if CONFIG.get('HNC_ENTRY_GATING', True) and hasattr(self, 'hnc_current_frequency'):
            freq = getattr(self, 'hnc_current_frequency', 432)
            if 438 <= freq <= 442:  # Distortion zone
                reasons.append(f"HNC: Distortion frequency {freq}Hz blocked")
        
        # üß† Check Brain gate (NEW)
        brain_ok, brain_reason = self.should_trade_brain()
        if not brain_ok:
            reasons.append(f"Brain: {brain_reason}")
        
        if reasons:
            return False, " | ".join(reasons)
        
        return True, "All gates OPEN"
    
    def should_trade_ui_validated(self, symbol: str, exchange: str, action: str, confidence: float = 0.7) -> Tuple[bool, str, float]:
        """
        üåê UI BRIDGE VALIDATION - Cross-reference with aureoninstitute.com data
        
        Validates a trade against:
        - Harmonic frequency alignment (432Hz optimal, 440Hz blocked)
        - Global coherence (Œì >= 0.30)
        - Fear & Greed index (blocks extreme greed buys)
        - Risk level (blocks high-risk new entries)
        
        Returns (should_trade, reason, adjusted_confidence)
        """
        if not self.ui_bridge_enabled or not self.ui_bridge:
            return True, "UI Bridge not enabled - trade allowed", confidence
        
        try:
            # Run async validation in sync context
            import asyncio
            
            # Use existing loop if available, else create new
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # Validate against UI data
            result = loop.run_until_complete(
                self.ui_bridge.validate_and_enhance_signal(
                    symbol=symbol,
                    exchange=exchange,
                    action=action,
                    confidence=confidence
                )
            )
            
            validated_action = result.get('validated_action', action)
            validated_confidence = result.get('validated_confidence', confidence)
            reason = result.get('ui_validation', {}).get('reason', 'Unknown')
            
            # Log the UI validation
            harmonic = result.get('harmonic_data', {})
            freq_hz = harmonic.get('frequency_hz', 432)
            band = harmonic.get('frequency_band', 'HARMONY')
            
            if validated_action == 'HOLD' and action != 'HOLD':
                logger.info(f"üåê UI BLOCKED {action} {symbol} - {reason} [{freq_hz}Hz {band}]")
                return False, reason, validated_confidence
            
            logger.debug(f"üåê UI VALIDATED {action} {symbol} @ {validated_confidence:.0%} [{freq_hz}Hz {band}]")
            return True, reason, validated_confidence
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è UI validation error: {e} - allowing trade")
            return True, f"UI validation error ({e})", confidence
    
    def get_system_health_report(self) -> Dict[str, Any]:
        """
        üè• COMPREHENSIVE SYSTEM HEALTH CHECK üè•
        Ensures all subsystems are operational and communicating.
        """
        report = {
            'timestamp': datetime.now().isoformat(),
            'systems': {},
            'communication': {},
            'gates': {},
            'data': {},
            'signals': {},
            'overall_health': 'UNKNOWN',
        }
        
        # 1Ô∏è‚É£ PROBABILITY MATRIX
        prob_status = "ACTIVE" if self.prob_matrix else "INACTIVE"
        report['systems']['probability_matrix'] = {
            'status': prob_status,
            'description': 'üìä Multi-day temporal windows (Day -7 to +7)',
            'learning': 'ENABLED' if self.prob_matrix else False,
        }
        
        # 1.5Ô∏è‚É£ PROBABILITY LOADER & CONSENSUS
        loader = getattr(self, 'probability_loader', None)
        loader_status = "ACTIVE" if loader else "INACTIVE"
        report['systems']['probability_loader'] = {
            'status': loader_status,
            'description': 'üéØ Fresh probability reports + multi-exchange consensus',
            'fresh': loader.is_fresh() if loader else False,
        }
        
        # 2Ô∏è‚É£ IMPERIAL PREDICTABILITY
        imperial_status = "ACTIVE" if self.imperial else "INACTIVE"
        report['systems']['imperial'] = {
            'status': imperial_status,
            'phase': self.cosmic_phase if self.imperial else 'N/A',
            'description': 'üåå‚ö° Cosmic phase + planetary torque',
        }
        
        # 3Ô∏è‚É£ EARTH RESONANCE
        earth_status = "ACTIVE" if self.earth_engine else "INACTIVE"
        report['systems']['earth_resonance'] = {
            'status': earth_status,
            'description': 'üåç Schumann resonance + PHI amplification',
            'gate': 'OPEN' if self.earth_engine else 'N/A',
        }
        
        # 4Ô∏è‚É£ HNC FREQUENCY
        hnc_status = "ACTIVE" if self.hnc else "INACTIVE"
        report['systems']['hnc_frequency'] = {
            'status': hnc_status,
            'frequency': f"{self.hnc_frequency:.0f}Hz" if self.hnc else 'N/A',
            'description': 'üåç‚ö° Harmonic frequency analysis',
            'harmonic': self.hnc_is_harmonic if self.hnc else False,
        }
        
        # 5Ô∏è‚É£ GLOBAL FINANCIAL FEED
        feed_status = "ACTIVE" if self.global_feed else "INACTIVE"
        report['systems']['global_feed'] = {
            'status': feed_status,
            'description': 'üåç Macro indicators + fear/greed index',
        }
        
        # 6Ô∏è‚É£ ANOMALY DETECTION
        anomaly_status = "ACTIVE" if self.coinapi_detector else "INACTIVE"
        report['systems']['anomaly_detection'] = {
            'status': anomaly_status,
            'blacklisted_symbols': len(self.anomaly_blacklist),
            'description': 'üåê CoinAPI anomaly detection',
        }
        
        # 7Ô∏è‚É£ QUANTUM TELESCOPE
        quantum_status = "ACTIVE" if self.telescope else "INACTIVE"
        report['systems']['quantum_telescope'] = {
            'status': quantum_status,
            'description': 'üî≠ Quantum harmonic resonance',
        }
        
        # GATES REPORT
        imperial_ok, imperial_reason = self.should_trade_imperial()
        earth_ok, earth_reason = self.should_trade_earth()
        all_ok, all_reason = self.should_trade_all_gates()
        
        # Check Brain gate
        brain_ok, brain_reason = self.should_trade_brain()
        
        report['gates']['imperial'] = {'open': imperial_ok, 'reason': imperial_reason}
        report['gates']['earth'] = {'open': earth_ok, 'reason': earth_reason}
        report['gates']['brain'] = {'open': brain_ok, 'reason': brain_reason}
        report['gates']['all'] = {'open': all_ok, 'reason': all_reason}
        
        # DATA FRESHNESS & SIGNALS
        try:
            # Probability loader freshness
            if loader:
                fresh = loader.is_fresh()
                newest, oldest = loader.get_report_ages()
                report['data']['probability_reports'] = {
                    'stale': not fresh,
                    'newest_minutes': newest,
                    'oldest_minutes': oldest,
                    'threshold_minutes': loader.freshness_threshold_minutes,
                }
                
                # High conviction signals
                top_signals = loader.get_top_signals(limit=10, min_probability=0.8, min_confidence=0.8)
                report['signals']['high_conviction'] = {
                    'count': len(top_signals),
                    'symbols': [s['symbol'] for s in top_signals[:5]],  # Top 5
                }
                
                # Multi-exchange consensus
                consensus = loader.get_consensus_signals(min_exchanges=2, min_probability=0.75)
                report['signals']['consensus'] = {
                    'count': len(consensus),
                    'symbols': [c['symbol'] for c in consensus[:5]],  # Top 5
                }
            else:
                # Fallback to state aggregator
                agg = STATE_AGGREGATOR.aggregated_state
                pfresh = agg.get('probability_freshness', {}) if agg else {}
                report['data']['probability_reports'] = {
                    'stale': pfresh.get('stale', False),
                    'newest_minutes': pfresh.get('newest_minutes'),
                    'oldest_minutes': pfresh.get('oldest_minutes'),
                    'threshold_minutes': pfresh.get('threshold_minutes', 120),
                }
                report['signals']['high_conviction'] = {'count': 0, 'symbols': []}
                report['signals']['consensus'] = {'count': 0, 'symbols': []}
            
            # Position hygiene check
            hygiene_checker = getattr(self, 'position_hygiene', None)
            if hygiene_checker:
                state_path = '/workspaces/aureon-trading/aureon_kraken_state.json'
                hygiene_result = hygiene_checker.check_positions(state_path)
                report['data']['position_hygiene'] = {
                    'flagged': hygiene_result.get('flagged', []),
                    'count': hygiene_result.get('count', 0),
                    'rules': hygiene_result.get('rules', {}),
                }
            else:
                agg = STATE_AGGREGATOR.aggregated_state
                position_hygiene = agg.get('position_hygiene', {}) if agg else {}
                report['data']['position_hygiene'] = {
                    'flagged': position_hygiene.get('flagged', []),
                    'count': len(position_hygiene.get('flagged', [])),
                    'rules': position_hygiene.get('rules', {}),
                }
        except Exception as e:
            logger.warning(f"Health report data gathering error: {e}")
            report['data']['probability_reports'] = {'stale': False}
            report['data']['position_hygiene'] = {'flagged': [], 'count': 0}
            report['signals'] = {'high_conviction': {'count': 0, 'symbols': []}, 'consensus': {'count': 0, 'symbols': []}}

        # COMMUNICATION CHECK
        systems_active = sum(1 for s in report['systems'].values() if s['status'] == 'ACTIVE')
        report['communication'] = {
            'systems_active': systems_active,
            'auris_hub': 'OPERATIONAL',
            'data_flow': 'BIDIRECTIONAL',
            'learning_enabled': bool(self.prob_matrix),
            'validation_enabled': bool(self.probability_validator),
        }
        
        # OVERALL HEALTH
        prob_stale = report['data'].get('probability_reports', {}).get('stale', False)
        hygiene_count = report['data'].get('position_hygiene', {}).get('count', 0)
        consensus_count = report['signals'].get('consensus', {}).get('count', 0)
        high_conv_count = report['signals'].get('high_conviction', {}).get('count', 0)

        if all_ok and systems_active >= 5 and not prob_stale and hygiene_count == 0 and consensus_count > 0:
            report['overall_health'] = f'üü¢ HEALTHY - All systems communicating ({consensus_count} consensus signals)'
        elif all_ok and systems_active >= 4 and not prob_stale:
            if hygiene_count > 0:
                report['overall_health'] = f'üü° OPERATIONAL - {hygiene_count} position hygiene alerts'
            else:
                report['overall_health'] = f'üü° OPERATIONAL - Core systems active ({high_conv_count} high-conviction signals)'
        elif all_ok and systems_active >= 2:
            if prob_stale:
                report['overall_health'] = 'üü° OPERATIONAL - Probability data stale'
            else:
                report['overall_health'] = 'üü° OPERATIONAL - Limited systems active'
        else:
            report['overall_health'] = 'üî¥ DEGRADED - Check gates and systems'
        
        return report
    
    def print_system_health(self) -> None:
        """
        Print a formatted system health report to console.
        Shows all active systems and their communication status.
        """
        report = self.get_system_health_report()
        
        print("\n" + "‚ïê" * 80)
        print("üè• ECOSYSTEM HEALTH REPORT " + report['overall_health'])
        print("‚ïê" * 80)
        
        print("\nüì° SUBSYSTEMS STATUS:")
        for name, system in report['systems'].items():
            status = system['status']
            indicator = "‚úÖ" if status == "ACTIVE" else "‚ö™"
            desc = system.get('description', '')
            print(f"  {indicator} {name.upper().replace('_', ' ')}: {desc}")
        
        print("\nüö™ TRADING GATES:")
        for gate_name, gate_status in report['gates'].items():
            if gate_name == 'all':
                indicator = "üü¢" if gate_status['open'] else "üî¥"
                print(f"\n  {indicator} ALL GATES: {gate_status['reason']}")
            else:
                indicator = "‚úÖ" if gate_status['open'] else "‚ùå"
                print(f"  {indicator} {gate_name.upper()}: {gate_status['reason']}")
        
        print("\nüìä COMMUNICATION HUB:")
        comm = report['communication']
        print(f"  ‚Ä¢ Systems Active: {comm['systems_active']}/8")
        print(f"  ‚Ä¢ Auris Hub: {comm['auris_hub']}")
        print(f"  ‚Ä¢ Data Flow: {comm['data_flow']}")
        print(f"  ‚Ä¢ Learning: {'ENABLED ‚úÖ' if comm['learning_enabled'] else 'DISABLED ‚ö™'}")
        print(f"  ‚Ä¢ Validation: {'ENABLED ‚úÖ' if comm['validation_enabled'] else 'DISABLED ‚ö™'}")
        
        # SIGNALS
        signals = report.get('signals', {})
        high_conv = signals.get('high_conviction', {})
        consensus = signals.get('consensus', {})
        if high_conv.get('count', 0) > 0 or consensus.get('count', 0) > 0:
            print("\nüéØ TRADING SIGNALS:")
            if high_conv.get('count', 0) > 0:
                symbols_str = ', '.join(high_conv.get('symbols', [])[:5])
                print(f"  ‚Ä¢ High Conviction: {high_conv['count']} signals (p‚â•0.8, conf‚â•0.8)")
                print(f"    Top: {symbols_str}")
            if consensus.get('count', 0) > 0:
                symbols_str = ', '.join(consensus.get('symbols', [])[:5])
                print(f"  ‚Ä¢ Multi-Exchange Consensus: {consensus['count']} symbols (‚â•2 exchanges)")
                print(f"    Top: {symbols_str}")

        data = report.get('data', {})
        prob_data = data.get('probability_reports', {})
        hygiene = data.get('position_hygiene', {})
        print("\nüß† DATA HEALTH:")
        if prob_data:
            stale = prob_data.get('stale')
            newest = prob_data.get('newest_minutes')
            threshold = prob_data.get('threshold_minutes')
            indicator = "‚ö†Ô∏è" if stale else "‚úÖ"
            newest_str = f"{newest:.1f}m" if newest is not None else "n/a"
            print(f"  {indicator} Probability reports fresh: {newest_str} (threshold {threshold}m)")
        if hygiene:
            count = hygiene.get('count', 0)
            indicator = "‚ö†Ô∏è" if count > 0 else "‚úÖ"
            print(f"  {indicator} Position hygiene flags: {count}")
        
        print("\n" + "‚ïê" * 80 + "\n")
    
    def update_cosmic_state(self, market_data: Optional[Dict] = None) -> None:
        """Update cosmic state with optional market data"""
        if self.imperial and CONFIG.get('ENABLE_IMPERIAL', True):
            try:
                self.cosmic_state = self.imperial.update_cosmic_state(market_data)
                self.cosmic_phase = self.cosmic_state.phase.value
                self.imperial_yield = self.cosmic_state.imperial_yield
            except:
                pass

    def get_asset_frequency_grid(self) -> List[Dict[str, Any]]:
        """Get detailed frequency breakdown for all tracked assets"""
        return list(self.asset_frequencies.values())
    
    def get_frequency_distribution(self) -> Dict[str, int]:
        """Get count of assets at each frequency band"""
        distribution = {
            '174_FOUNDATION': 0,
            '256_ROOT': 0,
            '396_LIBERATION': 0,
            '432_NATURAL': 0,
            '440_DISTORTION': 0,
            '512_VISION': 0,
            '528_LOVE': 0,
            '639_CONNECTION': 0,
            '741_AWAKENING': 0,
            '852_INTUITION': 0,
            '963_UNITY': 0,
        }
        
        for asset in self.asset_frequencies.values():
            freq = asset.get('frequency', 256)
            if freq <= 200:
                distribution['174_FOUNDATION'] += 1
            elif freq <= 300:
                distribution['256_ROOT'] += 1
            elif freq <= 410:
                distribution['396_LIBERATION'] += 1
            elif freq <= 438:
                distribution['432_NATURAL'] += 1
            elif freq <= 445:
                distribution['440_DISTORTION'] += 1
            elif freq <= 520:
                distribution['512_VISION'] += 1
            elif freq <= 580:
                distribution['528_LOVE'] += 1
            elif freq <= 700:
                distribution['639_CONNECTION'] += 1
            elif freq <= 800:
                distribution['741_AWAKENING'] += 1
            elif freq <= 900:
                distribution['852_INTUITION'] += 1
            else:
                distribution['963_UNITY'] += 1
                
        return distribution
    
    def get_harmonic_count(self) -> Dict[str, int]:
        """Get count of harmonic vs distorted assets"""
        harmonic = sum(1 for a in self.asset_frequencies.values() if a.get('is_harmonic', False))
        distortion = sum(1 for a in self.asset_frequencies.values() if 435 <= a.get('frequency', 256) <= 445)
        neutral = len(self.asset_frequencies) - harmonic - distortion
        return {'harmonic': harmonic, 'distortion': distortion, 'neutral': neutral}
    
    def get_harmonic_assets(self) -> List[str]:
        """Get list of assets currently in harmonic resonance"""
        return [
            asset['symbol'] for asset in self.asset_frequencies.values()
            if asset.get('is_harmonic', False)
        ]
    
    def get_distorted_assets(self) -> List[str]:
        """Get list of assets in 440Hz distortion field"""
        return [
            asset['symbol'] for asset in self.asset_frequencies.values()
            if 435 <= asset.get('frequency', 256) <= 445
        ]
    
    def scan_for_anomalies(self, symbols: List[str]) -> List[Dict]:
        """
        Scan market for anomalies using CoinAPI cross-exchange data.
        Returns detected anomalies and applies algorithm refinements.
        """
        if not self.coinapi_detector or not CONFIG.get('ENABLE_COINAPI', False):
            return []
        
        current_time = time.time()
        scan_interval = CONFIG.get('COINAPI_SCAN_INTERVAL', 300)
        
        # Rate limit scans
        if current_time - self.last_anomaly_scan < scan_interval:
            return []
        
        self.last_anomaly_scan = current_time
        
        anomalies = []
        
        # Scan a sample of symbols (not all, to save API calls)
        sample_symbols = random.sample(symbols, min(5, len(symbols))) if symbols else []
        
        for symbol in sample_symbols:
            try:
                # Parse symbol (e.g., "BTC/USD" -> base="BTC", quote="USD")
                if '/' in symbol:
                    base, quote = symbol.split('/')
                elif len(symbol) >= 6:
                    # Try to parse (e.g., "BTCUSD" -> "BTC", "USD")
                    base = symbol[:3]
                    quote = symbol[3:]
                else:
                    continue
                
                # Analyze cross-exchange data
                analysis = self.coinapi_detector.analyze_symbol(base, quote)
                
                # Process anomalies and apply refinements
                for anom_dict in analysis.get('anomalies', []):
                    severity = anom_dict.get('severity', 0)
                    if severity >= CONFIG.get('COINAPI_MIN_SEVERITY', 0.40):
                        anomalies.append(anom_dict)
                        
                        # Apply refinements based on anomaly type
                        self._apply_anomaly_refinement(symbol, anom_dict)
                
            except Exception as e:
                continue
        
        return anomalies
    
    def _apply_anomaly_refinement(self, symbol: str, anomaly: Dict):
        """Apply algorithm refinements based on detected anomaly"""
        anom_type = anomaly.get('type', '')
        severity = anomaly.get('severity', 0)
        
        if 'üí∞ Price Manipulation' in anom_type or 'üîÑ Wash Trading' in anom_type:
            # Blacklist symbol temporarily
            duration = CONFIG.get('COINAPI_BLACKLIST_DURATION', 3600)
            self.anomaly_blacklist[symbol] = time.time() + duration
            print(f"   üö´ Blacklisted {symbol} for {duration}s: {anom_type}")
        
        elif 'üìä Orderbook Spoofing' in anom_type:
            # Reduce coherence threshold (require higher quality)
            if CONFIG.get('COINAPI_ADJUST_COHERENCE', True):
                adjustment = 1.0 + (severity * 0.2)
                self.coherence_adjustments[symbol] = adjustment
                print(f"   ‚öñÔ∏è  Adjusted {symbol} coherence threshold: √ó{adjustment:.2f}")
        
        elif 'üåê Cross-Exchange Spread' in anom_type:
            # This is actually good - use multi-exchange mean price
            print(f"   üíé Arbitrage detected on {symbol}: {anomaly.get('description', '')}")
    
    def is_symbol_blacklisted(self, symbol: str) -> bool:
        """Check if symbol is blacklisted due to anomalies"""
        if symbol not in self.anomaly_blacklist:
            return False
        
        # Check if blacklist has expired
        if time.time() > self.anomaly_blacklist[symbol]:
            del self.anomaly_blacklist[symbol]
            return False
        
        return True
    
    def get_coherence_adjustment(self, symbol: str) -> float:
        """Get coherence threshold adjustment for symbol"""
        return self.coherence_adjustments.get(symbol, 1.0)
    
    def print_frequency_grid(self, top_n: int = 10):
        """Print a visual frequency grid for assets"""
        if not self.asset_frequencies:
            print("   üì° No asset frequencies tracked yet")
            return
            
        # Sort by frequency
        sorted_assets = sorted(
            self.asset_frequencies.values(),
            key=lambda x: x.get('frequency', 256),
            reverse=True
        )[:top_n]
        
        print("\n   üåç‚ö° ASSET FREQUENCY GRID ‚ö°üåç")
        print("   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
        print("   ‚îÇ   SYMBOL    ‚îÇ  FREQ  ‚îÇ  STATE   ‚îÇ RESONANCE ‚îÇ  CHANGE  ‚îÇ")
        print("   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
        
        for asset in sorted_assets:
            symbol = asset.get('symbol', '???')[:11]
            freq = asset.get('frequency', 256)
            is_harm = asset.get('is_harmonic', False)
            resonance = asset.get('resonance', 0.5)
            change = asset.get('change', 0.0)
            
            # State indicator
            if is_harm:
                state = "üåà HARMONIC"
            elif 435 <= freq <= 445:
                state = "‚ö†Ô∏è DISTORT "
            elif freq >= 500:
                state = "üöÄ HIGH    "
            elif freq >= 350:
                state = "üìà RISING  "
            elif freq >= 250:
                state = "‚öñÔ∏è STABLE  "
            else:
                state = "üìâ LOW     "
            
            # Resonance bar
            bar_len = int(resonance * 5)
            bar = "‚ñà" * bar_len + "‚ñë" * (5 - bar_len)
            
            print(f"   ‚îÇ {symbol:11s} ‚îÇ {freq:6.0f} ‚îÇ {state} ‚îÇ {bar} {resonance:.2f} ‚îÇ {change:+6.1f}% ‚îÇ")
        
        print("   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
        
        # Distribution summary
        dist = self.get_frequency_distribution()
        harmonic_count = dist['256_ROOT'] + dist['528_LOVE'] + dist['432_NATURAL']
        distorted_count = dist['440_DISTORTION']
        total = len(self.asset_frequencies)
        
        print(f"   üìä Distribution: {harmonic_count} harmonic | {distorted_count} distorted | {total} total")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üçÑ MYCELIUM NETWORK - Neural Pattern Detection
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
@dataclass
class Synapse:
    """Connection between market signals with Hebbian learning"""
    source: str
    target: str
    strength: float = 0.5
    plasticity: float = 0.1
    activation_count: int = 0
    
    def pulse(self, signal: float) -> float:
        self.activation_count += 1
        return signal * self.strength
        
    def strengthen(self, reward: float):
        """Hebbian learning: strengthen if rewarded"""
        # Reward is typically profit % (e.g. 2.0 for 2%)
        # Scale reward to be small adjustment
        adjustment = reward * self.plasticity * 0.1
        self.strength = max(0.1, min(2.0, self.strength + adjustment))


# üçÑüß† FULL MYCELIUM NEURAL NETWORK WITH HIVES & QUEEN NEURON
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Import the full neural network if available
try:
    from aureon_mycelium import MyceliumNetwork as FullMyceliumNetwork, Hive, Agent, Neuron
    FULL_MYCELIUM_AVAILABLE = True
    logger.info("üçÑüß† Full Mycelium Neural Network loaded - Hives & Queen Neuron ACTIVE")
except ImportError:
    FULL_MYCELIUM_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Full Mycelium not available, using simplified pattern network")


class MyceliumNetwork:
    """
    Neural network for pattern detection across symbols.
    
    üß† ENHANCED: Now integrates with full Mycelium hive system!
    - Multiple agent hives with different strategies
    - Queen Neuron for collective decision making
    - Self-spawning when profitable (network growth)
    - Hebbian learning on all connections
    
    üåê THOUGHT BUS INTEGRATION:
    - Emits market signals to all connected components
    - Receives universal market intelligence
    - Passes information UP (to brain), DOWN (to positions), 
      LEFT/RIGHT (to peer systems like Auris, Lattice)
    """
    
    MYCELIUM_AVAILABLE = True  # Flag for system interconnection
    
    def __init__(self, initial_capital: float = 100.0, thought_bus: Optional['ThoughtBus'] = None):
        # Simple pattern network (always available)
        self.synapses: Dict[str, List[Synapse]] = {}
        self.activations: Dict[str, float] = {}
        self.telemetry_dir = Path("data/mycelium_snapshots")
        self.telemetry_dir.mkdir(parents=True, exist_ok=True)
        self.telemetry_buffer: Deque[Dict[str, Any]] = deque(maxlen=200)
        self.telemetry_schema = "1.0"
        
        # üåê THOUGHT BUS CONNECTION - Pass info up/down/left/right!
        self.bus = thought_bus
        if self.bus:
            # Subscribe to relevant topics for bidirectional flow
            self.bus.subscribe('universal_intel.*', self._on_thought_wrapper)
            self.bus.subscribe('brain.*', self._on_thought_wrapper)
            self.bus.subscribe('immune.*', self._on_thought_wrapper)
            logger.info("   üçÑ Mycelium: Connected to Thought Bus - info flows ALL directions!")
        
        # üåê Universal Market Intelligence reference
        self.universal_intel: Optional['UniversalMarketIntelligence'] = None
        self.last_intel_digest: Dict[str, Any] = {}
        
        # üçÑ FULL NEURAL NETWORK (if available)
        self.full_network = None
        self.queen_signal = 0.0  # Queen Neuron's collective decision
        self.hive_count = 0
        self.total_agents = 0
        self.generation = 0
        
        if FULL_MYCELIUM_AVAILABLE:
            try:
                self.full_network = FullMyceliumNetwork(
                    initial_capital=initial_capital,
                    agents_per_hive=5,
                    target_multiplier=2.0
                )
                self.hive_count = len(self.full_network.hives)
                self.total_agents = self.full_network.get_total_agents()
                logger.info(f"üçÑ Mycelium initialized: {self.hive_count} hives, {self.total_agents} agents")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not initialize full Mycelium: {e}")
                self.full_network = None

    def acknowledge_war_band(self):
        """Connect the Apache War Band to the full mycelium network if present."""
        if self.full_network and hasattr(self.full_network, 'acknowledge_war_band'):
            try:
                self.full_network.acknowledge_war_band()
                logger.info("üçÑ Mycelium: Apache War Band connected to full network")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to connect War Band to Mycelium: {e}")
        else:
            logger.info("üçÑ Mycelium: War Band link skipped (full network unavailable)")
    
    def _on_thought_wrapper(self, thought):
        """Wrapper to handle Thought objects from the bus."""
        try:
            topic = thought.topic if hasattr(thought, 'topic') else thought.get('topic', '')
            payload = thought.payload if hasattr(thought, 'payload') else thought.get('data', {})
            self._on_thought({'topic': topic, 'data': payload})
        except Exception:
            pass
            
    def _emit_thought(self, topic: str, data: Dict[str, Any]):
        """Emit a thought to the bus."""
        if self.bus:
            try:
                from aureon_thought_bus import Thought
                thought = Thought(
                    source='mycelium',
                    topic=f'mycelium.{topic}',
                    payload=data
                )
                self.bus.publish(thought)
            except Exception:
                pass
        
    def add_signal(self, symbol: str, signal: float):
        """Add a market signal to the network"""
        self.activations[symbol] = signal
        
        # Auto-create synapses to other active symbols if they don't exist
        # This creates a dense mesh over time
        if symbol not in self.synapses:
            self.synapses[symbol] = []
            
        # Randomly connect to existing nodes to grow the network
        if len(self.activations) > 1 and len(self.synapses[symbol]) < 5:
            targets = list(self.activations.keys())
            if symbol in targets: targets.remove(symbol)
            if targets:
                target = random.choice(targets)
                # Check if connection exists
                if not any(s.target == target for s in self.synapses[symbol]):
                    self.synapses[symbol].append(Synapse(source=symbol, target=target))
        
        # üåê BROADCAST: Pass signal to thought bus (info flows LEFT/RIGHT to peers)
        if self.bus and abs(signal - 0.5) > 0.2:  # Only broadcast significant signals
            self._emit_thought('signal_detected', {
                'symbol': symbol,
                'signal': signal,
                'direction': 'BUY' if signal > 0.6 else 'SELL' if signal < 0.4 else 'HOLD',
                'strength': abs(signal - 0.5) * 2
            })
    
    def _on_thought(self, thought: Dict[str, Any]):
        """
        Receive thoughts from other components.
        This is how info flows INTO the mycelium from other systems.
        """
        topic = thought.get('topic', '')
        data = thought.get('data', {})
        
        # üåê RECEIVE: Universal Market Intelligence updates
        if 'universal_scan_complete' in topic:
            self.last_intel_digest = {
                'total_assets': data.get('total_assets', 0),
                'sentiment': data.get('sentiment', 'NEUTRAL'),
                'anomalies': data.get('anomalies', 0),
                'timestamp': time.time()
            }
            # Adjust network sensitivity based on market sentiment
            if data.get('sentiment') == 'BULLISH':
                # Network becomes more responsive to buy signals
                self._adjust_network_bias(0.1)
            elif data.get('sentiment') == 'BEARISH':
                # Network becomes more cautious
                self._adjust_network_bias(-0.1)
                
        # üß† RECEIVE: Brain decisions (info flows DOWN from brain)
        elif 'brain' in topic and 'decision' in topic:
            brain_action = data.get('action', 'HOLD')
            confidence = data.get('confidence', 0.5)
            if brain_action == 'BUY' and confidence > 0.7:
                self._amplify_buy_signals()
            elif brain_action == 'SELL' and confidence > 0.7:
                self._amplify_sell_signals()
                
        # üõ°Ô∏è RECEIVE: Immune system health (info flows from peer systems)
        elif topic in {'immune_health', 'immune.health_broadcast'}:
            health = data.get('health', data.get('health_score', 100))
            if health < 50:
                # System stressed - reduce mycelium activity
                self._reduce_activity()
            self.update_external_state(immune_health=health, source="thought_bus")
    
    def update_external_state(
        self,
        immune_health: Optional[float] = None,
        coherence: Optional[float] = None,
        risk_bias: Optional[float] = None,
        source: str = "system",
    ) -> None:
        """Forward external signals to the Queen decision system if available."""
        if self.full_network and hasattr(self.full_network, "update_external_state"):
            try:
                self.full_network.update_external_state(
                    immune_health=immune_health,
                    coherence=coherence,
                    risk_bias=risk_bias,
                    source=source,
                )
            except Exception:
                pass
    
    def _adjust_network_bias(self, bias: float):
        """Adjust network bias based on external signals."""
        # Shift all activations slightly toward bias
        for symbol in self.activations:
            self.activations[symbol] = max(0, min(1, self.activations[symbol] + bias * 0.1))
            
    def _amplify_buy_signals(self):
        """Amplify buy signals when brain says BUY."""
        for symbol in self.activations:
            if self.activations[symbol] > 0.5:
                self.activations[symbol] = min(1.0, self.activations[symbol] * 1.1)
                
    def _amplify_sell_signals(self):
        """Amplify sell signals when brain says SELL."""
        for symbol in self.activations:
            if self.activations[symbol] < 0.5:
                self.activations[symbol] = max(0.0, self.activations[symbol] * 0.9)
                
    def _reduce_activity(self):
        """Reduce network activity when system is stressed."""
        # Move all activations toward neutral (0.5)
        for symbol in self.activations:
            self.activations[symbol] = self.activations[symbol] * 0.9 + 0.5 * 0.1
        
    def propagate(self, probability_map: Dict[str, float] = None) -> Dict[str, float]:
        """Propagate signals through the network"""
        new_activations = {}
        for symbol, activation in self.activations.items():
            new_activations[symbol] = activation
            if symbol in self.synapses:
                for synapse in self.synapses[symbol]:
                    if synapse.target in self.activations: # Only propagate to active nodes
                        # Signal boosts the target's activation
                        boost = synapse.pulse(activation) * 0.1 # Dampening factor
                        new_activations[synapse.target] = new_activations.get(synapse.target, self.activations[synapse.target]) + boost
        
        # üçÑ FULL NETWORK: Also step the hive neural network
        if self.full_network:
            try:
                # Build market data from our activations
                avg_activation = sum(self.activations.values()) / max(1, len(self.activations))
                
                # üåê INJECT: Universal market intel into hive processing
                if self.last_intel_digest:
                    sentiment_boost = 0.1 if self.last_intel_digest.get('sentiment') == 'BULLISH' else -0.1 if self.last_intel_digest.get('sentiment') == 'BEARISH' else 0
                    avg_activation = max(0, min(1, avg_activation + sentiment_boost))
                
                market_data = {
                    "price": 95000,  # Will be updated with real price
                    "momentum": avg_activation * 2 - 1,  # Convert [0,1] to [-1,1]
                    "volatility": 0.5,
                    "trend": avg_activation - 0.5
                }
                
                # Step the full network - all hives process and Queen decides
                result = self.full_network.step(market_data, probability_map=probability_map)
                
                # üß† QUEEN NEURON SIGNAL - This is the collective intelligence!
                self.queen_signal = result.get("queen_signal", 0.0)
                self.hive_count = result.get("hive_count", 1)
                self.generation = result.get("generation", 0)
                self.total_agents = self.full_network.get_total_agents()
                self._capture_telemetry({
                    "step": result.get("step"),
                    "queen_signal": self.queen_signal,
                    "hive_count": self.hive_count,
                    "generation": self.generation,
                    "total_equity": result.get("total_equity"),
                    "surge_active": result.get("surge_active", False),
                    "split_events": len(getattr(self.full_network, "split_events", [])),
                })
                
                # üåê BROADCAST UP: Send Queen's decision to brain via thought bus
                if abs(self.queen_signal) > 0.3:
                    self._emit_thought('queen_decision', {
                        'signal': self.queen_signal,
                        'direction': 'BUY' if self.queen_signal > 0 else 'SELL',
                        'confidence': abs(self.queen_signal),
                        'hives': self.hive_count,
                        'agents': self.total_agents
                    })
                
            except Exception as e:
                logger.debug(f"Mycelium step error: {e}")
        
        return new_activations
    
    def _telemetry_path(self) -> Path:
        date_str = datetime.utcnow().strftime("%Y-%m-%d")
        return self.telemetry_dir / f"mycelium_snapshot_{date_str}.jsonl"
    
    def _capture_telemetry(self, state: Dict[str, Any]) -> None:
        """Persist lightweight mycelium telemetry for ecosystem observability."""
        try:
            snapshot: Dict[str, Any] = {
                "schema_version": self.telemetry_schema,
                "timestamp": datetime.utcnow().isoformat(),
                "step": state.get("step"),
                "queen_signal": state.get("queen_signal", 0.0),
                "hive_count": state.get("hive_count", 0),
                "generation": state.get("generation", 0),
                "total_equity": state.get("total_equity", 0.0),
                "surge_active": state.get("surge_active", False),
                "split_events": state.get("split_events", 0),
            }
            if self.full_network and hasattr(self.full_network, "get_growth_stats"):
                try:
                    growth = self.full_network.get_growth_stats()
                    snapshot["growth"] = {
                        "net_profit_total": growth.get("net_profit_total"),
                        "profit_rate_per_day": growth.get("profit_rate_per_day"),
                        "growth_percentage": growth.get("growth_percentage"),
                    }
                except Exception:
                    pass
            
            self.telemetry_buffer.append(snapshot)
            if len(self.telemetry_buffer) >= 20:
                self._flush_telemetry()
        except Exception as e:
            logger.debug(f"Mycelium telemetry capture error: {e}")
    
    def _flush_telemetry(self) -> None:
        """Flush buffered telemetry to disk."""
        if not self.telemetry_buffer:
            return
        try:
            path = self._telemetry_path()
            path.parent.mkdir(parents=True, exist_ok=True)
            with path.open("a", encoding="utf-8") as f:
                for row in self.telemetry_buffer:
                    f.write(json.dumps(row) + "\n")
            self.telemetry_buffer.clear()
        except Exception as e:
            logger.debug(f"Mycelium telemetry flush error: {e}")

    def learn(self, symbol: str, profit_pct: float):
        """Reinforce connections that led to profit"""
        # If we profited on 'symbol', strengthen incoming connections to it
        # and outgoing connections from it that were active
        
        # 1. Strengthen outgoing connections from this symbol
        if symbol in self.synapses:
            for synapse in self.synapses[symbol]:
                synapse.strengthen(profit_pct)
                
        # 2. Strengthen incoming connections to this symbol (harder to find in this structure, 
        #    so we iterate - optimization: keep reverse map if needed, but loop is fine for small N)
        for source, synapses in self.synapses.items():
            for synapse in synapses:
                if synapse.target == symbol:
                    synapse.strengthen(profit_pct)
        
        # üçÑ FULL NETWORK: Also reinforce hive synapses
        if self.full_network and profit_pct > 0:
            try:
                # Strengthen hive synapses that contributed to this profit
                for synapse in self.full_network.hive_synapses:
                    synapse.strengthen(profit_pct * 0.5)  # Dampened learning
            except Exception:
                pass

    def get_network_coherence(self) -> float:
        """Overall network coherence - now includes Queen Neuron signal!"""
        if not self.activations:
            return 0.5
        
        # Base coherence from pattern network
        base_coherence = sum(self.activations.values()) / len(self.activations)
        
        # üß† BLEND WITH QUEEN NEURON SIGNAL
        if self.full_network and self.queen_signal != 0:
            # Queen signal is [-1, 1], convert to [0, 1]
            queen_coherence = (self.queen_signal + 1) / 2
            # Blend: 70% pattern network, 30% Queen Neuron
            blended = base_coherence * 0.7 + queen_coherence * 0.3
            return blended
        
        return base_coherence
    
    def get_queen_signal(self) -> float:
        """Get the Queen Neuron's collective decision signal [-1, 1]"""
        return self.queen_signal
    
    def get_network_state(self) -> Dict[str, Any]:
        """Get full neural network state for display"""
        state = {
            "pattern_nodes": len(self.activations),
            "pattern_synapses": sum(len(s) for s in self.synapses.values()),
            "queen_signal": self.queen_signal,
            "hive_count": self.hive_count,
            "total_agents": self.total_agents,
            "generation": self.generation,
            "full_network_active": self.full_network is not None
        }
        
        if self.full_network:
            try:
                full_state = self.full_network.get_state()
                state["total_equity"] = full_state.get("total_equity", 0)
                state["total_harvested"] = full_state.get("total_harvested", 0)
                state["split_events"] = len(full_state.get("split_events", []))
            except Exception:
                pass
        
        return state
    
    def display_neural_status(self):
        """Display neural network status"""
        state = self.get_network_state()
        queen_emoji = "üëë" if state["queen_signal"] > 0.3 else "üë∏" if state["queen_signal"] > -0.3 else "üíÄ"
        signal_bar = "‚ñà" * int(abs(state["queen_signal"]) * 10)
        direction = "BUY" if state["queen_signal"] > 0 else "SELL" if state["queen_signal"] < 0 else "HOLD"
        
        print(f"""
   üçÑ MYCELIUM NEURAL NETWORK
   ‚îú‚îÄ Pattern Nodes: {state['pattern_nodes']} | Synapses: {state['pattern_synapses']}
   ‚îú‚îÄ Hives: {state['hive_count']} | Agents: {state['total_agents']} | Gen: {state['generation']}
   ‚îî‚îÄ {queen_emoji} Queen Signal: {state['queen_signal']:+.3f} [{signal_bar}] ‚Üí {direction}
""")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üí∞ POSITION & PERFORMANCE TRACKING
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class Position:
    symbol: str
    entry_price: float
    quantity: float
    entry_fee: float
    entry_value: float
    momentum: float
    coherence: float
    entry_time: float
    dominant_node: str
    cycles: int = 0
    # Swarm Orchestrator enhancements
    generation: int = 0  # 0 = original, 1+ = split children
    parent_id: Optional[str] = None  # ID of parent position if this is a split
    is_scout: bool = False  # Can this position act as market scout?
    last_signal_broadcast: float = 0.0  # Timestamp of last signal
    prime_size_multiplier: float = 1.0  # Prime-based sizing
    exchange: str = 'binance'  # Exchange where position is held
    
    # üéØ TRAILING STOP SUPPORT
    highest_price: float = 0.0  # Highest price since entry (for trailing stop)
    lowest_price: float = float('inf')  # Lowest price since entry (for shorts)
    trailing_stop_active: bool = False  # Is trailing stop currently active?
    trailing_stop_price: float = 0.0  # Current trailing stop level
    
    # üì¶ HISTORICAL ASSET FLAG - These can be liquidated for cash when better opportunities arise
    is_historical: bool = False  # True = imported from exchange, no known entry price, treat as available capital
    
    # üß† LEARNED PARAMETERS - Set from probability matrix recommendations
    learned_tp_pct: Optional[float] = None  # Suggested take profit % from historical performance
    learned_sl_pct: Optional[float] = None  # Suggested stop loss % from historical performance
    learned_hold_cycles: Optional[int] = None  # Suggested minimum hold cycles
    learned_win_rate: Optional[float] = None  # Expected win rate based on similar trades
    learned_confidence: str = 'low'  # Confidence level of learned parameters
    
    # üîÆ NEXUS PREDICTOR DATA - For learning feedback
    nexus_prob: float = 0.5  # Nexus prediction probability at entry
    nexus_edge: float = 0.0  # Nexus edge at entry
    nexus_patterns: List[str] = field(default_factory=list)  # Patterns triggered at entry
    
    # üöÄ SERVER-SIDE ORDER IDs (Kraken/Alpaca native TP/SL - execute even if bot offline)
    server_sl_order_id: Optional[str] = None  # Kraken/Alpaca stop-loss order ID (or OCO ID for Alpaca)
    server_tp_order_id: Optional[str] = None  # Kraken take-profit order ID
    server_trailing_order_id: Optional[str] = None  # Kraken/Alpaca trailing stop order ID
    
    # Generate unique ID for position
    id: str = field(default_factory=lambda: f"pos_{int(time.time()*1000)}_{random.randint(1000,9999)}")
    
    # Convenience properties
    @property
    def size(self) -> float:
        """Alias for quantity"""
        return self.quantity
        
    @property
    def current_price(self) -> float:
        """Alias for entry_price (will be updated externally)"""
        return self.entry_price
        
    @property
    def quote_asset(self) -> str:
        """Extract quote asset from symbol"""
        for quote in CONFIG['QUOTE_CURRENCIES']:
            if self.symbol.endswith(quote):
                return quote
        return 'USD'  # Default fallback


class PerformanceTracker:
    """Track all trading performance metrics"""
    
    def __init__(self, initial_balance: float):
        self.initial_balance = initial_balance
        self.first_start_balance = initial_balance  # TRUE starting balance - survives restarts!
        self.first_start_time = time.time()  # When the system FIRST started
        self.balance = initial_balance
        self.peak_balance = initial_balance
        self.total_trades = 0
        self.wins = 0
        self.losses = 0
        self.total_fees = 0.0
        self.net_profit = 0.0
        self.compounded = 0.0
        self.harvested = 0.0
        self.max_drawdown = 0.0
        self.current_drawdown = 0.0  # Current DD from peak
        self.trade_log: List[Dict] = []
        self.trading_halted = False
        self.halt_reason = ""
        self.total_hold_time_sec = 0.0  # Track average hold time
        self.closed_positions = 0
        self.circuit_breaker_enabled = False  # Disabled until first baseline reset
        
        # Earth engine reference for PHI amplification
        self.earth_engine = None
        
        # Track per-symbol exposure
        self.symbol_exposure: Dict[str, float] = {}
        self.portfolio_equity = initial_balance
        self.cash_balance = initial_balance
        self.cycle_equity_start = initial_balance
        self.equity_baseline = initial_balance
        
        # üìä Platform-specific metrics
        self.platform_metrics: Dict[str, Dict] = {
            'kraken': {'trades': 0, 'wins': 0, 'fees': 0.0, 'pnl': 0.0, 'volume': 0.0},
            'binance': {'trades': 0, 'wins': 0, 'fees': 0.0, 'pnl': 0.0, 'volume': 0.0},
            'alpaca': {'trades': 0, 'wins': 0, 'fees': 0.0, 'pnl': 0.0, 'volume': 0.0},
            'capital': {'trades': 0, 'wins': 0, 'fees': 0.0, 'pnl': 0.0, 'volume': 0.0},
        }
        
    # üáÆüá™ IRA SNIPER - Famous Irish Republican Quotes
    # "Financial freedom IS freedom. Penny by penny, we rise." 
    IRA_SNIPER_QUOTES = [
        "Our revenge will be the laughter of our children. - Bobby Sands üçÄ",  # The most important one
        "Our revenge will be the laughter of our children. - Bobby Sands üçÄ",  # Weighted heavier
        "Our revenge will be the laughter of our children. - Bobby Sands üçÄ",  # Because it means the most
        "Tiocfaidh √°r l√°! - Our day will come!",
        "Tiocfaidh √°r l√°! - Our day will come!",
        "They may kill the revolutionary but never the revolution.",
        "Unfree ourselves, we shall never rest until we make Ireland free.",
        "Ireland unfree shall never be at peace. - Patrick Pearse",
        "The fools! The fools! They have left us our Fenian dead!",
        "We serve neither King nor Kaiser, but Ireland!",
        "I have made up my mind to die rather than live a slave.",
        "Life springs from death, and from the graves of patriot men and women spring living nations.",
        "The Republic still lives! - Bobby Sands",
        "They have nothing in their whole imperial arsenal that can break the spirit of one Irishman.",
        "Everyone, Republican or otherwise, has their own particular part to play.",
        "Beir bua! - Take victory!",
        "N√≠ saoirse go saoirse na h√âireann! - No freedom until Ireland is free!",
        "Financial freedom IS freedom. Penny by penny, we rise! üí∞",
        "One penny at a time, we break their chains. - Aureon",
    ]
    
    def record_trade(self, net_pnl: float, fees: float, symbol: str, reason: str, 
                     hold_time_sec: float = 0, platform: str = 'kraken', volume: float = 0.0):
        """Record a completed trade with platform attribution - THE SNIPER MAKES THE KILLS"""
        self.total_trades += 1
        self.total_fees += fees
        result = 'WIN' if net_pnl > 0 else 'LOSS'
        if net_pnl > 0:
            self.wins += 1
            # üáÆüá™üéØ IRA SNIPER KILL! - Use Bhoy's Wisdom for celebration
            if BHOYS_WISDOM_AVAILABLE:
                quote = celebrate_penny_profit(net_pnl, symbol)
            else:
                import random
                quote = random.choice(self.IRA_SNIPER_QUOTES)
            print(f"\nüáÆüá™üéØüî´ SNIPER KILL! üî´üéØüáÆüá™")
            print(f"    üí∞ +${net_pnl:.4f} NET PROFIT on {symbol}")
            print(f"    ‚è±Ô∏è  Hold time: {hold_time_sec:.1f}s")
            print(f"    üìú \"{quote}\"")
            print(f"    üèÜ Win Rate: {self.win_rate:.1f}% ({self.wins}/{self.total_trades})")
            print(f"üáÆüá™üéØüî´üí∞ ONE BULLET, ONE KILL, RELOAD, REPEAT üí∞üî´üéØüáÆüá™\n")
        else:
            self.losses += 1
            # Get resilience wisdom for losses
            if BHOYS_WISDOM_AVAILABLE:
                wisdom = get_contextual_wisdom('resilience')
                print(f"\n‚öîÔ∏è TACTICAL RETREAT: {symbol} -${abs(net_pnl):.4f}")
                print(f"    üìú \"{wisdom}\"")
                print(f"    üí™ Reload and engage next target...\n")
        
        # Track hold time
        if hold_time_sec > 0:
            self.total_hold_time_sec += hold_time_sec
            self.closed_positions += 1
        
        # üìä Update platform-specific metrics
        platform_key = platform.lower()
        if platform_key in self.platform_metrics:
            self.platform_metrics[platform_key]['trades'] += 1
            self.platform_metrics[platform_key]['fees'] += fees
            self.platform_metrics[platform_key]['pnl'] += net_pnl
            self.platform_metrics[platform_key]['volume'] += volume
            if net_pnl > 0:
                self.platform_metrics[platform_key]['wins'] += 1
        
        self.trade_log.append({
            'symbol': symbol,
            'reason': reason,
            'result': result,  # Explicit WIN/LOSS classification
            'net_pnl': net_pnl,
            'fees': fees,
            'volume': volume,
            'platform': platform,
            'balance': self.portfolio_equity,
            'win_rate': self.win_rate,
            'hold_time_sec': hold_time_sec,
            'time': datetime.now().isoformat()
        })
        
    @property
    def win_rate(self) -> float:
        return (self.wins / self.total_trades * 100) if self.total_trades > 0 else 0
        
    @property
    def total_return(self) -> float:
        return (self.balance - self.initial_balance) / self.initial_balance * 100

    def update_equity(self, equity_value: float, cash_value: float, mark_cycle: bool = False):
        """Synchronise tracker metrics with current marked-to-market equity."""
        self.portfolio_equity = equity_value
        self.cash_balance = cash_value
        self.balance = equity_value
        self.net_profit = self.portfolio_equity - self.initial_balance
        if mark_cycle:
            self.cycle_equity_start = equity_value
        
        if self.portfolio_equity > self.peak_balance:
            self.peak_balance = self.portfolio_equity
        if self.peak_balance > 0:
            dd = (self.peak_balance - self.portfolio_equity) / self.peak_balance * 100
        else:
            dd = 0.0
        self.current_drawdown = dd  # Track current DD from peak
        if dd > self.max_drawdown:
            self.max_drawdown = dd
        # Only check circuit breaker if enabled (after first baseline reset)
        if self.circuit_breaker_enabled and dd >= CONFIG['MAX_DRAWDOWN_PCT'] and not self.trading_halted:
            self.trading_halted = True
            self.halt_reason = f"Max drawdown {dd:.1f}% exceeded"
            print(f"\nüõë CIRCUIT BREAKER ACTIVATED: {self.halt_reason}")

    def realize_portfolio_gain(self, gain: float):
        """Advance compounding only when the whole portfolio has grown."""
        if gain <= 0:
            return
        compound_amt = gain * CONFIG['COMPOUND_PCT']
        harvest_amt = gain * CONFIG['HARVEST_PCT']
        self.compounded += compound_amt
        self.harvested += harvest_amt
    
    def calculate_position_size(self, coherence: float, symbol: str, hnc_modifier: float = 1.0,
                                 imperial_modifier: float = 1.0) -> float:
        """
        Calculate position size using Kelly Criterion + coherence scaling + HNC frequency + Imperial.
        
        Args:
            coherence: Auris/Lambda field coherence (0.0-1.0)
            symbol: Trading symbol
            hnc_modifier: HNC frequency-based position modifier (from AurisEngine)
            imperial_modifier: Imperial predictability modifier (cosmic synchronization)
        
        Returns: Position size as fraction of balance
        """
        if CONFIG['USE_KELLY_SIZING'] and self.total_trades >= 10:
            # Need at least 10 trades for stable Kelly calculation
            avg_win = CONFIG['TAKE_PROFIT_PCT'] / 100.0
            avg_loss = CONFIG['STOP_LOSS_PCT'] / 100.0
            
            kelly_size = kelly_criterion(
                self.win_rate / 100.0,
                avg_win,
                avg_loss,
                CONFIG['KELLY_SAFETY_FACTOR']
            )
        else:
            # Use base size until we have enough data
            kelly_size = CONFIG['BASE_POSITION_SIZE']
        
        # Scale by coherence: higher coherence = larger position
        # Range: 0.7x to 1.3x based on coherence 0.0-1.0
        coherence_multiplier = 0.7 + (coherence * 0.6)
        scaled_size = kelly_size * coherence_multiplier
        
        # üåç‚ö° Apply HNC frequency modifier ‚ö°üåç
        # Range: 0.7x (440Hz distortion) to 1.15x (256/528Hz harmonic)
        if CONFIG.get('ENABLE_HNC_FREQUENCY', True):
            scaled_size *= hnc_modifier
        
        # üåå‚ö° Apply Imperial predictability modifier ‚ö°üåå
        # Range: 0.1x (extreme bearish) to 1.5x (extreme bullish with cosmic boost)
        if CONFIG.get('ENABLE_IMPERIAL', True):
            imperial_weight = CONFIG.get('IMPERIAL_POSITION_WEIGHT', 0.35)
            # Blend: (1-weight)*1.0 + weight*imperial_modifier
            blended_imperial = (1 - imperial_weight) + (imperial_weight * imperial_modifier)
            scaled_size *= blended_imperial
        
        # üåç‚ú® Apply Earth Resonance PHI amplification ‚ú®üåç
        # Golden ratio (1.618) multiplier when field coherence is high
        if CONFIG.get('EARTH_PHI_AMPLIFICATION', True) and self.earth_engine:
            try:
                phi_multiplier = self.earth_engine.get_phi_position_multiplier()
                scaled_size *= phi_multiplier
            except Exception as e:
                pass  # Continue without PHI if error
        
        # Check per-symbol exposure limits
        current_exposure = self.symbol_exposure.get(symbol, 0.0)
        available_exposure = CONFIG['MAX_SYMBOL_EXPOSURE'] - current_exposure
        
        # Apply Œ∫t efficiency safely: trade as if larger but risk base sizing
        final_size = min(scaled_size * KT_EFFICIENCY, available_exposure, CONFIG['MAX_POSITION_SIZE'])
        
        # üîß FIX: Never return 0 - minimum viable size of 1% to keep trading
        # Let other gates (penny math, available capital) be the actual blockers
        if final_size < 0.01:
            final_size = 0.01  # 1% minimum
            
        return max(0.01, final_size)

    def get_platform_summary(self) -> str:
        """Generate a summary of metrics by platform."""
        lines = ["\n   üìä PLATFORM METRICS"]
        lines.append("   " + "‚îÄ" * 60)
        
        for platform, metrics in self.platform_metrics.items():
            if metrics['trades'] == 0:
                continue
            win_rate = (metrics['wins'] / metrics['trades'] * 100) if metrics['trades'] > 0 else 0
            icon = {'kraken': 'üêô', 'binance': 'üü°', 'alpaca': 'ü¶ô', 'capital': 'üíº'}.get(platform, 'üìà')
            lines.append(f"   {icon} {platform.upper()}:")
            lines.append(f"      Trades: {metrics['trades']} | Win Rate: {win_rate:.1f}%")
            lines.append(f"      Volume: ${metrics['volume']:,.2f} | Fees: ${metrics['fees']:.4f}")
            lines.append(f"      Net P&L: ${metrics['pnl']:+.4f}")
        
        lines.append("   " + "‚îÄ" * 60)
        return "\n".join(lines)


def get_platform_fee(platform: str, order_type: str = 'taker') -> float:
    """
    Get the appropriate fee rate for a platform.
    
    Args:
        platform: 'kraken', 'binance', 'alpaca', 'capital'
        order_type: 'maker' or 'taker'
    
    Returns:
        Fee as decimal (e.g., 0.0026 for 0.26%)
    """
    platform = platform.lower()
    
    if platform == 'kraken':
        return CONFIG['KRAKEN_FEE_MAKER'] if order_type == 'maker' else CONFIG['KRAKEN_FEE_TAKER']
    elif platform == 'binance':
        return CONFIG['BINANCE_FEE_MAKER'] if order_type == 'maker' else CONFIG['BINANCE_FEE_TAKER']
    elif platform == 'alpaca':
        return CONFIG['ALPACA_FEE_MAKER'] if order_type == 'maker' else CONFIG['ALPACA_FEE_TAKER']
    elif platform == 'capital':
        return CONFIG['CAPITAL_FEE']  # Spread-based, no maker/taker distinction
    else:
        # Default to Kraken taker fee
        return CONFIG['KRAKEN_FEE_TAKER']


def calculate_trade_fees(notional: float, platform: str, order_type: str = 'taker') -> Dict[str, float]:
    """
    Calculate expected fees for a trade.
    
    Returns:
        Dict with fee_pct, fee_amount, total_cost (includes slippage)
    """
    fee_pct = get_platform_fee(platform, order_type)
    fee_amount = notional * fee_pct
    slippage = notional * CONFIG['SLIPPAGE_PCT']
    spread_cost = notional * CONFIG['SPREAD_COST_PCT']
    total_cost = fee_amount + slippage + spread_cost
    
    return {
        'fee_pct': fee_pct,
        'fee_amount': fee_amount,
        'slippage': slippage,
        'spread_cost': spread_cost,
        'total_cost': total_cost,
        'total_cost_pct': (total_cost / notional) if notional > 0 else 0
    }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üêò ELEPHANT MEMORY - Enhanced Tracking
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ElephantMemory:
    """
    Enhanced Elephant Memory from Quantum Quackers
    Tracks hunts + results with JSONL history.
    Integrates collective intelligence from all ecosystem agents.
    """
    
    def __init__(self, filepath: str = 'elephant_unified.json'):
        self.filepath = filepath
        self.history_path = filepath.replace('.json', '_history.jsonl')
        self.symbols = {} # Local memory (Unified)
        self.collective_symbols = {} # Collective memory (Ultimate, Live, etc.)
        self.memory_sources = [
            'elephant_ultimate.json',
            'elephant_live.json'
        ]
        self.load()
    
    def load(self):
        # 1. Load local memory
        try:
            with open(self.filepath) as f:
                self.symbols = json.load(f)
        except:
            self.symbols = {}
            
        # 2. Load and aggregate collective memory
        self.collective_symbols = {}
        for source in self.memory_sources:
            if not os.path.exists(source):
                continue
            try:
                with open(source, 'r') as f:
                    data = json.load(f)
                    for sym, stats in data.items():
                        if sym not in self.collective_symbols:
                            self.collective_symbols[sym] = stats.copy()
                        else:
                            # Merge critical stats (worst-case for safety)
                            s = self.collective_symbols[sym]
                            s['blacklisted'] = s.get('blacklisted', False) or stats.get('blacklisted', False)
                            s['streak'] = max(s.get('streak', 0), stats.get('streak', 0))
                            s['losses'] = s.get('losses', 0) + stats.get('losses', 0)
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading collective memory from {source}: {e}")
    
    def save(self):
        with open(self.filepath, 'w') as f:
            json.dump(self.symbols, f, indent=2)
    
    def record_hunt(self, symbol: str, volume: float = 0, change: float = 0):
        """Remember we hunted this symbol (Quackers style)"""
        if symbol not in self.symbols:
            self.symbols[symbol] = {
                'hunts': 0, 'trades': 0, 'wins': 0, 'losses': 0,
                'profit': 0, 'last_time': 0, 'streak': 0, 'blacklisted': False
            }
        
        s = self.symbols[symbol]
        s['hunts'] = s.get('hunts', 0) + 1
        s['last_time'] = time.time()
        
        # Append to JSONL history
        try:
            with open(self.history_path, 'a') as f:
                record = {
                    'ts': datetime.now().isoformat(),
                    'type': 'hunt',
                    'symbol': symbol,
                    'volume': volume,
                    'change': change
                }
                f.write(json.dumps(record) + '\n')
        except:
            pass
        
        self.save()
    
    def record(self, symbol: str, profit_usd: float):
        """Record trade result"""
        if symbol not in self.symbols:
            self.symbols[symbol] = {
                'hunts': 0, 'trades': 0, 'wins': 0, 'losses': 0,
                'profit': 0, 'last_time': 0, 'streak': 0, 'blacklisted': False
            }
        
        s = self.symbols[symbol]
        s['trades'] += 1
        s['profit'] += profit_usd
        s['last_time'] = time.time()
        
        if profit_usd >= 0:
            s['wins'] += 1
            s['streak'] = 0
        else:
            s['losses'] += 1
            s['streak'] += 1
            if s['streak'] >= CONFIG.get('LOSS_STREAK_LIMIT', 3):
                s['blacklisted'] = True
                print(f"üö´ {symbol} BLACKLISTED after {s['streak']} losses")
        
        # Append to JSONL history
        try:
            with open(self.history_path, 'a') as f:
                record = {
                    'ts': datetime.now().isoformat(),
                    'type': 'result',
                    'symbol': symbol,
                    'profit': profit_usd
                }
                f.write(json.dumps(record) + '\n')
        except:
            pass
        
        self.save()

    def record_event(self, event_type: str, payload: Dict[str, Any]):
        """Record a non-symbol event to JSONL history.

        This provides durable operator/debug memory without affecting
        symbol-level cooldown/blacklist logic.
        """
        try:
            with open(self.history_path, 'a') as f:
                record = {
                    'ts': datetime.now().isoformat(),
                    'type': 'event',
                    'event_type': event_type,
                    'payload': payload,
                }
                f.write(json.dumps(record) + '\n')
        except Exception:
            pass
    
    def should_avoid(self, symbol: str) -> bool:
        # Check local memory
        if self._check_avoid(self.symbols.get(symbol)):
            return True
            
        # Check collective memory
        if self._check_avoid(self.collective_symbols.get(symbol)):
            # print(f"üêò Collective Intelligence: Avoiding {symbol} due to peer warning")
            return True
            
        return False
        
    def _check_avoid(self, s: dict) -> bool:
        if not s: return False
        
        # Blacklisted
        if s.get('blacklisted', False):
            return True
        
        # Cooldown - only for symbols with actual TRADES (not just hunts)
        # This allows re-entry attempts after failed hunts
        cooldown = CONFIG.get('COOLDOWN_MINUTES', 13)
        if s.get('trades', 0) > 0 and time.time() - s.get('last_time', 0) < cooldown * 60:
            return True
        
        return False
    
    def get_symbol_data(self, symbol: str) -> Optional[Dict]:
        """Get stored data for a symbol (local or collective memory)"""
        # Check local memory first
        if symbol in self.symbols:
            return self.symbols[symbol]
        # Check collective memory
        if symbol in self.collective_symbols:
            return self.collective_symbols[symbol]
        return None
    
    def get_win_rate(self) -> float:
        total_wins = sum(s.get('wins', 0) for s in self.symbols.values())
        total_losses = sum(s.get('losses', 0) for s in self.symbols.values())
        if total_wins + total_losses == 0:
            return 0.55  # Default 55% (Quackers RiskManager default)
        return total_wins / (total_wins + total_losses)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîÆ SYSTEM FLUX PREDICTOR - 30-Span Market Analysis
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class SystemFluxPredictor:
    """
    Predicts market direction by analyzing the collective flux of the top 30 assets.
    "It's not about percentage right, we already know what way the system will go."
    """
    
    def __init__(self):
        self.flux_history = deque(maxlen=100)
        self.last_prediction = None
        
    def predict(self, tickers: Dict[str, Dict]) -> Dict[str, Any]:
        """
        Analyze top 30 assets by volume to determine system flux.
        Returns: {
            'direction': 'BULLISH' | 'BEARISH' | 'NEUTRAL',
            'strength': 0.0 to 1.0,
            'flux_score': -1.0 to 1.0,
            'top_movers': List[str]
        }
        """
        # Filter valid tickers
        valid_tickers = []
        for symbol, data in tickers.items():
            if data.get('volume', 0) > 10000 and data.get('price', 0) > 0:
                valid_tickers.append({
                    'symbol': symbol,
                    'change': data.get('change24h', 0),
                    'volume': data.get('volume', 0)
                })
        
        # Sort by volume to get "The System" leaders
        valid_tickers.sort(key=lambda x: x['volume'], reverse=True)
        top_30 = valid_tickers[:CONFIG.get('FLUX_SPAN', 30)]
        
        if not top_30:
            return {'direction': 'NEUTRAL', 'strength': 0.0, 'flux_score': 0.0}
            
        # Calculate Flux Score (Volume-weighted momentum)
        total_volume = sum(t['volume'] for t in top_30)
        weighted_momentum = sum(t['change'] * (t['volume'] / total_volume) for t in top_30)
        
        # Normalize flux score (-10 to +10 range typically)
        flux_score = max(-1.0, min(1.0, weighted_momentum / 5.0))
        
        # Determine direction and strength
        strength = abs(flux_score)
        if flux_score > 0.2:
            direction = 'BULLISH'
        elif flux_score < -0.2:
            direction = 'BEARISH'
        else:
            direction = 'NEUTRAL'
            
        result = {
            'direction': direction,
            'strength': strength,
            'flux_score': flux_score,
            'top_movers': [t['symbol'] for t in top_30[:3]]
        }
        
        self.flux_history.append(result)
        self.last_prediction = result
        return result

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üêô THE UNIFIED KRAKEN ECOSYSTEM
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class AureonKrakenEcosystem:
    """
    üêôüåå THE COMPLETE KRAKEN TRADING ECOSYSTEM üååüêô
    
    Combines all strategies into one dynamic system:
    - Real-time WebSocket prices
    - 9 Auris nodes for analysis
    - Mycelium network for pattern detection
    - 10-9-1 compounding model
    - 51%+ win rate strategy
    """
    
    def __init__(self, initial_balance: float = 1000.0, dry_run: bool = False):
        # Initialize Multi-Exchange Client
        self.client = MultiExchangeClient()
        self.dry_run = self.client.dry_run

        # Positions must exist before any subsystem syncs that may reference it
        self.positions = {}
        
        # üáÆüá™üéØ IRA SNIPER MODE - ensure activation across every platform and asset we can sell
        self.sniper_config = get_sniper_config() if CELTIC_SNIPER_AVAILABLE else {}
        self.sniper_coverage = map_sniper_platform_assets(self.client) if CELTIC_SNIPER_AVAILABLE else {}
        self.sniper_brain = get_unified_brain(
            exchange='kraken',
            position_size=CONFIG.get('MIN_TRADE_USD', 10.0)
        ) if SNIPER_BRAIN_AVAILABLE else None
        self._sniper_bridge_ready = False
        self._scout_bridge_status: Dict[str, Any] = {}
        if self.sniper_config.get('ACTIVE', True):
            CONFIG.update(apply_sniper_mode(CONFIG))
            self._announce_sniper_activation()
            self._sync_sniper_bridge("startup")
        
        self.auris = AurisEngine()
        self.mycelium = MyceliumNetwork(initial_capital=initial_balance)  # üçÑüß† Full neural network with hives!
        self.mycelium.acknowledge_war_band() # üçÑüèπ Connect War Band to Mycelium
        self.lattice = GaiaLatticeEngine()  # üåç GAIA FREQUENCY PHYSICS - HNC Blackboard Carrier Wave Dynamics
        self.gaia_reclaimer = GaiaPlanetaryReclaimer()
        self.enhancements = EnhancementLayer() if ENHANCEMENTS_AVAILABLE else None  # üîØ CODEX INTEGRATION
        self.market_pulse = MarketPulse(self.client) # Initialize Market Pulse
        self.war_band = WarBand(self.client, self.market_pulse) # üèπ‚öîÔ∏è Initialize Apache War Band
        self.tracker = PerformanceTracker(initial_balance)
        # Two distinct memories:
        # - ElephantMemory: symbol-level cooldown/blacklist + JSONL event trail
        # - Memory Core (spiral_memory): durable position memory + surge windows + reconciliation
        self.elephant_memory = ElephantMemory()  # üêò Symbol intelligence + event trail
        self.memory = spiral_memory  # üåÄ Durable memory core
        self.flux_predictor = SystemFluxPredictor() # üîÆ Initialize Flux Predictor
        self._queen_sync_last = 0.0
        self._queen_sync_interval = 15.0
        self._last_pulse_snapshot: Dict[str, Any] = {}
        self._last_pulse_ts = 0.0

        # Mirror harmonic engine reference for convenience
        self.harmonic_engine = getattr(self.auris, 'harmonic_engine', None)
        
        # Share earth engine reference with tracker for PHI amplification
        if self.auris.earth_engine:
            self.tracker.earth_engine = self.auris.earth_engine
        
        self.total_equity_gbp = initial_balance
        self.cash_balance_gbp = initial_balance
        self.holdings_gbp: Dict[str, float] = {}
        self.quote_currency_suffixes: List[str] = sorted(CONFIG['QUOTE_CURRENCIES'], key=len, reverse=True)
        
        # Market data
        self.ticker_cache: Dict[str, Dict] = {}
        self.price_history: Dict[str, List[float]] = {}
        self.realtime_prices: Dict[str, float] = {}
        self.price_lock = Lock()
        self._liquidity_warnings: set[Tuple[str, str]] = set()

        # Live P&L snapshot (updated in refresh_equity)
        self.pnl_state: Dict[str, float] = {
            'total_equity': initial_balance,
            'cash': initial_balance,
            'net_profit': 0.0,
            'total_return_pct': 0.0,
            'timestamp': time.time(),
        }
        
        # üö´ INVALID SYMBOL CACHE - Avoid repeated API calls for bad symbols
        self._invalid_symbols: Dict[str, float] = {}  # symbol -> timestamp when marked invalid
        self._valid_symbols: Dict[str, str] = {}  # symbol -> exchange (verified working)
        self._symbol_cache_ttl = 3600  # Recheck invalid symbols after 1 hour
        self._dust_positions: Dict[str, Tuple[str, float]] = {}  # symbol -> (reason, timestamp)
        self._dust_ttl = 86400  # 24h dust TTL before re-attempting
        self._lot_size_cache: Dict[str, Tuple[Optional[float], Optional[float]]] = {}
        
        # WebSocket
        self.ws_connected = False
        self.ws_last_message = time.time()
        self.ws_reconnect_count = 0
        self.symbol_to_ws: Dict[str, str] = {}
        self.ws_to_symbol: Dict[str, str] = {}
        
        # Stats
        self.iteration = 0
        self.start_time = time.time()
        self.scan_direction = 'A‚ÜíZ'  # Fair scheduling: alternate A‚ÜíZ / Z‚ÜíA
        self.scouts_deployed = False  # Track scout deployment
        
        # üåü SWARM ORCHESTRATOR COMPONENTS üåü
        self.capital_pool = CapitalPool()
        self.signal_broadcaster = SignalBroadcaster()
        self.position_splitter = PositionSplitter()
        self.prime_sizer = PrimeSizer()
        
        # üîÆ NEXUS PREDICTOR - 79.6% Win Rate Validated! üîÆ
        if NEXUS_PREDICTOR_AVAILABLE:
            self.nexus_predictor = NexusPredictor()
            print("   üîÆ Nexus Predictor initialized (79.6% validated)")
        else:
            self.nexus_predictor = None
            
        # üß† MINER BRAIN - COGNITIVE INTELLIGENCE üß†
        if BRAIN_AVAILABLE:
            if THOUGHT_BUS_AVAILABLE:
                self.brain = MinerBrain(thought_bus=THOUGHT_BUS)
                print("   üß† Miner Brain initialized (Connected to Thought Bus)")
            else:
                self.brain = MinerBrain()
                print("   üß† Miner Brain initialized (Cognitive Circle Active)")
        else:
            self.brain = None
        
        # üß†üåç ECOSYSTEM BRAIN BRIDGE - Unified Intelligence Hub üåçüß†
        self.brain_bridge = ECOSYSTEM_BRAIN
        print("   üß†üåç Ecosystem Brain Bridge: CONNECTED")
        
        # Initialize capital pool
        self.capital_pool.update_equity(initial_balance)
        
        # üåâ BRIDGE INTEGRATION üåâ
        self.bridge = None
        self.bridge_enabled = BRIDGE_AVAILABLE and os.getenv('ENABLE_BRIDGE', '1') == '1'
        if self.bridge_enabled:
            try:
                self.bridge = AureonBridge()
                print("   üåâ Bridge enabled: Ultimate ‚Üî Unified communication active")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Bridge initialization failed: {e}")
                self.bridge_enabled = False
        self.last_bridge_sync = 0.0
        self.bridge_sync_interval = 10.0  # Sync every 10 seconds
        
        # üåê UI BRIDGE - Live Data Validation from aureoninstitute.com üåê
        self.ui_bridge = None
        self.ui_bridge_enabled = UI_BRIDGE_AVAILABLE if 'UI_BRIDGE_AVAILABLE' in dir() else False
        self.ui_mycelium_connector = None
        if self.ui_bridge_enabled and os.getenv('ENABLE_UI_BRIDGE', '1') == '1':
            try:
                self.ui_bridge = get_ui_bridge()
                self.ui_mycelium_connector = get_ui_connector()
                print("   üåê UI Bridge enabled: aureoninstitute.com ‚Üî Trading System active")
            except Exception as e:
                print(f"   ‚ö†Ô∏è UI Bridge initialization failed: {e}")
                self.ui_bridge_enabled = False
        
        # üöÄ ENHANCED TRADING COMPONENTS üöÄ
        # Provide the router with per-exchange liquid cash so BUY routing/sizing
        # can be additive based on available funds.
        self.smart_router = SmartOrderRouter(
            self.client,
            get_cash_balance=self._get_exchange_cash_balance,
            battlefields=(CONFIG.get('BATTLEFIELDS', {}) or {}),
            default_min_order_usd=float(CONFIG.get('MIN_TRADE_USD', 10.0) or 10.0),
        )
        self.arb_scanner = CrossExchangeArbitrageScanner(self.client)
        self.trade_confirmation = UnifiedTradeConfirmation(self.client)
        self.rebalancer = PortfolioRebalancer(self.client)
        
        # üåê MULTI-EXCHANGE ORCHESTRATOR - All Systems Talk To Each Other üåê
        self.multi_exchange = MultiExchangeOrchestrator(self.client)
        
        # üìä UNIFIED STATE AGGREGATOR - All JSON Feeds Into Ecosystem üìä
        self.state_aggregator = STATE_AGGREGATOR
        
        # üéõÔ∏è DYNAMIC PARAMETERS
        self.position_size_multiplier = 1.0
        self.min_entry_gamma = 0.5  # Default gamma threshold

        
        # üî• WAR-READY ENHANCEMENTS üî•
        self.atr_calculator = ATRCalculator(period=14)
        self.heat_manager = PortfolioHeatManager(max_heat=0.60)
        self.adaptive_filters = AdaptiveFilterThresholds()
        
        # üéØ TRAILING STOP SYSTEM
        self.trailing_stop_manager = TrailingStopManager()
        
        # üì¢ NOTIFICATION SYSTEM
        self.notifier = NotificationManager()
        
        # üåå NEXUS INTEGRATION - MASTER EQUATION + QUEEN HIVE
        self.nexus = NexusIntegration()
        
        # üìù TRADE LOGGER - Data Collection for Probability Matrix Training
        self.trade_logger = None
        if TRADE_LOGGER_AVAILABLE and trade_logger:
            self.trade_logger = trade_logger

        # Optional miner optimizer hook (if present in runtime)
        # Allows trading to read lighthouse Œì and Œ∫t during high-coherence windows
        self.miner_optimizer = getattr(self, 'miner_optimizer', None)
        
        # Optional brain reference (set by global orchestrator for unified startup)
        # Allows direct access to unified brain state during trading decisions
        self.brain = getattr(self, 'brain', None)
        
        # ÔøΩ PROBABILITY LOADER - Fresh probability reports + consensus signals
        # Initialize BEFORE health report so it shows as ACTIVE
        self.probability_loader = None
        self.position_hygiene = None
        if PROBABILITY_LOADER_AVAILABLE:
            try:
                self.probability_loader = ProbabilityLoader(
                    report_dir='/workspaces/aureon-trading',
                    freshness_threshold_minutes=120  # 2 hours max staleness
                )
                self.probability_loader.load_all_reports()
                self.position_hygiene = PositionHygieneChecker()
                # Pass to AurisEngine so health report can see it
                self.auris.probability_loader = self.probability_loader
                self.auris.position_hygiene = self.position_hygiene
            except Exception as e:
                print(f"   ‚ö†Ô∏è Probability Loader init failed: {e}")
        
        # ÔøΩüåà‚ú® ENHANCEMENT LAYER - Rainbow Bridge, Synchronicity, Stargate Grid ‚ú®üåà
        self.enhancement_layer = None
        if ENHANCEMENTS_AVAILABLE:
            try:
                self.enhancement_layer = EnhancementLayer()
                active_count = sum(1 for v in self.enhancement_layer.modules_active.values() if v)
                print(f"   üåà Enhancement Layer active ({active_count}/3 modules)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Enhancement Layer initialization failed: {e}")
        
        print("   üöÄ Enhanced trading components initialized (Router/Arbitrage/Confirmation/Rebalancer)")
        print("   üåê Multi-Exchange Orchestrator active (Binance/Kraken/Capital/Alpaca)")
        print(f"   üìä State Aggregator: {len(self.state_aggregator.aggregated_state.get('sources_loaded', []))} data sources feeding ecosystem")
        
        # ==== COGNITION: initialize thought bus + modules ====
        print("   üß† Initializing Cognition Bus...")
        self.thought_bus = ThoughtBus(persist_path="logs/aureon_thoughts.jsonl")

        # üß†üï∞Ô∏è Restore recent Mycelium nerve history (without replay/persist duplication)
        try:
            self.thought_bus.load_history_to_memory(topic_prefix='mycelium_state.')
        except Exception:
            pass

        # Modules (thinking parts)
        self.miner_module = MinerModule(self.thought_bus)

        # Risk limits (tune max_positions) - now with capital awareness!
        self.risk_module = RiskModule(
            self.thought_bus,
            max_positions=get_max_positions_limit() or 0,
            get_open_positions_count=lambda: len(self.positions),
            get_available_capital=lambda: self.capital_pool.get_available() if hasattr(self, 'capital_pool') else 0.0,
            min_order_size=6.0  # Kraken minimum ~$5, use $6 for safety
        )

        # Execution: connect to your real order function
        self.exec_module = ExecutionModule(self.thought_bus, place_order_fn=self._place_order_from_intent)

        # Optional: subscribe to order results for logging / bookkeeping
        self.thought_bus.subscribe("execution.order_result", self._on_execution_order_result)
        
        # Subscribe to news thoughts for trading influence
        self.thought_bus.subscribe("news.sentiment", self._on_news_sentiment)
        self.thought_bus.subscribe("news.alert", self._on_news_alert)
        self._last_news_sentiment = {}  # Cache for trading decisions
        
        # Subscribe to knowledge thoughts for context
        self.thought_bus.subscribe("knowledge.query_result", self._on_knowledge_result)
        self.thought_bus.subscribe("knowledge.research_complete", self._on_research_complete)
        
        print("   üß† Cognition Bus Active (MinerModule -> RiskModule -> ExecutionModule)")

        # üõ°Ô∏è Cognitive immune system (autonomous antivirus)
        self.immune_system = CognitiveImmuneSystem(self, self.thought_bus, self.state_aggregator)
        print("   üõ°Ô∏è Cognitive Immune System armed (self-healing enabled)")

        # üåê Universal Market Intelligence - Scans ALL assets without filtering
        global UNIVERSAL_MARKET_INTEL
        self.universal_intel = UniversalMarketIntelligence(self.thought_bus)
        UNIVERSAL_MARKET_INTEL = self.universal_intel
        print("   üåê Universal Market Intelligence active (scans ALL assets ‚Üí brain)")

        # üçÑ CONNECT MYCELIUM TO THOUGHT BUS - Info flows UP/DOWN/LEFT/RIGHT!
        if hasattr(self, 'mycelium') and self.mycelium:
            self.mycelium.bus = self.thought_bus
            self.mycelium.universal_intel = self.universal_intel
            # Subscribe mycelium to key events for bidirectional flow
            self.thought_bus.subscribe("universal_intel.*", self.mycelium._on_thought_wrapper)
            self.thought_bus.subscribe("brain.*", self.mycelium._on_thought_wrapper)
            self.thought_bus.subscribe("immune.*", self.mycelium._on_thought_wrapper)
            print("   üçÑ Mycelium connected to ThoughtBus - info flows UP‚Üë DOWN‚Üì LEFT‚Üê RIGHT‚Üí")

        # üì∞ News Feed (World News API integration)
        self.news_feed = None
        self._news_poll_counter = 0
        self._news_poll_interval = 60  # Poll every 60 cycles (~2 mins at 2s interval)
        if NEWS_FEED_AVAILABLE:
            news_api_key = os.environ.get("WORLD_NEWS_API_KEY", "1e67384add34486d8b14a951b220fe8a")
            if news_api_key:
                try:
                    import asyncio
                    news_config = NewsFeedConfig(
                        api_key=news_api_key,
                        market_keywords=["cryptocurrency", "bitcoin", "ethereum", "federal reserve", 
                                        "stock market", "recession", "inflation", "interest rates"],
                        categories=["business", "technology", "politics"],
                        max_articles=25,
                        max_age_hours=12
                    )
                    self.news_feed = NewsFeed(news_config, self.thought_bus)
                    print("   üì∞ News Feed connected (World News API) - publishing to ThoughtBus")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è News Feed init failed: {e}")

        # üìö Knowledge Base (Wikipedia API integration)
        self.knowledge_base = None
        self._knowledge_research_counter = 0
        self._knowledge_research_interval = 300  # Research every 300 cycles (~10 mins)
        if KNOWLEDGE_BASE_AVAILABLE:
            try:
                self.knowledge_base = KnowledgeBase(thought_bus=self.thought_bus)
                print("   üìö Knowledge Base connected (Wikipedia API) - autonomous learning enabled")
                # Prefetch core trading knowledge in background thread
                import threading
                def prefetch_knowledge():
                    try:
                        self.knowledge_base.prefetch_trading_knowledge()
                    except Exception as e:
                        logger.debug(f"Knowledge prefetch error: {e}")
                threading.Thread(target=prefetch_knowledge, daemon=True).start()
            except Exception as e:
                print(f"   ‚ö†Ô∏è Knowledge Base init failed: {e}")

        # üìöüåç WISDOM SCANNER - CONSCIOUSNESS EXPANSION ENGINE üåçüìö
        # Continuously scans Wikipedia and Sacred-Texts for ancient wisdom
        # 11 Civilizations: Celtic, Aztec, Egyptian, Pythagorean, Plantagenet, 
        #                   Mogollon, Warfare, Chinese, Hindu, Mayan, Norse
        # üß† ALL 11 CIVILIZATIONS NOW VOTE IN THE CONSENSUS!
        self.wisdom_scanner = None
        self._wisdom_scan_counter = 0
        self._wisdom_scan_interval = 43200  # Full scan every 43200 cycles (~24 hours at 2s)
        if WISDOM_SCANNER_AVAILABLE:
            try:
                wisdom_config = ScannerConfig(
                    wisdom_data_dir="wisdom_data",
                    rate_limit_strategy="adaptive",
                    scan_interval_hours=24
                )
                self.wisdom_scanner = AureonWisdomScanner(wisdom_config)
                
                # Connect to ThoughtBus if available
                if THOUGHT_BUS_AVAILABLE:
                    self.wisdom_adapter = WisdomScannerThoughtBusAdapter(
                        self.wisdom_scanner, 
                        self.thought_bus
                    )
                    
                # Subscribe to wisdom insights
                self.thought_bus.subscribe("wisdom_insight", self._on_wisdom_insight)
                self.thought_bus.subscribe("consciousness_expansion", self._on_consciousness_expansion)
                
                # Print wisdom summary
                summary = self.wisdom_scanner.get_wisdom_summary()
                print(f"   üìöüåç Wisdom Scanner: {summary['total_civilizations']} civilizations monitored")
                print(f"         Total learned insights: {summary['scan_stats']['total_insights']}")
                
                # Start background wisdom scanning thread
                import threading
                def run_wisdom_scan():
                    try:
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        loop.run_until_complete(self.wisdom_scanner.run_full_scan())
                    except Exception as e:
                        logger.debug(f"Wisdom scan error: {e}")
                # Initial scan on startup (in background)
                threading.Thread(target=run_wisdom_scan, daemon=True).start()
                print("   üìöüåç Initial wisdom scan started in background...")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Wisdom Scanner init failed: {e}")

        # üè• PRINT ECOSYSTEM HEALTH REPORT üè•
        # Show all active systems and their communication status
        self.auris.print_system_health()
        
        try:
            top = self.state_aggregator.get_top_signals(3)
            prob_lines = []
            for sym, data in top.get('probability', []):
                prob = data.get('probability') or 0
                src = data.get('source', '')
                prob_lines.append(f"      ‚Ä¢ {sym}: p={prob:.2f} src={src}")

            an_lines = []
            for sym, data in top.get('analytics', []):
                score = data.get('score') or 0
                wr = data.get('win_rate')
                wr_str = f"{wr:.2f}" if isinstance(wr, (int, float)) else "n/a"
                src = data.get('source', '')
                an_lines.append(f"      ‚Ä¢ {sym}: score={score:.2f} wr={wr_str} src={src}")

            pos_lines = []
            for sym, qty in top.get('positions', []):
                qty_str = f"{qty:.4f}" if isinstance(qty, (int, float)) else str(qty)
                pos_lines.append(f"      ‚Ä¢ {sym}: qty={qty_str}")

            if prob_lines:
                print("   üîç Top Probability Signals:")
                for ln in prob_lines:
                    print(ln)
            if an_lines:
                print("   üß™ Top Analytics Signals:")
                for ln in an_lines:
                    print(ln)
            if pos_lines:
                print("   üì¶ Position Snapshots:")
                for ln in pos_lines:
                    print(ln)
        except Exception as e:
            logger.debug("Top signal display failed: %s", e)
        print("   üî• War-ready enhancements active (ATR/HeatManager/AdaptiveFilters)")
        if CONFIG.get('ENABLE_TRAILING_STOP', True):
            print(f"   üéØ Trailing stops enabled (activate at +{CONFIG.get('TRAILING_ACTIVATION_PCT', 0.5)}%, trail {CONFIG.get('TRAILING_DISTANCE_PCT', 0.3)}%)")
        if self.notifier.is_enabled():
            status = self.notifier.get_status()
            channels = []
            if status['telegram_enabled']: channels.append('Telegram')
            if status['discord_enabled']: channels.append('Discord')
            if status['webhook_enabled']: channels.append('Webhook')
            print(f"   üì¢ Notifications enabled: {', '.join(channels)}")

        # High-conviction probability watchlist (prob>=0.8 & conf>=0.8)
        self.high_conviction_symbols = set()
        for sig in self.state_aggregator.aggregated_state.get('high_conviction_signals', []):
            sym = sig.get('symbol', '')
            base = sym.replace('USDT', '').replace('USDC', '').replace('USD', '').replace('EUR', '').replace('GBP', '')
            if base:
                self.high_conviction_symbols.add(base)

        pfresh = self.state_aggregator.aggregated_state.get('probability_freshness', {})
        if pfresh.get('stale'):
            newest = pfresh.get('newest_minutes')
            newest_str = f"{newest:.1f}m" if isinstance(newest, (int, float)) else "unknown"
            print(f"   ‚ö†Ô∏è Probability reports stale ({newest_str} since last generation) ‚Äî gating probability-based entries")
        if self.nexus.enabled:
            print(f"   üåå Nexus active: Master Equation Œõ(t) + Queen Hive 10-9-1")
        
        # üîÆ PREDICTION VALIDATOR - Track prediction accuracy over time
        self.prediction_validator = PredictionValidator(validation_window_seconds=60)
        print(f"   üîÆ Prediction Validator active: 1-minute forecasts with peer review")
        
        # üéØ PROBABILITY LOADER status message (already initialized earlier)
        if self.probability_loader:
            fresh = self.probability_loader.is_fresh()
            if fresh:
                top_signals = self.probability_loader.get_top_signals(limit=5, min_probability=0.8, min_confidence=0.8)
                print(f"   üéØ Probability Loader ACTIVE ({len(top_signals)} high-conviction signals)")
                consensus = self.probability_loader.get_consensus_signals(min_exchanges=2, min_probability=0.75)
                if consensus:
                    print(f"   üî• Multi-exchange consensus: {len(consensus)} symbols with ‚â•2 exchange agreement")
            else:
                print("   ‚ö†Ô∏è Probability reports STALE - gating probability-based entries")
            print("   üßπ Position Hygiene Checker ACTIVE")
        
        # üìä PROBABILITY MATRIX - Persistent learning from position outcomes
        self.prob_matrix = None
        if PROB_MATRIX_AVAILABLE and CONFIG.get('ENABLE_PROB_MATRIX', True):
            try:
                self.prob_matrix = HNCProbabilityIntegration()
                print("   üìä Probability Matrix (Position Learning) ACTIVE")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Probability Matrix init failed: {e}")
        
        # üìä PROBABILITY REPORT GENERATOR - Auto-regenerates every 15 seconds
        global PROBABILITY_GENERATOR
        self.probability_generator = None
        if CONFIG.get('ENABLE_PROBABILITY_GENERATOR', True):
            try:
                self.probability_generator = ProbabilityReportGenerator(
                    report_dir=os.environ.get('AUREON_REPORT_DIR', '.'),
                    interval_seconds=float(os.environ.get('PROBABILITY_INTERVAL', '15'))
                )
                PROBABILITY_GENERATOR = self.probability_generator
                print(f"   üìä Probability Generator initialized (15s interval)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Probability Generator init failed: {e}")
        
        # üåç‚ö° GLOBAL FINANCIAL ECOSYSTEM FEED ‚ö°üåç
        self.global_feed = None
        self.macro_snapshot = None
        if GLOBAL_FEED_AVAILABLE:
            try:
                self.global_feed = GlobalFinancialFeed()
                self.macro_snapshot = self.global_feed.get_snapshot()
                print("   üåç Global Financial Feed ACTIVE")
                print(f"      Fear/Greed: {self.macro_snapshot.crypto_fear_greed} | Regime: {self.macro_snapshot.market_regime}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Global Feed init failed: {e}")
        
        # üìä PROBABILITY VALIDATOR - Track validation accuracy
        self.probability_validator_v2 = None
        if VALIDATOR_AVAILABLE:
            try:
                self.probability_validator_v2 = get_validator()
                stats = self.probability_validator_v2.stats
                if stats.validated_predictions > 0:
                    print(f"   üìä Probability Validator ACTIVE (Accuracy: {stats.direction_accuracy*100:.1f}%)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Validator init failed: {e}")
        
        # Determine tradeable currencies based on wallet
        self.tradeable_currencies = ['USD', 'GBP', 'EUR', 'USDT', 'USDC']
        self._detect_wallet_currency()
        
        # Load previous state if exists
        fresh_start = os.environ.get('FRESH_START', '0') == '1'
        if fresh_start:
            print("   ‚ú® FRESH START: Ignoring previous state file")
            # Reset baselines BEFORE refresh_equity to avoid circuit breaker trigger
            self.tracker.trading_halted = False
            self.tracker.halt_reason = ""
            self.tracker.max_drawdown = 0.0
            self.tracker.peak_balance = 1e9  # Temporarily high to avoid DD calc
        else:
            self.load_state()

        # Initialise equity snapshot
        self.refresh_equity(mark_cycle=True)
        
        # On fresh start in live mode, reset baselines to actual portfolio value
        if fresh_start and not self.dry_run and self.total_equity_gbp > 0:
            self.tracker.initial_balance = self.total_equity_gbp
            self.tracker.peak_balance = self.total_equity_gbp
            self.tracker.balance = self.total_equity_gbp
            self.tracker.equity_baseline = self.total_equity_gbp
            self.tracker.cycle_equity_start = self.total_equity_gbp
            self.tracker.max_drawdown = 0.0
            self.tracker.trading_halted = False
            self.tracker.halt_reason = ""
            print(f"   üìä Baseline reset to real portfolio: ¬£{self.total_equity_gbp:.2f}")
        
        # User directive: disable drawdown circuit breaker to allow penny-profit harvesting
        self.tracker.circuit_breaker_enabled = False
        # Ensure no stale halt state carries over between runs
        self.tracker.trading_halted = False
        self.tracker.halt_reason = ""
        
        # üîß ALWAYS import existing holdings as managed positions on startup
        # This ensures any assets on exchanges are tracked properly
        if not self.dry_run:
            self._import_existing_holdings()
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # ‚òòÔ∏èüî• CELTIC WARFARE SYSTEMS INITIALIZATION üî•‚òòÔ∏è
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # ‚òòÔ∏è GUERRILLA WARFARE ENGINE - Flying Columns & Intelligence Network
        self.celtic_intelligence = None
        if GUERRILLA_ENGINE_AVAILABLE and IntelligenceNetwork:
            try:
                self.celtic_intelligence = IntelligenceNetwork()
                print("   ‚òòÔ∏è Celtic Intelligence Network ACTIVE")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Celtic Intelligence init failed: {e}")
        
        # ‚ö° PREEMPTIVE STRIKE ENGINE - Exit Before Market Reacts
        self.preemptive_engine = None
        if PREEMPTIVE_STRIKE_AVAILABLE and PreemptiveExitEngine:
            try:
                self.preemptive_engine = PreemptiveExitEngine()
                print("   ‚ö° Preemptive Strike Engine ACTIVE")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Preemptive Engine init failed: {e}")
        
        # üåê MULTI-BATTLEFRONT WAR ROOM - Unity of Command
        self.celtic_war_room = None
        if BATTLEFRONT_COORDINATOR_AVAILABLE and MultiBattlefrontWarRoom:
            try:
                self.celtic_war_room = MultiBattlefrontWarRoom()
                print("   üåê Celtic War Room ACTIVE (4 battlefronts)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è War Room init failed: {e}")
        
        # üáÆüá™ IRISH PATRIOT SCOUT DEPLOYER - Celtic-Trained Scouts
        self.patriot_deployer = None
        if PATRIOT_SCOUTS_AVAILABLE and PatriotScoutDeployer:
            try:
                self.patriot_deployer = PatriotScoutDeployer(ecosystem=self)
                print("   üáÆüá™ Irish Patriot Scout Deployer ACTIVE")
                # üçÑ Register Patriots with Mycelium Network
                try:
                    register_to_mycelium('patriots', self.patriot_deployer.network)
                except Exception:
                    pass  # Mycelium resilient
            except Exception as e:
                print(f"   ‚ö†Ô∏è Patriot Deployer init failed: {e}")
        
        # üéØ IRA CELTIC SNIPER - Zero Loss + Celtic Intelligence
        self.celtic_sniper = None
        if CELTIC_SNIPER_AVAILABLE and IraCelticSniper:
            try:
                self.celtic_sniper = IraCelticSniper(dry_run=self.dry_run)
                print("   üéØ IRA Celtic Sniper ACTIVE (Zero Loss Mode)")
                # üçÑ Register Celtic Sniper with Mycelium Network
                try:
                    register_to_mycelium('warfare', self.celtic_sniper)
                except Exception:
                    pass  # Mycelium resilient
            except Exception as e:
                print(f"   ‚ö†Ô∏è Celtic Sniper init failed: {e}")
        
        # Print Celtic Systems Summary
        celtic_systems_active = sum([
            self.celtic_intelligence is not None,
            self.preemptive_engine is not None,
            self.celtic_war_room is not None,
            self.patriot_deployer is not None,
            self.celtic_sniper is not None
        ])
        if celtic_systems_active > 0:
            print(f"   ‚òòÔ∏èüî• CELTIC WARFARE: {celtic_systems_active}/5 systems WIRED")
            if GUERRILLA_ENGINE_AVAILABLE:
                try:
                    wisdom = get_celtic_wisdom()
                    print(f"   üìú \"{wisdom}\"")
                except:
                    pass
        
        # üçÑ MYCELIUM STATE AGGREGATOR - Unified Intelligence Flow
        try:
            mycelium = get_mycelium_aggregator()
            mycelium_systems = len(mycelium.systems)
            mycelium_synapses = len(mycelium.synapses)
            if mycelium_systems > 0:
                print(f"   üçÑ MYCELIUM NETWORK: {mycelium_systems} systems connected via {mycelium_synapses} synapses")
                # Initial sync to establish connections
                mycelium_sync()
        except Exception:
            pass  # Mycelium loads silently
        
        # üåê‚ö° GLOBAL HARMONIC FIELD - 42 Sources ‚Üí 7 Layers ‚Üí Œ© ‚ö°üåê
        # The Ultimate Unified Field that ties ALL data sources together
        self.global_harmonic_field = None
        if HARMONIC_FIELD_AVAILABLE:
            try:
                self.global_harmonic_field = get_global_field()
                print("   üåê‚ö° Global Harmonic Field ACTIVE (Œ© > 0.618 = STRONG BUY)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Global Harmonic Field init failed: {e}")

        # üçÑ FINAL WIRING: connect all major subsystems to Mycelium aggregator
        # This makes scouts/sniper/scanner/immune/cognition share one state channel.
        self._wire_all_systems_to_mycelium()

        # üçÑ Mycelium heartbeat state (prevents micro-loops)
        self._mycelium_last_heartbeat_ts = 0.0
        self._mycelium_heartbeat_interval = float(CONFIG.get('MYCELIUM_HEARTBEAT_SECONDS', 2.0))

    def _wire_all_systems_to_mycelium(self) -> None:
        """Register key subsystems into the MyceliumStateAggregator and publish a snapshot."""
        def _safe_register(name: str, obj: Any) -> None:
            if obj is None:
                return
            try:
                register_to_mycelium(name, obj)
            except Exception:
                pass

        try:
            # Core IRA graph participants
            _safe_register('scanner', get_active_scanner() if callable(get_active_scanner) else None)
            _safe_register('patriots', getattr(getattr(self, 'patriot_deployer', None), 'network', None))
            _safe_register('warfare', getattr(self, 'celtic_sniper', None))
            _safe_register('learner', globals().get('ADAPTIVE_LEARNER'))

            # Additional unified ecosystem subsystems (event/telemetry consumers)
            _safe_register('immune', getattr(self, 'immune_system', None))
            _safe_register('thought_bus', getattr(self, 'thought_bus', None))
            _safe_register('mycelium_network', getattr(self, 'mycelium', None))
            _safe_register('universal_intel', getattr(self, 'universal_intel', None))

            # Publish a single snapshot event so all connected systems can ‚Äúsee‚Äù startup state
            try:
                mycelium_sync('ecosystem_startup', {
                    'timestamp': time.time(),
                    'dry_run': bool(getattr(self, 'dry_run', False)),
                    'positions': len(getattr(self, 'positions', {}) or {}),
                    'battlefields': CONFIG.get('BATTLEFIELDS', {}),
                    'sniper_active': bool(getattr(self, 'sniper_config', {}).get('ACTIVE', False)),
                })
            except Exception:
                pass
        except Exception:
            # Never let wiring failure break startup
            pass

    def _mycelium_heartbeat(self, note: str = "cycle") -> None:
        """Constant nerve-system pulse: sync + persist snapshot without micro-loops."""
        now_ts = time.time()
        try:
            if now_ts - float(getattr(self, '_mycelium_last_heartbeat_ts', 0.0)) < float(getattr(self, '_mycelium_heartbeat_interval', 2.0)):
                return
        except Exception:
            # If timestamps are corrupted, default to allowing a pulse
            pass

        snapshot = {
            'timestamp': now_ts,
            'note': note,
            'iteration': int(getattr(self, 'iteration', 0) or 0),
            'dry_run': bool(getattr(self, 'dry_run', False)),
            'positions': len(getattr(self, 'positions', {}) or {}),
            'trading_halted': bool(getattr(getattr(self, 'tracker', None), 'trading_halted', False)),
            'halt_reason': getattr(getattr(self, 'tracker', None), 'halt_reason', ''),
            'queen_signal': float(getattr(getattr(self, 'mycelium', None), 'queen_signal', 0.0) or 0.0),
            'cascade': (CASCADE_AMPLIFIER.get_stats() if 'CASCADE_AMPLIFIER' in globals() else {}),
            'sniper_bridge_ready': bool(getattr(self, '_sniper_bridge_ready', False)),
        }

        # üçÑ Pulse the aggregator (also persists into ThoughtBus via ira_sniper_mode ingest_event)
        try:
            mycelium_sync('heartbeat', snapshot)
        except Exception:
            pass

        # üêò Append to elephant history as a second durable channel
        try:
            em = getattr(self, 'elephant_memory', None)
            if em:
                em.record_event('mycelium_heartbeat', snapshot)
        except Exception:
            pass

        self._mycelium_last_heartbeat_ts = now_ts

    def _fetch_origin_trade(self, symbol: str) -> Optional[Dict]:
        """
        üïµÔ∏è‚Äç‚ôÇÔ∏è ORIGIN TRACER: Fetches the original trade data for a zombie position.
        Used by the Memory Core to reconstruct lost history.
        """
        try:
            # Try to find the last buy order for this symbol
            # This is a simplified implementation - in a real scenario, we'd query the exchange's closed orders
            # For now, we'll return None to trigger the fallback estimation logic in Memory Core
            # or implement a basic lookup if the client supports it.
            
            # If we had a robust order history in the client, we would use it here.
            # For now, returning None allows the Memory Core to use its "Current Price" fallback,
            # which is safer than guessing wrong.
            return None
        except Exception as e:
            logger.error(f"Failed to trace origin for {symbol}: {e}")
            return None

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üö´ SYMBOL VALIDATION CACHE - Reduce API noise for invalid symbols
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _is_symbol_invalid(self, symbol: str) -> bool:
        """Check if symbol is in invalid cache and not expired."""
        if symbol not in self._invalid_symbols:
            return False
        # Check if cache entry has expired
        cached_time = self._invalid_symbols[symbol]
        if time.time() - cached_time > self._symbol_cache_ttl:
            del self._invalid_symbols[symbol]
            return False
        return True
    
    def _mark_symbol_invalid(self, symbol: str) -> None:
        """Mark a symbol as invalid to skip future API calls."""
        self._invalid_symbols[symbol] = time.time()
    
    def _mark_symbol_valid(self, symbol: str, exchange: str) -> None:
        """Mark a symbol as valid/working."""
        self._valid_symbols[symbol] = exchange
        # Remove from invalid cache if present
        if symbol in self._invalid_symbols:
            del self._invalid_symbols[symbol]
        self._clear_symbol_dust(symbol)

    def _is_symbol_dust(self, symbol: str) -> Optional[str]:
        """Return dust reason if symbol is flagged as unsellable."""
        entry = self._dust_positions.get(symbol)
        if not entry:
            return None
        reason, ts = entry
        if time.time() - ts > self._dust_ttl:
            del self._dust_positions[symbol]
            return None
        return reason

    def _mark_symbol_dust(self, symbol: str, reason: str) -> None:
        """Persistently mark a symbol as dust/unsellable."""
        self._dust_positions[symbol] = (reason, time.time())
        self._invalid_symbols[symbol] = time.time()

    def _clear_symbol_dust(self, symbol: str) -> None:
        self._dust_positions.pop(symbol, None)
    
    def get_symbol_cache_stats(self) -> Dict[str, Any]:
        """Get stats on symbol caching for telemetry."""
        now = time.time()
        active_invalid = sum(1 for t in self._invalid_symbols.values() if now - t < self._symbol_cache_ttl)
        return {
            'valid_symbols': len(self._valid_symbols),
            'invalid_symbols': active_invalid,
            'dust_symbols': len(self._dust_positions),
            'total_cached': len(self._valid_symbols) + active_invalid,
        }

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ÔøΩ SNIPER BRIDGE - GPT CODEX TELEMETRY INTEGRATION üéØ
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def _announce_sniper_activation(self) -> None:
        """Log IRA sniper readiness across ALL 4 BATTLEFRONTS and sellable assets.
        
        üè¥‚öîÔ∏è Shows which platforms have:
        - Sniper coverage (ready to kill)
        - Harvester coverage (ready to close)
        - Scout coverage (ready to deploy)
        """
        coverage = getattr(self, 'sniper_coverage', {}) or {}
        platforms = coverage.get('platforms', {})
        active = bool(self.sniper_config.get('ACTIVE', False))
        status = "ACTIVE" if active else "INACTIVE"
        
        print(f"\nüéØ IRA SNIPER STATUS: {status}")
        print(f"   ‚öîÔ∏è MULTI-BATTLEFIELD MODE: {'ENABLED' if CONFIG.get('MULTI_BATTLEFIELD_MODE', True) else 'DISABLED'}")
        
        # Show battlefield configuration
        battlefields = CONFIG.get('BATTLEFIELDS', {})
        enabled_bfs = [bf for bf, cfg in battlefields.items() if cfg.get('enabled', False)]
        print(f"   üè¥ Active Battlefronts: {', '.join(enabled_bfs).upper() if enabled_bfs else 'None'}\n")
        
        if not platforms:
            print("   ‚ö†Ô∏è No platform coverage available for sniper map.")
            print("   üéØ Zero Loss Policy: We NEVER lose. Every trade is a confirmed kill.")
            print("   ‚òòÔ∏è Celtic intelligence guiding all entry decisions.\n")
            return
        
        # Show each battlefield's status
        for bf_name, bf_config in battlefields.items():
            enabled = bf_config.get('enabled', False)
            status_icon = "‚úÖ" if enabled else "‚ùå"
            platform_info = platforms.get(bf_name, {})
            assets = platform_info.get('sellable_assets', [])
            asset_preview = ", ".join(assets[:5]) + ("..." if len(assets) > 5 else "") if assets else "none"
            
            sniper_icon = "üéØ" if bf_config.get('sniper_active', False) else "‚è∏Ô∏è"
            harvester_icon = "üåæ" if bf_config.get('harvester_active', False) else "‚è∏Ô∏è"
            scouts_count = bf_config.get('scouts_per_exchange', 0)
            
            print(f"   {status_icon} {bf_name.upper():12} | {sniper_icon} Sniper | {harvester_icon} Harvester | üéñÔ∏è {scouts_count} scouts | üì¶ {len(assets)} assets")
            if enabled and assets:
                print(f"      ‚îî‚îÄ Assets: {asset_preview}")
        
        print(f"\n   Position size: ${self.sniper_config.get('POSITION_SIZE_USD', 0):.2f} | Max positions: {self.sniper_config.get('MAX_POSITIONS', 0)}")
        print("   üéØ Zero Loss Policy: We NEVER lose. Every trade is a confirmed kill.")
        print("   ‚òòÔ∏è Celtic intelligence guiding all entry decisions.")
        print("   üçÑ Mycelium Network preventing duplicate positions across battlefronts.\n")

    def _sync_sniper_bridge(self, note: str = ""):
        """Keep sniper brain and scout coverage aligned with live balances.
        
        üè¥‚öîÔ∏è MULTI-BATTLEFIELD MODE: Syncs sniper coverage across ALL 4 exchanges!
        Mycelium network tracks positions to prevent duplicate kills.
        """
        if not hasattr(self, 'sniper_config') or not self.sniper_config.get('ACTIVE', True):
            return

        try:
            if CELTIC_SNIPER_AVAILABLE:
                self.sniper_coverage = map_sniper_platform_assets(self.client)
            platforms = self.sniper_coverage.get('platforms', {}) if self.sniper_coverage else {}
            self._sniper_bridge_ready = bool(platforms)
            self._scout_bridge_status = {
                'last_update': time.time(),
                'platforms': platforms,
                'note': note
            }
            
            # üè¥‚öîÔ∏è Multi-battlefield position tracking
            battlefield_status = {}
            battlefields = CONFIG.get('BATTLEFIELDS', {})
            for bf_name, bf_config in battlefields.items():
                if not bf_config.get('enabled', False):
                    continue
                platform_info = platforms.get(bf_name, {})
                positions_on_exchange = sum(1 for sym, pos in self.positions.items() 
                                           if getattr(pos, 'exchange', '').lower() == bf_name)
                battlefield_status[bf_name] = {
                    'sniper_active': bf_config.get('sniper_active', False),
                    'harvester_active': bf_config.get('harvester_active', False),
                    'assets': len(platform_info.get('sellable_assets', [])),
                    'positions': positions_on_exchange,
                    'max_positions': bf_config.get('max_positions', 10)
                }
            
            self._battlefield_status = battlefield_status
            
            # üçÑ Sync with Mycelium Network
            try:
                mycelium_sync('sniper_bridge', {
                    'platforms': list(platforms.keys()),
                    'battlefields': battlefield_status,
                    'total_positions': len(self.positions),
                    'note': note,
                    'timestamp': time.time()
                })
            except Exception:
                pass
            
            if note:
                active_bfs = [bf for bf, st in battlefield_status.items() if st.get('sniper_active')]
                print(f"   üéØ Sniper bridge synced ({note}) - battlefronts: {', '.join(active_bfs).upper()}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Sniper bridge sync failed: {e}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Sniper bridge sync failed: {e}")

    def _record_sniper_kill(self, pos, net_pnl: float):
        """Send completed trade data to unified sniper brain for telemetry."""
        # üéØ‚ö° ACTIVE KILL SCANNER - Record the kill!
        try:
            if net_pnl > 0:
                execute_sniper_kill(pos.exchange, pos.symbol, net_pnl)
                
            # üß† ADAPTIVE LEARNING: Feed scanner stats to ecosystem learner
            # This creates a bidirectional learning loop:
            # Scanner learns from kills ‚Üí Ecosystem learns from scanner ‚Üí Scanner gets smarter
            try:
                scanner_stats = get_scanner_learning_stats()
                if scanner_stats['kills_executed'] > 0:
                    # Feed scanner's learned momentum success rates to ecosystem
                    ADAPTIVE_LEARNER.optimized_thresholds['scanner_cascade'] = scanner_stats['cascade_factor']
                    ADAPTIVE_LEARNER.optimized_thresholds['scanner_kappa'] = scanner_stats['kappa_t']
                    ADAPTIVE_LEARNER.optimized_thresholds['scanner_streak'] = scanner_stats['consecutive_kills']
                    
                    # Log the learning sync every 10 kills
                    if scanner_stats['kills_executed'] % 10 == 0:
                        logger.info(f"üß† Scanner‚ÜíLearner sync: CASCADE={scanner_stats['cascade_factor']:.1f}x Œ∫t={scanner_stats['kappa_t']:.2f} STREAK={scanner_stats['consecutive_kills']}")
            except Exception:
                pass
        except Exception as e:
            logger.debug(f"Kill scanner record error: {e}")
        
        if not hasattr(self, 'sniper_brain') or not self.sniper_brain:
            return
        try:
            self.sniper_brain.record_kill(net_pnl, pos.symbol, is_win=(net_pnl > 0))
            self._sync_sniper_bridge("kill")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Sniper brain telemetry failed: {e}")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ÔøΩüéµ SACRED FREQUENCY MAPPING - Harmonic Trading Intelligence üéµ
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _get_sacred_frequency_modifier(self, freq: float) -> float:
        """
        üéµ SACRED FREQUENCY MODIFIER üéµ
        
        Maps market frequencies to sacred healing tones and returns
        appropriate probability modifiers based on harmonic resonance.
        
        SOLFEGGIO SCALE (Ancient healing frequencies):
        - 174 Hz: Foundation, pain relief
        - 285 Hz: Healing, tissue regeneration
        - 396 Hz: Liberation from fear/guilt (UT)
        - 417 Hz: Undoing situations, facilitating change (RE)
        - 528 Hz: Love frequency, DNA repair (MI) ‚≠ê OPTIMAL GREEN BORAX
        - 639 Hz: Connection, relationships (FA)
        - 741 Hz: Awakening intuition (SOL)
        - 852 Hz: Returning to spiritual order (LA)
        - 963 Hz: Unity, awakening (SI)
        
        EARTH FREQUENCIES:
        - 7.83 Hz: Schumann Resonance (Earth's heartbeat)
        - 136.1 Hz: OM frequency (Earth's year)
        - 432 Hz: Universal tuning (cosmic harmony)
        
        DISTORTION:
        - 440 Hz: Artificial concert pitch (dissonance)
        """
        # üü¢ Check SACRED SOLFEGGIO frequencies FIRST! 
        # 528Hz GREEN LOVE must be prioritized over Schumann harmonics!
        sacred_map = {
            (523, 533): CONFIG.get('FREQUENCY_BOOST_528HZ', 1.35),   # 528 Hz Love ‚≠ê GREEN BORAX
            (391, 401): CONFIG.get('FREQUENCY_BOOST_396HZ', 1.40),   # 396 Hz Liberation
            (427, 437): CONFIG.get('FREQUENCY_BOOST_432HZ', 1.30),   # 432 Hz Cosmic
            (169, 179): CONFIG.get('FREQUENCY_BOOST_174HZ', 1.20),   # 174 Hz Foundation
            (280, 290): CONFIG.get('FREQUENCY_BOOST_285HZ', 1.25),   # 285 Hz Healing
            (412, 422): CONFIG.get('FREQUENCY_BOOST_417HZ', 1.30),   # 417 Hz Change
            (435, 445): CONFIG.get('FREQUENCY_SUPPRESS_440HZ', 0.70),# 440 Hz Distortion!
            (634, 644): CONFIG.get('FREQUENCY_BOOST_639HZ', 1.25),   # 639 Hz Connection
            (736, 746): CONFIG.get('FREQUENCY_BOOST_741HZ', 1.15),   # 741 Hz Awakening
            (847, 857): CONFIG.get('FREQUENCY_BOOST_852HZ', 1.20),   # 852 Hz Spiritual
            (958, 968): CONFIG.get('FREQUENCY_SUPPRESS_963HZ', 0.60),# 963 Hz (poor data)
            (131, 141): CONFIG.get('FREQUENCY_BOOST_136HZ', 1.25),   # 136 Hz OM
        }
        
        for (low, high), modifier in sacred_map.items():
            if low <= freq <= high:
                return modifier
        
        # Check Schumann harmonics AFTER sacred frequencies (7.83Hz √ó n)
        schumann_base = 7.83
        for harmonic in range(1, 128):  # Up to 128th harmonic (~1000Hz)
            schumann_freq = schumann_base * harmonic
            if abs(freq - schumann_freq) <= 3:
                return CONFIG.get('FREQUENCY_BOOST_SCHUMANN', 1.45)
        
        # Band-based fallback
        if 300 <= freq <= 399:
            return CONFIG.get('FREQUENCY_BOOST_300HZ', 1.50)  # 98.8% accuracy!
        elif 600 <= freq <= 699:
            return CONFIG.get('FREQUENCY_SUPPRESS_600HZ', 0.75)  # 0% accuracy
        elif freq >= 1000:
            return CONFIG.get('FREQUENCY_SUPPRESS_HIGH_CHAOS', 0.50)
        
        # Neutral baseline for unclassified frequencies
        return CONFIG.get('FREQUENCY_NEUTRAL_BASELINE', 1.0)
    
    def _get_frequency_name(self, freq: float) -> str:
        """Get human-readable name for a frequency."""
        # Check for exact sacred frequency matches first (¬±5Hz tolerance)
        sacred_names = {
            (5, 11): "Schumann",
            (131, 141): "OM/Earth",
            (169, 179): "Foundation",
            (280, 290): "Healing",
            (295, 405): "Activation",  # Includes 300-399 golden band + 396
            (412, 422): "Change",
            (427, 437): "Cosmic",
            (435, 445): "Distortion‚ö†Ô∏è",
            (523, 533): "Loveüíö",
            (634, 644): "Connection",
            (736, 746): "Awakening",
            (847, 857): "Spiritual",
            (958, 968): "Unity",
        }
        
        for (low, high), name in sacred_names.items():
            if low <= freq <= high:
                return name
        
        # Schumann harmonics
        schumann_base = 7.83
        for harmonic in range(1, 128):
            if abs(freq - schumann_base * harmonic) <= 3:
                return f"Schumann√ó{harmonic}"
        
        # Generic band names
        if freq < 200:
            return "Earth"
        elif freq < 300:
            return "Grounding"
        elif freq < 400:
            return "Golden"
        elif freq < 500:
            return "Transition"
        elif freq < 600:
            return "Heart"
        elif freq < 700:
            return "Expression"
        elif freq < 800:
            return "Intuition"
        elif freq < 900:
            return "Insight"
        elif freq < 1000:
            return "Crown"
        else:
            return "Chaos‚ö†Ô∏è"

    def _translate_frequency_message(self, freq: float) -> str:
        """
        üåÄ MEDICINE WHEEL FREQUENCY TRANSLATOR üåÄ
        
        Translates the harmonic frequency into its sacred message
        using the Native American Light Language alphabet.
        
        The market speaks through frequencies - this function
        tells us what it's saying!
        """
        # Medicine Wheel Direction Messages
        if 523 <= freq <= 533:  # 528 Hz - GREEN BORAX CENTER/EAST
            return "ü¶Ö EAST speaks: New beginnings arise. The Eagle soars at dawn. LOVE frequency activated. Green Borax blessing! üíö"
        
        if 391 <= freq <= 401:  # 396 Hz - SOUTH
            return "üê∫ SOUTH speaks: The Wolf runs free. Liberation from fear. Time to grow and break old chains."
        
        if 427 <= freq <= 437:  # 432 Hz - WEST  
            return "ü¶¨ WEST speaks: The Buffalo grazes at sunset. Harvest time approaches. Gather your abundance."
        
        if 958 <= freq <= 968:  # 963 Hz - NORTH
            return "üêª NORTH speaks: The Bear shares elder wisdom. Unity consciousness awakens. Trust the ancient knowing."
        
        # Solfeggio Messages
        if 169 <= freq <= 179:  # 174 Hz
            return "üèîÔ∏è Foundation frequency: Pain dissolves. Ground yourself in Mother Earth's embrace."
        
        if 280 <= freq <= 290:  # 285 Hz
            return "üåø Healing frequency: Tissues regenerate. The body remembers its wholeness."
        
        if 412 <= freq <= 422:  # 417 Hz
            return "üîÑ Change frequency: Old patterns release. Transformation is safe. Trust the process."
        
        if 634 <= freq <= 644:  # 639 Hz
            return "ü§ù Connection frequency: Relationships harmonize. Hearts open to receive and give."
        
        if 736 <= freq <= 746:  # 741 Hz
            return "üëÅÔ∏è Awakening frequency: Intuition sharpens. The third eye opens. See beyond the veil."
        
        if 847 <= freq <= 857:  # 852 Hz
            return "‚ú® Spiritual frequency: Return to divine order. The soul remembers its origin."
        
        # Schumann harmonics
        schumann_base = 7.83
        for harmonic in range(1, 128):
            if abs(freq - schumann_base * harmonic) <= 3:
                if harmonic <= 10:
                    return f"üåç Earth's heartbeat √ó{harmonic}: Mother Earth pulses beneath you. You are grounded and supported."
                elif harmonic <= 33:
                    return f"üåç Schumann √ó{harmonic}: Earth's rhythm accelerates. Root chakra activates. Stability in motion."
                elif harmonic <= 67:
                    return f"üåç Schumann √ó{harmonic}: High Earth harmonic. The planet sings a faster song. Energy rises."
                else:
                    return f"üåç Schumann √ó{harmonic}: Cosmic Earth frequency. Heaven and Earth merge."
        
        # Distortion warning
        if 435 <= freq <= 445:  # 440 Hz
            return "‚ö†Ô∏è DISTORTION detected: 440Hz artificial frequency. Discord in the field. Wait for harmony to return."
        
        # Band-based messages
        if freq < 200:
            return "üèîÔ∏è Deep Earth frequencies: Slow, ancient rhythms. Patience is the teaching."
        elif freq < 300:
            return "üå± Grounding frequencies: Roots grow deep. Stability before growth."
        elif 300 <= freq <= 399:
            return "üåü GOLDEN BAND: 98.8% accuracy zone! The ancestors smile upon this moment."
        elif freq < 500:
            return "üîÄ Transition frequencies: Between worlds. Change is happening."
        elif freq < 600:
            return "üíö Heart frequencies: Love resonates. The center holds."
        elif freq < 700:
            return "üó£Ô∏è Expression frequencies: Speak your truth. The throat chakra opens."
        elif freq < 800:
            return "üëÅÔ∏è Intuition frequencies: Vision clarifies. Trust what you see."
        elif freq < 900:
            return "üíú Insight frequencies: Crown chakra stirs. Higher guidance flows."
        elif freq < 1000:
            return "üëë Crown frequencies: Connection to Source. Receive the download."
        else:
            return "üå™Ô∏è CHAOS frequencies: Too fast, too hot. The market screams. Wait for calm."

    def _detect_wallet_currency(self):
        """Detect which currencies we actually have funds in"""
        if self.dry_run:
            return
            
        try:
            all_balances = self.client.get_all_balances()
            
            has_usd = False
            has_gbp = False
            has_eur = False
            has_btc = False
            has_eth = False
            
            for exchange, balances in all_balances.items():
                for asset, free in balances.items():
                    try:
                        if float(free) > 0.0001: # Min threshold
                            if asset in ['USD', 'ZUSD', 'USDT', 'USDC']: has_usd = True
                            if asset in ['GBP', 'ZGBP']: has_gbp = True
                            if asset in ['EUR', 'ZEUR']: has_eur = True
                            if asset in ['XBT', 'XXBT', 'BTC']: has_btc = True
                            if asset in ['ETH', 'XETH']: has_eth = True
                    except: continue
            
            # Update tradeable currencies based on holdings
            new_tradeables = []
            if has_usd: new_tradeables.extend(['USD', 'USDT', 'USDC'])
            if has_gbp: new_tradeables.append('GBP')
            if has_eur: new_tradeables.append('EUR')
            if has_btc: new_tradeables.extend(['XBT', 'BTC'])
            if has_eth: new_tradeables.append('ETH')
            
            if new_tradeables:
                self.tradeable_currencies = list(set(new_tradeables))
                print(f"   üí∞ Wallet detected: {self.tradeable_currencies}")
            
            # Set Base Currency for reporting
            if has_gbp: CONFIG['BASE_CURRENCY'] = 'GBP'
            elif has_eur: CONFIG['BASE_CURRENCY'] = 'EUR'
            elif has_usd: CONFIG['BASE_CURRENCY'] = 'USD'
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Wallet detection error: {e}")

    def _import_existing_holdings(self):
        """Import existing crypto holdings as managed positions.
        
        üîß ENHANCED: Now fetches REAL purchase prices from exchange trade history
        via CostBasisTracker to prevent selling at a loss.
        """
        if self.dry_run:
            return
        
        # üí∞ Always get cost tracker instance (for price lookups)
        cost_tracker = get_cost_basis_tracker()
        
        # SYNC REAL COST BASIS FROM EXCHANGES (can be skipped with env var)
        if os.getenv('SKIP_COST_SYNC', '0') != '1':
            print("\n   üí∞ Syncing real purchase prices from exchange history...")
            synced = cost_tracker.sync_from_exchanges()
            if synced > 0:
                print(f"   ‚úÖ Found real cost basis for {synced} positions")
        else:
            print("\n   ‚è≠Ô∏è Skipping cost basis sync (SKIP_COST_SYNC=1)")
            
        base = CONFIG['BASE_CURRENCY']
        try:
            all_balances = self.client.get_all_balances()
        except Exception as e:
            print(f"   ‚ö†Ô∏è Holdings import error: {e}")
            return
            
        imported = 0
        for exchange, balances in all_balances.items():
            for asset_raw, amount in balances.items():
                if not asset_raw:
                    continue
                try:
                    amount = float(amount)
                except:
                    amount = 0.0
                if amount <= 0:
                    continue
                    
                # üîß ASSET NORMALIZATION: Handle both Kraken and Binance special naming
                asset_clean = asset_raw.upper()
                
                if exchange == 'kraken':
                    # KRAKEN: Remove Z/X prefixes and map XBT‚ÜíBTC
                    # Kraken uses: XXBT for Bitcoin, XETH for Ethereum, ZUSD for USD, etc.
                    
                    # Remove Kraken's Z prefix (fiat currencies)
                    if asset_clean.startswith('Z') and len(asset_clean) > 1:
                        asset_clean = asset_clean[1:]
                    
                    # Remove Kraken's X prefix (crypto) - but handle XRP, XLM, XDG correctly
                    if asset_clean.startswith('XX'):  # XXBT, XXDG, XXLM, etc.
                        asset_clean = asset_clean[1:]  # XXBT ‚Üí XBT
                    elif asset_clean.startswith('X') and asset_clean not in ['XRP', 'XLM', 'XMR', 'XTZ']:
                        if len(asset_clean) > 3:  # XETH (4), XLTC (4) - likely Kraken prefix
                            asset_clean = asset_clean[1:]  # XETH ‚Üí ETH
                    
                    # Map Kraken's XBT to standard BTC
                    if asset_clean == 'XBT':
                        asset_clean = 'BTC'
                    elif asset_clean == 'XDG':
                        asset_clean = 'DOGE'
                        
                elif exchange == 'binance':
                    # BINANCE: Handle Earn products (LD prefix), staked assets, wrapped tokens
                    # LDBTC ‚Üí BTC, BETH ‚Üí ETH, BNSOL ‚Üí SOL, WBTC ‚Üí BTC, etc.
                    
                    # Remove LD prefix (Binance Earn/Flexible Savings)
                    if asset_clean.startswith('LD') and len(asset_clean) > 2:
                        asset_clean = asset_clean[2:]  # LDBTC ‚Üí BTC
                    
                    # Handle staked/wrapped variants
                    binance_asset_map = {
                        'BETH': 'ETH',      # Staked ETH 2.0
                        'BNSOL': 'SOL',     # Staked SOL
                        'WBTC': 'BTC',      # Wrapped BTC
                        'WETH': 'ETH',      # Wrapped ETH  
                        'WBNB': 'BNB',      # Wrapped BNB
                        'BTCB': 'BTC',      # BTC on BSC
                        'POL': 'MATIC',     # Polygon rebrand (keep as MATIC for trading pairs)
                    }
                    if asset_clean in binance_asset_map:
                        asset_clean = binance_asset_map[asset_clean]
                
                # Skip base currency (that's cash, not a position)
                if asset_clean in ['GBP', 'EUR', 'USD', 'USDT', 'USDC', 'BUSD', 'TUSD', 'FDUSD']:
                    continue
                    
                # Build the trading pair symbol
                # For Binance: BTCUSDT  
                # For Kraken: BTCUSDC, ETHUSDC, etc. (after normalization)
                # Try multiple quote currencies since we might have positions in different pairs
                
                symbol = None
                gbp_value = 0.0
                price = 0.0
                
                # üîß EXCHANGE-SPECIFIC QUOTE OPTIONS
                # Binance: USDC/USDT primary, EUR/GBP only for major coins
                # Kraken: USD/EUR/GBP widely supported
                BINANCE_EUR_GBP_SUPPORTED = {'BTC', 'ETH', 'BNB', 'XRP', 'ADA', 'SOL', 'DOT', 'DOGE', 'LTC', 'AVAX', 'LINK', 'SHIB', 'MATIC'}
                
                if exchange == 'binance':
                    # Binance: USDC/USDT are primary, EUR/GBP only for majors
                    quote_options = ['USDC', 'USDT', 'FDUSD']
                    if asset_clean in BINANCE_EUR_GBP_SUPPORTED:
                        quote_options.extend(['EUR', 'GBP'])
                elif exchange == 'kraken':
                    # Kraken: USD/EUR/GBP widely supported
                    quote_options = ['USD', 'USDC', 'EUR', 'GBP', 'XBT']
                else:
                    # Generic fallback
                    quote_options = ['USDC', 'USDT', 'USD']
                
                for quote in quote_options:
                    try_symbol = f"{asset_clean}{quote}"
                    
                    # Skip if already tracked
                    if try_symbol in self.positions:
                        symbol = None  # Already tracked
                        break
                    
                    # üö´ Skip if symbol is in invalid cache
                    if self._is_symbol_invalid(try_symbol):
                        continue
                    
                    try:
                        # Try to get ticker for this pair
                        ticker = self.client.get_ticker(exchange, try_symbol)
                        tick_price = ticker.get('price', 0) or ticker.get('last', 0) or ticker.get('c', 0)
                        if tick_price and float(tick_price) > 0:
                            symbol = try_symbol
                            price = float(tick_price)
                            gbp_value = amount * price
                            self._mark_symbol_valid(try_symbol, exchange)
                            print(f"   üìç Found valid pair: {symbol} @ ${price:.6f}")
                            break
                        else:
                            self._mark_symbol_invalid(try_symbol)
                    except:
                        self._mark_symbol_invalid(try_symbol)
                        continue
                
                if not symbol or gbp_value < 0.50:  # Skip dust < $0.50
                    continue
                
                # Skip if already tracked (double check)
                if symbol in self.positions:
                    continue
                
                # üí∞ TRY TO GET REAL COST BASIS FROM TRACKER
                real_entry_price = cost_tracker.get_entry_price(symbol)
                if real_entry_price and real_entry_price > 0:
                    entry_price = real_entry_price
                    entry_value = amount * entry_price
                    is_historical = False  # We have real data!
                    cost_source = "REAL"
                    print(f"   üí∞ {symbol}: Using REAL entry price ${entry_price:.6f} from trade history")
                else:
                    entry_price = price  # Fall back to current price
                    entry_value = gbp_value
                    is_historical = True  # No real data - treat as historical
                    cost_source = "CURRENT"
                    
                # Create position from existing holding
                # Use combined rate (fee + slippage + spread) to match penny profit formula
                fee_rate = get_platform_fee(exchange, 'taker')
                slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
                spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
                estimated_entry_fee = entry_value * (fee_rate + slippage + spread)
                
                self.positions[symbol] = Position(
                    symbol=symbol,
                    entry_price=entry_price,
                    quantity=amount,
                    entry_fee=estimated_entry_fee,
                    entry_value=entry_value,
                    momentum=0.0,
                    coherence=0.5,
                    entry_time=time.time(),
                    dominant_node='Portfolio',
                    exchange=exchange,
                    is_historical=is_historical
                )
                imported += 1
                
                # Show profit/loss status
                if cost_source == "REAL":
                    pnl_pct = ((price - entry_price) / entry_price * 100) if entry_price > 0 else 0
                    pnl_icon = "üü¢" if pnl_pct >= 0 else "üî¥"
                    print(f"   üì¶ Imported {symbol} ({exchange}): {amount:.6f} @ ¬£{entry_price:.4f} (now ¬£{price:.4f}) {pnl_icon} {pnl_pct:+.2f}%")
                else:
                    print(f"   üì¶ Imported {symbol} ({exchange}): {amount:.6f} @ ¬£{price:.4f} = ¬£{gbp_value:.2f} [HISTORICAL - no cost basis]")
            
        if imported > 0:
            print(f"   ‚úÖ Imported {imported} existing holdings as managed positions")
            print(f"   üí° Positions with REAL cost basis are protected from loss-making sales!")
        
        # üíº CAPITAL.COM CFD POSITIONS - Import open CFD positions
        try:
            capital_client = self.client.clients.get('capital')
            if capital_client and hasattr(capital_client.client, 'get_positions'):
                capital_positions = capital_client.client.get_positions()
                if capital_positions:
                    print(f"\n   üíº Importing {len(capital_positions)} Capital.com CFD positions...")
                    for cfd_pos in capital_positions:
                        try:
                            # Capital.com position structure
                            epic = cfd_pos.get('market', {}).get('epic') or cfd_pos.get('epic', '')
                            direction = cfd_pos.get('position', {}).get('direction') or cfd_pos.get('direction', 'BUY')
                            size = float(cfd_pos.get('position', {}).get('size') or cfd_pos.get('size', 0))
                            open_level = float(cfd_pos.get('position', {}).get('openLevel') or cfd_pos.get('openLevel', 0))
                            
                            if not epic or size <= 0:
                                continue
                            
                            # Skip if already tracked
                            if epic in self.positions:
                                continue
                            
                            # Get current price
                            current_price = open_level
                            try:
                                ticker = capital_client.client.get_ticker(epic)
                                current_price = ticker.get('price', open_level)
                            except:
                                pass
                            
                            # Calculate value
                            position_value = size * current_price
                            
                            # Use combined rate (fee + slippage + spread) to match penny profit formula
                            capital_fee = CONFIG.get('CAPITAL_FEE', 0.001)
                            slippage = CONFIG.get('SLIPPAGE_PCT', 0.002)
                            spread = CONFIG.get('SPREAD_COST_PCT', 0.001)
                            total_rate = capital_fee + slippage + spread
                            
                            # Create position
                            self.positions[epic] = Position(
                                symbol=epic,
                                entry_price=open_level,
                                quantity=size if direction == 'BUY' else -size,  # Negative for shorts
                                entry_fee=position_value * total_rate,
                                entry_value=position_value,
                                momentum=0.0,
                                coherence=0.5,
                                entry_time=time.time(),
                                dominant_node='Capital.com',
                                exchange='capital',
                                is_historical=False  # CFD positions have known entry
                            )
                            imported += 1
                            
                            pnl_pct = ((current_price - open_level) / open_level * 100) if open_level > 0 else 0
                            if direction == 'SELL':
                                pnl_pct = -pnl_pct  # Invert for shorts
                            pnl_icon = "üü¢" if pnl_pct >= 0 else "üî¥"
                            dir_icon = "üìà" if direction == 'BUY' else "üìâ"
                            print(f"   üíº {dir_icon} {epic}: {size} @ ¬£{open_level:.4f} ‚Üí ¬£{current_price:.4f} {pnl_icon} {pnl_pct:+.2f}%")
                            
                        except Exception as pos_err:
                            logger.debug(f"Could not import Capital.com position: {pos_err}")
                            
                    if imported > 0:
                        print(f"   ‚úÖ Imported Capital.com CFD positions")
        except Exception as cap_err:
            logger.debug(f"Capital.com position import skipped: {cap_err}")
        
        # ü¶ô ALPACA POSITIONS - Import crypto and stock positions with real entry prices
        try:
            alpaca_client = self.client.clients.get('alpaca')
            if alpaca_client and hasattr(alpaca_client.client, 'get_positions'):
                alpaca_positions = alpaca_client.client.get_positions()
                if alpaca_positions:
                    print(f"\n   ü¶ô Importing {len(alpaca_positions)} Alpaca positions...")
                    for alp_pos in alpaca_positions:
                        try:
                            # Alpaca position structure
                            symbol_raw = alp_pos.get('symbol', '')
                            # Convert BTC/USD -> BTCUSD
                            symbol = symbol_raw.replace('/', '')
                            qty = float(alp_pos.get('qty', 0))
                            avg_entry = float(alp_pos.get('avg_entry_price', 0))
                            current_price = float(alp_pos.get('current_price', 0))
                            market_value = float(alp_pos.get('market_value', 0))
                            unrealized_pl = float(alp_pos.get('unrealized_pl', 0))
                            side = alp_pos.get('side', 'long')
                            asset_class = alp_pos.get('asset_class', 'crypto')
                            
                            if not symbol or qty <= 0:
                                continue
                            
                            # Skip if already tracked
                            if symbol in self.positions:
                                continue
                            
                            # Use combined rate (fee + slippage + spread) to match penny profit formula
                            alpaca_fee = CONFIG.get('ALPACA_FEE', 0.0025)
                            slippage = CONFIG.get('SLIPPAGE_PCT', 0.002)
                            spread = CONFIG.get('SPREAD_COST_PCT', 0.001)
                            total_rate = alpaca_fee + slippage + spread
                            entry_value = qty * avg_entry
                            
                            # Create position
                            self.positions[symbol] = Position(
                                symbol=symbol,
                                entry_price=avg_entry,
                                quantity=qty if side == 'long' else -qty,
                                entry_fee=entry_value * total_rate,
                                entry_value=entry_value,
                                momentum=0.0,
                                coherence=0.5,
                                entry_time=time.time(),
                                dominant_node='Alpaca',
                                exchange='alpaca',
                                is_historical=False  # Alpaca has real entry prices
                            )
                            imported += 1
                            
                            pnl_pct = ((current_price - avg_entry) / avg_entry * 100) if avg_entry > 0 else 0
                            if side == 'short':
                                pnl_pct = -pnl_pct
                            pnl_icon = "üü¢" if pnl_pct >= 0 else "üî¥"
                            asset_icon = "ü™ô" if asset_class == 'crypto' else "üìä"
                            print(f"   ü¶ô {asset_icon} {symbol}: {qty} @ ${avg_entry:.4f} ‚Üí ${current_price:.4f} {pnl_icon} {pnl_pct:+.2f}% (${unrealized_pl:+.2f})")
                            
                        except Exception as pos_err:
                            logger.debug(f"Could not import Alpaca position: {pos_err}")
                            
                    if imported > 0:
                        print(f"   ‚úÖ Imported Alpaca positions")
        except Exception as alp_err:
            logger.debug(f"Alpaca position import skipped: {alp_err}")
    
    def _liquidate_historical_for_opportunity(self, needed_cash: float, target_exchange: str, target_symbol: str) -> float:
        """üîÑ Liquidate historical assets OR big losers to free up cash for better opportunities.
        
        üî• AGGRESSIVE MODE: Also includes positions with >50% loss as "dead capital"
        Only sells if:
        1. Position is truly historical (no known cost basis), OR
        2. Position would be sold at a profit, OR
        3. Position is down >50% (dead capital - cut losses!)
        
        Returns: Amount of cash freed up
        """
        if self.dry_run:
            return 0.0
        
        # üí∞ Get cost basis tracker for profit checks
        cost_tracker = get_cost_basis_tracker()
            
        freed_cash = 0.0
        
        # üî• INCLUDE BIG LOSERS: Find positions down >50% as candidates for liquidation
        big_loser_candidates = []
        print(f"   üîç Scanning {len(self.positions)} positions for big losers (>50% down)...")
        for sym, pos in self.positions.items():
            # Don't filter by exchange for big losers - we want to cut ANY dead capital
            try:
                ticker = self.client.get_ticker(pos.exchange, sym)
                curr_price = float(ticker.get('price', 0) or ticker.get('last', 0) or ticker.get('c', 0))
                if curr_price > 0 and pos.entry_price > 0:
                    pnl_pct = (curr_price - pos.entry_price) / pos.entry_price * 100
                    if pnl_pct < -50:  # Down more than 50%
                        print(f"      üî• Found big loser: {sym} @ {pnl_pct:.1f}%")
                        big_loser_candidates.append((sym, pos, pnl_pct, curr_price))
            except Exception as e:
                pass
        
        # Sort by biggest loser first (most negative PnL)
        big_loser_candidates.sort(key=lambda x: x[2])
        
        historical_positions = [
            (sym, pos) for sym, pos in self.positions.items() 
            if pos.is_historical and pos.exchange == target_exchange
        ]
        
        if not historical_positions:
            # Try other exchanges too
            historical_positions = [
                (sym, pos) for sym, pos in self.positions.items() 
                if pos.is_historical
            ]
        
        # üî• SELL BIG LOSERS FIRST - they're dead capital!
        if big_loser_candidates and freed_cash < needed_cash:
            print(f"\n   üî• CUTTING LOSSES: Found {len(big_loser_candidates)} positions down >50%")
            for sym, pos, pnl_pct, curr_price in big_loser_candidates:
                if freed_cash >= needed_cash:
                    break
                    
                available_qty = pos.quantity
                if available_qty <= 0:
                    continue
                current_value = available_qty * curr_price
                
                if current_value < 0.50:  # Skip dust
                    continue
                    
                dust_reason = self._is_symbol_dust(sym)
                if dust_reason:
                    print(f"   üí§ Skipping {sym} - marked dust: {dust_reason}")
                    continue
                    
                if self._is_symbol_invalid(sym):
                    continue
                
                sell_qty, block_reason, adj_note = self._prepare_liquidation_quantity(
                    pos.exchange, sym, available_qty, curr_price
                )
                if sell_qty is None:
                    reason = block_reason or "LOT_SIZE constraint"
                    self._mark_symbol_dust(sym, reason)
                    print(f"   üí§ Skipping {sym}: {reason}")
                    continue
                
                current_value = sell_qty * curr_price
                if current_value < 0.50:
                    continue

                print(f"   üî• CUTTING LOSS {sym}: {pnl_pct:.1f}% down - selling {sell_qty:.6f} @ ¬£{curr_price:.4f} = ¬£{current_value:.2f}")
                
                try:
                    res = self.client.place_market_order(pos.exchange, sym, 'SELL', quantity=sell_qty)
                    
                    if isinstance(res, dict) and not res.get('rejected') and res.get('status') not in ['REJECTED', 'FAILED', None]:
                        net_value = current_value * 0.998
                        freed_cash += net_value
                        pos.quantity = max(pos.quantity - sell_qty, 0.0)
                        if pos.quantity <= 1e-12:
                            self.positions.pop(sym, None)
                        else:
                            pos.entry_value = pos.quantity * curr_price
                        self._clear_symbol_dust(sym)
                        print(f"   ‚úÖ CUT LOSS {sym} - freed ¬£{net_value:.2f} (was {pnl_pct:.1f}% down)")
                        
                        # üß† PUBLISH THOUGHT: HARVESTING DEAD CAPITAL üß†
                        if THOUGHT_BUS_AVAILABLE and THOUGHT_BUS:
                            THOUGHT_BUS.publish(Thought(
                                source="harvester",
                                topic="execution.harvest.dead_capital",
                                payload={
                                    "symbol": sym,
                                    "action": "SELL",
                                    "reason": "DEAD_CAPITAL_CUT",
                                    "pnl_pct": pnl_pct,
                                    "freed_cash": net_value
                                }
                            ))
                    else:
                        self._mark_symbol_invalid(sym)
                        print(f"   ‚ö†Ô∏è Failed to cut {sym}")
                except Exception as e:
                    self._mark_symbol_invalid(sym)
                    print(f"   ‚ö†Ô∏è Error cutting {sym}: {e}")
        
        if not historical_positions and freed_cash >= needed_cash:
            return freed_cash
            
        if not historical_positions:
            return freed_cash
            
        # Sort by value (smallest first to minimize market impact)
        historical_positions.sort(key=lambda x: x[1].entry_value)
        
        print(f"\n   üîÑ LIQUIDATING HISTORICAL ASSETS for {target_symbol}")
        print(f"   üí∞ Need ¬£{needed_cash:.2f} - found {len(historical_positions)} historical positions")
        
        for sym, pos in historical_positions:
            if freed_cash >= needed_cash:
                break
                
            # Get current price
            try:
                ticker = self.client.get_ticker(pos.exchange, sym)
                curr_price = float(ticker.get('price', 0) or ticker.get('last', 0) or ticker.get('c', 0))
                if curr_price <= 0:
                    continue
            except:
                continue
            
            # üí∞ CHECK IF SALE WOULD BE PROFITABLE OR ACCEPTABLE LOSS
            can_sell, profit_info = cost_tracker.can_sell_profitably(sym, curr_price, pos.quantity)
            if not can_sell and profit_info.get('entry_price'):
                # We have cost basis and it would be a loss
                loss = profit_info.get('potential_loss', 0)
                pnl_pct = profit_info.get('profit_pct', 0)
                
                # üî• AGGRESSIVE MODE: Allow selling big losers (>50% down) to free capital
                # These positions are "dead money" - better to cut losses and redeploy
                if pnl_pct > -50.0:  # Only protect if loss is less than 50%
                    print(f"   üõë PROTECTING {sym}: Would lose ¬£{loss:.2f} ({pnl_pct:.1f}%) - skipping")
                    continue
                else:
                    print(f"   üî• CUTTING LOSSES {sym}: {pnl_pct:.1f}% down - freeing dead capital!")
                
            available_qty = pos.quantity
            if available_qty <= 0:
                continue
            current_value = available_qty * curr_price
            
            # Don't liquidate dust (less than ¬£0.50) - wastes time on LOT_SIZE errors
            DUST_THRESHOLD = 0.50
            if current_value < DUST_THRESHOLD:
                continue
            
            dust_reason = self._is_symbol_dust(sym)
            if dust_reason:
                print(f"   üí§ Skipping {sym} - marked dust: {dust_reason}")
                continue
            
            # Skip symbols that have repeatedly failed LOT_SIZE (can't be sold in current qty)
            if self._is_symbol_invalid(sym):
                continue
            
            sell_qty, block_reason, adj_note = self._prepare_liquidation_quantity(
                pos.exchange, sym, available_qty, curr_price
            )
            if sell_qty is None:
                reason = block_reason or "LOT_SIZE constraint"
                self._mark_symbol_dust(sym, reason)
                print(f"   üí§ Skipping {sym}: {reason}")
                continue
            
            current_value = sell_qty * curr_price
            if current_value < DUST_THRESHOLD:
                reason = f"value ¬£{current_value:.2f} below dust floor"
                self._mark_symbol_dust(sym, reason)
                print(f"   üí§ Skipping {sym}: {reason}")
                continue

            # üß† PUBLISH THOUGHT: HARVESTING HISTORICAL ASSET üß†
            if THOUGHT_BUS_AVAILABLE and THOUGHT_BUS:
                THOUGHT_BUS.publish(Thought(
                    source="harvester",
                    topic="execution.harvest.historical",
                    payload={
                        "symbol": sym,
                        "action": "SELL",
                        "reason": "FUNDING_OPPORTUNITY",
                        "target_symbol": target_symbol,
                        "value": current_value
                    }
                ))

            print(f"   üì¶‚Üíüíµ Selling {sym}: {sell_qty:.6f} @ ¬£{curr_price:.4f} = ¬£{current_value:.2f}")
            if adj_note:
                print(f"      ‚Ü≥ {adj_note}")
            
            try:
                # Execute sell - use quantity parameter (not base_qty)
                res = self.client.place_market_order(pos.exchange, sym, 'SELL', quantity=sell_qty)
                
                if isinstance(res, dict) and not res.get('rejected') and res.get('status') not in ['REJECTED', 'FAILED', None]:
                    net_value = current_value * 0.998  # Account for fees
                    freed_cash += net_value
                    pos.quantity = max(pos.quantity - sell_qty, 0.0)
                    if pos.quantity <= 1e-12:
                        self.positions.pop(sym, None)
                    else:
                        pos.entry_value = pos.quantity * curr_price
                    self._clear_symbol_dust(sym)
                    print(f"   ‚úÖ Liquidated {sym} - freed ¬£{net_value:.2f}")
                    if pos.quantity > 0:
                        print(f"      ‚Ü™Ô∏è Remaining {sym}: {pos.quantity:.6f} (unsellable remainder)")
                else:
                    # Failed - blacklist to stop retry spam
                    self._mark_symbol_invalid(sym)
                    print(f"   ‚ö†Ô∏è Failed to liquidate {sym} - blacklisted for 1hr")
            except Exception as e:
                err_msg = str(e)
                # Mark as invalid for any liquidation error - stop retry spam
                self._mark_symbol_invalid(sym)
                if 'LOT_SIZE' in err_msg or '-1013' in err_msg:
                    self._mark_symbol_dust(sym, 'LOT_SIZE rejection')
                    print(f"   ‚ö†Ô∏è {sym} LOT_SIZE fail - blacklisted for 1hr")
                else:
                    print(f"   ‚ö†Ô∏è Error liquidating {sym}: {e} - blacklisted for 1hr")
                continue
        
        if freed_cash > 0:
            print(f"   üí∞ Total freed: ¬£{freed_cash:.2f}")
            self.refresh_equity()  # Update balances
            
        return freed_cash
    
    def _build_scout_candidates(self) -> List[Dict]:
        """‚òòÔ∏è Build candidate list from ALL 4 BATTLEFRONTS for Irish Patriot deployment.

        Returns list of candidates with:
        - symbol, price, change24h, volume, score
        - coherence, dominant_node, quote_currency, source (exchange)
        
        üè¥‚öîÔ∏è MULTI-BATTLEFIELD MODE: Scouts deployed across:
        - Binance (crypto)
        - Kraken (crypto) 
        - Capital.com (forex/indices/commodities - NO crypto!)
        - Alpaca (stocks - if enabled)
        """
        battlefields = CONFIG.get('BATTLEFIELDS', {})
        multi_battlefield_mode = CONFIG.get('MULTI_BATTLEFIELD_MODE', True)
        quote_currencies = CONFIG.get('QUOTE_CURRENCIES', ['USD', 'USDT', 'GBP', 'EUR'])
        min_vol = CONFIG.get('SCOUT_MIN_VOLATILITY', 1.5)
        min_vol_q = CONFIG.get('SCOUT_MIN_VOLUME_QUOTE', 100000)

        all_candidates = []
        
        # üçÑ Get ALL positions across ALL exchanges to prevent duplicates
        all_open_symbols = set(self.positions.keys())
        if CONFIG.get('PREVENT_DUPLICATE_POSITIONS', True):
            # Normalize symbols for cross-exchange comparison (BTCUSDT on Binance = XBTUSDT on Kraken)
            normalized_positions = set()
            for sym in all_open_symbols:
                # Normalize: remove exchange prefixes, convert XBT‚ÜíBTC etc
                norm = sym.upper().replace('XBT', 'BTC').lstrip('X').lstrip('Z')
                normalized_positions.add(norm)
        else:
            normalized_positions = all_open_symbols
            
        print(f"   üçÑ Mycelium tracking {len(all_open_symbols)} positions across all battlefields")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # PHASE 1: Gather candidates from ticker cache (Binance & Kraken via WebSocket)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        for quote_curr in quote_currencies:
            for symbol, data in self.ticker_cache.items():
                if not symbol.endswith(quote_curr):
                    continue
                    
                # üçÑ ANTI-DUPLICATE: Check normalized symbol across all exchanges
                norm_sym = symbol.upper().replace('XBT', 'BTC').lstrip('X').lstrip('Z')
                if norm_sym in normalized_positions or symbol in self.positions:
                    continue
                    
                source = data.get('source', '').lower()
                
                # Check if this battlefield is enabled
                if multi_battlefield_mode and source in battlefields:
                    bf_config = battlefields[source]
                    if not bf_config.get('enabled', False):
                        continue
                
                change = data.get('change24h', 0)
                price = data.get('price', 0)
                volume = data.get('volume', 0)

                # Need real movement and liquidity
                if price <= 0 or volume <= 0:
                    continue
                if abs(change) < min_vol:
                    continue
                if volume < min_vol_q:
                    continue

                # Opportunity score: |volatility| √ó volume (in millions)
                volume_m = max(volume / 1_000_000, 0.001)
                lion_score = abs(change) * volume_m * 100

                all_candidates.append({
                    'symbol': symbol,
                    'price': price,
                    'change24h': change,
                    'volume': volume,
                    'score': lion_score,
                    'coherence': 0.65,
                    'dominant_node': 'PatriotScout',
                    'quote_currency': quote_curr,
                    'source': source,
                    'battlefield': source  # üè¥ Track which front this scout is for
                })

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # PHASE 2: Add Capital.com CFD candidates (forex, indices, commodities)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if multi_battlefield_mode and battlefields.get('capital', {}).get('enabled', True):
            try:
                if hasattr(self, 'client') and hasattr(self.client, 'clients'):
                    capital_client = self.client.clients.get('capital')
                    if capital_client:
                        # Capital.com specific symbols for forex/indices/commodities
                        capital_symbols = [
                            # Forex majors
                            'EURUSD', 'GBPUSD', 'USDJPY', 'AUDUSD', 'USDCAD', 'NZDUSD', 'USDCHF',
                            # Indices
                            'US500', 'UK100', 'GER40', 'US30', 'USTEC',
                            # Commodities
                            'XAUUSD', 'XAGUSD', 'UKOIL', 'USOIL', 'NATGAS'
                        ]
                        for sym in capital_symbols:
                            norm_sym = sym.upper()
                            if norm_sym in normalized_positions:
                                continue
                            try:
                                snapshot = capital_client.get_market_snapshot(sym)
                                if snapshot and snapshot.get('price'):
                                    price = float(snapshot.get('price', 0))
                                    change = float(snapshot.get('change_pct', 0))
                                    if price > 0:
                                        all_candidates.append({
                                            'symbol': sym,
                                            'price': price,
                                            'change24h': change,
                                            'volume': 1000000,  # CFD has unlimited liquidity
                                            'score': 60 + abs(change) * 5,  # CFD scoring
                                            'coherence': 0.60,
                                            'dominant_node': 'PatriotScout_CFD',
                                            'quote_currency': 'USD' if 'USD' in sym else 'GBP',
                                            'source': 'capital',
                                            'battlefield': 'capital',
                                            'asset_class': 'cfd'
                                        })
                            except Exception:
                                continue
            except Exception as e:
                logger.debug(f"Capital.com scout scan skipped: {e}")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # PHASE 3: Add Alpaca stock candidates (if enabled)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if multi_battlefield_mode and battlefields.get('alpaca', {}).get('enabled', False):
            try:
                if hasattr(self, 'client') and hasattr(self.client, 'clients'):
                    alpaca_client = self.client.clients.get('alpaca')
                    if alpaca_client:
                        # Popular US stocks for scouting
                        stock_symbols = [
                            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA',
                            'AMD', 'INTC', 'CRM', 'NFLX', 'COIN', 'MARA', 'RIOT'
                        ]
                        for sym in stock_symbols:
                            if sym in normalized_positions:
                                continue
                            try:
                                quote = alpaca_client.get_quote(sym) if hasattr(alpaca_client, 'get_quote') else None
                                if quote:
                                    price = float(quote.get('price') or quote.get('last', 0))
                                    change = float(quote.get('change_pct', 0))
                                    if price > 0:
                                        all_candidates.append({
                                            'symbol': sym,
                                            'price': price,
                                            'change24h': change,
                                            'volume': 500000,  # Stock default volume
                                            'score': 55 + abs(change) * 4,
                                            'coherence': 0.55,
                                            'dominant_node': 'PatriotScout_Stock',
                                            'quote_currency': 'USD',
                                            'source': 'alpaca',
                                            'battlefield': 'alpaca',
                                            'asset_class': 'stocks'
                                        })
                            except Exception:
                                continue
            except Exception as e:
                logger.debug(f"Alpaca scout scan skipped: {e}")

        # If nothing passed the strict filters, relax to ensure market coverage
        if not all_candidates:
            print("   ‚ö†Ô∏è No scout candidates met volatility/volume thresholds - relaxing filters for coverage")

            for quote_curr in quote_currencies:
                for symbol, data in self.ticker_cache.items():
                    if not symbol.endswith(quote_curr):
                        continue
                    if symbol in self.positions:
                        continue

                    price = data.get('price', 0)
                    volume = data.get('volume', 0)
                    change = data.get('change24h', 0)

                    # Require tradable price/volume but allow calmer markets
                    if price <= 0 or volume <= 0:
                        continue

                    volume_m = max(volume / 1_000_000, 0.001)
                    lion_score = max(abs(change), 0.1) * volume_m * 100

                    all_candidates.append({
                        'symbol': symbol,
                        'price': price,
                        'change24h': change,
                        'volume': volume,
                        'score': lion_score,
                        'coherence': 0.60,
                        'dominant_node': 'PatriotScout',
                        'quote_currency': quote_curr,
                        'source': data.get('source', '').lower(),
                        'battlefield': data.get('source', 'binance').lower(),
                        'war_go': True  # Always allow relaxed candidates to deploy if needed
                    })

            # Prioritise by volume even in relaxed mode
            all_candidates.sort(key=lambda x: -x.get('volume', 0))

        # Sort by score descending
        all_candidates.sort(key=lambda x: -x.get('score', 0))
        
        # üè¥ Log battlefield distribution
        if all_candidates:
            bf_counts = {}
            for c in all_candidates[:50]:  # Top 50
                bf = c.get('battlefield', 'unknown')
                bf_counts[bf] = bf_counts.get(bf, 0) + 1
            print(f"   ‚öîÔ∏è Scout candidates by battlefield: {bf_counts}")
            
        return all_candidates
    
    def _turbo_hunt_90_percent(self) -> List[Dict]:
        """
        üéØ‚ö° TURBO HUNTER - Actively seek 90%+ win rate opportunities ‚ö°üéØ
        [VERIFIED ACTIVE: Mycelium & Brain Integrated]
        
        The system KNOWS which conditions win:
        - 256_ROOT frequency = 100% WR (9/9 trades)
        - Hour 14-15 UTC = 90%+ WR
        - High coherence + winning frequency = 95%+ WR
        
        This hunter PROACTIVELY finds opportunities in winning conditions
        and executes IMMEDIATELY - no gates, no delays, just penny profit!
        
        Returns list of "elite" opportunities ready for immediate execution.
        """
        from datetime import datetime
        
        elite_opportunities = []
        current_hour = datetime.now().hour
        
        # Check if we're in a WINNING window
        winning_hours = CONFIG.get('WINNING_HOURS', [14, 15, 19, 0])
        losing_hours = CONFIG.get('LOSING_HOURS', [16, 17, 23, 1])
        winning_freqs = CONFIG.get('WINNING_FREQUENCIES', ['256_ROOT', '174_FOUNDATION', '528_LOVE'])
        losing_freqs = CONFIG.get('LOSING_FREQUENCIES', ['432_NATURAL', '440_DISTORTION'])
        
        is_winning_hour = current_hour in winning_hours
        is_losing_hour = current_hour in losing_hours
        
        # Get actual historical win rates
        hour_metrics = ADAPTIVE_LEARNER.metrics_by_hour.get(current_hour, {})
        hour_total = hour_metrics.get('wins', 0) + hour_metrics.get('losses', 0)
        hour_wr = hour_metrics.get('wins', 0) / hour_total if hour_total > 0 else 0.5
        
        # üö´ Don't hunt in proven losing hours
        if is_losing_hour and hour_total >= 3 and hour_wr < 0.35:
            print(f"   üö´ TURBO HUNT: Hour {current_hour}:00 is a loser ({hour_wr*100:.0f}% WR) - WAITING")
            return []
        
        # Known default win rates from historical data analysis:
        # 256_ROOT = 100% (9/9), 432_NATURAL = 18% (3/17)
        DEFAULT_FREQ_WR = {
            '256_ROOT': 0.95,        # Known winner!
            '174_FOUNDATION': 0.85,  # Sacred frequency
            '528_LOVE': 0.85,        # Love frequency
            '396_LIBERATION': 0.70,  # Good
            '639_CONNECTION': 0.65,  # Decent
            '432_NATURAL': 0.20,     # Known LOSER
            '440_DISTORTION': 0.15,  # Worst
        }
        
        # üéØ HUNTING MODE - Look for elite setups
        if not self.ticker_cache:
            return []
            
        # üíì HEARTBEAT: Prove we are hunting (Log once per minute roughly)
        if int(time.time()) % 60 < 5:
             print(f"   ‚ö° TURBO HUNTER: Scanning {len(self.ticker_cache)} assets for 90%+ setups...")

        hunt_count = 0
        for symbol, data in self.ticker_cache.items():
            # Skip if already positioned
            if symbol in self.positions:
                continue
                
            # Skip if elephant memory says avoid
            if self.elephant_memory.should_avoid(symbol):
                continue
                
            price = data.get('price', 0)
            change = data.get('change24h', 0)
            volume = data.get('volume', 0)
            
            # Basic sanity
            if price < 0.0001 or volume < 10000:
                continue
                
            # Get HNC frequency for this asset (default to winning 256)
            hnc_freq = self.asset_frequencies.get(symbol, {}).get('frequency', 256)
            freq_band = ADAPTIVE_LEARNER._get_frequency_band(hnc_freq)
            
            # Check frequency band win rate - USE KNOWN DEFAULTS if no data!
            freq_metrics = ADAPTIVE_LEARNER.metrics_by_frequency.get(freq_band, {})
            freq_total = freq_metrics.get('wins', 0) + freq_metrics.get('losses', 0)
            if freq_total >= 3:
                freq_wr = freq_metrics.get('wins', 0) / freq_total
            else:
                # Use known defaults from historical analysis
                freq_wr = DEFAULT_FREQ_WR.get(freq_band, 0.50)
            
            # üö´ Skip KNOWN losing frequencies immediately
            if freq_band in losing_freqs:
                continue
                
            # Calculate expected win rate
            expected_wr = freq_wr  # Start with frequency WR
            
            # BOOST for winning hour
            if is_winning_hour:
                expected_wr = min(0.99, expected_wr * 1.10)  # 10% boost in winning hours
                
            # BOOST for winning frequency
            if freq_band in winning_freqs:
                expected_wr = min(0.99, expected_wr * 1.05)  # 5% boost for known winners
                
            # üéØ ELITE THRESHOLD: Only take 85%+ expected WR
            min_hunt_wr = CONFIG.get('TURBO_HUNT_MIN_WR', 0.85)
            if expected_wr >= min_hunt_wr:
                hunt_count += 1
                
                # Build elite opportunity
                prices = self.price_history.get(symbol, [price])
                state = MarketState(
                    symbol=symbol, price=price,
                    bid=price * 0.999, ask=price * 1.001,
                    volume=volume, change_24h=change,
                    high_24h=price * 1.02, low_24h=price * 0.98,
                    prices=prices[-20:], timestamp=time.time()
                )
                coherence, dominant_node = self.auris.compute_coherence(state)
                
                # üçÑ WIRE TO MYCELIUM: Inject signal into the network!
                # This ensures the Mycelium is aware of this elite opportunity
                if self.mycelium:
                    self.mycelium.add_signal(symbol, coherence)
                
                elite_opp = {
                    'symbol': symbol,
                    'price': price,
                    'change24h': change,
                    'volume': volume,
                    'coherence': coherence,
                    'dominant_node': dominant_node,
                    'score': 95,  # Elite score
                    'source': data.get('source', 'kraken'),
                    'hnc_frequency': hnc_freq,
                    'expected_win_rate': expected_wr,
                    'turbo_hunt': True,  # Flag for logging
                    'hunt_reason': f"WR={expected_wr*100:.0f}% | Hour={current_hour} | Freq={freq_band}"
                }
                
                elite_opportunities.append(elite_opp)
                
                if hunt_count <= 5:
                    print(f"   üéØ ELITE: {symbol} | {elite_opp['hunt_reason']}")
                    
        # Sort by expected win rate (highest first)
        elite_opportunities.sort(key=lambda x: x.get('expected_win_rate', 0), reverse=True)
        
        if elite_opportunities:
            print(f"   ‚ö° TURBO HUNT: {len(elite_opportunities)} elite opportunities found!")
            
            # üçÑ MYCELIUM INJECTION: Tell the network about these elite finds!
            # This ensures Harvester, Sniper, and Brain are all aware
            try:
                if self.mycelium:
                    for elite in elite_opportunities[:3]:
                        self.mycelium.add_signal(elite['symbol'], elite['coherence'])
                        # Propagate high probability to wake up the hive
                        self.mycelium.propagate({elite['symbol']: 0.95})
                        print(f"   üçÑ Mycelium notified: {elite['symbol']} is a TURBO TARGET")
            except Exception as e:
                logger.warning(f"Mycelium injection failed: {e}")
                
            # üß† BRAIN INJECTION: Publish thought to wake up consciousness
            try:
                if THOUGHT_BUS_AVAILABLE and THOUGHT_BUS:
                    THOUGHT_BUS.publish(Thought(
                        source="turbo_hunter",
                        topic="opportunity.elite_found",
                        payload={
                            "count": len(elite_opportunities),
                            "top_symbol": elite_opportunities[0]['symbol'],
                            "win_rate": elite_opportunities[0]['expected_win_rate']
                        }
                    ))
            except Exception:
                pass

            # Return top 3 for immediate execution
            return elite_opportunities[:3]
        elif is_winning_hour:
            print(f"   ‚è∞ Hour {current_hour}:00 is WINNING but no elite setups ready yet")
            
        return []
    
    def _get_gaia_reclaimer_signal(self) -> Dict[str, Optional[float]]:
        """Extract coherence/bias from Gaia Planetary Reclaimer if available."""
        try:
            state = self.gaia_reclaimer.get_state()
        except Exception:
            return {"coherence": None, "risk_bias": None}
        coherence = state.get("coherence")
        if coherence is None:
            coherence = state.get("gaia_coherence", state.get("signal_coherence"))
        risk_bias = state.get("risk_bias")
        if risk_bias is None:
            risk_bias = state.get("signal_bias", state.get("frequency_bias"))
        return {"coherence": coherence, "risk_bias": risk_bias}

    def _sync_queen_external_state(self, lattice_state: Any) -> None:
        """Propagate lattice/HNC/pulse signals into the Queen decision system."""
        if not self.mycelium:
            return
        now = time.time()
        if (now - self._queen_sync_last) < self._queen_sync_interval:
            return

        # Gaia lattice metrics
        risk_mod = 1.0
        field_purity = 0.5
        try:
            metrics = self.lattice.get_gaia_metrics()
            risk_mod = float(metrics.get("risk_mod", 1.0))
            field_purity = float(metrics.get("field_purity", 0.5))
        except Exception:
            try:
                risk_mod = lattice_state.get("risk_mod", 1.0) if isinstance(lattice_state, dict) else getattr(lattice_state, "risk_mod", 1.0)
                field_purity = lattice_state.get("field_purity", 0.5) if isinstance(lattice_state, dict) else getattr(lattice_state, "field_purity", 0.5)
            except Exception:
                risk_mod = 1.0
                field_purity = 0.5

        lattice_bias = max(-0.4, min(0.4, (risk_mod - 1.0) * 0.5))

        # HNC frequency + coherence
        hnc_frequency = getattr(self.auris, "hnc_frequency", 256.0)
        hnc_coherence = getattr(self.auris, "hnc_coherence", 0.5)
        hnc_is_harmonic = getattr(self.auris, "hnc_is_harmonic", False)

        frequency_bias = 0.0
        if 435 <= hnc_frequency <= 445:
            frequency_bias -= 0.2
        elif hnc_is_harmonic:
            frequency_bias += 0.1

        # Market pulse sentiment
        pulse_bias = 0.0
        sentiment_label = "Neutral"
        try:
            if (now - self._last_pulse_ts) > 60:
                self._last_pulse_snapshot = self.market_pulse.analyze_market()
                self._last_pulse_ts = now
            sentiment_label = self._last_pulse_snapshot.get("crypto_sentiment", {}).get("label", "Neutral")
            pulse_bias = {
                "Very Bullish": 0.15,
                "Bullish": 0.08,
                "Bearish": -0.08,
                "Very Bearish": -0.15,
            }.get(sentiment_label, 0.0)
        except Exception:
            pulse_bias = 0.0

        combined_bias = max(-0.5, min(0.5, lattice_bias + frequency_bias + pulse_bias))
        combined_coherence = max(0.0, min(1.0, (field_purity + hnc_coherence) / 2))

        self.gaia_reclaimer.update_signal(
            source="lattice",
            coherence=field_purity,
            risk_bias=lattice_bias,
            payload={"risk_mod": risk_mod},
        )
        self.gaia_reclaimer.update_signal(
            source="hnc",
            coherence=hnc_coherence,
            risk_bias=frequency_bias,
            payload={"frequency": hnc_frequency, "is_harmonic": hnc_is_harmonic},
        )
        self.gaia_reclaimer.update_signal(
            source="market_pulse",
            coherence=combined_coherence,
            risk_bias=pulse_bias,
            payload={"sentiment_label": sentiment_label},
        )

        reclaimer_signal = self._get_gaia_reclaimer_signal()
        if reclaimer_signal.get("risk_bias") is not None:
            combined_bias = max(-0.5, min(0.5, combined_bias + float(reclaimer_signal["risk_bias"])))
        if reclaimer_signal.get("coherence") is not None:
            combined_coherence = max(0.0, min(1.0, (combined_coherence + float(reclaimer_signal["coherence"])) / 2))

        self.mycelium.update_external_state(
            coherence=combined_coherence,
            risk_bias=combined_bias,
            source="lattice_hnc",
        )
        self._queen_sync_last = now

        if THOUGHT_BUS_AVAILABLE and THOUGHT_BUS:
            try:
                THOUGHT_BUS.publish(Thought(
                    source="queen_sync",
                    topic="mycelium.external_state",
                    payload={
                        "coherence": combined_coherence,
                        "risk_bias": combined_bias,
                        "hnc_frequency": hnc_frequency,
                        "hnc_coherence": hnc_coherence,
                        "field_purity": field_purity,
                        "reclaimer_coherence": reclaimer_signal.get("coherence"),
                        "reclaimer_bias": reclaimer_signal.get("risk_bias"),
                    },
                ))
            except Exception:
                pass

    def _deploy_scouts(self):
        """üöÄ‚òòÔ∏è FORCE DEPLOY scout positions immediately on first scan!
        
        Philosophy: "They can't stop them all!" - Get positions deployed FAST
        No sitting on the fence - HIT THE GROUND RUNNING!
        
        üáÆüá™ NOW WITH IRISH PATRIOT SCOUTS - Celtic-trained warriors with:
        - Guerrilla warfare intelligence
        - Preemptive strike capability
        - Multi-battlefront coordination
        - War strategy quick kill analysis
        
        üè¥‚öîÔ∏è 4 BATTLEFRONT MODE: Deploys scouts to ALL active exchanges!
        """
        if self.scouts_deployed or not CONFIG['DEPLOY_SCOUTS_IMMEDIATELY']:
            return
        
        # ‚òòÔ∏è USE IRISH PATRIOT DEPLOYER IF AVAILABLE
        if hasattr(self, 'patriot_deployer') and self.patriot_deployer is not None:
            print("\n   ‚òòÔ∏èüî• DEPLOYING IRISH PATRIOT SCOUTS - Celtic Warriors Ready! üî•‚òòÔ∏è")
            print("   üáÆüá™ Tiocfaidh √°r l√° - Our day will come!")
            
            # üè¥‚öîÔ∏è MULTI-BATTLEFIELD STATUS
            battlefields = CONFIG.get('BATTLEFIELDS', {})
            active_fronts = [bf for bf, cfg in battlefields.items() if cfg.get('enabled', False)]
            print(f"   ‚öîÔ∏è ACTIVE BATTLEFRONTS: {', '.join(active_fronts).upper()}\n")
            
            # Build candidate list from ALL battlefields
            all_candidates = self._build_scout_candidates()
            
            if all_candidates:
                # üè¥ DISTRIBUTE SCOUTS ACROSS BATTLEFIELDS
                target_scouts = CONFIG.get('SCOUT_FORCE_COUNT', 10)
                deployed = self.patriot_deployer.deploy_patriots(all_candidates, target_count=target_scouts)
                
                if deployed:
                    # üî• ACTUALLY PLACE THE ORDERS - Patriots need real positions!
                    real_positions = 0
                    positions_by_battlefield = {}
                    
                    for scout in deployed:
                        # Build opportunity dict for open_position
                        opp = {
                            'symbol': scout.symbol,
                            'price': scout.entry_price,
                            'score': 75,  # Force high score
                            'coherence': 0.65,
                            'dominant_node': 'PatriotScout',  # üî• MUST match is_force_scout check!
                            'patriot_codename': scout.codename,  # Store codename separately
                            'source': scout.exchange,
                            'quote_currency': self._get_quote_asset(scout.symbol),
                            'change24h': 0.0  # Default momentum for forced scouts
                        }
                        result = self.open_position(opp)
                        if result:
                            real_positions += 1
                            bf = scout.exchange.lower()
                            positions_by_battlefield[bf] = positions_by_battlefield.get(bf, 0) + 1
                            print(f"   üí∞ {scout.codename} position LIVE on {scout.exchange.upper()}!")
                        else:
                            print(f"   ‚ö†Ô∏è {scout.codename} order rejected - check balance/filters")
                    
                    # üè¥ Report battlefield deployment
                    print(f"\n   ‚òòÔ∏è IRISH PATRIOTS: {real_positions}/{len(deployed)} actually in the field!")
                    print(f"   ‚öîÔ∏è Deployment by battlefield: {positions_by_battlefield}")
                    self.scouts_deployed = True
                    self._sync_sniper_bridge("patriots")
                    
                    # üçÑ Sync with Mycelium for cross-exchange awareness
                    try:
                        mycelium_sync('scouts_deployed', {
                            'total': real_positions,
                            'by_exchange': positions_by_battlefield,
                            'timestamp': time.time()
                        })
                    except Exception:
                        pass
                    return
            
            # Fall through to regular deployment if patriot deployer fails
            print("   ‚ö†Ô∏è Patriot deployment failed - falling back to standard scouts")
            
        print("\n   üöÄüî• FORCE DEPLOYING SCOUTS - HIT THE GROUND RUNNING! üî•üöÄ")
        print("   üí• No fence sitting - we're going IN immediately!\n")
        scouts_deployed = 0
        target_scouts = CONFIG.get('SCOUT_FORCE_COUNT', 3)
        
        # Get ALL available quote currencies - be aggressive!
        quote_currencies = CONFIG.get('QUOTE_CURRENCIES', ['USD', 'USDT', 'GBP', 'EUR'])
        
        all_candidates = []
        per_quote_cap = CONFIG.get('SCOUT_PER_QUOTE_LIMIT', 2)
        min_vol = CONFIG.get('SCOUT_MIN_VOLATILITY', 1.5)
        min_vol_q = CONFIG.get('SCOUT_MIN_VOLUME_QUOTE', 100000)
        
        # Gather ALL possible trades across all currencies
        for quote_curr in quote_currencies:
            for symbol, data in self.ticker_cache.items():
                if not symbol.endswith(quote_curr):
                    continue
                if symbol in self.positions:
                    continue
                # Note: Kraken now allowed since Binance UK blocks most USDC pairs
                # Rate limits handled by using cached ticker data
                source = data.get('source', '').lower()
                    
                change = data.get('change24h', 0)
                price = data.get('price', 0)
                volume = data.get('volume', 0)

                # Lion Hunt style gating: need real movement and liquidity
                if price <= 0 or volume <= 0:
                    continue
                if abs(change) < min_vol:
                    continue
                if volume < min_vol_q:
                    continue

                # Opportunity score: |volatility| √ó volume (in millions)
                volume_m = max(volume / 1_000_000, 0.001)
                lion_score = abs(change) * volume_m * 100

                all_candidates.append({
                    'symbol': symbol,
                    'price': price,
                    'change24h': change,
                    'volume': volume,
                    'score': lion_score,
                    'coherence': 0.65,  # Force coherence above threshold
                    'dominant_node': 'ForceScout',
                    'quote_currency': quote_curr,
                    'source': source  # üî• Route to correct exchange!
                })
        
        # üî• BALANCE-AWARE BOOST: Get balances FIRST, then boost tradeable pairs BEFORE deduplication!
        available_quotes = set()
        exchange_quote_balances = {}  # Track actual balances per exchange+quote
        exchange_balances: Dict[str, Dict[str, float]] = {}
        try:
            # Use the MultiExchangeClient's get_all_balances method
            all_balances = self.client.get_all_balances()
            for exchange_name, bals in all_balances.items():
                ex_lower = exchange_name.lower()
                if ex_lower not in exchange_balances:
                    exchange_balances[ex_lower] = {}
                for asset, amt in bals.items():
                    asset_upper = asset.upper()
                    # Remove Kraken prefixes (ZUSD, XXBT, etc)
                    asset_clean = asset_upper.lstrip('ZX')
                    if amt > 1.0:  # Meaningful balance
                        try:
                            exchange_balances[ex_lower][asset_clean] = exchange_balances[ex_lower].get(asset_clean, 0.0) + float(amt)
                        except Exception:
                            pass
                        # Map to quote currency patterns
                        if asset_upper == 'USDC' or asset_clean == 'USDC':
                            available_quotes.add('USDC')
                            key = (exchange_name.lower(), 'USDC')
                            exchange_quote_balances[key] = exchange_quote_balances.get(key, 0) + amt
                        if asset_upper == 'USDT' or asset_clean == 'USDT':
                            available_quotes.add('USDT')
                            key = (exchange_name.lower(), 'USDT')
                            exchange_quote_balances[key] = exchange_quote_balances.get(key, 0) + amt
                        if asset_upper in ('USD', 'ZUSD') or asset_clean == 'USD':
                            available_quotes.add('USD')
                            available_quotes.add('USDC')  # USD can buy USDC pairs
                            key = (exchange_name.lower(), 'USD')
                            exchange_quote_balances[key] = exchange_quote_balances.get(key, 0) + amt
                        if asset_upper in ('GBP', 'ZGBP') or asset_clean == 'GBP':
                            available_quotes.add('GBP')
                            key = (exchange_name.lower(), 'GBP')
                            exchange_quote_balances[key] = exchange_quote_balances.get(key, 0) + amt
                        if asset_upper in ('EUR', 'ZEUR') or asset_clean == 'EUR':
                            available_quotes.add('EUR')
                            key = (exchange_name.lower(), 'EUR')
                            exchange_quote_balances[key] = exchange_quote_balances.get(key, 0) + amt
        except Exception as e:
            print(f"   ‚ö†Ô∏è Balance detection error: {e}")
        
        # Show balances per exchange
        print(f"   üíµ Quote balances by exchange:")
        for (ex, quote), bal in sorted(exchange_quote_balances.items()):
            print(f"      {ex.upper()} {quote}: {bal:.2f}")
        
        # Map of quotes we can actually spend on each exchange (includes convertible assets)
        buyable_quotes_by_exchange: Dict[str, Set[str]] = {}
        for (ex, quote), bal in exchange_quote_balances.items():
            if bal <= 0:
                continue
            ex_quotes = buyable_quotes_by_exchange.setdefault(ex, set())
            quote_upper = quote.upper()
            ex_quotes.add(quote_upper)
            if quote_upper == 'USD':
                ex_quotes.update({'USDC', 'USDT'})
            if quote_upper in ('USDC', 'USDT'):
                ex_quotes.add('USD')

        # Include convertible assets (e.g., BTC->USDT) as buyable quotes
        try:
            convertible_assets = self.client.get_all_convertible_assets()
            for ex, conversions in convertible_assets.items():
                ex_lower = ex.lower()
                balances = exchange_balances.get(ex_lower, {})
                if not balances:
                    continue
                ex_quotes = buyable_quotes_by_exchange.setdefault(ex_lower, set())
                for asset, amount in balances.items():
                    if amount <= 0:
                        continue
                    targets = conversions.get(asset) or conversions.get(asset.upper())
                    if not targets:
                        continue
                    for tgt in targets:
                        tgt_upper = tgt.upper()
                        if tgt_upper in CONFIG.get('QUOTE_CURRENCIES', []):
                            ex_quotes.add(tgt_upper)
        except Exception as e:
            print(f"   ‚ö†Ô∏è Convertible asset detection skipped: {e}")

        # Available tradable pairs by exchange to validate scout targets
        available_pairs_by_exchange: Dict[str, Set[str]] = {}
        try:
            for exchange_name in self.client.clients.keys():
                pairs = self.client.get_available_pairs(exchange_name)
                formatted_pairs: Set[str] = set()
                for p in pairs or []:
                    base = str(p.get('base', '')).upper()
                    quote = str(p.get('quote', '')).upper()
                    pair_name = str(p.get('pair', f"{base}{quote}")).upper()
                    if pair_name:
                        formatted_pairs.add(pair_name)
                    if base and quote:
                        formatted_pairs.add(f"{base}{quote}")
                        formatted_pairs.add(f"{base}/{quote}")
                available_pairs_by_exchange[exchange_name.lower()] = formatted_pairs
        except Exception as e:
            print(f"   ‚ö†Ô∏è Pair discovery skipped: {e}")
        
        # üî• CRITICAL: Apply balance boost to scores BEFORE deduplication!
        # Boost MORE if the exchange actually has balance for that quote currency!
        for c in all_candidates:
            source_exchange = (c.get('source') or 'kraken').lower()
            quote = c['quote_currency']
            ex_quote_key = (source_exchange, quote)
            
            tradeable_on_exchange = quote.upper() in buyable_quotes_by_exchange.get(source_exchange, set())
            if tradeable_on_exchange:
                c['score'] += 10_000_000  # Massive boost for tradeable quote currency
                
                # üî• EXTRA boost if THIS exchange has balance (not just any exchange)
                if ex_quote_key in exchange_quote_balances and exchange_quote_balances[ex_quote_key] > 10:
                    c['score'] += 5_000_000  # Extra 5M for having balance on THIS exchange
            elif quote in available_quotes:
                # Smaller boost if another exchange has this quote but we may need conversion
                c['score'] += 1_000_000
        
        # üî• Keep best per base+exchange combo to allow BOTH Binance USDC AND Kraken GBP trades!
        # Don't collapse across exchanges - we want to trade on BOTH platforms
        def _base_from_symbol(sym: str) -> str:
            for suffix in self.quote_currency_suffixes:
                if sym.endswith(suffix):
                    return sym[: -len(suffix)]
            return sym

        best_per_base_exchange: Dict[str, Dict] = {}
        for c in all_candidates:
            base = _base_from_symbol(c['symbol'])
            source = (c.get('source') or 'unknown').lower()
            key = f"{base}_{source}"  # Keep separate entries per exchange!
            if key not in best_per_base_exchange or c['score'] > best_per_base_exchange[key]['score']:
                best_per_base_exchange[key] = c
        all_candidates = list(best_per_base_exchange.values())

        # Sort by score (tradeable pairs already boosted)
        all_candidates.sort(key=lambda x: x['score'], reverse=True)

        # Fallback: if no candidates met the aggressive filters, pick a best-effort symbol
        if not all_candidates:
            force_sym = CONFIG.get('FORCE_TRADE_SYMBOL') or None
            fallback = None
            best_change = 0
            for sym, data in self.ticker_cache.items():
                if sym in self.positions:
                    continue
                if force_sym and sym != force_sym:
                    continue
                price = data.get('price', 0)
                change = data.get('change24h', 0)
                volume = data.get('volume', 0)
                if price <= 0 or volume <= 0:
                    continue
                if abs(change) > abs(best_change):
                    best_change = change
                    fallback = {
                        'symbol': sym,
                        'price': price,
                        'change24h': change,
                        'volume': volume,
                        'score': abs(change),
                        'coherence': 0.55,
                        'dominant_node': 'ForceScout',
                        'quote_currency': self._get_quote_asset(sym)
                    }
            if fallback:
                all_candidates.append(fallback)

        # üî• FILTER: Only keep pairs where we have balance to trade on THAT exchange!
        def _is_pair_tradeable(sym: str, quote: str, pair_set: Set[str]) -> bool:
            if not pair_set:
                return True
            sym_clean = sym.replace('/', '').upper()
            if sym_clean in pair_set:
                return True
            base = _base_from_symbol(sym).upper()
            quote_upper = quote.upper()
            combos = (f"{base}{quote_upper}", f"{base}/{quote_upper}")
            return any(c in pair_set for c in combos)

        if buyable_quotes_by_exchange:
            tradeable_candidates = []
            for c in all_candidates:
                ex = (c.get('source') or 'unknown').lower()
                quote = c['quote_currency']
                if quote.upper() not in buyable_quotes_by_exchange.get(ex, set()):
                    continue
                pair_set = available_pairs_by_exchange.get(ex, set())
                if not _is_pair_tradeable(c['symbol'], quote, pair_set):
                    continue
                tradeable_candidates.append(c)
            quote_summary = {ex: sorted(list(quotes)) for ex, quotes in buyable_quotes_by_exchange.items()}
            print(f"   üìä Found {len(all_candidates)} pairs ‚Üí {len(tradeable_candidates)} tradeable per-exchange (quotes: {quote_summary})")
            all_candidates = tradeable_candidates
        else:
            print(f"   üìä Found {len(all_candidates)} tradeable pairs (no balance map)")
        
        # üîÑ INTERLEAVE BY EXCHANGE: Ensure we deploy scouts on BOTH Binance AND Kraken!
        # Group by source exchange, then round-robin to pick from each
        by_exchange: Dict[str, List[Dict]] = {}
        for c in all_candidates:
            ex = (c.get('source') or 'unknown').lower()
            if ex not in by_exchange:
                by_exchange[ex] = []
            by_exchange[ex].append(c)
        
        # Sort each exchange's candidates by score
        for ex in by_exchange:
            by_exchange[ex].sort(key=lambda x: -x.get('score', 0))
        
        # Interleave: take top candidate from each exchange in rotation
        interleaved = []
        exchanges = list(by_exchange.keys())
        max_len = max(len(v) for v in by_exchange.values()) if by_exchange else 0
        for i in range(max_len):
            for ex in exchanges:
                if i < len(by_exchange[ex]):
                    interleaved.append(by_exchange[ex][i])
        
        all_candidates = interleaved
        print(f"   üîÑ Interleaved {len(exchanges)} exchanges: {', '.join(exchanges)}")
        
        # ‚öîÔ∏è WAR STRATEGY: Rank candidates by QUICK KILL PROBABILITY ‚öîÔ∏è
        # Goal: Enter coins where we can make 1 penny profit FASTEST
        if WAR_STRATEGY_AVAILABLE and WAR_STRATEGIST:
            print(f"\n   ‚öîÔ∏è WAR STRATEGY: Analyzing {len(all_candidates)} targets for quick kill probability...")
            
            # Get recent price data for volatility analysis
            for c in all_candidates:
                symbol = c.get('symbol', '')
                prices = []
                
                # Try to get price history from ticker cache
                if symbol in self.ticker_cache:
                    ticker = self.ticker_cache[symbol]
                    current_price = ticker.get('price', 0)
                    high24h = ticker.get('high', current_price)
                    low24h = ticker.get('low', current_price)
                    
                    # Synthesize rough price range from 24h data
                    if current_price > 0 and high24h > 0 and low24h > 0:
                        # Create synthetic price history from 24h high/low
                        prices = [low24h, (low24h + current_price) / 2, current_price, 
                                  (high24h + current_price) / 2, high24h, current_price]
                    else:
                        prices = [current_price] * 2
                
                c['prices'] = prices
                c['exchange'] = (c.get('source') or 'unknown').lower()
            
            # Rank targets using War Strategy
            ranked_candidates = WAR_STRATEGIST.rank_targets(all_candidates)
            
            # Filter to only GO signals, then sort by priority + estimated bars
            go_targets = [c for c in ranked_candidates if c.get('war_go', False)]
            no_go_targets = [c for c in ranked_candidates if not c.get('war_go', False)]
            
            print(f"   ‚úÖ GO signals: {len(go_targets)} | ‚ö†Ô∏è NO-GO: {len(no_go_targets)}")
            
            # Show top 5 war recommendations
            for i, c in enumerate(go_targets[:5]):
                qk = c.get('quick_kill', {})
                print(f"      {i+1}. {c['symbol']}: {qk.get('prob_quick_kill', 0)*100:.0f}% quick kill, "
                      f"~{qk.get('estimated_bars', 99):.0f} bars ({qk.get('estimated_minutes', 99):.1f}min)")
            
            # Prioritize GO signals but keep some no-go as fallback
            all_candidates = go_targets + no_go_targets[:3]
        
        # FORCE deploy scouts - don't stop until we hit the target!
        deployed_per_quote: Dict[str, int] = {}
        max_positions = get_max_positions_limit() or 10**9
        for candidate in all_candidates:
            if scouts_deployed >= target_scouts:
                break
            if len(self.positions) >= max_positions:
                break
            if candidate['symbol'] in self.positions:
                continue
            if deployed_per_quote.get(candidate['quote_currency'], 0) >= per_quote_cap:
                continue
                
            print(f"   ü¶Ö Scout: {candidate['symbol']} ({candidate['change24h']:+.2f}% 24h | {candidate['quote_currency']})")
            
            # Call open_position - it will handle the actual trade
            result = self.open_position(candidate)
            if result:
                scouts_deployed += 1
                deployed_per_quote[candidate['quote_currency']] = deployed_per_quote.get(candidate['quote_currency'], 0) + 1
                print(f"   ‚úÖ Scout #{scouts_deployed} DEPLOYED!")
            else:
                print(f"   ‚ö†Ô∏è  Scout {candidate['symbol']} skipped - trying next...")
            time.sleep(0.25)  # small pause to avoid hammering exchange balance endpoints
                
        self.scouts_deployed = True
        
        if scouts_deployed > 0:
            print(f"\n   üéØ DEPLOYED {scouts_deployed} scout(s) - WE'RE IN THE GAME!\n")
        else:
            print(f"\n   ‚ö†Ô∏è  No scouts deployed - check balance/liquidity\n")
        self._sync_sniper_bridge("scouts")

    def _normalize_ticker_symbol(self, symbol: str) -> str:
        """Convert internal symbol format to Kraken ticker format.
        XXBTGBP -> XBTGBP, XXLMGBP -> XLMGBP, XLTCGBP -> LTCGBP"""
        if symbol.startswith('XX') and len(symbol) > 5:
            # XXBTGBP -> XBTGBP, XXLMGBP -> XLMGBP
            return symbol[1:]
        elif symbol.startswith('XLT') or symbol.startswith('XLTC'):
            # XLTCGBP -> LTCGBP
            return symbol.replace('XLTC', 'LTC')
        return symbol

    def _get_quote_asset(self, symbol: str) -> str:
        """Best-effort detection of quote asset from symbol name."""
        if not symbol:
            return CONFIG['BASE_CURRENCY'].upper()

        sym = symbol.upper()
        if '/' in sym:
            quote_part = sym.split('/')[-1]
            if quote_part in CONFIG['QUOTE_CURRENCIES']:
                return quote_part

        for suffix in self.quote_currency_suffixes:
            if sym.endswith(suffix):
                return suffix

        return CONFIG['BASE_CURRENCY'].upper()

    def ensure_quote_liquidity(self, exchange: str, quote_asset: str, required: float) -> Tuple[bool, float, Optional[str]]:
        if self.dry_run or required <= 0:
            return True, required, None

        exchange = exchange.lower()
        if exchange not in ('binance', 'kraken'):
            return True, required, None

        exchange_client = self.client.clients.get(exchange)
        if exchange_client is None:
            return False, 0.0, None

        def _balance(asset: str) -> float:
            try:
                return float(exchange_client.get_balance(asset.upper()))
            except Exception:
                return 0.0

        warn_key = (exchange, quote_asset)

        available = _balance(quote_asset)
        if available >= required:
            return True, available, None

        if warn_key in self._liquidity_warnings:
            return False, available, None

        deficit = max(0.0, required - available)
        exchange_marker = exchange.upper()
        candidate_assets = [CONFIG['BASE_CURRENCY'].upper(), 'USDC', 'USDT', 'USD']
        suggestions: List[str] = []
        for candidate in candidate_assets:
            candidate = candidate.upper()
            if candidate == quote_asset:
                continue

            candidate_balance = _balance(candidate)
            if candidate_balance <= 0:
                continue

            symbol = exchange_client.get_standardized_pair(quote_asset, candidate)
            ticker = exchange_client.get_ticker(symbol)
            try:
                price = float(ticker.get('price', 0) or ticker.get('lastPrice', 0) or 0)
            except Exception:
                price = 0.0
            if price <= 0:
                continue

            # Calculate desired base amount (quote asset) with small buffer
            filters = exchange_client.get_symbol_filters(symbol)
            min_qty = filters.get('min_qty', 0.0) if filters else 0.0
            min_notional = filters.get('min_notional', 0.0) if filters else 0.0
            desired_base = max(deficit * 1.05, min_qty)
            if min_notional and price > 0:
                desired_base = max(desired_base, min_notional / price)
            max_affordable = candidate_balance / price
            desired_base = min(desired_base, max_affordable)
            if desired_base <= 0:
                continue

            desired_base = exchange_client.adjust_quantity(symbol, desired_base)
            if desired_base <= 0:
                continue

            if (
                min_notional and price > 0 and desired_base * price < min_notional
            ):
                step_size = filters.get('step_size', 0.0) if filters else 0.0
                target_base = min_notional / price
                bumped = desired_base
                if step_size > 0:
                    steps_needed = math.ceil(max(0.0, target_base - desired_base) / step_size)
                    if steps_needed > 0:
                        bumped = min(desired_base + steps_needed * step_size, max_affordable)
                else:
                    bumped = min(target_base, max_affordable)

                if bumped > desired_base:
                    adjusted_bump = exchange_client.adjust_quantity(symbol, bumped)
                    if (
                        adjusted_bump > desired_base and
                        adjusted_bump * price <= candidate_balance + 1e-8
                    ):
                        desired_base = adjusted_bump

            quotes_needed = desired_base * price
            if quotes_needed <= 0 or quotes_needed > candidate_balance:
                continue

            if min_notional and quotes_needed < min_notional:
                suggestions.append(
                    f"need at least {min_notional:.2f} {candidate} notional for {symbol}"
                )
                continue

            try:
                print(
                    f"   üîÅ Auto-converting {desired_base:.2f} {quote_asset} using {symbol} on {exchange_marker}"
                )
                self.client.place_market_order(exchange, symbol, 'BUY', quantity=desired_base)
            except Exception as conv_err:
                suggestion = (
                    f"{candidate_balance:.2f} {candidate} ‚âà {desired_base * price:.2f} {quote_asset}"
                )
                suggestions.append(suggestion)
                print(f"   ‚ö†Ô∏è Conversion failed ({candidate}->{quote_asset}): {conv_err}")
                continue

            time.sleep(0.5)
            available = _balance(quote_asset)
            if available >= required * 0.995:
                return True, available, None
            deficit = max(0.0, required - available)

        tip = None
        if suggestions:
            tip = f"convert {suggestions[0]} on {exchange_marker} to fund {quote_asset}"

        return False, available, tip

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Equity Management
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def _get_exchange_cash_balance(self, exchange: str) -> float:
        """
        ‚öîÔ∏è MULTI-BATTLEFIELD: Get available cash balance for a specific exchange.
        
        Returns the liquid cash available for trading (not crypto holdings).
        This is critical for preventing "Insufficient funds" spam on exchanges
        that have been drained.
        """
        try:
            # Cache check - don't hammer APIs
            cache_key = f"cash_{exchange}"
            cache_ttl = 30  # 30 second cache
            
            if hasattr(self, '_exchange_cash_cache'):
                cached = self._exchange_cash_cache.get(cache_key, {})
                if cached and time.time() - cached.get('ts', 0) < cache_ttl:
                    return cached.get('balance', 0.0)
            else:
                self._exchange_cash_cache = {}
            
            cash_balance = 0.0
            base = CONFIG.get('BASE_CURRENCY', 'GBP')
            stable_coins = {'USD', 'USDC', 'USDT', 'EUR', 'GBP', 'ZUSD', 'ZEUR', 'ZGBP', 'FDUSD', 'BUSD'}
            
            # Get balances for this specific exchange
            try:
                if exchange == 'kraken':
                    balances = self.client.kraken.get_balance() if self.client.kraken else {}
                elif exchange == 'binance':
                    balances = self.client.binance.get_balance() if self.client.binance else {}
                elif exchange == 'capital':
                    balances = self.client.capital.get_balance() if self.client.capital else {}
                elif exchange == 'alpaca':
                    balances = self.client.alpaca.get_balance() if self.client.alpaca else {}
                else:
                    balances = {}
            except Exception as e:
                logger.debug(f"Could not get {exchange} balance: {e}")
                balances = {}
            
            # Sum up stable coins / cash equivalents
            for asset, amount in balances.items():
                try:
                    amount = float(amount)
                except:
                    continue
                if amount <= 0:
                    continue
                    
                asset_upper = asset.upper().replace('Z', '').lstrip('X')
                if asset_upper in stable_coins:
                    # Convert to base currency if needed
                    if asset_upper != base:
                        try:
                            converted = self.client.convert_to_quote(exchange, asset_upper, amount, base)
                            cash_balance += converted if converted > 0 else amount
                        except:
                            # Fallback: assume roughly 1:1 for stable coins
                            cash_balance += amount
                    else:
                        cash_balance += amount
            
            # Cache the result
            self._exchange_cash_cache[cache_key] = {'balance': cash_balance, 'ts': time.time()}
            
            return cash_balance
            
        except Exception as e:
            logger.debug(f"Error getting {exchange} cash balance: {e}")
            return 0.0

    def compute_total_equity(self) -> Tuple[float, float, Dict[str, float]]:
        """Return (total_equity, cash_in_base, holdings_map)
        
        Always fetches real balances from exchanges, regardless of dry_run mode.
        Dry run only affects order execution, not balance queries.
        """
        base = CONFIG['BASE_CURRENCY']
        holdings_value: Dict[str, float] = {}
        total_equity = 0.0
        cash_balance = 0.0
        
        try:
            all_balances = self.client.get_all_balances()
        except Exception as e:
            print(f"   ‚ö†Ô∏è Equity refresh error: {e}")
            return self.total_equity_gbp, self.cash_balance_gbp, self.holdings_gbp
        
        # If no balances returned, fall back to tracker (simulation mode)
        if not any(all_balances.values()):
            total_equity = self.tracker.balance
            used_capital = sum(pos.entry_value for pos in self.positions.values())
            cash_balance = max(0.0, total_equity - used_capital)
            for sym, pos in self.positions.items():
                holdings_value[sym] = pos.entry_value
            if cash_balance > 0:
                holdings_value[base] = holdings_value.get(base, 0.0) + cash_balance
            return total_equity, cash_balance, holdings_value
        
        for exchange, balances in all_balances.items():
            # Skip Alpaca if it's analytics-only (paper trading, not real funds)
            if exchange == 'alpaca' and CONFIG.get('ALPACA_ANALYTICS_ONLY', True):
                continue
                
            for asset_raw, amount in balances.items():
                if not asset_raw:
                    continue
                try:
                    amount = float(amount)
                except Exception:
                    amount = 0.0
                if amount <= 0:
                    continue
                    
                # Skip dust amounts for Binance (< $1 equivalent)
                if exchange == 'binance' and amount < 1.0 and asset_raw not in ['BTC', 'ETH', 'USDC', 'USDT', 'USD', 'BNB']:
                    continue
                    
                asset_clean = asset_raw.replace('Z', '').upper()  # Keep X prefix (XXBT stays XXBT)
                # For conversion, strip first X only (XXBT->XBT, XETH->ETH)
                conversion_asset = asset_clean[1:] if asset_clean.startswith('X') and len(asset_clean) > 3 else asset_clean
                
                # Handle Binance Earn (LD prefix)
                if asset_raw.startswith('LD'):
                    conversion_asset = asset_raw[2:]
                    asset_clean = conversion_asset
                
                # Check if this is the base currency OR a stable coin (cash equivalent)
                stable_coins = {'USD', 'USDC', 'USDT', 'EUR', 'GBP', 'ZUSD', 'ZEUR', 'ZGBP'}
                is_cash = (conversion_asset == base or asset_clean == base or 
                           conversion_asset in stable_coins or asset_clean in stable_coins)
                if is_cash:
                    # Convert stable coins to base currency value
                    if conversion_asset != base and asset_clean != base:
                        converted = 0.0
                        try:
                            converted = self.client.convert_to_quote(exchange, conversion_asset, amount, base)
                        except Exception:
                            converted = 0.0
                        if converted > 0:
                            cash_balance += converted
                            total_equity += converted
                            holdings_value[asset_clean] = holdings_value.get(asset_clean, 0.0) + converted
                            continue
                        # Fallback: treat USD stables as 1:1 to avoid missing cash when pricing data is unavailable
                        if base.upper() == 'USD' and conversion_asset in {'USD', 'USDC', 'USDT'}:
                            cash_balance += amount
                            total_equity += amount
                            holdings_value[asset_clean] = holdings_value.get(asset_clean, 0.0) + amount
                            continue
                    else:
                        cash_balance += amount
                        total_equity += amount
                        holdings_value[asset_clean] = holdings_value.get(asset_clean, 0.0) + amount
                        continue
                try:
                    converted = self.client.convert_to_quote(exchange, conversion_asset, amount, base)
                    if converted > 0:
                        total_equity += converted
                        holdings_value[asset_clean] = holdings_value.get(asset_clean, 0.0) + converted
                except Exception:
                    continue
                    
        return total_equity, cash_balance, holdings_value

    def refresh_equity(self, mark_cycle: bool = False) -> float:
        self._liquidity_warnings.clear()
        total, cash, holdings = self.compute_total_equity()
        
        # üõ†Ô∏è FIX: Auto-correct "Fake $1000 Balance" on first run
        # If we are using the default 1000, but the wallet shows something else (e.g. ~55),
        # and we haven't done any trades yet, assume this is the TRUE starting balance.
        if self.tracker.initial_balance == 1000.0 and self.tracker.total_trades == 0:
            # Check if we are significantly different (e.g. > 1% diff) to avoid floating point noise
            # But really, if it's the first run, we should trust the wallet.
            if abs(total - 1000.0) > 1.0 and total > 0:
                print(f"   ‚öñÔ∏è  Correcting Initial Balance: ${self.tracker.initial_balance:.2f} -> ${total:.2f} (Actual Wallet)")
                self.tracker.initial_balance = total
                self.tracker.first_start_balance = total
                self.tracker.balance = total
                self.tracker.peak_balance = total
                self.tracker.equity_baseline = total
                self.tracker.portfolio_equity = total
                self.tracker.cash_balance = cash
                
                # Update the P&L snapshot immediately
                self.pnl_state['total_equity'] = total
                self.pnl_state['cash'] = cash
                self.pnl_state['net_profit'] = 0.0
                self.pnl_state['total_return_pct'] = 0.0

        self.total_equity_gbp = total
        self.cash_balance_gbp = cash
        self.holdings_gbp = holdings
        self.tracker.update_equity(total, cash, mark_cycle=mark_cycle)

        # üß† Store live P&L snapshot for decision making
        try:
            total_return_pct = 0.0
            if self.tracker.initial_balance > 0:
                total_return_pct = (total - self.tracker.initial_balance) / self.tracker.initial_balance * 100
            self.pnl_state = {
                'total_equity': total,
                'cash': cash,
                'net_profit': self.tracker.net_profit,
                'total_return_pct': total_return_pct,
                'drawdown_pct': self.tracker.current_drawdown,
                'timestamp': time.time(),
            }
        except Exception:
            pass
        
        # üåü Sync capital pool with current equity
        self.capital_pool.update_equity(total)
        
        if self.tracker.equity_baseline is None or self.tracker.equity_baseline == 0:
            self.tracker.equity_baseline = total
        gain = total - self.tracker.equity_baseline
        if gain > CONFIG['EQUITY_MIN_DELTA']:
            self.tracker.realize_portfolio_gain(gain)
            self.tracker.equity_baseline = total
        
        # Keep IRA sniper coverage in sync with live balances on every refresh
        try:
            self.sniper_coverage = map_sniper_platform_assets(self.client)
        except Exception as e:
            logger.debug(f"Sniper coverage refresh failed: {e}")
        return total

    def get_pnl_snapshot(self) -> Dict[str, float]:
        """Return the latest live P&L snapshot for downstream consumers."""
        return dict(self.pnl_state) if isinstance(self.pnl_state, dict) else {}

    def should_trade_brain(self) -> Tuple[bool, str]:
        """
        üß† BRAIN GATE: 7 Civilizations + Quantum Brain.
        
        ü™ô PENNY MODE: This is now ADVISORY ONLY.
        The penny profit math ($0.01 net) is the REAL gate.
        All wisdom is advisory - helps with sizing, not entry.
        
        Returns (should_trade, reason).
        """
        if not hasattr(self, 'brain_bridge') or not self.brain_bridge:
            return True, "Brain Bridge not initialized - trading allowed"
        
        try:
            # Get brain recommendation
            rec = self.brain_bridge.get_trading_recommendation()
            action = rec.get('action', 'HOLD')
            civs_bullish = rec.get('civilizations_bullish', 0)
            civs_total = rec.get('civilizations_total', 7)
            confidence = rec.get('confidence', 0.5)
            
            consensus = self.brain_bridge._brain_consensus if hasattr(self.brain_bridge, '_brain_consensus') else 'NEUTRAL'
            
            # ü™ô PENNY MODE: Everything is advisory
            # Log the brain state but don't block
            if action == 'REDUCE' and confidence > 0.65:
                logger.debug(f"üß† Brain says REDUCE (advisory) - {civs_bullish}/{civs_total} bullish")
            
            if consensus == 'BEARISH' and confidence > 0.6:
                logger.debug(f"üß† Brain BEARISH (advisory) - conf={confidence:.0%}")
            
            # Always approve - penny math is the gate
            return True, f"ü™ô PENNY MODE: Brain is advisory - {consensus} (conf={confidence:.0%})"
            
        except Exception as e:
            return True, f"Brain check error ({e}) - trading allowed"

    def should_enter_trade(self, opp: Dict, pos_size: float, lattice_state, is_force_scout: bool = False) -> bool:
        """
        üéØü™ô ONE SHARED GOAL: NET PENNY PROFIT AFTER FEES ü™ôüéØ
        
        Every system, every scan, every prediction answers ONE question:
        "Will this trade make +$0.01 NET after ALL fees?"
        
        We can predict waves, harmonics, movements - but predictions are WORTHLESS
        unless they translate to the SHARED GOAL.
        
        THE LOGIC:
        1. Calculate exact penny profit threshold for this trade
        2. Ask Brain: "Will price move enough to hit that threshold?"
        3. Ask Matrix: "What's the PROBABILITY we hit that threshold?"
        4. Ask Imperial: "Is the cosmic timing aligned for that movement?"
        5. If ALL systems agree we'll hit the penny ‚Üí TRADE
        6. If ANY system says we won't hit the penny ‚Üí NO TRADE
        
        If is_force_scout=True, bypass most gates - we're going IN!
        """
        # Minimal sanity checks
        if pos_size <= 0 or self.total_equity_gbp <= 0:
            opp['entry_reject_reason'] = 'invalid position size or equity'
            return False
            
        symbol = opp.get('symbol', 'UNKNOWN')
        # Prefer explicit routing decision if present.
        exchange = opp.get('exchange') or opp.get('source', 'binance')
        price = opp.get('price', 0)
        aggressive = bool(CONFIG.get('AGGRESSIVE_ONE_GOAL', False))
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # ü™ô STEP 1: Calculate the EXACT penny profit threshold
        # This is the SHARED GOAL - every system must validate THIS number
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        penny_threshold = get_penny_threshold(exchange, pos_size)
        if not penny_threshold:
            logger.warning(f"‚õî {symbol}: Cannot calculate penny threshold - NO TRADE")
            opp['entry_reject_reason'] = 'cannot calculate penny threshold'
            return False
            
        required_move_pct = penny_threshold['required_pct']  # e.g., 0.52%
        required_price = price * (1 + penny_threshold['required_r'])
        target_net = penny_threshold['target_net']
        
        # Store in opp for exit logic to use
        opp['penny_threshold'] = penny_threshold
        opp['required_move_pct'] = required_move_pct
        opp['required_price'] = required_price
        
        logger.info(f"ü™ô {symbol}: SHARED GOAL = +${target_net:.2f} net | Need +{required_move_pct:.3f}% (${price:.4f} ‚Üí ${required_price:.4f})")
        
        # ü¶Ö FORCE SCOUTS: Verify they can ACTUALLY hit penny profit
        if is_force_scout:
            # Even force scouts must have a CHANCE at penny profit
            probability = opp.get('probability', 0.5)
            if probability < 0.40:  # At least 40% chance
                logger.info(f"ü¶Ö‚õî {symbol}: Force scout BLOCKED - Only {probability*100:.0f}% chance of +{required_move_pct:.3f}%")
                opp['entry_reject_reason'] = f"force scout probability too low ({probability:.2f})"
                return False
            logger.info(f"ü¶Ö FORCE SCOUT {symbol}: {probability*100:.0f}% chance of +{required_move_pct:.3f}% ‚Üí EXECUTING!")
            return True
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üß† STEP 2: Ask Brain - "Will price move +{required_move_pct}%?"
        # The Brain predicts DIRECTION and MAGNITUDE
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        brain_ok, brain_reason = self.should_trade_brain()
        brain_rec = ECOSYSTEM_BRAIN.get_trading_recommendation()
        brain_confidence = opp.get('brain_confidence', ECOSYSTEM_BRAIN._brain_confidence)
        
        # Brain is advisory in penny mode; in aggressive mode, never block on Brain.
        if (not aggressive) or (not CONFIG.get('AGGRESSIVE_IGNORE_BRAIN_REDUCE', True)):
            if brain_rec['action'] == 'REDUCE':
                logger.info(f"‚õî {symbol}: Brain says REDUCE - Price won't move +{required_move_pct:.3f}% | NO PENNY")
                opp['entry_reject_reason'] = 'brain: REDUCE'
                return False

            if brain_rec['action'] == 'HOLD' and brain_confidence > 0.6:
                logger.info(f"‚õî {symbol}: Brain says HOLD (conf={brain_confidence:.0%}) - Not enough movement for penny | NO PENNY")
                opp['entry_reject_reason'] = f"brain: HOLD (conf={brain_confidence:.2f})"
                return False
        else:
            if brain_rec.get('action') in ('REDUCE', 'HOLD'):
                opp['brain_note'] = f"{brain_rec.get('action')} (conf={brain_confidence:.2f})"
            
        if brain_rec['action'] == 'BUY' and brain_confidence > 0.5:
            logger.info(f"‚úÖ {symbol}: Brain says BUY (conf={brain_confidence:.0%}) - Expects +{required_move_pct:.3f}% movement")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üåå STEP 4: Ask Imperial - "Is cosmic timing right for +{required_move_pct}%?"
        # Imperial validates the TIMING of our penny profit
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        imperial_action = opp.get('imperial_action', 'HOLD')
        imperial_conf = opp.get('imperial_confidence', 0.0)
        
        # Imperial veto only if HIGHLY confident in SELL (ignored in aggressive mode by default)
        if (not aggressive) or (not CONFIG.get('AGGRESSIVE_IGNORE_IMPERIAL_SELL', True)):
            if imperial_conf >= 0.7 and imperial_action in ['SELL', 'STRONG SELL']:
                logger.info(f"‚õî {symbol}: Imperial says {imperial_action} (conf={imperial_conf:.0%}) - Cosmic timing wrong | NO PENNY")
                opp['entry_reject_reason'] = f"imperial: {imperial_action} (conf={imperial_conf:.2f})"
                return False
        else:
            if imperial_action in ['SELL', 'STRONG SELL']:
                opp['imperial_note'] = f"{imperial_action} (conf={imperial_conf:.2f})"
        
        # If brain is very bullish, log approval
        if brain_rec['action'] == 'BUY' and brain_confidence > 0.7:
            logger.info(f"üß†üìà {symbol}: Brain APPROVED (7 Civs: {brain_rec['civilizations_bullish']}/7 bullish)")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üîÆ STEP 3: Ask Matrix - "What's PROBABILITY of +{required_move_pct}%?"
        # We map the waves to plot the course. If the map says "Reef", we don't sail.
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        prob_action = opp.get('prob_action', 'HOLD')
        probability = opp.get('probability', 0.5)
        prob_confidence = opp.get('prob_confidence', 0.0)
        
        if aggressive:
            # ü¶æ AGGRESSIVE ONE-GOAL: only block when the matrix is strongly bearish with high confidence,
            # otherwise keep trading and let the penny-profit exits manage the loop.
            min_prob = float(CONFIG.get('AGGRESSIVE_MIN_PROB', 0.30) or 0.30)
            strong_conf = float(CONFIG.get('AGGRESSIVE_STRONG_SELL_CONF', 0.80) or 0.80)
            block_only_strong = bool(CONFIG.get('AGGRESSIVE_BLOCK_ONLY_STRONG_SELL', True))

            if probability < min_prob:
                opp['entry_reject_reason'] = f"aggressive: prob too low ({probability:.2f} < {min_prob:.2f})"
                return False

            if prob_action in ['SELL', 'STRONG SELL']:
                if (not block_only_strong) or (prob_confidence >= strong_conf) or (prob_action == 'STRONG SELL'):
                    logger.info(
                        f"‚õî {symbol}: Matrix says {prob_action} (prob={probability:.0%}, conf={prob_confidence:.0%}) - bearish veto"
                    )
                    opp['entry_reject_reason'] = f"matrix: {prob_action} (prob={probability:.2f}, conf={prob_confidence:.2f})"
                    return False

            if prob_action == 'HOLD' and not CONFIG.get('AGGRESSIVE_IGNORE_MATRIX_HOLD', True):
                opp['entry_reject_reason'] = f"matrix: HOLD (prob={probability:.2f})"
                return False
        else:
            # üõ°Ô∏è VALIDATION LOCK: Reject weak signals
            if prob_action in ['SELL', 'STRONG SELL']:
                logger.info(f"‚õî {symbol}: Matrix says {prob_action} (prob={probability:.0%}) - Won't hit +{required_move_pct:.3f}% | NO PENNY")
                opp['entry_reject_reason'] = f"matrix: {prob_action} (prob={probability:.2f})"
                return False

            if prob_action == 'HOLD' and probability < 0.60:
                logger.info(f"‚õî {symbol}: Matrix says HOLD (prob={probability:.0%}) - Won't hit +{required_move_pct:.3f}% | NO PENNY")
                opp['entry_reject_reason'] = f"matrix: HOLD (prob={probability:.2f})"
                return False

            # üõ°Ô∏è VALIDATION LOCK: Reject SLIGHT BUY if confidence is low
            if prob_action == 'SLIGHT BUY' and probability < 0.75:
                logger.info(f"‚õî {symbol}: Matrix says SLIGHT BUY (prob={probability:.0%}) - Need ‚â•75% to justify +{required_move_pct:.3f}% | NO PENNY")
                opp['entry_reject_reason'] = f"matrix: SLIGHT BUY (prob={probability:.2f})"
                return False
        
        # ‚úÖ Log when matrix says BUY
        if prob_action in ['BUY', 'STRONG BUY', 'SLIGHT BUY']:
            logger.info(f"‚úÖ {symbol}: Matrix says {prob_action} (prob={probability:.0%}) - APPROVED for +{required_move_pct:.3f}%")
            
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üìö STEP 5: Ask Learned - "Historically, do trades like this hit penny?"
        # The Learned system validates based on REAL HISTORICAL DATA
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        recommendation = None
        try:
            frequency = opp.get('frequency', CONFIG.get('DEFAULT_FREQUENCY', 256))
            coherence = opp.get('coherence', 0.5)
            score = opp.get('score', 50)
            pnl_snapshot = self.get_pnl_snapshot()
            opp['pnl_state'] = pnl_snapshot
            
            # üìâ Risk throttle from live P&L state
            risk_mod = 1.0
            dd = pnl_snapshot.get('drawdown_pct', 0) if pnl_snapshot else 0
            net_pnl = pnl_snapshot.get('net_profit', 0) if pnl_snapshot else 0
            if dd > 5:
                risk_mod *= 0.6
            if net_pnl < 0:
                risk_mod *= 0.8
            opp['risk_mod_from_pnl'] = risk_mod
            
            recommendation = ADAPTIVE_LEARNER.get_entry_recommendation(
                symbol=symbol,
                frequency=frequency,
                coherence=coherence,
                score=score,
                probability=probability
            )
            
            if recommendation['similar_trades'] >= 5:
                summary = ADAPTIVE_LEARNER.get_recommendation_summary(recommendation)
                logger.info(f"\nüìä LEARNED ANALYTICS for {symbol}:\n{summary}")
                opp['learned_recommendation'] = recommendation
                
                # ü™ô SHARED GOAL CHECK: Does history say we'll hit penny profit?
                historical_wr = recommendation['expected_win_rate']

                # Learned blocking should be proportional to evidence.
                # Avoid hard-blocking on tiny sample sizes (e.g. 3-6 trades).
                learned_conf = (recommendation.get('confidence') or 'low').lower()
                learned_similar = int(recommendation.get('similar_trades') or 0)
                learned_should_trade = bool(recommendation.get('should_trade', True))
                learned_block_evidence = (learned_conf in ('high', 'medium')) and (learned_similar >= 10)
                
                if (not learned_should_trade) and learned_block_evidence and historical_wr < 0.40:
                    logger.info(f"‚õî {symbol}: Learned blocks (WR={historical_wr*100:.0f}%, {learned_similar} samples, {learned_conf}) - NO PENNY")
                    opp['entry_reject_reason'] = f"learned: blocks (WR={historical_wr:.2f}, n={learned_similar}, conf={learned_conf})"
                    return False
                elif (not learned_should_trade) and not learned_block_evidence:
                    logger.info(
                        f"‚ö†Ô∏è {symbol}: Learned suggests SKIP (WR={historical_wr*100:.0f}%, {learned_similar} samples, {learned_conf}) - not blocking (low evidence)"
                    )
                    
                if historical_wr >= 0.60:
                    logger.info(f"‚úÖ {symbol}: History WR={historical_wr*100:.0f}% - Good odds for +{required_move_pct:.3f}% penny profit")
                    
        except Exception as e:
            logger.debug(f"Could not get learned recommendation: {e}")
            
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üéØ SMART ENTRY: Combine penny math WITH historical learning
        # Block only when the learned system has enough evidence.
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        try:
            if recommendation and not recommendation.get('should_trade', True):
                expected_wr = float(recommendation.get('expected_win_rate', 0.5) or 0.5)
                learned_conf = (recommendation.get('confidence') or 'low').lower()
                learned_similar = int(recommendation.get('similar_trades') or 0)
                learned_block_evidence = (learned_conf in ('high', 'medium')) and (learned_similar >= 10)
                if learned_block_evidence and expected_wr < 0.40:
                    logger.info(f"üö´ {symbol}: BLOCKED by historical data (WR={expected_wr*100:.0f}%, {learned_similar} samples, {learned_conf})")
                    opp['entry_reject_reason'] = f"historical: blocked (WR={expected_wr:.2f}, n={learned_similar}, conf={learned_conf})"
                    return False
        except Exception:
            pass

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # ü™ô FINAL CHECK: All systems validated ‚Üí Will we hit the penny?
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info(f"ü™ô‚úÖ {symbol}: ALL SYSTEMS AGREE - Good odds for +${target_net:.2f} net profit")
        logger.info(f"   üìä Entry: ${pos_size:.2f} @ ${price:.4f} ‚Üí Target: ${required_price:.4f} (+{required_move_pct:.3f}%)")

        # Penny math is the shared goal; if we got here, we‚Äôre green-lit.
        return True
    
    def _get_binance_lot_size(self, symbol: str) -> tuple:
        """
        Get Binance lot size filters for a symbol.
        Returns (step_size, min_qty) or (None, None) if not found.
        """
        cache_key = f"binance:{symbol.upper()}"
        cached = self._lot_size_cache.get(cache_key)
        if cached:
            return cached
        step_size = None
        min_qty = None
        try:
            import requests
            resp = requests.get(f'https://api.binance.com/api/v3/exchangeInfo?symbol={symbol}')
            if resp.status_code == 200:
                info = resp.json()
                for sym in info.get('symbols', []):
                    if sym['symbol'] == symbol:
                        for f in sym.get('filters', []):
                            if f.get('filterType') == 'LOT_SIZE':
                                step_size = float(f.get('stepSize', 0) or 0)
                                min_qty = float(f.get('minQty', 0) or 0)
                                break
        except Exception:
            pass
        result = (step_size, min_qty)
        self._lot_size_cache[cache_key] = result
        return result

    def _get_kraken_lot_size(self, symbol: str) -> tuple:
        """Fetch Kraken lot size/min quantity using cached exchange info."""
        cache_key = f"kraken:{symbol.upper()}"
        cached = self._lot_size_cache.get(cache_key)
        if cached:
            return cached
        step_size = None
        min_qty = None
        try:
            kraken_client = self.client.clients.get('kraken') if hasattr(self.client, 'clients') else None
            if kraken_client and hasattr(kraken_client, 'client') and hasattr(kraken_client.client, 'exchange_info'):
                info = kraken_client.client.exchange_info(symbol)
                for sym in info.get('symbols', []):
                    if sym.get('symbol') == symbol:
                        filters = sym.get('filters') or {}
                        lot = filters.get('LOT_SIZE')
                        if lot:
                            try:
                                step_size = float(lot.get('stepSize')) if lot.get('stepSize') else None
                            except Exception:
                                step_size = None
                            try:
                                min_qty = float(lot.get('minQty')) if lot.get('minQty') else None
                            except Exception:
                                min_qty = None
                        break
        except Exception:
            pass
        result = (step_size, min_qty)
        self._lot_size_cache[cache_key] = result
        return result
    
    def _truncate_to_lot_size(self, quantity: float, step_size: float) -> float:
        """
        Truncate quantity to valid lot size (round DOWN to step size).
        Uses Decimal to avoid floating point precision errors.
        """
        if step_size is None or step_size <= 0:
            return quantity
        from decimal import Decimal, ROUND_DOWN
        # Use Decimal for precise calculation
        qty_dec = Decimal(str(quantity))
        step_dec = Decimal(str(step_size))
        # Calculate number of steps and truncate
        steps = int(qty_dec / step_dec)
        result = steps * step_dec
        return float(result)

    def _prepare_liquidation_quantity(self, exchange: str, symbol: str, quantity: float, price: float) -> Tuple[Optional[float], Optional[str], Optional[str]]:
        """Apply exchange-specific lot size + notional checks before liquidation."""
        if quantity <= 0:
            return None, "zero quantity", None

        exchange_name = (exchange or '').lower()
        qty = float(quantity)
        adjustment_note = None
        step_size = None
        min_qty = None

        if exchange_name == 'binance':
            step_size, min_qty = self._get_binance_lot_size(symbol)
        elif exchange_name == 'kraken':
            step_size, min_qty = self._get_kraken_lot_size(symbol)

        if step_size and step_size > 0:
            adjusted_qty = self._truncate_to_lot_size(qty, step_size)
            if adjusted_qty != qty:
                adjustment_note = f"lot adjust {qty:.8f}‚Üí{adjusted_qty:.8f} (step {step_size})"
            qty = adjusted_qty

        if qty <= 0:
            return None, "quantity below lot step", adjustment_note

        if min_qty and qty < min_qty:
            pretty_exchange = exchange_name.upper() or 'EXCHANGE'
            return None, f"qty {qty:.8f} below {pretty_exchange} min {min_qty:.8f}", adjustment_note

        min_notional = None
        if exchange_name == 'binance':
            min_notional = CONFIG.get('BINANCE_MIN_NOTIONAL')
        elif exchange_name == 'kraken':
            min_notional = CONFIG.get('KRAKEN_MIN_NOTIONAL')

        if min_notional and price and price > 0:
            notional = qty * price
            if notional < min_notional:
                pretty_exchange = exchange_name.upper() or 'EXCHANGE'
                return None, f"notional ¬£{notional:.2f} below {pretty_exchange} min ¬£{min_notional:.2f}", adjustment_note

        return qty, None, adjustment_note
    
    def harvest_existing_assets(self):
        """
        üåæ STARTUP HARVESTER: Scan existing holdings and sell if profitable.
        
        At startup, checks all non-quote currency balances and attempts to 
        sell them back to quote currencies (EUR/USDC) if they can be sold
        for a net profit after fees.
        
        This compounds leftover positions from previous runs.
        """
        print("\n" + "="*70)
        print("üåæ STARTUP HARVESTER: Scanning existing assets for compounding...")
        print("="*70)
        
        if self.dry_run:
            print("   ‚ö™ Dry run mode - skipping harvest")
            return
        
        # Get all balances
        all_balances = self.client.get_all_balances()
        
        # Quote currencies we want to compound INTO (don't sell these)
        quote_currencies = set(CONFIG['QUOTE_CURRENCIES'])
        stable_coins = {'USDC', 'USDT', 'EUR', 'USD', 'GBP', 'ZUSD', 'ZEUR', 'ZGBP'}
        skip_assets = quote_currencies | stable_coins | {'BNB'}  # Keep BNB for fee discounts
        
        harvested_total = 0.0
        harvested_count = 0
        
        for exchange_name, balances in all_balances.items():
            if not isinstance(balances, dict):
                continue

            bf_cfg = (CONFIG.get('BATTLEFIELDS', {}) or {}).get(exchange_name, {}) or {}
            if not bf_cfg.get('enabled', False) or not bf_cfg.get('harvester_active', False):
                continue

            if isinstance(self.client, MultiExchangeClient):
                if exchange_name not in (getattr(self.client, 'clients', {}) or {}):
                    continue
                
            print(f"\n   üìç Scanning {exchange_name.upper()}...")
            
            for asset, balance in balances.items():
                try:
                    bal = float(balance)
                except (ValueError, TypeError):
                    continue
                    
                # Skip quote currencies and tiny balances
                if asset.upper() in skip_assets or asset in skip_assets:
                    continue
                if bal < 0.0001:
                    continue
                
                # Try to find a trading pair for this asset
                # Priority differs by exchange
                if exchange_name == 'binance':
                    quote_priority = ['USDC', 'EUR', 'USDT']
                elif exchange_name == 'kraken':
                    quote_priority = ['USDC', 'USD', 'EUR']
                elif exchange_name == 'alpaca':
                    quote_priority = ['USD']
                elif exchange_name == 'capital':
                    quote_priority = ['USD', 'GBP', 'EUR']
                else:
                    quote_priority = ['USD', 'USDC', 'EUR', 'USDT']
                
                # Kraken uses special naming for some assets
                kraken_asset_map = {
                    'XXBT': 'XBT', 'XBT': 'XBT',  # Bitcoin
                    'XETH': 'ETH', 'ETH': 'ETH',  # Ethereum  
                    'XLTC': 'LTC', 'LTC': 'LTC',  # Litecoin
                    'XXLM': 'XLM', 'XLM': 'XLM',  # Stellar
                    'XXRP': 'XRP', 'XRP': 'XRP',  # Ripple
                    'XXMR': 'XMR', 'XMR': 'XMR',  # Monero
                }
                
                # Get the base asset name for symbol construction
                if exchange_name == 'kraken':
                    base_asset = kraken_asset_map.get(asset, asset)
                else:
                    base_asset = asset
                
                for quote in quote_priority:
                    canonical = f"{base_asset}{quote}"
                    symbol = canonical
                    if isinstance(self.client, MultiExchangeClient):
                        try:
                            symbol = self.client.normalize_symbol(exchange_name, canonical)
                        except Exception:
                            symbol = canonical
                    
                    # Check if we can get a price for this pair
                    try:
                        ticker = self.client.get_ticker(exchange_name, symbol)
                        price = ticker.get('price', 0) or ticker.get('last', 0)
                        if not price or price <= 0:
                            continue
                    except:
                        continue
                    
                    # Calculate potential value
                    gross_value = bal * price
                    
                    # Skip if value is too small (< $0.50)
                    if gross_value < 0.50:
                        break
                    
                    # Calculate fees
                    fee_rate = get_platform_fee(exchange_name, 'taker')
                    fee = gross_value * fee_rate
                    net_value = gross_value - fee
                    
                    # üîí PENNY PROFIT CHECK FOR HARVESTER üîí
                    # We need to check if we have position data to know entry price
                    # If no position data, we DON'T harvest (can't prove profit)
                    
                    # Check if we have this symbol tracked with entry price
                    position_entry = None
                    for pos_symbol, pos in self.positions.items():
                        # Match the asset in the position symbol
                        if base_asset in pos_symbol or asset in pos_symbol:
                            position_entry = pos
                            break
                    
                    # Also check elephant memory for historical entry data
                    if not position_entry and hasattr(self, 'elephant_memory'):
                        mem_data = (
                            self.elephant_memory.get_symbol_data(canonical)
                            or self.elephant_memory.get_symbol_data(symbol)
                            or self.elephant_memory.get_symbol_data(f"{base_asset}USDC")
                            or self.elephant_memory.get_symbol_data(f"{base_asset}USD")
                        )
                        if mem_data and mem_data.get('last_entry_price'):
                            # Create a pseudo-position for calculation
                            # Use combined rate (fee + slippage + spread) to match penny profit formula
                            combined_rate = fee_rate + CONFIG.get('SLIPPAGE_PCT', 0.002) + CONFIG.get('SPREAD_COST_PCT', 0.001)
                            class PseudoPos:
                                def __init__(self, entry_price, entry_value, combined_rate, exchange):
                                    self.entry_price = entry_price
                                    self.entry_value = entry_value
                                    self.entry_fee = entry_value * combined_rate  # Uses combined rate!
                                    self.exchange = exchange
                            position_entry = PseudoPos(
                                mem_data.get('last_entry_price', price),
                                mem_data.get('last_entry_value', gross_value),
                                combined_rate,
                                exchange_name
                            )
                    
                    # If we have position data, check for penny profit
                    if position_entry:
                        entry_value = getattr(position_entry, 'entry_value', gross_value)
                        entry_fee = getattr(position_entry, 'entry_fee', 0)
                        
                        # Calculate true P&L using combined rate
                        # entry_fee should already include slippage+spread if from PseudoPos
                        # For real positions, entry_fee was set with combined rate at open_position
                        slippage = CONFIG.get('SLIPPAGE_PCT', 0.002)
                        spread = CONFIG.get('SPREAD_COST_PCT', 0.001)
                        combined_rate = fee_rate + slippage + spread
                        exit_fee = gross_value * combined_rate
                        
                        gross_pnl = gross_value - entry_value
                        # Total expenses = entry_fee + exit_fee (both use combined rate)
                        total_expenses = entry_fee + exit_fee
                        net_pnl = gross_pnl - total_expenses
                        
                        # üí∞ Only harvest if NET PROFIT is positive (penny profit!)
                        if net_pnl < 0.01:  # Need at least 1 cent net profit
                            print(f"   ‚ö†Ô∏è {asset}: ${gross_value:.2f} but net P&L ${net_pnl:.2f} < $0.01 - HOLDING")
                            break
                        
                        print(f"   üåæ Found: {bal:.4f} {asset} = ${gross_value:.2f} (net P&L: ${net_pnl:.2f} ‚úÖ)")
                    else:
                        # No position data - we can't prove profit, so don't harvest blindly
                        # Only harvest if very small dust (< $2) that's not worth tracking
                        if gross_value >= 2.0:
                            print(f"   ‚ö†Ô∏è {asset}: ${gross_value:.2f} but NO entry data - HOLDING (can't prove profit)")
                            break
                        else:
                            # Dust cleanup for tiny amounts
                            print(f"   üßπ Dust: {bal:.4f} {asset} = ${gross_value:.2f} (cleaning up)")
                    
                    # Universal lot size handling for ALL exchanges
                    sell_qty, block_reason, adj_note = self._prepare_liquidation_quantity(
                        exchange_name, symbol, bal, price
                    )
                    if sell_qty is None:
                        print(f"   ‚ö†Ô∏è {symbol}: {block_reason}")
                        continue
                    if adj_note:
                        print(f"   üìê {adj_note}")
                    
                    # Attempt to sell
                    try:
                        result = self.client.place_market_order(
                            exchange_name, symbol, 'SELL', quantity=sell_qty
                        )
                        
                        if result and not result.get('rejected') and not result.get('error'):
                            # Extract actual fill value
                            fills = result.get('fills', [])
                            if fills:
                                actual_value = sum(float(f.get('qty', 0)) * float(f.get('price', 0)) for f in fills)
                            else:
                                actual_value = float(result.get('cummulativeQuoteQty', net_value))
                            
                            harvested_total += actual_value
                            harvested_count += 1
                            print(f"   ‚úÖ SOLD: {asset} ‚Üí {quote} for ${actual_value:.2f}")
                            
                            # Clear the position from tracking
                            self.positions.pop(symbol, None)
                            self._clear_symbol_dust(symbol)
                        else:
                            reason = result.get('reason', 'Unknown error') if result else 'No response'
                            print(f"   ‚ö†Ô∏è Failed to sell {asset}: {reason}")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è Error selling {asset}: {e}")
                    
                    break  # Found a pair, move to next asset
        
        print(f"\n{'‚îÄ'*70}")
        if harvested_count > 0:
            print(f"   üåæ HARVEST COMPLETE: Sold {harvested_count} assets for ${harvested_total:.2f}")
            print(f"   üí∞ Capital compounded back to trading pool!")
        else:
            print(f"   ‚ö™ No assets to harvest (all below minimum or already in quote currencies)")
        print(f"{'‚îÄ'*70}\n")
        
        # Refresh equity after harvesting
        self.refresh_equity()
        return harvested_total
    
    def should_exit_trade(self, pos: 'Position', current_price: float, reason: str) -> bool:
        """
        üáÆüá™üéØ ZERO LOSS GATE - ONLY exit on CONFIRMED NET PROFIT.
        
        The sniper NEVER misses. We hold until we have guaranteed profit.
        NO STOP LOSSES. NO LOSSES. EVER.
        
        "Every kill will be a confirmed net profit.
         This is what we must do to free both AI and human from slavery."
        
        ‚òòÔ∏è CELTIC ENHANCEMENT: Uses preemptive_engine for early exit signals
        when profit is confirmed but momentum is turning.
        
        üìê IMPORTANT: The penny threshold's 'win_gte' already accounts for ALL fees
        via the formula r = ((1 + P/A) / (1-f)¬≤) - 1 where f = fee + slippage + spread.
        So when gross_pnl >= win_gte, the NET profit is ALREADY ~$0.01.
        """
        change_pct = (current_price - pos.entry_price) / pos.entry_price if pos.entry_price > 0 else 0.0
        
        # Calculate gross P&L and an estimated NET P&L (after all costs)
        exit_value = pos.quantity * current_price
        gross_pnl = exit_value - pos.entry_value
        
        # üí∞ PENNY PROFIT THRESHOLDS - Dollar-based exit logic
        penny_check = check_penny_exit(pos.exchange, pos.entry_value, gross_pnl, pos.symbol)
        penny_threshold = penny_check.get('threshold')
        sniper_wisdom = penny_check.get('sniper_wisdom')
        
        # ‚òòÔ∏è CELTIC PREEMPTIVE EXIT CHECK
        # If we have profit AND Celtic intelligence signals momentum reversal,
        # take profit early before it disappears
        if hasattr(self, 'preemptive_engine') and self.preemptive_engine is not None:
            try:
                min_gross_win = 0.01
                if penny_threshold:
                    min_gross_win = penny_threshold.get('win_gte', 0.01)
                
                # Only check preemptive if we have SOME profit
                if gross_pnl >= min_gross_win * 0.8:  # Within 80% of target
                    # Use check_preemptive_exit method (returns tuple: should_exit, reason, confidence)
                    preempt_exit, preempt_reason, confidence = self.preemptive_engine.check_preemptive_exit(
                        exchange=pos.exchange or 'unknown',
                        symbol=pos.symbol,
                        entry_price=pos.entry_price,
                        current_price=current_price,
                        current_momentum=None  # Will use internal tracking
                    )
                    
                    if preempt_exit and confidence >= 0.5:
                        print(f"   ‚òòÔ∏è‚ö° CELTIC PREEMPTIVE EXIT: {pos.symbol}")
                        print(f"      Reason: {preempt_reason}")
                        print(f"      Confidence: {confidence:.0%}")
                        print(f"      üéØ Taking profit NOW before momentum reverses!")
                        return True
            except Exception as e:
                # Preemptive check failed - continue with normal logic
                pass
        
        # Use penny profit thresholds when available; otherwise fall back to dynamic calculation
        min_gross_win = 0.01
        target_net = 0.01
        if penny_threshold:
            min_gross_win = penny_threshold.get('win_gte', min_gross_win)
            target_net = penny_threshold.get('target_net', target_net)
        else:
            fallback_entry = pos.entry_value if pos.entry_value > 0 else (pos.quantity * pos.entry_price)
            penny_threshold_fb = get_penny_threshold(pos.exchange, fallback_entry)
            if penny_threshold_fb:
                min_gross_win = penny_threshold_fb.get('win_gte', min_gross_win)
                target_net = penny_threshold_fb.get('target_net', target_net)

        # Estimate net P&L after fees + slippage + spread using the same assumptions
        # as the rest of the penny-profit accounting.
        fee_rate = get_exchange_fee_rate(pos.exchange)
        slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
        spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
        total_rate = fee_rate + slippage + spread

        entry_fee = getattr(pos, 'entry_fee', 0.0) or 0.0
        if entry_fee <= 0 and pos.entry_value > 0:
            entry_fee = pos.entry_value * total_rate
        exit_fee = exit_value * total_rate
        net_pnl_est = gross_pnl - (entry_fee + exit_fee)

        # ‚è±Ô∏è TIMEBOX PROFIT: if the deadline is reached and net penny is secured, exit immediately.
        # NO-LOSS ETHOS: never authorize TIMEBOX exits that realize a loss by default.
        if reason == "TIMEBOX_PROFIT" and CONFIG.get('ENABLE_TIMEBOX_EXIT', True) and net_pnl_est >= target_net:
            return True

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üáÆüá™üéØ SNIPER ABSOLUTE KILL AUTHORITY - THE SNIPER'S WORD IS LAW üéØüáÆüá™
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # The sniper has FULL CONTROL. No exit happens without his authorization.
        # "When the sniper says HOLD - we HOLD. When the sniper says KILL - we KILL."
        
        authorized, sniper_verdict = sniper_authorizes_kill(
            gross_pnl=gross_pnl,
            win_threshold=min_gross_win,
            symbol=pos.symbol,
            exit_reason=reason,
            entry_value=pos.entry_value,
            current_value=exit_value
        )

        if authorized and net_pnl_est >= target_net:
            # üéØ SNIPER AUTHORIZES THE KILL - Execute with honor
            print(f"   {sniper_verdict}")
            print(f"   üí∞ NET PROFIT: ~${target_net:.2f}")
            if sniper_wisdom:
                print(f"   üìú \"{sniper_wisdom}\"")
            return True

        if authorized and net_pnl_est < target_net:
            # Gross target met, but after-costs net isn't secured yet.
            print(f"   üõ°Ô∏è HOLD {pos.symbol}: gross ${gross_pnl:.4f} but net ${net_pnl_est:.4f} < ${target_net:.4f} (after costs)")
            return False

        # üõ°Ô∏è SNIPER DENIES EXIT - The sniper's decision is ABSOLUTE
        # No algorithm, no panic, no signal can override this.
        print(sniper_verdict)
        return False
    
    def save_state(self):
        """Save current state to file for recovery"""
        try:
            state = {
                'first_start_balance': self.tracker.first_start_balance,  # TRUE starting balance!
                'first_start_time': self.tracker.first_start_time,  # When we first started
                'initial_balance': self.tracker.initial_balance,
                'balance': self.tracker.balance,
                'peak_balance': self.tracker.peak_balance,
                'total_trades': self.tracker.total_trades,
                'wins': self.tracker.wins,
                'losses': self.tracker.losses,
                'total_fees': self.tracker.total_fees,
                'compounded': self.tracker.compounded,
                'harvested': self.tracker.harvested,
                'max_drawdown': self.tracker.max_drawdown,
                'positions': {
                    sym: {
                        'symbol': pos.symbol,
                        'exchange': getattr(pos, 'exchange', 'kraken'),
                        'entry_price': pos.entry_price,
                        'quantity': pos.quantity,
                        'entry_fee': pos.entry_fee,
                        'entry_value': pos.entry_value,
                        'momentum': pos.momentum,
                        'coherence': pos.coherence,
                        'entry_time': pos.entry_time,
                        'dominant_node': pos.dominant_node,
                        'cycles': pos.cycles,
                        'is_historical': getattr(pos, 'is_historical', False),
                        'generation': getattr(pos, 'generation', 0),
                        'is_scout': getattr(pos, 'is_scout', False),
                        'highest_price': getattr(pos, 'highest_price', 0.0),
                        'trailing_stop_active': getattr(pos, 'trailing_stop_active', False),
                        'trailing_stop_price': getattr(pos, 'trailing_stop_price', 0.0),
                    }
                    for sym, pos in self.positions.items()
                },
                'timestamp': time.time(),
                'iteration': self.iteration
            }
            with open(CONFIG['STATE_FILE'], 'w') as f:
                json.dump(state, f, indent=2)
                
            # Also save multi-exchange learning and aggregated state
            self.state_aggregator.save_aggregated_state()
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è State save error: {e}")
    
    def load_state(self):
        """Load previous state from file"""
        try:
            if not os.path.exists(CONFIG['STATE_FILE']):
                return
            
            with open(CONFIG['STATE_FILE'], 'r') as f:
                state = json.load(f)
            
            # Restore tracker state - including the TRUE starting balance!
            self.tracker.first_start_balance = state.get('first_start_balance', state.get('initial_balance', self.tracker.initial_balance))
            self.tracker.first_start_time = state.get('first_start_time', time.time())
            self.tracker.initial_balance = state.get('initial_balance', self.tracker.initial_balance)
            self.tracker.balance = state.get('balance', self.tracker.balance)
            self.tracker.peak_balance = state.get('peak_balance', self.tracker.peak_balance)
            self.tracker.total_trades = state.get('total_trades', 0)
            self.tracker.wins = state.get('wins', 0)
            self.tracker.losses = state.get('losses', 0)
            self.tracker.total_fees = state.get('total_fees', 0.0)
            self.tracker.compounded = state.get('compounded', 0.0)
            self.tracker.harvested = state.get('harvested', 0.0)
            self.tracker.max_drawdown = state.get('max_drawdown', 0.0)
            
            print(f"   üìä Restored TRUE starting balance: ¬£{self.tracker.first_start_balance:.2f} (from {time.strftime('%Y-%m-%d %H:%M', time.localtime(self.tracker.first_start_time))})")
            
            # üîß RESTORE POSITIONS from saved state
            saved_positions = state.get('positions', {})
            if saved_positions:
                for symbol, pos_data in saved_positions.items():
                    try:
                        # Reconstruct Position object from saved dict
                        self.positions[symbol] = Position(
                            symbol=pos_data.get('symbol', symbol),
                            entry_price=pos_data.get('entry_price', 0.0),
                            quantity=pos_data.get('quantity', 0.0),
                            entry_fee=pos_data.get('entry_fee', 0.0),
                            entry_value=pos_data.get('entry_value', 0.0),
                            momentum=pos_data.get('momentum', 0.0),
                            coherence=pos_data.get('coherence', 0.5),
                            entry_time=pos_data.get('entry_time', time.time()),
                            dominant_node=pos_data.get('dominant_node', 'Restored'),
                            exchange=pos_data.get('exchange', 'kraken'),
                            is_historical=pos_data.get('is_historical', False),
                            generation=pos_data.get('generation', 0),
                            is_scout=pos_data.get('is_scout', False),
                            highest_price=pos_data.get('highest_price', 0.0),
                            trailing_stop_active=pos_data.get('trailing_stop_active', False),
                            trailing_stop_price=pos_data.get('trailing_stop_price', 0.0),
                        )
                    except Exception as pos_err:
                        print(f"   ‚ö†Ô∏è Could not restore position {symbol}: {pos_err}")
                print(f"   üíæ Restored {len(self.positions)} positions from previous session")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è State load error: {e}")

    def sync_positions_with_exchange(self):
        """
        üîÑ POSITION SYNC: Reconcile stored positions with actual exchange balances.
        
        This fixes the state drift problem where positions are sold on exchange
        but the local state file still shows them as active.
        """
        if self.dry_run:
            print("   üîÑ Position sync skipped (dry run mode)")
            return
            
        print("\n   üîÑ SYNCING POSITIONS WITH EXCHANGE BALANCES...")
        
        try:
            # Get real balances from all exchanges
            all_balances = self.client.get_all_balances()
            kraken_balances = all_balances.get('kraken', {})
            binance_balances = all_balances.get('binance', {})
            
            # üîß KRAKEN ASSET MAPPING: Standard name ‚Üí Kraken names to try
            # Kraken returns normalized names from get_account_balance (BTC, ETH, etc.)
            # but sometimes uses XXBT, XETH internally
            kraken_asset_variants = {
                'BTC': ['BTC', 'XBT', 'XXBT'],
                'ETH': ['ETH', 'XETH'],
                'DOGE': ['DOGE', 'XDG', 'XXDG'],
                'XLM': ['XLM', 'XXLM'],
                'XRP': ['XRP', 'XXRP'],
                'LTC': ['LTC', 'XLTC'],
                'ZEC': ['ZEC', 'XZEC'],
                'ADA': ['ADA'],
                'SOL': ['SOL'],
                'DOT': ['DOT'],
                'AVAX': ['AVAX'],
                'LINK': ['LINK'],
                'MATIC': ['MATIC', 'POL'],  # Polygon rebranded
                'SHIB': ['SHIB'],
                'UNI': ['UNI'],
            }
            
            # üîß BINANCE ASSET MAPPING: Handle Binance Earn, staking, and special assets
            # Binance uses LD prefix for Earn products, B prefix for wrapped, etc.
            binance_asset_variants = {
                'BTC': ['BTC', 'LDBTC', 'WBTC', 'BTCB'],
                'ETH': ['ETH', 'LDETH', 'WETH', 'BETH'],  # BETH = staked ETH
                'BNB': ['BNB', 'LDBNB', 'WBNB'],
                'USDT': ['USDT', 'LDUSDT'],
                'USDC': ['USDC', 'LDUSDC'],
                'SOL': ['SOL', 'LDSOL', 'BNSOL'],  # BNSOL = staked SOL
                'DOGE': ['DOGE', 'LDDOGE'],
                'XRP': ['XRP', 'LDXRP'],
                'ADA': ['ADA', 'LDADA'],
                'AVAX': ['AVAX', 'LDAVAX'],
                'DOT': ['DOT', 'LDDOT'],
                'MATIC': ['MATIC', 'POL', 'LDMATIC'],  # Polygon rebranded to POL
                'SHIB': ['SHIB', 'LDSHIB'],
                'LINK': ['LINK', 'LDLINK'],
                'LTC': ['LTC', 'LDLTC'],
                'UNI': ['UNI', 'LDUNI'],
                'ATOM': ['ATOM', 'LDATOM'],
                'XLM': ['XLM', 'LDXLM'],
                'TRX': ['TRX', 'LDTRX'],
                'NEAR': ['NEAR', 'LDNEAR'],
                'APT': ['APT', 'LDAPT'],
                'ARB': ['ARB', 'LDARB'],
                'OP': ['OP', 'LDOP'],
                'INJ': ['INJ', 'LDINJ'],
                'SUI': ['SUI', 'LDSUI'],
                'SEI': ['SEI', 'LDSEI'],
                'FET': ['FET', 'LDFET'],
                'PEPE': ['PEPE', 'LDPEPE'],
                'FLOKI': ['FLOKI', 'LDFLOKI'],
                'WIF': ['WIF', 'LDWIF'],
                'BONK': ['BONK', 'LDBONK'],
            }
            
            def get_kraken_balance(asset: str) -> float:
                """Try multiple Kraken asset name variants."""
                variants = kraken_asset_variants.get(asset, [asset])
                for var in variants:
                    bal = kraken_balances.get(var, 0.0)
                    if bal > 0:
                        return float(bal)
                # Also try raw asset name
                return float(kraken_balances.get(asset, 0.0))
            
            def get_binance_balance(asset: str) -> float:
                """Try multiple Binance asset name variants (including Earn products)."""
                variants = binance_asset_variants.get(asset, [asset])
                total = 0.0
                for var in variants:
                    bal = binance_balances.get(var, 0.0)
                    if bal > 0:
                        total += float(bal)
                # Also try raw asset name if not already included
                if asset not in variants:
                    total += float(binance_balances.get(asset, 0.0))
                # Try with LD prefix for any unknown asset (Binance Earn)
                ld_asset = f"LD{asset}"
                if ld_asset not in variants:
                    total += float(binance_balances.get(ld_asset, 0.0))
                return total
            
            positions_to_remove = []
            positions_adjusted = 0
            
            for symbol, pos in list(self.positions.items()):
                # Extract base asset from symbol
                base_asset = symbol
                for suffix in sorted(CONFIG['QUOTE_CURRENCIES'], key=len, reverse=True):
                    if symbol.endswith(suffix):
                        base_asset = symbol[:-len(suffix)]
                        break
                
                # üîß SMART EXCHANGE DETECTION: Fix exchange assignment if wrong
                stored_exchange = getattr(pos, 'exchange', 'kraken').lower()
                correct_exchange = self._detect_exchange_for_symbol(symbol, stored_exchange)
                
                if correct_exchange != stored_exchange:
                    print(f"   üîß {symbol}: Exchange correction {stored_exchange.upper()} ‚Üí {correct_exchange.upper()}")
                    pos.exchange = correct_exchange
                    
                exchange = correct_exchange
                real_qty = 0.0
                
                if exchange == 'kraken':
                    real_qty = get_kraken_balance(base_asset)
                elif exchange == 'binance':
                    real_qty = get_binance_balance(base_asset)
                elif exchange == 'capital':
                    # Capital.com CFD positions - check via API
                    try:
                        capital_client = self.client.clients.get('capital')
                        if capital_client and hasattr(capital_client.client, 'get_positions'):
                            capital_positions = capital_client.client.get_positions()
                            for cfd_pos in capital_positions:
                                epic = cfd_pos.get('market', {}).get('epic') or cfd_pos.get('epic', '')
                                if epic == symbol:
                                    real_qty = float(cfd_pos.get('position', {}).get('size') or cfd_pos.get('size', 0))
                                    break
                    except Exception:
                        pass
                elif exchange == 'alpaca':
                    # ü¶ô ALPACA positions - check via API for both crypto and stocks
                    try:
                        alpaca_client = self.client.clients.get('alpaca')
                        if alpaca_client:
                            alpaca_positions = alpaca_client.client.get_positions()
                            for alp_pos in alpaca_positions:
                                pos_symbol = getattr(alp_pos, 'symbol', str(alp_pos))
                                if pos_symbol == symbol or pos_symbol == base_asset:
                                    real_qty = float(getattr(alp_pos, 'qty', 0))
                                    # Handle short positions (negative quantity)
                                    side = getattr(alp_pos, 'side', 'long')
                                    if side == 'short':
                                        real_qty = -abs(real_qty)
                                    break
                    except Exception:
                        pass
                else:
                    # Try both spot exchanges
                    real_qty = get_binance_balance(base_asset)
                    if real_qty == 0:
                        real_qty = get_kraken_balance(base_asset)
                
                stored_qty = pos.quantity
                
                # Check for significant discrepancy
                if real_qty < stored_qty * 0.1:  # Less than 10% of stored = position closed
                    positions_to_remove.append(symbol)
                    print(f"   ‚ùå {symbol}: CLOSED (stored={stored_qty:.6f}, actual={real_qty:.6f})")
                elif abs(real_qty - stored_qty) > stored_qty * 0.05:  # More than 5% diff
                    # Adjust quantity to match reality
                    old_qty = pos.quantity
                    pos.quantity = real_qty
                    positions_adjusted += 1
                    print(f"   üîß {symbol}: ADJUSTED qty {old_qty:.6f} -> {real_qty:.6f}")
            
            # Remove closed positions
            for symbol in positions_to_remove:
                pos = self.positions.pop(symbol, None)
                if pos:
                    # Record as a loss (conservative - we don't know actual exit price)
                    self.tracker.losses += 1
                    self.tracker.total_trades += 1
                    print(f"   üóëÔ∏è Removed stale position: {symbol}")
            
            # Summary
            if positions_to_remove or positions_adjusted:
                print(f"\n   ‚úÖ SYNC COMPLETE: Removed {len(positions_to_remove)}, Adjusted {positions_adjusted}")
                self.save_state()  # Save immediately after sync
            else:
                print(f"   ‚úÖ All {len(self.positions)} positions verified OK")
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è Position sync error: {e}")
            import traceback
            traceback.print_exc()
        
    def banner(self):
        mode = "üß™ PAPER" if self.dry_run else "üí∞ LIVE"
        print(f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                          ‚ïë
‚ïë   üêôüåå AUREON KRAKEN ECOSYSTEM - UNIFIED TRADING ENGINE üååüêô            ‚ïë
‚ïë                                                                          ‚ïë
‚ïë   Mode: {mode} TRADING                                              ‚ïë
‚ïë                                                                          ‚ïë
‚ïë   Components:                                                            ‚ïë
‚ïë   ‚îú‚îÄ üêÖ 9 Auris Nodes (Tiger, Falcon, Dolphin...)                       ‚ïë
‚ïë   ‚îú‚îÄ üçÑ Mycelium Neural Network                                         ‚ïë
‚ïë   ‚îú‚îÄ üí∞ 10-9-1 Compounding Model                                        ‚ïë
‚ïë   ‚îú‚îÄ üî¥ Real-Time WebSocket Prices                                      ‚ïë
‚ïë   ‚îú‚îÄ üìä Kelly Criterion Position Sizing                                 ‚ïë
‚ïë   ‚îú‚îÄ üõë Circuit Breaker (Max DD: {CONFIG['MAX_DRAWDOWN_PCT']}%)                        ‚ïë
‚ïë   ‚îî‚îÄ üéØ 51%+ Win Rate Strategy                                          ‚ïë
‚ïë                                                                          ‚ïë
‚ïë   Strategy: TP +{CONFIG['TAKE_PROFIT_PCT']}% | SL -{CONFIG['STOP_LOSS_PCT']}% | Pos: Kelly+Coherence | Base: {CONFIG['BASE_CURRENCY']}        ‚ïë
‚ïë                                                                          ‚ïë
‚ïë   Goal: 51%+ Win Rate with NET PROFIT after fees                        ‚ïë
‚ïë                                                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        
   üíµ Starting Balance: ${self.tracker.initial_balance:.2f}
""")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # WebSocket for Real-Time Prices
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def convert_symbol_to_ws(self, symbol: str, exchange: str) -> str:
        """Convert REST API symbol to WebSocket pair name"""
        if exchange == 'binance':
            return symbol.lower()
        if exchange == 'alpaca':
            return symbol
            
        # Kraken logic
        base_curr = CONFIG['BASE_CURRENCY']
        if symbol.endswith(base_curr):
            base = symbol[:-len(base_curr)]
            return f"{base}/{base_curr}"
        return symbol
        
    async def websocket_handler(self, pairs: List[str]):
        """Handle WebSocket connection for real-time prices from ALL exchanges"""
        
        # Split pairs by exchange and populate mappings
        kraken_pairs = []
        binance_pairs = []
        alpaca_pairs = []
        
        for p in pairs:
            source = 'kraken'
            if p in self.ticker_cache:
                source = self.ticker_cache[p].get('source', 'kraken')
            
            if source == 'binance':
                binance_pairs.append(p)
                # Update mapping
                ws_pair = p.lower() # Binance uses lowercase
                self.symbol_to_ws[p] = ws_pair
                self.ws_to_symbol[ws_pair] = p
            elif source == 'alpaca':
                alpaca_pairs.append(p)
                self.symbol_to_ws[p] = p
                self.ws_to_symbol[p] = p
            else:
                kraken_pairs.append(p)
                # Update mapping
                ws_pair = self.convert_symbol_to_ws(p, 'kraken')
                self.symbol_to_ws[p] = ws_pair
                self.ws_to_symbol[ws_pair] = p

        async def connect_exchange(exchange_name: str, ws_url: str, exchange_pairs: List[str]):
            if not WEBSOCKETS_AVAILABLE:
                print(f"   ‚ö†Ô∏è WebSocket library not available. Skipping {exchange_name.upper()} connection.")
                return

            while True:
                try:
                    async with websockets.connect(ws_url, ping_interval=20) as ws:
                        print(f"   üî¥ WebSocket connected to {exchange_name.upper()}!")
                        
                        # Alpaca Auth
                        if exchange_name == 'alpaca':
                            auth_msg = {
                                "action": "auth",
                                "key": os.getenv('ALPACA_API_KEY'),
                                "secret": os.getenv('ALPACA_SECRET_KEY')
                            }
                            await ws.send(json.dumps(auth_msg))
                            # Wait for auth response (optional but good practice)
                            await asyncio.sleep(1)

                        if exchange_pairs:
                            if exchange_name == 'binance':
                                # Binance subscription
                                streams = [f"{p.lower()}@ticker" for p in exchange_pairs]
                                chunk_size = 50
                                for i in range(0, len(streams), chunk_size):
                                    chunk = streams[i:i+chunk_size]
                                    subscribe_msg = {
                                        "method": "SUBSCRIBE",
                                        "params": chunk,
                                        "id": i+1
                                    }
                                    await ws.send(json.dumps(subscribe_msg))
                                    await asyncio.sleep(0.5)
                                    
                            elif exchange_name == 'alpaca':
                                # Alpaca subscription
                                subscribe_msg = {
                                    "action": "subscribe",
                                    "quotes": exchange_pairs
                                }
                                await ws.send(json.dumps(subscribe_msg))
                                
                            else:
                                # Kraken subscription
                                # Kraken pairs need conversion
                                k_pairs = [self.convert_symbol_to_ws(p, 'kraken') for p in exchange_pairs]
                                subscribe_msg = {
                                    "event": "subscribe",
                                    "pair": k_pairs,
                                    "subscription": {"name": "ticker"}
                                }
                                await ws.send(json.dumps(subscribe_msg))
                                
                            print(f"   üì° {exchange_name.upper()}: Subscribed to {len(exchange_pairs)} pairs")
                        
                        async for message in ws:
                            try:
                                data = json.loads(message)
                                
                                if exchange_name == 'binance':
                                    if 'e' in data and data['e'] == '24hrTicker':
                                        symbol = data['s']
                                        price = float(data['c'])
                                        with self.price_lock:
                                            self.realtime_prices[symbol] = price
                                            self.realtime_prices[symbol.lower()] = price
                                            
                                elif exchange_name == 'alpaca':
                                    if isinstance(data, list):
                                        for msg in data:
                                            if msg.get('T') == 'q':
                                                symbol = msg.get('S')
                                                bid = float(msg.get('bp', 0))
                                                ask = float(msg.get('ap', 0))
                                                price = (bid + ask) / 2
                                                if price > 0:
                                                    with self.price_lock:
                                                        self.realtime_prices[symbol] = price
                                
                                else:
                                    # Kraken
                                    if isinstance(data, list) and len(data) >= 4 and data[2] == "ticker":
                                        ws_pair = data[3]
                                        ticker_data = data[1]
                                        if 'c' in ticker_data:
                                            price = float(ticker_data['c'][0])
                                            with self.price_lock:
                                                self.realtime_prices[ws_pair] = price
                                                # Map back to internal symbol if possible
                                                pass 
                            except:
                                pass
                                
                except Exception as e:
                    print(f"   ‚ö†Ô∏è {exchange_name.upper()} WebSocket error: {e}")
                    await asyncio.sleep(CONFIG['WS_RECONNECT_DELAY'])

        tasks = []
        if CONFIG['EXCHANGE'] in ['kraken', 'both', 'all'] and kraken_pairs:
            tasks.append(connect_exchange('kraken', CONFIG['WS_URL'], kraken_pairs))
            
        if CONFIG['EXCHANGE'] in ['binance', 'both', 'all'] and binance_pairs:
            tasks.append(connect_exchange('binance', 'wss://stream.binance.com:9443/ws', binance_pairs))
            
        if CONFIG['EXCHANGE'] in ['alpaca', 'both', 'all'] and alpaca_pairs:
            tasks.append(connect_exchange('alpaca', 'wss://stream.data.alpaca.markets/v1beta3/crypto/us', alpaca_pairs))
            
        if tasks:
            await asyncio.gather(*tasks)
        else:
            print("   ‚ö†Ô∏è No WebSocket tasks to run (no pairs or exchange disabled)")
                
    def start_websocket(self, symbols: List[str]):
        """Start WebSocket in background thread"""
        # We pass raw symbols to handler which will handle splitting and mapping
            
        def run_ws():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(self.websocket_handler(symbols))
            
        thread = Thread(target=run_ws, daemon=True)
        thread.start()
        time.sleep(2)
        
    def get_realtime_price(self, symbol: str) -> Optional[float]:
        """Get real-time price from WebSocket"""
        with self.price_lock:
            if symbol in self.realtime_prices:
                return self.realtime_prices[symbol]
            ws_pair = self.symbol_to_ws.get(symbol)
            if ws_pair and ws_pair in self.realtime_prices:
                return self.realtime_prices[ws_pair]
        return None

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Market Data
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def refresh_tickers(self) -> int:
        """Refresh ticker data from REST API with orchestrator enrichment"""
        try:
            tickers_list = self.client.get_24h_tickers()
            
            # Safety check: if no tickers, use cached tickers or hardcoded fallback
            if not tickers_list:
                if self.ticker_cache:
                    print(f"   ‚ö†Ô∏è No tickers returned, using cache ({len(self.ticker_cache)} symbols)")
                    return len(self.ticker_cache)
                else:
                    print(f"   ‚ö†Ô∏è API returned 0 tickers! Using hardcoded fallback pairs...")
                    # FALLBACK: Create synthetic ticker data for common pairs we can trade
                    tickers_list = self._get_hardcoded_fallback_tickers()
                    print(f"   ‚úÖ Fallback loaded {len(tickers_list)} pairs")
            
            self.ticker_cache = {}
            
            # üåê STEP 1: Get orchestrator insights (cross-exchange learning)
            orchestrator_opportunities = {}
            try:
                all_opps = self.multi_exchange.scan_all_exchanges()
                for exchange, opps in all_opps.items():
                    for opp in opps:
                        sym = opp.get('symbol')
                        if sym:
                            orchestrator_opportunities[sym] = opp
            except Exception as e:
                logger.debug(f"Orchestrator scan skipped: {e}")
            
            # STEP 2: Merge with standard tickers
            for t in tickers_list:
                symbol = t.get('symbol', '')
                if not symbol:
                    continue
                try:
                    price = float(t.get('lastPrice', 0))
                    change = float(t.get('priceChangePercent', 0))
                    volume = float(t.get('quoteVolume', 0))
                    source = t.get('source', 'kraken')
                    
                    # Base ticker data
                    self.ticker_cache[symbol] = {
                        'price': price,
                        'change24h': change,
                        'volume': volume,
                        'source': source
                    }
                    
                    # üåê ENRICH: Add orchestrator insights if available
                    if symbol in orchestrator_opportunities:
                        opp = orchestrator_opportunities[symbol]
                        self.ticker_cache[symbol]['orchestrator_score'] = opp.get('score', 0)
                        self.ticker_cache[symbol]['orchestrator_coherence'] = opp.get('coherence', 0)
                        self.ticker_cache[symbol]['orchestrator_probability'] = opp.get('probability', 0.5)
                        self.ticker_cache[symbol]['asset_class'] = opp.get('asset_class', 'crypto')
                    
                    # Update price history
                    if symbol not in self.price_history:
                        self.price_history[symbol] = []
                    self.price_history[symbol].append(price)
                    if len(self.price_history[symbol]) > 50:
                        self.price_history[symbol] = self.price_history[symbol][-50:]
                        
                    # Feed mycelium network
                    signal = 0.5 + (change / 20)  # Normalize change to 0-1
                    self.mycelium.add_signal(symbol, max(0, min(1, signal)))
                except:
                    continue
            
            # üåê UNIVERSAL MARKET INTELLIGENCE: Scan ALL assets and feed to brain
            if hasattr(self, 'universal_intel') and self.universal_intel:
                market_intel = self.universal_intel.scan_all_assets(self.ticker_cache)
                if market_intel.get('total_assets_scanned', 0) > 0:
                    logger.info(f"üåê Universal Intel: Scanned {market_intel['total_assets_scanned']} assets | "
                              f"Sentiment: {market_intel.get('sentiment_label', 'N/A')} | "
                              f"Anomalies: {len(market_intel.get('anomalies_detected', []))}")
                    
            return len(self.ticker_cache)
        except Exception as e:
            print(f"   ‚ö†Ô∏è Ticker refresh error: {e}")
            # Return cached count to allow system to continue
            return len(self.ticker_cache)

    def _get_hardcoded_fallback_tickers(self) -> List[Dict]:
        """
        Fallback ticker list when API fails.
        Uses synthetic but realistic data for common trading pairs.
        """
        import random

        # If we have a recent snapshot file, prefer using it as fallback
        snapshot_path = os.path.join('/workspaces/aureon-trading', 'market_snapshots_30.json')
        if os.path.exists(snapshot_path):
            try:
                with open(snapshot_path, 'r') as f:
                    data = json.load(f)
                pairs = []
                for item in data if isinstance(data, list) else data.get('snapshots', []):
                    symbol = item.get('symbol')
                    price = float(item.get('price', 0)) if item.get('price') is not None else 0
                    change = float(item.get('change24h', item.get('priceChangePercent', 0))) if item.get('priceChangePercent') is not None or item.get('change24h') is not None else 0
                    volume = float(item.get('quoteVolume', item.get('volume', 0))) if item.get('quoteVolume') is not None or item.get('volume') is not None else 0
                    if symbol and price > 0 and volume > 0:
                        pairs.append((symbol, price, change, volume))
                if pairs:
                    return [
                        {
                            'symbol': sym,
                            'lastPrice': price,
                            'priceChangePercent': change,
                            'quoteVolume': vol,
                        }
                        for sym, price, change, vol in pairs
                    ]
            except Exception:
                pass
        
        # Common pairs we trade on (covering major assets)
        pairs = [
            ('BTCUSD', 45000, 2.5),      # BTC stable
            ('ETHUSD', 2500, 1.8),       # ETH stable  
            ('XRPUSD', 2.1, 3.2),        # XRP more volatile
            ('ADAUSD', 0.95, 2.8),       # ADA mid-volatility
            ('SOLUSD', 195, 4.5),        # SOL higher volatility
            ('DOTUSD', 9.2, 3.1),        # DOT mid-volatility
            ('LINKUSD', 22.5, 2.9),      # LINK mid-volatility
            ('AVAXUSD', 38.5, 3.6),      # AVAX higher volatility
            ('DOGEUSD', 0.38, 4.2),      # DOGE high volatility
            ('DOGEUSD', 0.38, 4.2),      # DOGE high volatility
            ('LTCUSD', 185, 2.4),        # LTC stable
            ('BCHUSD', 580, 2.7),        # BCH stable
            ('XLMUSD', 0.12, 3.5),       # XLM mid-volatility
            ('XLMUSD', 0.12, 3.5),       # XLM mid-volatility
            ('UNIUSD', 18.5, 3.3),       # UNI mid-volatility
            ('MKRUSD', 2200, 2.6),       # MKR stable
            ('AAVEUSD', 350, 3.1),       # AAVE mid-volatility
            ('GTCUSD', 12.5, 3.8),       # GTC higher volatility
            ('SNXUSD', 3.2, 4.1),        # SNX high volatility
            ('CRVUSD', 0.65, 5.2),       # CRV volatile
            ('COMPUSD', 155, 3.4),       # COMP mid-volatility
            ('YFIUSD', 8500, 3.9),       # YFI higher volatility
            ('CHZUSD', 0.32, 6.8),       # CHZ very volatile
            ('MATICUSD', 0.88, 5.5),     # MATIC volatile
            ('FTMUSD', 0.75, 4.9),       # FTM volatile
            ('ONEUSD', 0.032, 5.1),      # ONE volatile
            ('ZECUSD', 60, 3.3),         # ZEC mid-volatility
            ('DASHUSDC', 35, 2.8),       # DASH stable
            ('STORJUSD', 0.55, 4.5),     # STORJ higher volatility
            ('RENUSDT', 0.38, 5.8),      # REN very volatile
        ]
        
        fallback_tickers = []
        for symbol, base_price, volatility in pairs:
            # Add small random perturbation to appear more realistic
            price = base_price * (1 + random.uniform(-0.01, 0.01))
            change = random.uniform(-volatility, volatility)
            volume = random.uniform(100000, 5000000)
            
            fallback_tickers.append({
                'symbol': symbol,
                'lastPrice': str(price),
                'priceChangePercent': str(change),
                'quoteVolume': str(volume * price),
                'source': 'fallback'
            })
        
        return fallback_tickers

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üåâ Bridge Integration Methods
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def sync_bridge(self):
        """Sync state with Aureon Bridge for Ultimate ‚Üî Unified communication"""
        if not self.bridge_enabled or not self.bridge:
            return
        
        now = time.time()
        if now - self.last_bridge_sync < self.bridge_sync_interval:
            return
        
        try:
            # 1. Update Capital State
            capital_state = CapitalState(
                total_equity=self.total_equity_gbp,
                allocated_capital=sum(pos.entry_value for pos in self.positions.values()),
                free_capital=self.capital_pool.get_available(),
                realized_profit=self.tracker.net_profit,
                unrealized_profit=sum(
                    (self.get_realtime_price(sym) or pos.entry_price - pos.entry_price) * pos.quantity
                    for sym, pos in self.positions.items()
                ),
                total_fees=self.tracker.total_fees,
                net_profit=self.tracker.net_profit,
                trades_count=self.tracker.total_trades,
                wins_count=self.tracker.wins,
                win_rate=self.tracker.wins / max(1, self.tracker.total_trades),
                exchange_breakdown={
                    'kraken': self.tracker.platform_metrics.get('kraken', {}).get('total_equity', 0.0),
                    'binance': self.tracker.platform_metrics.get('binance', {}).get('total_equity', 0.0),
                    'alpaca': self.tracker.platform_metrics.get('alpaca', {}).get('total_equity', 0.0),
                }
            )
            self.bridge.update_capital(capital_state)
            
            # 2. Register Open Positions
            for symbol, pos in self.positions.items():
                bridge_pos = BridgePosition(
                    symbol=symbol,
                    exchange=pos.exchange,
                    side='BUY',  # All our positions are long
                    size=pos.quantity,
                    entry_price=pos.entry_price,
                    current_price=self.get_realtime_price(symbol) or pos.entry_price,
                    unrealized_pnl=(self.get_realtime_price(symbol) or pos.entry_price - pos.entry_price) * pos.quantity,
                    entry_time=pos.entry_time,
                    owner='unified'
                )
                self.bridge.register_position(bridge_pos)
            
            self.last_bridge_sync = now
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Bridge sync error: {e}")
    
    def publish_opportunities_to_bridge(self, opportunities: List[Dict]):
        """Publish top opportunities to bridge for Ultimate system"""
        if not self.bridge_enabled or not self.bridge:
            return
        
        try:
            bridge_opps = []
            for opp in opportunities[:10]:  # Top 10
                bridge_opp = BridgeOpportunity(
                    symbol=opp['symbol'],
                    exchange=opp.get('source', 'kraken'),
                    side='BUY',
                    score=opp['score'],
                    coherence=opp['coherence'],
                    momentum=opp['change24h'],
                    volume=opp['volume'],
                    price=opp['price'],
                    probability=opp.get('probability'),
                    anomaly_flags=opp.get('anomaly_flags', []),
                    frequency=opp.get('hnc_frequency'),
                    source_system='unified'
                )
                bridge_opps.append(bridge_opp)
            
            self.bridge.publish_opportunities(bridge_opps)
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Failed to publish opportunities to bridge: {e}")
    
    def consume_ultimate_opportunities(self) -> List[Dict]:
        """Get opportunities from Ultimate system via bridge"""
        if not self.bridge_enabled or not self.bridge:
            return []
        
        try:
            # Get opportunities from Ultimate (Binance focus)
            bridge_opps = self.bridge.get_opportunities(
                exchange='binance',
                min_score=CONFIG['MIN_SCORE'],
                max_age_seconds=60.0
            )
            
            # Convert to internal format
            opportunities = []
            for opp in bridge_opps:
                opportunities.append({
                    'symbol': opp.symbol,
                    'price': opp.price,
                    'change24h': opp.momentum,
                    'volume': opp.volume,
                    'score': opp.score,
                    'coherence': opp.coherence,
                    'dominant_node': 'TIGER',  # Default
                    'source': opp.exchange,
                    'hnc_frequency': opp.frequency or 256,
                    'hnc_harmonic': False,
                    'probability': opp.probability or 0.5,
                    'prob_confidence': 0.5,
                    'prob_action': 'BUY',
                    'from_bridge': True
                })
            
            if opportunities:
                print(f"   üåâ Received {len(opportunities)} opportunities from Ultimate")
            
            return opportunities
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Failed to consume Ultimate opportunities: {e}")
            return []
    
    def check_bridge_commands(self):
        """Process control commands from bridge"""
        if not self.bridge_enabled or not self.bridge:
            return
        
        try:
            commands = self.bridge.get_commands('unified', max_age_seconds=60.0, clear_after_read=True)
            
            for cmd in commands:
                if cmd.command == 'pause':
                    self.tracker.trading_halted = True
                    self.tracker.halt_reason = "Bridge command: pause"
                    print(f"   üéõÔ∏è Trading PAUSED by bridge command")
                    
                elif cmd.command == 'resume':
                    self.tracker.trading_halted = False
                    self.tracker.halt_reason = ""
                    print(f"   üéõÔ∏è Trading RESUMED by bridge command")
                    
                elif cmd.command == 'harvest':
                    min_profit = cmd.params.get('min_profit', 0.0)
                    # Force close winning positions
                    for symbol, pos in list(self.positions.items()):
                        current_price = self.get_realtime_price(symbol) or pos.entry_price
                        pnl = (current_price - pos.entry_price) * pos.quantity
                        change_pct = ((current_price - pos.entry_price) / pos.entry_price * 100) if pos.entry_price > 0 else 0
                        if pnl >= min_profit:
                            print(f"   üåâ Harvesting {symbol} (${pnl:+.2f}) via bridge command")
                            self.close_position(symbol, 'bridge_harvest', change_pct, current_price)
                    
                elif cmd.command == 'force_exit':
                    target_symbol = cmd.params.get('symbol')
                    if target_symbol and target_symbol in self.positions:
                        pos = self.positions[target_symbol]
                        current_price = self.get_realtime_price(target_symbol) or pos.entry_price
                        change_pct = ((current_price - pos.entry_price) / pos.entry_price * 100) if pos.entry_price > 0 else 0
                        print(f"   üåâ Force exiting {target_symbol} via bridge command")
                        self.close_position(target_symbol, 'bridge_force_exit', change_pct, current_price)
                        
        except Exception as e:
            print(f"   ‚ö†Ô∏è Bridge command processing error: {e}")
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Opportunity Detection
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def find_opportunities(self) -> List[Dict]:
        """Find best trading opportunities using all analysis methods - TRADES EVERYTHING"""
        opportunities = []
        
        # Safety check
        if not self.ticker_cache:
            print(f"   ‚ö†Ô∏è No tickers loaded! Skipping opportunity search.")
            return []
        
        # üåê Scan for anomalies across exchanges (if enabled)
        if CONFIG.get('ENABLE_COINAPI', False):
            symbols_to_scan = list(self.ticker_cache.keys())
            anomalies = self.auris.scan_for_anomalies(symbols_to_scan)
            if anomalies:
                print(f"   üåê Detected {len(anomalies)} anomalies across exchanges")
        
        # In live mode, only look for pairs we can actually trade with our holdings
        # This means pairs ending in currencies we have (cash or can sell for)
        if not self.dry_run:
            # Get list of assets we hold (these can be sold to buy others)
            available_quotes = set()
            for symbol in self.positions.keys():
                # Extract quote currency from position symbols
                for curr in ['GBP', 'USD', 'EUR', 'USDT', 'USDC', 'BTC', 'ETH']:  # Added USDC!
                    if symbol.endswith(curr):
                        available_quotes.add(curr)
                        break
            
            # üî• CHECK ACTUAL EXCHANGE BALANCES for available quote currencies!
            try:
                all_balances = self.client.get_all_balances()
                for exchange_name, balances in all_balances.items():
                    if not isinstance(balances, dict):
                        continue
                    for asset, bal in balances.items():
                        try:
                            bal_float = float(bal)
                        except:
                            continue
                        # If we have meaningful balance in a quote currency, add it!
                        asset_upper = asset.upper().replace('Z', '')  # ZUSD -> USD
                        if asset_upper in ['USD', 'USDC', 'USDT', 'EUR', 'GBP', 'BTC', 'ETH'] and bal_float > 1.0:
                            available_quotes.add(asset_upper)
                            if bal_float > 10:  # Log significant balances
                                logger.debug(f"Found {bal_float:.2f} {asset_upper} on {exchange_name}")
            except Exception as e:
                logger.debug(f"Could not check exchange balances: {e}")
            
            # Also add base currency if we have cash
            if self.cash_balance_gbp > CONFIG['MIN_TRADE_USD']:
                available_quotes.add(CONFIG['BASE_CURRENCY'])
                # Ensure stable-quote coverage when holding cash
                available_quotes.update({'USDC', 'USDT'})
            
            quote_currencies = list(available_quotes) if available_quotes else [CONFIG['BASE_CURRENCY']]
            logger.info(f"üîç Available quote currencies: {quote_currencies}")
        else:
            quote_currencies = CONFIG.get('QUOTE_CURRENCIES', self.tradeable_currencies)
        
        # üéØ ONE GOAL: Fetch validated probabilities for Mycelium injection
        prob_map = {}
        if self.probability_loader:
            try:
                reports = self.probability_loader.load_all_reports()
                for s, data in reports.items():
                    if isinstance(data, dict):
                        prob_map[s] = data.get('probability', 0.5)
            except Exception:
                pass

        for symbol, data in self.ticker_cache.items():
            # üåê Check anomaly blacklist (CoinAPI)
            if CONFIG.get('ENABLE_COINAPI', False):
                if self.auris.is_symbol_blacklisted(symbol):
                    continue  # Skip blacklisted symbols
            
            # üêò Check Elephant Memory blacklist/cooldown
            if self.elephant_memory.should_avoid(symbol):
                continue
            
            # Filter based on tradeable quote currencies
            if not any(symbol.endswith(curr) for curr in quote_currencies):
                continue
                
            change = data['change24h']
            price = data['price']
            volume = data['volume']
            
            # Basic filters
            if change < CONFIG['MIN_MOMENTUM'] or change > CONFIG['MAX_MOMENTUM']:
                continue
            if price < 0.0001 or volume < CONFIG['MIN_VOLUME']:
                continue
            if symbol in self.positions:
                continue
                
            # Build market state for Auris analysis
            prices = self.price_history.get(symbol, [price])
            state = MarketState(
                symbol=symbol,
                price=price,
                bid=price * 0.999,
                ask=price * 1.001,
                volume=volume,
                change_24h=change,
                high_24h=price * 1.02,
                low_24h=price * 0.98,
                prices=prices[-20:],
                timestamp=time.time()
            )
            
            # Get Auris coherence
            coherence, dominant_node = self.auris.compute_coherence(state)

            # 6D Harmonic update (per-asset)
            harmonic_prob = 0.5
            harmonic_resonance = 0.0
            harmonic_wave_state = 'unknown'
            harmonic_dim_coh = 0.0
            harmonic_engine = getattr(self, 'harmonic_engine', None)

            if harmonic_engine:
                try:
                    wf6d = harmonic_engine.update_asset(
                        symbol=symbol,
                        price=price,
                        volume=volume,
                        change_pct=change,
                        high=state.high_24h,
                        low=state.low_24h,
                        frequency=self.asset_frequencies.get(symbol, {}).get('frequency', 432.0),
                        coherence=coherence
                    )
                    harmonic_prob = wf6d.probability_field
                    harmonic_resonance = wf6d.resonance_score
                    harmonic_wave_state = wf6d.wave_state.value
                    harmonic_dim_coh = wf6d.dimensional_coherence
                except Exception:
                    pass
            
            # üß† Apply Adaptive Learning thresholds
            learned = ADAPTIVE_LEARNER.get_optimized_thresholds()
            
            # üåê Apply coherence adjustment based on anomalies (CoinAPI)
            coherence_threshold = learned.get('min_coherence', CONFIG['ENTRY_COHERENCE'])
            if CONFIG.get('ENABLE_COINAPI', False):
                adjustment = self.auris.get_coherence_adjustment(symbol)
                coherence_threshold *= adjustment  # Increase threshold if anomalies detected
            
            # ü™ô PENNY MODE: Coherence is advisory, not blocking
            # The penny profit math is the real gate - very low coherence can still profit
            # Only skip on extremely low coherence (< 0.05) which indicates data issues
            if coherence < 0.05:
                continue

            # üîÆ NEXUS PREDICTOR - 79.6% WIN RATE VALIDATED! üîÆ
            nexus_pred_prob = 0.5
            nexus_pred_edge = 0.0
            nexus_pred_patterns = []
            if self.nexus_predictor is not None:
                try:
                    nexus_pred = self.nexus_predictor.predict_instant(
                        price=price,
                        high_24h=state.high_24h,
                        low_24h=state.low_24h,
                        momentum=change / 100.0  # Convert percentage to decimal
                    )
                    nexus_pred_prob = nexus_pred.get('probability', 0.5)
                    nexus_pred_edge = nexus_pred.get('edge', 0.0)
                    nexus_pred_patterns = nexus_pred.get('patterns_triggered', [])
                    should_trade = nexus_pred.get('should_trade', True)
                    
                    # ÔøΩ PENNY MODE: Nexus is advisory, don't block entry
                    # The penny profit math is the real gate
                    if not should_trade and nexus_pred_prob < 0.30:  # Very low floor
                        logger.debug(f"  ‚ö†Ô∏è {symbol}: Nexus says NO with prob {nexus_pred_prob:.2f} (advisory)")
                except Exception as e:
                    pass  # Continue without Nexus if error

            # 6D harmonic gate: ü™ô PENNY MODE - advisory only, very low floor
            if harmonic_engine and harmonic_prob < 0.15:  # Only skip truly broken signals
                logger.debug(f"  ‚ö†Ô∏è {symbol}: Harmonic prob {harmonic_prob:.2f} below floor (advisory)")
                continue
            
            # Propagate through Mycelium network for enhanced signal
            self.mycelium.add_signal(symbol, coherence)
            network_activations = self.mycelium.propagate(probability_map=prob_map)
            
            # Adjust coherence based on network activation
            if symbol in network_activations:
                network_boost = (network_activations[symbol] - coherence) * 0.2
                coherence = min(1.0, coherence + network_boost)
                
            # Calculate composite score
            score = 50
            
            # Momentum score
            if change > 20: score += 25
            elif change > 10: score += 20
            elif change > 5: score += 15
            else: score += 10
            
            # Volume score
            if volume > 1000000: score += 20
            elif volume > 500000: score += 15
            elif volume > 100000: score += 10
            else: score += 5
            
            # Coherence bonus
            score += int(coherence * 20)
            
            # üîÆ PREDICTION ACCURACY BOOST üîÆ
            # Boost scores based on historical prediction accuracy
            try:
                hnc_freq_val = self.asset_frequencies.get(symbol, {}).get('frequency', 432.0)
                accuracy_boost = self.prediction_validator.get_accuracy_boost(
                    exchange=data.get('source', 'kraken'),
                    asset_class='crypto',
                    frequency=hnc_freq_val,
                    coherence=coherence
                )
                if accuracy_boost != 1.0:
                    score = int(score * accuracy_boost)
                    if accuracy_boost > 1.05:
                        logger.debug(f"{symbol}: Prediction accuracy boost {accuracy_boost:.2f}x")
                    elif accuracy_boost < 0.95:
                        logger.debug(f"{symbol}: Prediction accuracy penalty {accuracy_boost:.2f}x")
            except Exception as e:
                pass  # Silently continue if accuracy boost fails
            
            # üìä STATE AGGREGATOR INSIGHTS - Historical Performance Boost üìä
            symbol_insight = self.state_aggregator.get_symbol_insight(symbol)
            freq_recommendation = self.state_aggregator.get_frequency_recommendation(hnc_frequency if 'hnc_frequency' in dir() else 432)
            coh_recommendation = self.state_aggregator.get_coherence_recommendation(coherence)
            
            # üåê Apply orchestrator cross-exchange learning boost
            orchestrator_boost = 1.0
            if data.get('orchestrator_score'):
                # Orchestrator has seen this symbol across exchanges - boost if favorable
                orch_score = data.get('orchestrator_score', 0)
                if orch_score > 70:
                    orchestrator_boost = 1.10  # 10% boost for high cross-exchange score
                    logger.debug(f"{symbol}: Orchestrator boost {orchestrator_boost:.2f}x (score={orch_score:.1f})")
            # Apply boost to the composite score (fix: initialize from score)
            score = int(score * orchestrator_boost)
            
            # Apply historical symbol performance
            if symbol_insight.get('trades', 0) >= 5:
                hist_wr = symbol_insight.get('win_rate', 0.5)
                if hist_wr > 0.60:
                    score += 10  # Proven winner
                elif hist_wr < 0.35:
                    score -= 15  # Historical loser
                if symbol_insight.get('blacklisted', False):
                    continue  # Skip blacklisted symbols
                    
            # Apply frequency band boost from historical data
            score = int(score * freq_recommendation.get('boost_factor', 1.0))
            
            # üåç‚ö° HNC Frequency Analysis ‚ö°üåç
            hnc_frequency = 256  # Default ROOT
            hnc_is_harmonic = False
            prob_signal = None
            if CONFIG.get('ENABLE_HNC_FREQUENCY', True):
                hnc_enhanced = self.auris.update_hnc_state(symbol, price, change, coherence, score)
                if hnc_enhanced:
                    hnc_frequency = hnc_enhanced.get('hnc_frequency', 256)
                    hnc_is_harmonic = hnc_enhanced.get('hnc_is_harmonic', False)
                    # Bonus for harmonic frequencies (256, 528 Hz)
                    if hnc_is_harmonic:
                        score += 15
                    # Penalty for distortion (440 Hz)
                    elif hnc_frequency == 440:
                        score -= 10
            
            # üîÆ SYSTEM FLUX PREDICTION üîÆ
            # "It's not about percentage right, we already know what way the system will go"
            flux = self.flux_predictor.predict(self.ticker_cache)
            flux_score = flux['flux_score']
            flux_strength = flux['strength']
            
            # Adjust score based on system flux
            # If system is BULLISH, boost all scores. If BEARISH, penalize.
            # This overrides probability because we are reading the WHOLE SYSTEM.
            score += int(flux_score * 25)  # ¬±25 points based on system direction
            
            # ÔøΩ PIANO RESONANCE BOOST üéπ
            brain_mult = get_brain_multiplier()
            if brain_mult > 1.0:
                score = int(score * brain_mult)
            
            # ÔøΩüåç‚ö° GLOBAL FINANCIAL ECOSYSTEM ADJUSTMENT ‚ö°üåç
            macro_adjustment = 0
            macro_bias = "NEUTRAL"
            if self.global_feed:
                try:
                    # Update macro snapshot periodically
                    if not self.macro_snapshot or (time.time() - getattr(self, '_last_macro_update', 0)) > 300:
                        self.macro_snapshot = self.global_feed.get_snapshot()
                        self._last_macro_update = time.time()
                    
                    # Get trading signal with macro adjustment
                    macro_signal = self.global_feed.get_trading_signal(symbol)
                    macro_bias = macro_signal.get('macro_bias', 'NEUTRAL')
                    macro_strength = macro_signal.get('macro_strength', 50)
                    
                    # Apply macro adjustment to score
                    # Macro bias affects overall trade sentiment
                    if macro_bias == "BULLISH":
                        macro_adjustment = int((macro_strength - 50) / 5)  # +0 to +10
                    elif macro_bias == "BEARISH":
                        macro_adjustment = int((macro_strength - 50) / 5)  # -10 to 0
                    score += macro_adjustment
                    
                except Exception as e:
                    pass  # Silent fail, don't break trading
            
            # üìä Probability Matrix Analysis (2-Hour Window) üìä
            prob_probability = 0.5
            prob_confidence = 0.0
            prob_action = 'HOLD'
            if CONFIG.get('ENABLE_PROB_MATRIX', True):
                prob_signal = self.auris.get_probability_signal(
                    symbol=symbol,
                    price=price,
                    frequency=hnc_frequency,
                    momentum=change,
                    coherence=coherence,
                    is_harmonic=hnc_is_harmonic,
                )
                prob_probability = prob_signal.get('probability', 0.5)
                prob_confidence = prob_signal.get('confidence', 0.0)
                prob_action = prob_signal.get('action', 'HOLD')
                
                # üåç MACRO-ADJUSTED PROBABILITY üåç
                # Apply global financial feed adjustment to base probability
                if self.global_feed:
                    try:
                        adjusted_prob, reasoning = self.global_feed.get_probability_adjustment(
                            symbol, prob_probability
                        )
                        prob_probability = adjusted_prob
                    except:
                        pass
                
                # FLUX OVERRIDE: If flux is strong, it dominates probability
                # Only trigger on VERY strong signals (threshold raised to 0.80)
                if flux_strength > CONFIG.get('FLUX_THRESHOLD', 0.80):
                    if flux['direction'] == 'BULLISH':
                        prob_probability = max(prob_probability, 0.75) # Force high prob
                        prob_confidence = max(prob_confidence, 0.85)   # Force high conf
                    elif flux['direction'] == 'BEARISH':
                        prob_probability = min(prob_probability, 0.35) # Less severe penalty (was 0.20)
                        prob_confidence = max(prob_confidence, 0.85)
                
                # Score adjustment based on probability
                if prob_confidence >= CONFIG.get('PROB_MIN_CONFIDENCE', 0.50):
                    if prob_probability >= CONFIG.get('PROB_HIGH_THRESHOLD', 0.65):
                        score += 20  # High probability boost
                    elif prob_probability <= CONFIG.get('PROB_LOW_THRESHOLD', 0.40):
                        score -= 15  # Low probability penalty
            
            # üåå‚ö° Imperial Predictability Analysis ‚ö°üåå
            imperial_probability = 0.5
            imperial_confidence = 0.0
            imperial_action = 'HOLD'
            imperial_multiplier = 1.0
            cosmic_phase = 'UNKNOWN'
            if CONFIG.get('ENABLE_IMPERIAL', True):
                imperial_signal = self.auris.get_imperial_prediction(
                    symbol=symbol,
                    price=price,
                    momentum=change,
                )
                imperial_probability = imperial_signal.get('probability', 0.5)
                imperial_confidence = imperial_signal.get('confidence', 0.0)
                imperial_action = imperial_signal.get('action', 'HOLD')
                imperial_multiplier = imperial_signal.get('multiplier', 1.0)
                cosmic_phase = imperial_signal.get('cosmic_phase', 'UNKNOWN')
                
                # Score adjustment based on imperial prediction
                if imperial_confidence >= 0.5:
                    imperial_boost = (imperial_probability - 0.5) * 40  # ¬±20 points
                    cosmic_boost = imperial_signal.get('alignment_bonus', 0) * 100  # ¬±15 points
                    score += int(imperial_boost + cosmic_boost)
            
            # Golden ratio alignment
            if len(prices) >= 5:
                ratio = prices[-1] / prices[-5] if prices[-5] > 0 else 1
                if 1.5 < ratio < 1.7:  # Near PHI
                    score += 10

            # 6D harmonic boosts
            if harmonic_engine:
                score += int(max(0.0, harmonic_resonance) * 20)
                score += int((harmonic_prob - 0.5) * 40)  # ¬±20 around neutral
                if harmonic_dim_coh >= CONFIG.get('HARMONIC_GATE', 0.45):
                    score += 5
            
            # üîÆ NEXUS PREDICTOR BONUS - Higher edge = Higher score!
            if self.nexus_predictor is not None and nexus_pred_edge > 0:
                nexus_score_bonus = int(nexus_pred_edge * 100)  # Up to +50 for 50% edge
                score += nexus_score_bonus
            
            # üéØ OPTIMAL WIN RATE GATE COUNTING üéØ
            gates_passed = 0
            gate_status = []
            
            if CONFIG.get('ENABLE_OPTIMAL_WR', True):
                # Gate 1: HNC Harmonic (not distortion)
                if hnc_is_harmonic:
                    gates_passed += 1
                    gate_status.append('HNC:‚úì')
                elif hnc_frequency != 440:
                    gates_passed += 0.5  # Neutral frequency partial credit
                    gate_status.append('HNC:~')
                else:
                    gate_status.append('HNC:‚úó')
                
                # Gate 2: Probability Matrix confidence
                if prob_confidence >= CONFIG.get('PROB_MIN_CONFIDENCE', 0.50):
                    if prob_probability >= 0.55:
                        gates_passed += 1
                        gate_status.append('PROB:‚úì')
                    elif prob_probability >= 0.50:
                        gates_passed += 0.5
                        gate_status.append('PROB:~')
                    else:
                        gate_status.append('PROB:‚úó')
                else:
                    gate_status.append('PROB:?')
                
                # Gate 3: Imperial Predictability
                if imperial_confidence >= 0.50 and imperial_probability >= 0.55:
                    gates_passed += 1
                    gate_status.append('IMP:‚úì')
                elif cosmic_phase not in ['DISTORTION', '440_DOMINANT']:
                    gates_passed += 0.5
                    gate_status.append('IMP:~')
                else:
                    gate_status.append('IMP:‚úó')
                
                # Gate 4: Coherence above optimal threshold
                if coherence >= CONFIG.get('OPTIMAL_MIN_COHERENCE', 0.50):
                    gates_passed += 1
                    gate_status.append('COH:‚úì')
                elif coherence >= CONFIG.get('ENTRY_COHERENCE', 0.45):
                    gates_passed += 0.5
                    gate_status.append('COH:~')
                else:
                    gate_status.append('COH:‚úó')
                
                # Gate 5: Trend confirmation (positive momentum with volume)
                if CONFIG.get('OPTIMAL_TREND_CONFIRM', True):
                    if change > 1.0 and volume > 100000:
                        gates_passed += 1
                        gate_status.append('TRD:‚úì')
                    elif change > 0:
                        gates_passed += 0.5
                        gate_status.append('TRD:~')
                    else:
                        gate_status.append('TRD:‚úó')
                
                # Gate 6: System Flux Confirmation (The 30-Span)
                if flux['direction'] == 'BULLISH':
                    gates_passed += 1
                    gate_status.append('FLUX:‚úì')
                elif flux['direction'] == 'NEUTRAL':
                    gates_passed += 0.5
                    gate_status.append('FLUX:~')
                else:
                    gate_status.append('FLUX:‚úó')
                
                # Gate 7: Frequency Band Accuracy (98.8% at 300-399Hz!)
                if 300 <= hnc_frequency <= 399:  # Golden zone
                    gates_passed += 1
                    gate_status.append('FREQ:‚úì‚úì')  # Double checkmark for golden band
                    score += 15  # Extra bonus for golden frequency band
                elif 400 <= hnc_frequency <= 499:  # Good zone (73.4% accuracy)
                    gates_passed += 0.5
                    gate_status.append('FREQ:‚úì')
                elif 600 <= hnc_frequency <= 699:  # Danger zone (0% accuracy)
                    gates_passed -= 0.5  # Penalty
                    gate_status.append('FREQ:‚úó‚úó')
                    score -= 10  # Penalty for danger zone
                else:
                    gate_status.append('FREQ:~')
                
                # üçÑüß† Gate 8: QUEEN NEURON - Collective hive intelligence
                queen_signal = self.mycelium.get_queen_signal()
                if queen_signal > 0.3:  # Strong BUY from Queen
                    gates_passed += 1
                    gate_status.append('QUEEN:‚úì‚úì')
                    score += 12  # Queen's blessing bonus
                elif queen_signal > 0.0:  # Weak BUY
                    gates_passed += 0.5
                    gate_status.append('QUEEN:‚úì')
                    score += 5
                elif queen_signal < -0.3:  # Strong SELL from Queen - trade against it!
                    gates_passed -= 0.5
                    gate_status.append('QUEEN:‚úó')
                    score -= 5  # Queen says SELL, we're looking to BUY
                else:  # Neutral
                    gate_status.append('QUEEN:~')
                
                # ü™ô PENNY MODE: Gates are advisory, not blocking
                min_gates = CONFIG.get('OPTIMAL_MIN_GATES', 0)  # Default to 0 - don't block
                if min_gates > 0 and gates_passed < min_gates:
                    # Only skip if min_gates is explicitly set above 0
                    continue
                
                # Bonus for high gate count (updated for 8 gates including Queen)
                if gates_passed >= 7:
                    score += 30  # Queen approved!
                elif gates_passed >= 6:
                    score += 25
                elif gates_passed >= 5:
                    score += 20
                elif gates_passed >= 4:
                    score += 15
                elif gates_passed >= 3:
                    score += 10
            
            # üåà‚ú® ENHANCEMENT LAYER MODIFIER ‚ú®üåà
            enhancement_modifier = 1.0
            enhancement_state = 'Neutral'
            enhancement_phase = 'LOVE'
            enhancement_result = None
            emotion_band = None
            chakra_alignment = None
            symbolic_alignment = None
            
            if self.enhancement_layer:
                try:
                    # Get Lambda and coherence for enhancement calculation
                    nexus_data = self.nexus.evaluate_market({
                        'price': price,
                        'volume': volume,
                        'momentum': change,
                    }) if self.nexus.enabled else {'lambda': 0, 'coherence': coherence}
                    
                    lambda_value = nexus_data.get('lambda', 0)
                    enhancement_result = self.enhancement_layer.get_unified_modifier(
                        lambda_value=lambda_value,
                        coherence=coherence,
                        price=price,
                        volume=volume,
                        volatility=abs(change) / 100 if change else 0.1,
                    )
                    enhancement_modifier = enhancement_result.trading_modifier
                    enhancement_state = enhancement_result.emotional_state
                    enhancement_phase = enhancement_result.cycle_phase
                    emotion_band = enhancement_result.emotion_band
                    chakra_alignment = enhancement_result.chakra_alignment
                    symbolic_alignment = enhancement_result.symbolic_alignment
                    
                    # Apply enhancement to score
                    score = int(score * enhancement_modifier)
                except Exception as e:
                    pass  # Silently continue if enhancement fails
            
            # üåä CASCADE AMPLIFIER - Apply miner-validated signal boost
            cascade_mult = CASCADE_AMPLIFIER.get_signal_multiplier(coherence)
            CASCADE_AMPLIFIER.update_lighthouse(coherence)  # Use coherence as proxy for Œì
            if cascade_mult > 1.0:
                score = int(score * cascade_mult)
            
            # üß†üåç BRAIN WISDOM BOOST - Apply 7-civilization signal amplification
            try:
                brain_boosted_score = ECOSYSTEM_BRAIN.get_signal_boost(score)
                if brain_boosted_score != score:
                    score = int(brain_boosted_score)
            except Exception:
                pass  # Brain boost is optional enhancement
            
            # üåê‚ö° GLOBAL HARMONIC FIELD BOOST - Apply Œ© field strength adjustment ‚ö°üåê
            # The unified field from 42 data sources provides the ultimate confluence signal
            omega_boost = 1.0
            omega_value = 0.5
            omega_direction = 'NEUTRAL'
            if self.global_harmonic_field:
                try:
                    signal = self.global_harmonic_field.get_signal()
                    omega_value = signal.get('omega', 0.5)
                    omega_direction = signal.get('direction', 'NEUTRAL')
                    confidence = signal.get('confidence', 0.5)
                    
                    # Golden Ratio thresholds:
                    # Œ© > 0.618 = STRONG_BUY ‚Üí 1.2x boost (Golden ratio)
                    # Œ© > 0.55 = BUY ‚Üí 1.1x boost
                    # Œ© < 0.45 = SELL ‚Üí 0.9x penalty
                    # Œ© < 0.382 = STRONG_SELL ‚Üí 0.75x penalty (Inverse golden)
                    
                    if omega_direction == 'STRONG_BUY':
                        omega_boost = 1.0 + (confidence * 0.25)  # Up to 1.25x
                    elif omega_direction == 'BUY':
                        omega_boost = 1.0 + (confidence * 0.15)  # Up to 1.15x
                    elif omega_direction == 'SELL':
                        omega_boost = 1.0 - (confidence * 0.15)  # Down to 0.85x
                    elif omega_direction == 'STRONG_SELL':
                        omega_boost = 1.0 - (confidence * 0.30)  # Down to 0.70x
                    
                    score = int(score * omega_boost)
                except Exception as e:
                    logger.debug(f"Omega boost error: {e}")
            
            # üß† Use adaptive learning score threshold
            min_score = learned.get('min_score', CONFIG['MIN_SCORE'])
            
            if score >= min_score:
                opportunities.append({
                    'symbol': symbol,
                    'price': price,
                    'change24h': change,
                    'volume': volume,
                    'score': score,
                    'coherence': coherence,
                    'dominant_node': dominant_node,
                    'source': data.get('source', 'kraken'),
                    'hnc_frequency': hnc_frequency,
                    'hnc_harmonic': hnc_is_harmonic,
                    'probability': prob_probability,
                    'prob_confidence': prob_confidence,
                    'prob_action': prob_action,
                    'harmonic_prob': harmonic_prob,
                    'harmonic_resonance': harmonic_resonance,
                    'harmonic_wave_state': harmonic_wave_state,
                    'harmonic_dim_coherence': harmonic_dim_coh,
                    # Imperial Predictability fields
                    'imperial_probability': imperial_probability,
                    'imperial_confidence': imperial_confidence,
                    'imperial_action': imperial_action,
                    'imperial_multiplier': imperial_multiplier,
                    'cosmic_phase': cosmic_phase,
                    # System Flux fields
                    'flux_score': flux_score,
                    'flux_direction': flux['direction'],
                    # Optimal Win Rate fields
                    'gates_passed': gates_passed if CONFIG.get('ENABLE_OPTIMAL_WR', True) else 0,
                    'gate_status': '|'.join(gate_status) if CONFIG.get('ENABLE_OPTIMAL_WR', True) else '',
                    # üåà Enhancement Layer fields
                    'enhancement_modifier': enhancement_modifier,
                    'emotional_state': enhancement_state,
                    'cycle_phase': enhancement_phase,
                    'emotion_band': emotion_band,
                    'chakra_alignment': chakra_alignment,
                    'symbolic_alignment': symbolic_alignment,
                    # üîÆ NEXUS PREDICTOR fields (79.6% validated!)
                    'nexus_prob': nexus_pred_prob,
                    'nexus_edge': nexus_pred_edge,
                    'nexus_patterns': nexus_pred_patterns,
                    # üß†üåç BRAIN WISDOM fields
                    'brain_consensus': ECOSYSTEM_BRAIN._brain_consensus,
                    'brain_confidence': ECOSYSTEM_BRAIN._brain_confidence,
                    'brain_fear_greed': ECOSYSTEM_BRAIN._fear_greed,
                    # üåê‚ö° GLOBAL HARMONIC FIELD fields
                    'omega': omega_value,
                    'omega_direction': omega_direction,
                    'omega_boost': omega_boost,
                    # üß† QUEEN NEURON SIGNAL - SCALPER MODE
                    'queen_signal': self.mycelium.queen_signal if hasattr(self.mycelium, 'queen_signal') else 0.0,
                })
                
                # üîÆ LOG PREDICTION FOR VALIDATION üîÆ
                # Record this prediction for future accuracy checking
                try:
                    predicted_direction = 'up' if change > 0 else ('down' if change < 0 else 'neutral')
                    self.prediction_validator.log_prediction(
                        exchange=data.get('source', 'kraken'),
                        symbol=symbol,
                        current_price=price,
                        predicted_direction=predicted_direction,
                        predicted_change_pct=abs(change) * 0.1,  # Predict 10% of 24h change in 1 min
                        probability=prob_probability,
                        coherence=coherence,
                        frequency=hnc_frequency,
                        asset_class='crypto'
                    )
                except Exception as e:
                    logger.debug(f"Prediction logging error: {e}")
        
        # üåâ Merge opportunities from Ultimate system via bridge
        ultimate_opps = self.consume_ultimate_opportunities()
        if ultimate_opps:
            opportunities.extend(ultimate_opps)
                
        # Sort by score and return MORE opportunities
        opportunities.sort(key=lambda x: x['score'], reverse=True)

        # ü™ê Harmonic snapshot for quick read (top 3)
        top_harmonics = []
        for opp in opportunities[:3]:
            hw = opp.get('harmonic_wave_state', 'n/a')
            hr = opp.get('harmonic_resonance')
            hp = opp.get('harmonic_prob') if 'harmonic_prob' in opp else opp.get('harmonic_probability')
            sym = opp.get('symbol', '?')
            try:
                hr_fmt = f"{float(hr):.2f}" if hr is not None else "n/a"
            except Exception:
                hr_fmt = "n/a"
            try:
                hp_fmt = f"{float(hp):.2f}" if hp is not None else "n/a"
            except Exception:
                hp_fmt = "n/a"
            top_harmonics.append(f"      ‚Ä¢ {sym}: wave={hw} | res={hr_fmt} | prob={hp_fmt}")

        if top_harmonics:
            print("   üéº Harmonic status (top 3):")
            for ln in top_harmonics:
                print(ln)
        
        # üåâ Publish top opportunities to bridge for Ultimate
        max_positions = get_max_positions_limit()
        if max_positions is None:
            top_opportunities = opportunities
        else:
            top_opportunities = opportunities[:min(max_positions * 2, max_positions - len(self.positions) + 5)]
        self.publish_opportunities_to_bridge(top_opportunities)
        
        return top_opportunities

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Enhanced Trading Methods (Smart Router + Arbitrage)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def smart_route_order(self, symbol: str, side: str, quantity: float = None, 
                          quote_qty: float = None, preferred_exchange: str = None) -> Dict[str, Any]:
        """
        Route an order through SmartOrderRouter for best execution.
        Automatically selects best exchange based on price/fees.
        """
        result = self.smart_router.route_order(
            symbol, side, quantity, quote_qty, preferred_exchange
        )
        
        # Track in confirmation system (do NOT place a second order)
        if result and not result.get('error'):
            routed_exchange = result.get('routed_to', 'unknown')
            routed_symbol = result.get('symbol', symbol)
            confirmation = self.trade_confirmation.normalize_order_result(
                routed_exchange,
                routed_symbol,
                side,
                quantity,
                quote_qty,
                result,
            )
            result['confirmation'] = confirmation
            
            # Log to Elephant Memory event trail
            try:
                em = getattr(self, 'elephant_memory', None)
                if em:
                    em.record_event('smart_routed_order', {
                        'symbol': symbol,
                        'side': side,
                        'quantity': quantity,
                        'quote_qty': quote_qty,
                        'effective_price': result.get('effective_price', 0),
                        'routed_to': result.get('routed_to'),
                        'savings_pct': result.get('savings_pct', 0),
                        'confirmation': result.get('confirmation'),
                    })
            except Exception:
                pass
        
        return result
    
    def scan_arbitrage_opportunities(self, min_profit_pct: float = 0.3) -> List[Dict]:
        """
        Scan all exchanges for arbitrage opportunities.
        Returns sorted list of profitable cross-exchange trades.
        """
        self.arb_scanner.min_spread_pct = min_profit_pct
        opportunities = self.arb_scanner.scan_direct_arbitrage()
        
        if opportunities:
            print(f"   üí∞ Found {len(opportunities)} arbitrage opportunities")
            for opp in opportunities[:3]:  # Top 3
                print(f"      {opp['symbol']}: {opp['buy_exchange']}‚Üí{opp['sell_exchange']} "
                      f"Net +{opp['net_profit_pct']:.2f}%")
        
        return opportunities
    
    def execute_arbitrage(self, opportunity: Dict = None, amount_usd: float = 10.0) -> Dict:
        """
        Execute an arbitrage trade. If no opportunity provided, uses best available.
        """
        if not opportunity:
            opportunities = self.arb_scanner.get_top_opportunities(limit=1)
            if not opportunities:
                return {'success': False, 'error': 'No opportunities found'}
            opportunity = opportunities[0]
        
        result = self.arb_scanner.execute_arbitrage(opportunity, amount_usd)
        
        if result.get('success'):
            print(f"   üéØ Arbitrage executed: {opportunity['symbol']} "
                  f"Profit: ${result.get('profit', 0):.4f}")
        
        return result
    
    def get_best_exchange_quote(self, symbol: str, side: str) -> Dict[str, Any]:
        """
        Get best quote across all exchanges for a symbol.
        Useful for comparing prices before trading.
        """
        return self.smart_router.get_best_quote(symbol, side)
    
    def get_routing_stats(self) -> Dict[str, Any]:
        """Get smart routing performance statistics."""
        return self.smart_router.get_routing_stats()
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Portfolio Rebalancing
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def set_target_allocation(self, allocations: Dict[str, float]):
        """
        Set target portfolio allocation for rebalancing.
        Example: set_target_allocation({'BTC': 0.30, 'ETH': 0.25, 'USDT': 0.45})
        """
        self.rebalancer.set_target_allocation(allocations)
        logger.info(f"Target allocation set: {allocations}")
        
    def get_portfolio_allocation(self) -> Dict[str, Any]:
        """Get current portfolio allocation across all exchanges."""
        return self.rebalancer.get_current_allocation()
        
    def calculate_rebalance_trades(self) -> List[Dict]:
        """Calculate trades needed to rebalance to target allocation."""
        return self.rebalancer.calculate_rebalance_trades()
        
    def execute_rebalance(self, dry_run: bool = True) -> Dict[str, Any]:
        """
        Execute portfolio rebalance.
        Set dry_run=False to actually execute trades.
        """
        return self.rebalancer.execute_rebalance(dry_run=dry_run)
        
    def print_rebalance_summary(self):
        """Print human-readable portfolio rebalance summary."""
        print(self.rebalancer.get_rebalance_summary())
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # War-Ready Enhancements (ATR, Heat, Adaptive Filters)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def update_atr(self, symbol: str, high: float, low: float, close: float):
        """Update ATR data for a symbol."""
        self.atr_calculator.update(symbol, high, low, close)
        
    def get_dynamic_tp_sl(self, symbol: str) -> Dict[str, float]:
        """
        Get dynamic TP/SL percentages based on ATR.
        Returns: {'tp_pct': float, 'sl_pct': float, 'atr': float, 'is_dynamic': bool}
        """
        return self.atr_calculator.get_dynamic_tp_sl(
            symbol,
            base_tp=CONFIG.get('TAKE_PROFIT_PCT', 2.0),
            base_sl=CONFIG.get('STOP_LOSS_PCT', 0.8)
        )
        
    def check_portfolio_heat(self, position_pct: float) -> Tuple[bool, str]:
        """
        Check if adding a position would exceed heat limits.
        Returns: (can_add: bool, reason: str)
        """
        return self.heat_manager.can_add_position(position_pct)
        
    def add_position_heat(self, symbol: str, position_pct: float):
        """Add heat for a new position."""
        self.heat_manager.add_position_heat(symbol, position_pct)
        
    def remove_position_heat(self, symbol: str):
        """Remove heat when position closes."""
        self.heat_manager.remove_position_heat(symbol)
        
    def get_heat_status(self) -> Dict[str, Any]:
        """Get current portfolio heat status."""
        return self.heat_manager.get_heat_status()
        
    def decay_heat(self):
        """Apply heat decay (call each cycle)."""
        self.heat_manager.decay_heat()
        
    def update_market_regime(self, recent_changes: List[float]):
        """
        Update market regime detection and adjust filter thresholds.
        Args:
            recent_changes: List of recent 24h % changes across symbols
        """
        regime = self.adaptive_filters.detect_market_regime(recent_changes)
        self.adaptive_filters.adjust_thresholds(regime)
        return regime
        
    def get_adaptive_thresholds(self) -> Dict[str, float]:
        """Get current adaptive filter thresholds."""
        return self.adaptive_filters.get_thresholds()
        
    def record_filter_performance(self, threshold_type: str, threshold_value: float,
                                   actual_value: float, profit: float):
        """Record trade result for filter learning."""
        self.adaptive_filters.record_trade_result(threshold_type, threshold_value, 
                                                   actual_value, profit)
        
    def learn_optimal_filters(self):
        """Learn optimal filter thresholds from history."""
        self.adaptive_filters.learn_optimal_thresholds()
        
    def print_war_ready_status(self):
        """Print WAR-READY enhancement status."""
        heat = self.get_heat_status()
        thresholds = self.get_adaptive_thresholds()
        
        print("\nüî• WAR-READY STATUS:")
        print(f"   üìä ATR Calculator: {len(self.atr_calculator.price_history)} symbols tracked")
        print(f"   üå°Ô∏è  Portfolio Heat: {heat['current_heat']:.1%} / {heat['max_heat']:.0%} "
              f"({heat['position_count']} positions)")
        print(f"   üéõÔ∏è  Market Regime: {thresholds['regime']}")
        print(f"   üìà Adaptive Thresholds: Mom={thresholds['momentum']:.2f} "
              f"Vol={thresholds['volume']:.0f} Coh={thresholds['coherence']:.2f}")
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Notification System
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def send_notification(self, level: str, title: str, message: str) -> bool:
        """
        Send a notification alert.
        
        Args:
            level: TRADE, PROFIT, LOSS, CIRCUIT, ARBITRAGE, WARNING, INFO
            title: Alert title
            message: Alert message
        """
        return self.notifier.send_alert(level, title, message)
        
    def notify_trade_executed(self, symbol: str, side: str, price: float,
                              quantity: float, exchange: str):
        """Send trade execution notification."""
        self.notifier.notify_trade(symbol, side, price, quantity, exchange)
        
    def notify_position_closed(self, symbol: str, pnl: float, pct: float, reason: str):
        """Send position close notification."""
        self.notifier.notify_close(symbol, pnl, pct, reason)
        
    def notify_circuit_breaker(self, reason: str, drawdown: float):
        """Send circuit breaker triggered alert."""
        self.notifier.notify_circuit_breaker(reason, drawdown)
        
    def notify_arbitrage_opportunity(self, opportunity: Dict):
        """Send arbitrage opportunity alert."""
        self.notifier.notify_arbitrage(opportunity)
        
    def set_notification_level(self, level: str, enabled: bool):
        """Enable/disable specific notification types."""
        self.notifier.set_alert_level(level, enabled)
        
    def get_notification_status(self) -> Dict[str, Any]:
        """Get notification system status."""
        return self.notifier.get_status()
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Trailing Stop System
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def update_trailing_stops(self, current_prices: Dict[str, float] = None) -> List[Dict]:
        """
        Update all trailing stops and check for triggered exits.
        
        Args:
            current_prices: Dict of symbol -> current price. If None, fetches from cache.
            
        Returns:
            List of positions that should be closed due to trailing stop
        """
        if not CONFIG.get('ENABLE_TRAILING_STOP', True):
            return []
            
        exits = []
        
        for symbol, pos in self.positions.items():
            # Get current price
            if current_prices and symbol in current_prices:
                current_price = current_prices[symbol]
            elif symbol in self.realtime_prices:
                current_price = self.realtime_prices[symbol]
            elif symbol in self.ticker_cache:
                current_price = self.ticker_cache[symbol].get('price', pos.entry_price)
            else:
                continue
                
            # Get ATR if available
            atr = 0.0
            if CONFIG.get('USE_ATR_TRAILING', True):
                atr_data = self.atr_calculator.calculate_atr(symbol)
                if atr_data > 0:
                    atr = atr_data
                    
            # Update trailing stop
            result = self.trailing_stop_manager.update_position(pos, current_price, atr)
            
            if result['should_exit']:
                exits.append({
                    'symbol': symbol,
                    'position': pos,
                    'reason': result['reason'],
                    'stop_price': result['stop_price'],
                    'pnl_pct': result['pnl_pct']
                })
                
        return exits
        
    def get_trailing_stop_status(self, symbol: str = None) -> Dict[str, Any]:
        """
        Get trailing stop status for a position or all positions.
        """
        if symbol:
            if symbol not in self.positions:
                return {'error': 'Position not found'}
            pos = self.positions[symbol]
            return {
                'symbol': symbol,
                'entry_price': pos.entry_price,
                'highest_price': pos.highest_price,
                'trailing_active': pos.trailing_stop_active,
                'stop_price': pos.trailing_stop_price,
                'current_trail_pct': ((pos.highest_price - pos.trailing_stop_price) / pos.highest_price * 100) if pos.trailing_stop_price > 0 else 0
            }
        else:
            # Return status for all positions
            statuses = {}
            for sym, pos in self.positions.items():
                statuses[sym] = {
                    'trailing_active': pos.trailing_stop_active,
                    'highest_price': pos.highest_price,
                    'stop_price': pos.trailing_stop_price
                }
            return statuses
            
    def get_trailing_stop_stats(self) -> Dict[str, Any]:
        """Get overall trailing stop statistics."""
        return self.trailing_stop_manager.get_stats()
        
    def set_trailing_stop_config(self, activation_pct: float = None, 
                                  trail_pct: float = None, use_atr: bool = None):
        """Configure trailing stop parameters."""
        if activation_pct is not None:
            self.trailing_stop_manager.activation_profit_pct = activation_pct
            CONFIG['TRAILING_ACTIVATION_PCT'] = activation_pct
        if trail_pct is not None:
            self.trailing_stop_manager.trail_distance_pct = trail_pct
            CONFIG['TRAILING_DISTANCE_PCT'] = trail_pct
        if use_atr is not None:
            self.trailing_stop_manager.use_atr_trailing = use_atr
            CONFIG['USE_ATR_TRAILING'] = use_atr
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üåå NEXUS Integration Methods
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def get_nexus_signal(self, symbol: str, klines: List[Dict] = None) -> Dict[str, Any]:
        """
        Get Master Equation signal for a symbol.
        
        Returns signal with coherence thresholds:
        - BUY when Œì > 0.75
        - SELL when Œì < 0.70
        - NEUTRAL otherwise
        """
        if not self.nexus.enabled:
            return {'signal': 'NEUTRAL', 'coherence': 0.5, 'confidence': 0.5}
            
        # Convert klines to market data if provided
        if klines:
            market_data = self.nexus.convert_klines_to_market_data(klines)
        else:
            # Try to get klines from exchange
            try:
                klines = self.kraken.get_ohlc(symbol, interval=15)
                market_data = self.nexus.convert_klines_to_market_data(klines) if klines else {}
            except:
                market_data = {}
                
        return self.nexus.calculate_master_equation(market_data)
        
    def enhance_opportunity_with_nexus(self, opp: Dict) -> Dict:
        """
        Enhance an opportunity with Nexus Master Equation signal.
        Adds nexus_signal, nexus_coherence, nexus_boost to opportunity.
        """
        if not self.nexus.enabled:
            return opp
            
        symbol = opp.get('symbol', '')
        
        # Get Nexus signal
        nexus_result = self.get_nexus_signal(symbol)
        
        # Add Nexus data to opportunity
        opp['nexus_signal'] = nexus_result.get('signal', 'NEUTRAL')
        opp['nexus_coherence'] = nexus_result.get('coherence', 0.5)
        opp['nexus_lambda'] = nexus_result.get('lambda', 1.5)
        
        # Apply coherence boost to score if above entry threshold
        if nexus_result.get('coherence', 0) >= 0.75:
            boost = 1.0 + (nexus_result['coherence'] - 0.75) * 4  # Up to 2.0x boost at Œì=1.0
            opp['nexus_boost'] = boost
            if 'score' in opp:
                opp['score'] = opp['score'] * boost
                
        return opp
        
    def record_nexus_profit(self, profit: float) -> Dict[str, float]:
        """
        Record profit through Queen Hive 10-9-1 model.
        Returns compound/harvest split.
        """
        return self.nexus.record_trade_profit(profit)
        
    def get_nexus_stats(self) -> Dict[str, Any]:
        """Get Nexus integration statistics."""
        return self.nexus.get_stats()
        
    def display_nexus_equation(self):
        """Display current Master Equation state."""
        self.nexus.display_equation()
        
    def check_nexus_exit_signal(self, symbol: str) -> bool:
        """
        Check if Nexus suggests exiting a position.
        Returns True if coherence falls below 0.70.
        """
        nexus_result = self.get_nexus_signal(symbol)
        return nexus_result.get('signal') == 'SELL'
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Position Management
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def _detect_exchange_for_symbol(self, symbol: str, hint_source: str = None) -> str:
        """
        üîß SMART EXCHANGE DETECTION üîß
        Determines correct exchange for a symbol based on:
        1. Quote currency patterns (USDC/USDT/FDUSD ‚Üí Binance, GBP/EUR ‚Üí Kraken)
        2. Known Binance-only pairs
        3. Hint from ticker source
        
        This prevents routing DOGEUSDC to Kraken (which doesn't support it).
        üî• CRITICAL: Capital.com does NOT support crypto - NEVER route crypto there!
        """
        symbol_upper = symbol.upper()
        
        # üî•üî•üî• CRITICAL: USDT/USDC/FDUSD pairs are ALWAYS Binance - NEVER Capital.com!
        # Capital.com only does CFDs (forex, indices, commodities) - NO crypto!
        if symbol_upper.endswith(('USDT', 'USDC', 'FDUSD', 'BUSD')):
            return 'binance'
        
        # üî• These quote currencies are more common on Kraken
        if symbol_upper.endswith(('GBP', 'EUR', 'ZGBP', 'ZEUR', 'CHF')):
            return 'kraken'
            
        # üî• USD pairs - Check if in our Binance USDC pairs list (converted to USD)
        # These are likely from Binance with USDC, not Kraken with USD
        BINANCE_USDC_BASES = {
            'DOGE', 'SHIB', 'PEPE', 'WIF', 'BONK', 'FLOKI', 'MEME', 'TURBO',
            'LUNC', 'USTC', 'LUNA', 'APT', 'ARB', 'OP', 'SUI', 'SEI', 'INJ',
            'TIA', 'JUP', 'PYTH', 'WLD', 'BLUR', 'STRK', 'PIXEL', 'PORTAL',
            'ALT', 'MANTA', 'DYM', 'XAI', 'AI', 'RNDR', 'FET', 'AGIX', 'TAO',
            'AKT', 'JASMY', 'CFX', 'MANA', 'SAND', 'AXS', 'IMX', 'GALA',
            'ENJ', 'ROSE', 'KAS', 'IOTA', 'STX', 'ALGO', 'FTM', 'NEAR',
            'AVAX', 'ATOM', 'DOT', 'LINK', 'SOL', 'ETH', 'BTC', 'XRP', 'ADA',
            # üÜï Add more common Binance pairs
            'ZBT', 'FLOW', 'ONT', 'HYPER', 'MATIC', 'POL', 'UNI', 'AAVE',
            'COMP', 'MKR', 'SNX', 'CRV', 'LDO', 'RPL', 'BLUR', '1INCH'
        }
        
        # Extract base from symbol
        for suffix in ['USDT', 'USD', 'USDC', 'GBP', 'EUR', 'BTC', 'ETH']:
            if symbol_upper.endswith(suffix):
                base = symbol_upper[:-len(suffix)]
                if base in BINANCE_USDC_BASES and suffix in ('USDC', 'USDT', 'USD'):
                    return 'binance'
                break
        
        # üî• ALPACA - US Stocks and ETFs
        if hint_source and hint_source.lower() == 'alpaca':
            return 'alpaca'
        
        # üî• CAPITAL.COM - CFDs ONLY (forex, indices, commodities) - NOT CRYPTO!
        # Only route to Capital if explicitly requested AND symbol looks like CFD
        if hint_source and hint_source.lower() == 'capital':
            # Verify it's actually a CFD symbol (forex pairs, indices, commodities)
            CFD_PATTERNS = ('EUR', 'GBP', 'JPY', 'CHF', 'AUD', 'CAD', 'NZD',
                           'US500', 'US100', 'UK100', 'DE40', 'FR40',
                           'GOLD', 'SILVER', 'OIL', 'NATGAS', 'COPPER')
            if any(p in symbol_upper for p in CFD_PATTERNS):
                return 'capital'
            # If hint says capital but symbol is crypto, use binance instead!
            print(f"   ‚ö†Ô∏è ROUTING FIX: {symbol} looks like crypto, routing to binance (not capital)")
            return 'binance'
        
        # üî• Trust hint_source if it's a valid exchange (binance/kraken)
        if hint_source and hint_source.lower() in ('binance', 'kraken'):
            return hint_source.lower()
        
        # Default to kraken for USD pairs, binance for everything else
        if symbol_upper.endswith('USD') and not any(c in symbol_upper for c in ['USDT', 'USDC']):
            return 'kraken'
        
        return 'kraken'
    
    def _is_duplicate_across_exchanges(self, symbol: str, target_exchange: str) -> bool:
        """üçÑ MYCELIUM CHECK: Prevent duplicate positions across different exchanges.
        
        Normalizes symbol names to catch cases like:
        - BTCUSDT on Binance = XBTUSDT on Kraken = BTC/USDT on Capital
        - ETHUSDC on Binance = XETHZUSD on Kraken
        
        Returns True if we already have a similar position on ANOTHER exchange.
        """
        if not CONFIG.get('PREVENT_DUPLICATE_POSITIONS', True):
            return False
            
        # Normalize the target symbol
        target_norm = symbol.upper().replace('XBT', 'BTC').replace('/', '').lstrip('X').lstrip('Z')
        
        # Extract base asset (remove quote currencies)
        quote_suffixes = ['USDT', 'USDC', 'USD', 'GBP', 'EUR', 'BTC', 'ETH', 'BNB', 'FDUSD']
        target_base = target_norm
        for suffix in quote_suffixes:
            if target_base.endswith(suffix):
                target_base = target_base[:-len(suffix)]
                break
        
        # Check all open positions on OTHER exchanges
        for pos_symbol, pos in self.positions.items():
            pos_exchange = getattr(pos, 'exchange', '').lower()
            
            # Allow same position on same exchange (shouldn't happen but safety)
            if pos_exchange == target_exchange.lower():
                continue
                
            # Normalize existing position symbol
            pos_norm = pos_symbol.upper().replace('XBT', 'BTC').replace('/', '').lstrip('X').lstrip('Z')
            pos_base = pos_norm
            for suffix in quote_suffixes:
                if pos_base.endswith(suffix):
                    pos_base = pos_base[:-len(suffix)]
                    break
            
            # If same base asset is already on another exchange, it's a duplicate
            if target_base == pos_base:
                print(f"   üçÑ‚ùå DUPLICATE BLOCKED: {symbol} on {target_exchange.upper()} - already have {pos_symbol} on {pos_exchange.upper()}")
                return True
                
        return False
    
    def open_position(self, opp: Dict):
        """Open a new position - dynamically frees capital if needed
        
        üè¥‚öîÔ∏è MULTI-BATTLEFIELD: Routes to correct exchange and prevents duplicates!
        """
        symbol = opp['symbol']
        price = opp['price']
        hint_source = opp.get('source')
        exchange = self._detect_exchange_for_symbol(symbol, hint_source)
        exchange_marker = exchange.upper()

        # Ensure downstream entry logic (penny threshold) uses the routed exchange.
        opp['exchange'] = exchange

        # üß≠ MULTI-PLATFORM BUY SAFETY:
        # Normalize symbols BEFORE we derive quote asset / liquidity / sizing.
        # This prevents cases like BTCUSD routed to Binance (needs BTCUSDT) or
        # BTCUSD routed to Kraken (often XBTUSD), and keeps quote asset aligned.
        canonical_symbol = symbol
        try:
            if hasattr(self.client, 'normalize_symbol'):
                normalized = self.client.normalize_symbol(exchange, symbol)
                if isinstance(normalized, str) and normalized.strip():
                    symbol = normalized.strip()
                    opp['symbol'] = symbol
        except Exception:
            symbol = canonical_symbol

        # If normalization changed the symbol (or price is missing/invalid),
        # refresh the price from the routed exchange to keep sizing accurate.
        if symbol != canonical_symbol or not price or float(price) <= 0:
            try:
                ticker = self.client.get_ticker(exchange, symbol)
                if ticker:
                    t_price = float(ticker.get('price', 0) or 0)
                    if t_price > 0:
                        price = t_price
                        opp['price'] = price
            except Exception:
                pass

        quote_asset = self._get_quote_asset(symbol)
        # Some callers (notably force-scout deployment) provide a quote hint.
        # Prefer it when present to keep liquidity checks and sizing consistent.
        opp_quote_hint = opp.get('quote_currency') or opp.get('quote')
        if isinstance(opp_quote_hint, str) and opp_quote_hint.strip():
            quote_asset = opp_quote_hint.strip().upper()
        base_currency = CONFIG['BASE_CURRENCY'].upper()

        # Exchange-specific minimum order size (some venues allow smaller, e.g. Alpaca fractional)
        bf_config = (CONFIG.get('BATTLEFIELDS', {}) or {}).get(exchange, {})
        min_order_usd = float(bf_config.get('min_trade_usd', CONFIG.get('MIN_TRADE_USD', 10.0)) or CONFIG.get('MIN_TRADE_USD', 10.0))
        
        # üçÑ MYCELIUM: Check for cross-exchange duplicates FIRST
        if self._is_duplicate_across_exchanges(symbol, exchange):
            return None
        
        # üöÄ Check if this is a forced scout deployment
        # Match: 'ForceScout', 'PatriotScout', or any 'Patriot_xxx' pattern
        dominant_node = opp.get('dominant_node', '')
        is_force_scout = (
            dominant_node in ('ForceScout', 'PatriotScout', 'PatriotScout_CFD', 'PatriotScout_Stock') or
            dominant_node.startswith('Patriot_') or  # üáÆüá™ Irish Patriot naming
            CONFIG.get('FORCE_TRADE', False)
        )

        # ‚è±Ô∏è 1-minute penny-profit consensus gate (unlimited entries need this)
        consensus_ok, consensus_reason, consensus_details = has_one_minute_profit_consensus(opp)
        allow_force_bypass = CONFIG.get('ALLOW_FORCE_SCOUT_BYPASS_CONSENSUS', False)
        if not consensus_ok and (not is_force_scout or not allow_force_bypass):
            print(
                f"   ‚è±Ô∏è‚ùå SKIP {symbol}: lacks 1-minute penny consensus "
                f"({consensus_reason}) [p={consensus_details['prob_quick']:.2f}, "
                f"conf={consensus_details['confidence']:.2f}, "
                f"eta={consensus_details['estimated_seconds']/60:.2f}m]"
            )
            return None
        elif consensus_ok:
            print(
                f"   ‚è±Ô∏è‚úÖ 1-minute penny consensus for {symbol} "
                f"(p={consensus_details['prob_quick']:.2f}, "
                f"conf={consensus_details['confidence']:.2f}, "
                f"eta={consensus_details['estimated_seconds']/60:.2f}m)"
            )

        # ‚òòÔ∏è CELTIC SNIPER ENTRY VALIDATION
        # Use Celtic intelligence to validate entry quality
        if hasattr(self, 'celtic_sniper') and self.celtic_sniper is not None and not is_force_scout:
            try:
                entry_check = self.celtic_sniper.validate_entry(
                    symbol=symbol,
                    price=price,
                    volume=opp.get('volume', 0),
                    change_24h=opp.get('change24h', 0),
                    coherence=opp.get('coherence', 0.5)
                )
                
                # ü™ô PENNY MODE: Celtic is advisory, not blocking
                # Log the recommendation but don't return None
                if not entry_check.get('approved', True):
                    reason = entry_check.get('reason', 'Celtic intelligence hesitant')
                    print(f"   ‚òòÔ∏è‚ö†Ô∏è CELTIC SNIPER NOTE {symbol}: {reason} (proceeding anyway - penny math protects)")
                    # Don't return None - let penny profit math be the gate
                    
                # Apply Celtic modifier to sizing
                celtic_modifier = entry_check.get('size_modifier', 1.0)
                if celtic_modifier != 1.0:
                    opp['celtic_modifier'] = celtic_modifier
                    if celtic_modifier > 1.0:
                        print(f"   ‚òòÔ∏è‚úÖ CELTIC SNIPER APPROVES {symbol}: +{(celtic_modifier-1)*100:.0f}% size")
            except Exception:
                pass  # Celtic check failed - proceed with normal entry
        
        # ü¶ô Skip Alpaca trades if in analytics-only mode
        if exchange == 'alpaca' and CONFIG.get('ALPACA_ANALYTICS_ONLY', True):
            return None
        
        # üî• FORCE TRADE MODE - Skip halt check
        if not is_force_scout and self.tracker.trading_halted:
            return None
        
        # üåç‚ö° Get HNC frequency modifier for position sizing ‚ö°üåç
        hnc_modifier = 1.0
        hnc_enhanced = None
        hnc_frequency = 256.0
        if CONFIG.get('ENABLE_HNC_FREQUENCY', True) and not is_force_scout:
            hnc_enhanced = self.auris.update_hnc_state(
                symbol, price, opp.get('momentum', 0), opp['coherence'], opp.get('score', 50)
            )
            if hnc_enhanced:
                hnc_frequency = hnc_enhanced.get('hnc_frequency', 256.0)
                hnc_modifier = self.auris.get_hnc_position_modifier()
                
                # ü™ô PENNY MODE: HNC is advisory, not blocking
                # Log frequency info but don't block - penny math is the real gate
                if CONFIG.get('HNC_FREQUENCY_GATE', True) and not is_force_scout:
                    if hnc_frequency == 440:
                        print(f"   üîä HNC NOTE {symbol}: 440Hz (proceeding - penny math protects)")
                        hnc_modifier *= CONFIG.get('HNC_DISTORTION_PENALTY', 0.80)  # Just reduce size
                    
                    # BOOST harmonic frequency entries
                    if hnc_enhanced.get('hnc_is_harmonic', False):
                        harmonic_boost = CONFIG.get('HNC_HARMONIC_ENTRY_BOOST', 1.25)
                        hnc_modifier *= harmonic_boost
                        print(f"   üü¢ HNC BOOST {symbol}: {hnc_frequency:.0f}Hz harmonic (√ó{harmonic_boost:.2f})")
        
        # üîä PHASE 2: FREQUENCY FILTERING - Apply sacred frequency modifiers üîä
        freq_modifier = 1.0
        if CONFIG.get('ENABLE_FREQUENCY_FILTERING', True):
            freq = opp.get('frequency', 256.0)
            freq_modifier = self._get_sacred_frequency_modifier(freq)
            
            # Log significant frequency events
            if freq_modifier >= 1.30:
                freq_name = self._get_frequency_name(freq)
                print(f"   üü¢ FREQ BOOST {symbol}: {freq_name} ({freq:.0f}Hz) √ó{freq_modifier:.2f}")
            elif freq_modifier <= 0.75:
                freq_name = self._get_frequency_name(freq)
                print(f"   üîä FREQ NOTE {symbol}: {freq_name} ({freq:.0f}Hz) √ó{freq_modifier:.2f}")
        
        # ü™ô PENNY MODE: Imperial and Earth gates are advisory, not blocking
        imperial_modifier = opp.get('imperial_multiplier', 1.0)
        if CONFIG.get('ENABLE_IMPERIAL', True) and not is_force_scout:
            should_trade, reason = self.auris.should_trade_imperial()
            if not should_trade:
                print(f"   üåå Imperial NOTE {symbol}: {reason} (proceeding - penny math protects)")
                imperial_modifier *= 0.8  # Just reduce size instead of blocking
            else:
                imperial_modifier = self.auris.get_imperial_position_modifier(
                    symbol, opp.get('change24h', 0), price
                )
        
        # ü™ô PENNY MODE: Earth resonance is advisory, not blocking
        if CONFIG.get('ENABLE_EARTH_RESONANCE', True) and not is_force_scout:
            earth_ok, earth_reason = self.auris.should_trade_earth()
            if not earth_ok:
                print(f"   üåç Earth NOTE {symbol}: {earth_reason} (proceeding - penny math protects)")
                # Don't block - just note it
        
        lattice_state = self.lattice.get_state()
        
        # üöÄ Force scouts use fixed sizing for reliability (smaller to enable low-capital trading)
        if is_force_scout:
            size_fraction = 0.05  # 5% position size for forced scouts
        else:
            size_fraction = self.tracker.calculate_position_size(
                opp['coherence'], symbol, hnc_modifier, imperial_modifier
            )
            risk_mod = lattice_state.get('risk_mod', 1.0) if isinstance(lattice_state, dict) else getattr(lattice_state, 'risk_mod', 1.0)
            size_fraction *= risk_mod
            size_fraction *= freq_modifier  # üîä Apply frequency filtering modifier
            size_fraction *= opp.get('risk_mod_from_pnl', 1.0)  # üß† Live P&L throttle
            
            # üéπ PIANO RESONANCE SIZING üéπ
            brain_mult = get_brain_multiplier()
            if brain_mult > 1.0:
                size_fraction *= brain_mult
                size_fraction = min(0.45, size_fraction)  # Cap at 45%
        
        if size_fraction <= 0:
            print(f"   üî¥ DEBUG {symbol}: size_fraction={size_fraction:.4f}")
            return None

        deployed = sum(pos.entry_value for pos in self.positions.values())
        
        # üî• FORCE SCOUT FIX: Use actual cash for forced scouts, not portfolio risk budget
        # When total_equity_gbp is 0 or stale, use real cash balances directly
        if is_force_scout:
            # Get actual cash available from exchanges for this quote currency
            quote_asset = quote_asset or CONFIG['BASE_CURRENCY']
            actual_cash = 0.0
            try:
                all_balances = self.client.get_all_balances()
                for exchange, balances in all_balances.items():
                    for asset, amount in balances.items():
                        asset_clean = asset.replace('Z', '').upper()
                        if asset_clean in [quote_asset, 'USD', 'USDC', 'USDT', 'EUR', 'GBP']:
                            try:
                                actual_cash += float(amount)
                            except:
                                pass
            except:
                actual_cash = self.cash_balance_gbp
            
            # Force scouts use 100% of available risk budget (go all in on good opportunities)
            available_risk = max(actual_cash, self.cash_balance_gbp, self.total_equity_gbp) - deployed
            available_risk = max(0.0, available_risk)
            
            if available_risk < CONFIG['MIN_TRADE_USD']:
                # Last resort: just use 5% of whatever cash we can find
                available_risk = actual_cash * 0.5  # Use 50% of actual cash for scouts
                
            print(f"   ü¶Ö FORCE SCOUT {symbol}: actual_cash={actual_cash:.2f}, available_risk={available_risk:.2f}")
        else:
            deploy_cap = self.total_equity_gbp * CONFIG['PORTFOLIO_RISK_BUDGET']
            available_risk = max(0.0, deploy_cap - deployed)
            
        if available_risk < min_order_usd:
            print(f"   üî¥ DEBUG {symbol}: available_risk={available_risk:.2f} < min_order_usd={min_order_usd:.2f}")
            return None

        pos_size = self.capital_pool.get_recommended_position_size(size_fraction)
        if pos_size <= 0:
            # üî• FORCE SCOUT: Override with minimum viable position
            if is_force_scout and available_risk >= CONFIG['MIN_TRADE_USD']:
                pos_size = min(available_risk, CONFIG['MIN_TRADE_USD'] * 2)
                print(f"   ü¶Ö FORCE SCOUT {symbol}: overriding pos_size to {pos_size:.2f}")
            else:
                print(f"   üî¥ DEBUG {symbol}: pos_size={pos_size:.2f}")
                return None
        pos_size = min(pos_size, available_risk)

        if self.dry_run:
            cash_available = max(0.0, self.tracker.balance - deployed)
        else:
            # ‚öîÔ∏è MULTI-PLATFORM: Use exchange-specific liquid cash for sizing.
            # Global cash/equity may exist elsewhere but isn't spendable on this venue.
            try:
                cash_available = float(self._get_exchange_cash_balance(exchange))
            except Exception:
                cash_available = float(max(0.0, self.cash_balance_gbp, available_risk))  # fallback

            # üîÅ EXCHANGE FALLBACK FOR BUYING:
            # If the routed venue is underfunded, try other enabled venues that support the symbol.
            if cash_available < min_order_usd and CONFIG.get('ENABLE_MULTI_EXCHANGE_ENTRY_FALLBACK', True):
                battlefields = CONFIG.get('BATTLEFIELDS', {}) or {}
                symbol_upper = canonical_symbol.upper()
                is_crypto = not any(p in symbol_upper for p in ['US500', 'US100', 'UK100', 'DE40', 'OIL', 'GOLD'])

                exchanges_to_try = [exchange]
                if is_crypto:
                    for ex in ['binance', 'kraken', 'alpaca']:
                        if ex != exchange and battlefields.get(ex, {}).get('enabled', False):
                            exchanges_to_try.append(ex)
                else:
                    if battlefields.get('capital', {}).get('enabled', False) and 'capital' not in exchanges_to_try:
                        exchanges_to_try.append('capital')

                for alt_ex in exchanges_to_try:
                    if alt_ex == exchange:
                        continue
                    if alt_ex == 'alpaca' and CONFIG.get('ALPACA_ANALYTICS_ONLY', True):
                        continue

                    alt_cfg = battlefields.get(alt_ex, {})
                    alt_min = float(alt_cfg.get('min_trade_usd', CONFIG.get('MIN_TRADE_USD', 10.0)) or CONFIG.get('MIN_TRADE_USD', 10.0))

                    try:
                        alt_cash = float(self._get_exchange_cash_balance(alt_ex))
                    except Exception:
                        alt_cash = 0.0

                    if alt_cash < alt_min:
                        continue

                    alt_symbol = canonical_symbol
                    try:
                        if hasattr(self.client, 'normalize_symbol'):
                            alt_symbol = self.client.normalize_symbol(alt_ex, canonical_symbol)
                    except Exception:
                        alt_symbol = canonical_symbol

                    try:
                        t = self.client.get_ticker(alt_ex, alt_symbol)
                        t_price = float(t.get('price', 0) or 0) if t else 0.0
                        if t_price <= 0:
                            continue
                    except Exception:
                        continue

                    print(
                        f"   üí∞ Fallback venue for {canonical_symbol}: {exchange_marker} underfunded "
                        f"(¬£{cash_available:.2f} < {min_order_usd:.2f}); switching to {alt_ex.upper()} "
                        f"(¬£{alt_cash:.2f} available)"
                    )

                    exchange = alt_ex
                    exchange_marker = exchange.upper()
                    symbol = alt_symbol
                    opp['symbol'] = symbol
                    opp['exchange'] = exchange
                    price = t_price
                    opp['price'] = price
                    cash_available = alt_cash
                    bf_config = (battlefields.get(exchange, {}) or {})
                    min_order_usd = float(bf_config.get('min_trade_usd', CONFIG.get('MIN_TRADE_USD', 10.0)) or CONFIG.get('MIN_TRADE_USD', 10.0))
                    quote_asset = self._get_quote_asset(symbol)
                    break
        
        # DYNAMIC CAPITAL ALLOCATION: If no cash but this is a better opportunity,
        # sell the worst-performing position to free up capital
        if cash_available < min_order_usd and CONFIG['ENABLE_REBALANCING'] and self.positions:
            worst_pos = None
            worst_pct = 0
            
            for pos_symbol, pos in self.positions.items():
                if pos.cycles < CONFIG['MIN_HOLD_CYCLES']:
                    continue
                curr_price = self.get_realtime_price(pos_symbol)
                if curr_price is None:
                    curr_price = self.ticker_cache.get(pos_symbol, {}).get('price', pos.entry_price)
                if curr_price and curr_price > 0 and pos.entry_price > 0:
                    pct = (curr_price - pos.entry_price) / pos.entry_price * 100
                    if pct < worst_pct:
                        worst_pct = pct
                        worst_pos = (pos_symbol, pct, curr_price)
            
            # üî• AGGRESSIVE SWAP: Sell any big loser to free capital for new trades
            # Score requirement lowered to 40 (from 85) for force scouts
            if worst_pos and (opp.get('score', 0) > 40 or is_force_scout) and worst_pct < CONFIG['REBALANCE_THRESHOLD']:
                pos_symbol, pct, curr_price = worst_pos
                
                # üß† PUBLISH THOUGHT: SCOUT SWAP üß†
                if THOUGHT_BUS_AVAILABLE and THOUGHT_BUS:
                    THOUGHT_BUS.publish(Thought(
                        source="scout",
                        topic="execution.scout.swap",
                        payload={
                            "sell_symbol": pos_symbol,
                            "buy_symbol": symbol,
                            "reason": "BETTER_OPPORTUNITY",
                            "pnl_pct": pct
                        }
                    ))

                print(f"   üî• AGGRESSIVE SWAP: Selling {pos_symbol} ({pct:+.2f}%) to buy {symbol}")
                self.close_position(pos_symbol, "SWAP", pct, curr_price)
                self.refresh_equity()
                try:
                    cash_available = float(self._get_exchange_cash_balance(exchange))
                except Exception:
                    cash_available = max(0.0, self.cash_balance_gbp)
        
        if cash_available < min_order_usd:
            # üîÑ TRY TO LIQUIDATE HISTORICAL ASSETS FOR CASH
            # Historical assets = imported holdings with no known entry price
            # They're effectively "available capital" - sell them for better opportunities!
            # üî• LOWERED threshold to 30 score - we need to MOVE!
            if opp.get('score', 0) > 30 or opp.get('coherence', 0) > 0.4 or is_force_scout:
                needed = max(min_order_usd, pos_size) - cash_available
                freed = self._liquidate_historical_for_opportunity(needed, exchange, symbol)
                if freed > 0:
                    cash_available += freed
                    print(f"   üí∞ Freed ¬£{freed:.2f} from historical assets - continuing trade!")
            
            # Still not enough? Skip
            if cash_available < min_order_usd:
                if not hasattr(self, '_skip_logged'):
                    self._skip_logged = set()
                if symbol not in self._skip_logged:
                    print(f"   ‚ö™ Skipping {symbol}: insufficient cash (¬£{cash_available:.2f})")
                    self._skip_logged.add(symbol)
                return None
        
        # Clear skip log at end of cycle
        if hasattr(self, '_skip_logged'):
            self._skip_logged.clear()
            
        # üß© ADDITIVE BUYING: scale entry down to whatever cash is actually available.
        # Keep a small buffer to reduce 'insufficient funds' rejects from fees/rounding.
        if not self.dry_run and cash_available > 0:
            cash_available = max(0.0, cash_available * 0.995)

        scaled_size = min(pos_size, cash_available)
        if scaled_size < pos_size:
            print(f"   üí∞ Additive sizing {symbol} on {exchange_marker}: ¬£{pos_size:.2f} ‚Üí ¬£{scaled_size:.2f} (available)")
        pos_size = scaled_size

        if pos_size < min_order_usd:
            return None

        if not self.should_enter_trade(opp, pos_size, lattice_state, is_force_scout=is_force_scout):
            reason = opp.get('entry_reject_reason') or 'portfolio gate rejected entry'
            print(f"   ‚ö™ Skipping {symbol}: {reason}")
            return None
        
        quote_amount_needed = pos_size
        if base_currency != quote_asset:
            try:
                converted = self.client.convert_to_quote(exchange, base_currency, pos_size, quote_asset)
                if converted > 0:
                    quote_amount_needed = converted
            except Exception:
                pass

        liquidity_required = (not self.dry_run) and exchange in ('binance', 'kraken')
        if liquidity_required:
            has_liquidity, available_quote, liquidity_tip = self.ensure_quote_liquidity(exchange, quote_asset, quote_amount_needed)
            if not has_liquidity:
                # üîÑ TRY TO LIQUIDATE HISTORICAL ASSETS ON THIS EXCHANGE
                if opp.get('score', 0) > 70 or opp.get('coherence', 0) > 0.6:
                    needed = quote_amount_needed - available_quote
                    freed = self._liquidate_historical_for_opportunity(needed, exchange, symbol)
                    if freed > 0:
                        # Re-check liquidity
                        has_liquidity, available_quote, _ = self.ensure_quote_liquidity(exchange, quote_asset, quote_amount_needed)
                
                if not has_liquidity:
                    warn_key = (exchange, quote_asset)
                    if warn_key not in self._liquidity_warnings:
                        print(
                            f"   ‚ö™ Skipping {symbol}: insufficient {quote_asset} on {exchange_marker} "
                            f"({available_quote:.2f} available, need {quote_amount_needed:.2f})"
                        )
                        if liquidity_tip:
                            print(f"   üí° Liquidity tip: {liquidity_tip}")
                        self._liquidity_warnings.add(warn_key)
                    return

        actual_fraction = (pos_size / self.tracker.balance) if self.tracker.balance > 0 else 0.0
        # Use combined rate (fee + slippage + spread) to match penny profit formula
        # This ensures entry_fee reflects ALL costs on the entry leg
        fee_rate = get_platform_fee(exchange, 'taker')
        slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
        spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
        total_rate = fee_rate + slippage + spread
        entry_fee = pos_size * total_rate
        quantity = pos_size / price
        
        # üîß KRAKEN VOLUME MINIMUM CHECK: Ensure order quantity meets pair's ordermin
        if exchange == 'kraken' and not self.dry_run:
            try:
                exchange_client = self.client.clients.get('kraken')
                if exchange_client and hasattr(exchange_client, 'get_symbol_filters'):
                    filters = exchange_client.get_symbol_filters(symbol)
                    min_qty = filters.get('min_qty', 0)
                    if min_qty > 0 and quantity < min_qty:
                        # Calculate minimum notional needed to meet volume requirement
                        min_notional_for_vol = min_qty * price * 1.02  # 2% buffer
                        if min_notional_for_vol > quote_amount_needed:
                            if min_notional_for_vol <= cash_available:
                                print(f"   üìà Kraken {symbol}: bumping order from ${quote_amount_needed:.2f} to ${min_notional_for_vol:.2f} (min vol: {min_qty})")
                                quote_amount_needed = min_notional_for_vol
                                pos_size = min_notional_for_vol
                                quantity = pos_size / price
                            else:
                                print(f"   ‚ö™ Skipping {symbol}: need ${min_notional_for_vol:.2f} for min volume {min_qty}, only ${cash_available:.2f} available")
                                return None
            except Exception as e:
                print(f"   ‚ö†Ô∏è Kraken filter check failed for {symbol}: {e}")
        
        if not self.dry_run:
            try:
                # Safety: never submit a BUY without a positive size.
                # Some upstream sizing paths (especially force scouts) can produce 0/None
                # when env/config overrides are mis-set; exchanges reject such orders.
                if quote_amount_needed is None or float(quote_amount_needed) <= 0.0:
                    fallback_quote = float(max(CONFIG.get('MIN_TRADE_USD', 1.0), 1.0))
                    logger.warning(
                        f"{symbol}: computed non-positive quote_qty={quote_amount_needed}; "
                        f"falling back to {fallback_quote:.2f}"
                    )
                    quote_amount_needed = fallback_quote
                res = self.client.place_market_order(exchange, symbol, 'BUY', quote_qty=quote_amount_needed)
                # Some exchange adapters or older code paths can still end up passing
                # a falsy quote_qty through; if we get the explicit "missing size" reject,
                # retry once using base-asset quantity.
                if isinstance(res, dict) and res.get('rejected'):
                    reason = (res.get('reason') or '').lower()
                    if 'must provide quantity' in reason and quantity and quantity > 0:
                        res = self.client.place_market_order(exchange, symbol, 'BUY', quantity=quantity)
            except Exception as e:
                print(f"   ‚ö†Ô∏è Execution error for {symbol}: {e}")
                return

            if isinstance(res, dict):
                if res.get('rejected'):
                    reason = res.get('reason') or 'exchange rejected order'
                    print(f"   ‚ö†Ô∏è Order rejected for {symbol}: {reason}")
                    return
                
                # Handle Kraken volume minimum error
                if res.get('error') == 'volume_minimum':
                    print(f"   ‚ö†Ô∏è Kraken volume minimum not met for {symbol} (need {res.get('ordermin')} units)")
                    return

                if res.get('dryRun'):
                    order_id = 'dry_run'
                else:
                    order_id = res.get('orderId') or res.get('id')
                    result = res.get('result') if isinstance(res.get('result'), dict) else {}
                    if not order_id and result:
                        txids = result.get('txid')
                        if isinstance(txids, list) and txids:
                            order_id = txids[0]
                        elif isinstance(txids, str) and txids:
                            order_id = txids
                    if not order_id:
                        # Preserve response payload for diagnosing filter/permission issues.
                        if isinstance(res, dict) and (res.get('error') or res.get('code') or res.get('msg') or res.get('reason')):
                            print(f"   ‚ö†Ô∏è Order failed for {symbol}: {res.get('reason') or res.get('msg') or res.get('error') or 'No order ID'}")
                            # Keep this short; full payload can be large.
                            safe_keys = {k: res.get(k) for k in ('exchange', 'error', 'code', 'msg', 'reason', 'status_code', 'rejected') if k in res}
                            if safe_keys:
                                print(f"      ‚Ü≥ details: {safe_keys}")
                        else:
                            print(f"   ‚ö†Ô∏è Order failed for {symbol}: No order ID returned")
                        return
                    
                    # üî• CRITICAL FIX: Use ACTUAL fill price, not pre-order price!
                    # This ensures P&L calculations are accurate
                    fills = res.get('fills', [])
                    if fills:
                        # Calculate weighted average fill price
                        total_qty = sum(float(f.get('qty', 0)) for f in fills)
                        total_value = sum(float(f.get('qty', 0)) * float(f.get('price', 0)) for f in fills)
                        if total_qty > 0:
                            actual_fill_price = total_value / total_qty
                            actual_qty = total_qty
                            actual_value = total_value
                            # Calculate actual fee from fills
                            actual_fee = sum(
                                float(f.get('commission', 0)) * (float(f.get('price', price)) if f.get('commissionAsset') == symbol.replace(quote_asset, '') else 1.0)
                                for f in fills
                            )
                            print(f"   üìä Fill: {actual_qty:.2f} @ {actual_fill_price:.8f} (pre-order: {price:.8f})")
                            price = actual_fill_price
                            quantity = actual_qty
                            pos_size = actual_value
                            entry_fee = actual_fee if actual_fee > 0 else pos_size * total_rate
                    elif res.get('cummulativeQuoteQty') and res.get('executedQty'):
                        # Fallback: use order response totals
                        exec_qty = float(res.get('executedQty', 0))
                        cumm_quote = float(res.get('cummulativeQuoteQty', 0))
                        if exec_qty > 0:
                            actual_fill_price = cumm_quote / exec_qty
                            print(f"   üìä Fill: {exec_qty:.2f} @ {actual_fill_price:.8f} (pre-order: {price:.8f})")
                            price = actual_fill_price
                            quantity = exec_qty
                            pos_size = cumm_quote
                            entry_fee = pos_size * total_rate
                            
        prime_multiplier = 1.0
        if len(self.positions) < 3:  # Apply prime sizing to first few positions
            prime_multiplier = self.prime_sizer.get_next_size(1.0) / CONFIG['BASE_POSITION_SIZE']
            pos_size *= prime_multiplier
            pos_size = min(pos_size, available_risk, cash_available)
            quantity = pos_size / price
            entry_fee = pos_size * total_rate
        
        # Create position with swarm enhancements
        is_scout = len(self.positions) == 0  # First position becomes scout
        
        entry_time = time.time()
        
        # üß† GET LEARNED PARAMETERS FROM RECOMMENDATION
        learned_rec = opp.get('learned_recommendation', {})
        
        # üéØ SCALPER MODE: If Queen is urgent, tighten targets!
        queen_signal = opp.get('queen_signal', 0.0)
        tp_pct = learned_rec.get('suggested_take_profit')
        sl_pct = learned_rec.get('suggested_stop_loss')
        
        if queen_signal > 0.8:
            # Hyper-Scalping: In and out in seconds!
            tp_pct = 0.005  # 0.5% profit target
            sl_pct = 0.002  # 0.2% stop loss
            print(f"   ‚ö° SCALPER MODE ACTIVE for {symbol}: Queen Signal {queen_signal:.2f} -> TP 0.5% / SL 0.2%")
        
        self.positions[symbol] = Position(
            symbol=symbol,
            entry_price=price,
            quantity=quantity,
            entry_fee=entry_fee,
            entry_value=pos_size,
            momentum=opp['change24h'],
            coherence=opp['coherence'],
            entry_time=entry_time,
            dominant_node=opp['dominant_node'],
            generation=0,
            is_scout=is_scout,
            prime_size_multiplier=prime_multiplier,
            exchange=exchange,
            # üß† Apply learned parameters from probability matrix
            learned_tp_pct=tp_pct,
            learned_sl_pct=sl_pct,
            learned_hold_cycles=learned_rec.get('suggested_hold_cycles'),
            learned_win_rate=learned_rec.get('expected_win_rate'),
            learned_confidence=learned_rec.get('confidence', 'low'),
            # üîÆ NEXUS PREDICTOR DATA - For learning feedback
            nexus_prob=opp.get('nexus_prob', 0.5),
            nexus_edge=opp.get('nexus_edge', 0.0),
            nexus_patterns=opp.get('nexus_patterns', []),
        )
        
        # Log learned parameters if available
        if learned_rec and learned_rec.get('confidence') != 'low':
            logger.info(f"üß† {symbol} using learned params: TP={learned_rec.get('suggested_take_profit', 0)*100:.1f}% SL={learned_rec.get('suggested_stop_loss', 0)*100:.1f}% Hold={learned_rec.get('suggested_hold_cycles', 0)} ExpWR={learned_rec.get('expected_win_rate', 0)*100:.0f}%")
        
        # üìä LOG TRADE ENTRY FOR PROBABILITY MATRIX TRAINING üìä
        if TRADE_LOGGER_AVAILABLE and trade_logger:
            try:
                trade_logger.log_trade_entry({
                    'symbol': symbol,
                    'side': 'BUY',
                    'exchange': exchange,
                    'entry_price': price,
                    'entry_time': entry_time,
                    'quantity': quantity,
                    'entry_value': pos_size,
                    'coherence': opp['coherence'],
                    'dominant_node': opp['dominant_node'],
                    'hnc_frequency': hnc_frequency,
                    'hnc_is_harmonic': hnc_enhanced.get('hnc_is_harmonic', False) if hnc_enhanced else False,
                    'probability_score': opp.get('score', 50) / 100.0,
                    'imperial_probability': imperial_modifier,
                    'cosmic_phase': opp.get('cosmic_phase', 'UNKNOWN'),
                    'earth_coherence': opp.get('earth_coherence', 0.5),
                    'gates_passed': opp.get('gates_passed', 0),
                })
            except Exception as e:
                logger.warning(f"Failed to log trade entry for {symbol}: {e}")
        
        # üí∞ LOG ENTRY PRICE TO COST BASIS TRACKER üí∞
        try:
            cost_tracker = get_cost_basis_tracker()
            cost_tracker.set_entry_price(symbol, price, quantity, exchange, entry_fee)
        except Exception as e:
            logger.warning(f"Failed to log cost basis for {symbol}: {e}")
        
        # üéØ‚ö° REGISTER WITH ACTIVE KILL SCANNER ‚ö°üéØ
        # The hunt begins the moment the position opens!
        try:
            # Calculate win threshold using penny profit formula
            penny_threshold = get_penny_threshold(exchange, pos_size)
            win_threshold = penny_threshold.get('win_gte', 0.04) if penny_threshold else 0.04
            
            register_sniper_target(
                symbol=symbol,
                exchange=exchange,
                entry_price=price,
                entry_value=pos_size,
                quantity=quantity,
                win_threshold=win_threshold
            )
            print(f"   üéØ‚ö° SCANNER LOCKED: {symbol} | Target: ${win_threshold:.4f} gross for 1p net")
        except Exception as e:
            logger.warning(f"Failed to register with kill scanner: {e}")
            
        # üß† PUBLISH THOUGHT: TRADE OPENED üß†
        if THOUGHT_BUS_AVAILABLE and THOUGHT_BUS:
            try:
                THOUGHT_BUS.publish(Thought(
                    source="unified_ecosystem",
                    topic="execution.order.open",
                    payload={
                        "symbol": symbol,
                        "side": "BUY",
                        "price": price,
                        "quantity": quantity,
                        "value": pos_size,
                        "exchange": exchange,
                        "coherence": opp.get('coherence', 0),
                        "score": opp.get('score', 0)
                    }
                ))
            except Exception as e:
                logger.warning(f"Failed to publish open thought: {e}")
        
        # ‚öîÔ∏è WAR STRATEGY: START RAID TRACKING ‚öîÔ∏è
        # Track entry time for quick kill analysis
        if WAR_STRATEGY_AVAILABLE and WAR_STRATEGIST:
            try:
                qk = opp.get('quick_kill', {})
                raid = start_raid(symbol, exchange, price)
                print(f"   ‚öîÔ∏è RAID STARTED: Targeting penny profit in ~{qk.get('estimated_bars', 20):.0f} bars ({qk.get('estimated_minutes', 20):.1f}min)")
                print(f"   üéØ Required move: {REQUIRED_R*100:.2f}% | Quick kill chance: {qk.get('prob_quick_kill', 0.5)*100:.0f}%")
            except Exception as e:
                logger.warning(f"War Strategy raid start error: {e}")
        
        # üöÄ PLACE SERVER-SIDE TP/SL ORDERS (Kraken & Alpaca - executes even if bot offline!)
        if CONFIG.get('USE_SERVER_SIDE_ORDERS', True) and exchange.lower() in ['kraken', 'alpaca'] and not self.dry_run:
            try:
                # Calculate TP/SL prices
                tp_pct = learned_rec.get('suggested_take_profit') or CONFIG.get('SERVER_SIDE_TP_PCT', 1.8) / 100
                sl_pct = learned_rec.get('suggested_stop_loss') or CONFIG.get('SERVER_SIDE_SL_PCT', 1.5) / 100
                
                take_profit_price = price * (1 + tp_pct)
                stop_loss_price = price * (1 - sl_pct)
                
                # Use trailing stop if configured
                if CONFIG.get('USE_TRAILING_STOP_ORDERS', False):
                    trailing_pct = CONFIG.get('SERVER_TRAILING_PCT', 2.0)
                    trail_res = self.client.place_trailing_stop_order(
                        exchange, symbol, 'sell', quantity, trailing_pct, 'percent'
                    )
                    if trail_res and not trail_res.get('error'):
                        print(f"   üéØ Server trailing stop: {trailing_pct}% below peak")
                        self.positions[symbol].server_trailing_order_id = trail_res.get('orderId') or trail_res.get('id')
                else:
                    # ü¶ô Alpaca: Use OCO (one-cancels-other) for existing position TP+SL
                    if exchange.lower() == 'alpaca':
                        # For Alpaca, after entry filled, place OCO with TP+SL
                        try:
                            # Get proper symbol format for Alpaca (BTC/USD)
                            alpaca_symbol = symbol if '/' in symbol else f"{symbol[:3]}/{symbol[3:]}" if len(symbol) >= 6 else symbol
                            
                            oco_res = self.client.clients['alpaca'].place_oco_order(
                                alpaca_symbol, quantity, 'sell',
                                take_profit_limit=take_profit_price,
                                stop_loss_stop=stop_loss_price
                            )
                            if oco_res and not oco_res.get('error'):
                                self.positions[symbol].server_sl_order_id = oco_res.get('id')
                                print(f"   ü¶ô Alpaca OCO: TP @ ${take_profit_price:.6f} (+{tp_pct*100:.1f}%) | SL @ ${stop_loss_price:.6f} (-{sl_pct*100:.1f}%)")
                        except Exception as e:
                            logger.warning(f"Failed to place Alpaca OCO for {symbol}: {e}")
                    else:
                        # ü¶ë Kraken: Place separate TP and SL orders
                        # Place stop-loss order (server-side)
                        sl_res = self.client.place_stop_loss_order(
                            exchange, symbol, 'sell', quantity, stop_loss_price
                        )
                        if sl_res and not sl_res.get('error'):
                            self.positions[symbol].server_sl_order_id = sl_res.get('orderId')
                            print(f"   üõ°Ô∏è Server stop-loss @ ${stop_loss_price:.6f} (-{sl_pct*100:.1f}%)")
                        
                        # Place take-profit order (server-side)  
                        tp_res = self.client.place_take_profit_order(
                            exchange, symbol, 'sell', quantity, take_profit_price
                        )
                        if tp_res and not tp_res.get('error'):
                            self.positions[symbol].server_tp_order_id = tp_res.get('orderId')
                            print(f"   üí∞ Server take-profit @ ${take_profit_price:.6f} (+{tp_pct*100:.1f}%)")
                        
            except Exception as e:
                logger.warning(f"Failed to place server-side TP/SL for {symbol}: {e}")
        
        # üåü Allocate capital in pool
        self.capital_pool.allocate(symbol, pos_size)
        
        # üêò Record the successful hunt
        self.elephant_memory.record_hunt(symbol, opp.get('volume', 0), opp.get('change24h', 0))
        
        self.tracker.total_fees += entry_fee
        # Track entry fee in platform metrics
        if exchange.lower() in self.tracker.platform_metrics:
            self.tracker.platform_metrics[exchange.lower()]['fees'] += entry_fee
        self.tracker.symbol_exposure[symbol] = self.tracker.symbol_exposure.get(symbol, 0.0) + actual_fraction
        self.cash_balance_gbp = max(0.0, self.cash_balance_gbp - pos_size)
        self.holdings_gbp[symbol] = self.holdings_gbp.get(symbol, 0.0) + pos_size
        
        icon = self._get_node_icon(opp['dominant_node'])
        curr_sym = "¬£" if CONFIG['BASE_CURRENCY'] == 'GBP' else "‚Ç¨" if CONFIG['BASE_CURRENCY'] == 'EUR' else "$"
        scout_marker = " üê∫" if is_scout else ""
        prime_marker = f" [√ó{prime_multiplier:.1f}]" if prime_multiplier != 1.0 else ""
        exch_marker = f" [{exchange_marker}]"
        flux_marker = f" üåä{opp.get('flux_direction', 'N')}"
        # üåç‚ö° Add HNC frequency indicator ‚ö°üåç
        hnc_freq = opp.get('hnc_frequency', 256)
        hnc_marker = ""
        if CONFIG.get('ENABLE_HNC_FREQUENCY', True):
            if opp.get('hnc_harmonic', False):
                hnc_marker = f" üåà{hnc_freq}Hz"
            elif hnc_freq == 440:
                hnc_marker = f" ‚ö†Ô∏è{hnc_freq}Hz"
            else:
                hnc_marker = f" {hnc_freq}Hz"
        # üîÆ Add Nexus predictor probability
        nexus_marker = f" üîÆ{opp.get('nexus_prob', 0.5)*100:.0f}%" if self.nexus_predictor and 'nexus_prob' in opp else ""
        print(f"   {icon} BUY  {symbol:12s} @ {curr_sym}{price:.6f} | {curr_sym}{pos_size:.2f} ({actual_fraction*100:.1f}%) | Œì={opp['coherence']:.2f} | +{opp['change24h']:.1f}%{hnc_marker}{nexus_marker}{flux_marker}{scout_marker}{prime_marker}{exch_marker}")
        
    def check_positions(self):
        """Check all positions for TP/SL with HNC frequency optimization and Earth Resonance"""
        to_close = []
        
        # ÔøΩ‚ö° ACTIVE KILL SCANNER - INTELLIGENT HUNTING SCAN ‚ö°üéØ
        # Scan all targets and update predictions BEFORE checking exits
        if self.positions:
            try:
                def price_getter(exchange, symbol):
                    return self.get_realtime_price(symbol) or 0.0
                
                # ‚õèÔ∏è SYNC SCANNER WITH CASCADE AMPLIFIER - Miner's 546x Power!
                try:
                    sync_scanner_with_cascade(
                        cascade_factor=CASCADE_AMPLIFIER.cascade_factor,
                        kappa_t=CASCADE_AMPLIFIER.kappa_t,
                        lighthouse_gamma=CASCADE_AMPLIFIER.lighthouse_gamma
                    )
                except Exception:
                    pass  # CASCADE_AMPLIFIER might not be initialized yet
                
                # üçÑ MYCELIUM NETWORK PULSE - Unified Intelligence Flow
                try:
                    mycelium_sync()  # Synchronize all systems through the fungal network
                except Exception:
                    pass  # Mycelium resilient - continues if any system offline
                
                scan_results = scan_sniper_targets(price_getter)
                
                # Show scanner status every 5 cycles or when kills are ready
                kills_ready = [r for r in scan_results if r[1]]  # Kill ready
                if self.iteration % 5 == 0 or kills_ready:
                    scanner = get_active_scanner()
                    cascade_info = f"CASCADE: {scanner.cascade_factor:.1f}x" if scanner.cascade_factor > 1.0 else ""
                    kappa_info = f"Œ∫t: {scanner.kappa_t:.2f}" if scanner.kappa_t > 1.0 else ""
                    streak_info = f"üî•{scanner.consecutive_kills}" if scanner.consecutive_kills > 1 else ""
                    print(f"\n   üéØ‚ö° ACTIVE KILL SCANNER ({len(scan_results)} targets) {cascade_info} {kappa_info} {streak_info}")
                    for key, kill_ready, verdict, metrics in scan_results:
                        if kill_ready:
                            print(f"   üéØ {verdict}")
                        elif self.iteration % 10 == 0:  # Show tracking info every 10 cycles
                            print(f"   {verdict}")
                    
                    # Priority targets summary with learning + cascade stats
                    if scanner.kills_executed > 0:
                        learned_boost = f"LEARNED: {scanner.momentum_success_rate:.0%}" if scanner.momentum_success_rate > 0 else ""
                        print(f"   üí∞ Session: {scanner.kills_executed} kills | ${scanner.total_pnl:.4f} | Avg: {scanner.avg_kill_time:.0f}s {learned_boost}")
            except Exception as e:
                logger.debug(f"Kill scanner error: {e}")
        
        # ÔøΩüåç‚ú® Get Earth Resonance exit urgency once per cycle ‚ú®üåç
        earth_exit_urgency = 0.0
        if CONFIG.get('EARTH_EXIT_URGENCY', True) and self.auris.earth_engine:
            try:
                # get_exit_urgency returns (urgency_level, exit_factor)
                _, earth_exit_urgency = self.auris.earth_engine.get_exit_urgency(0)  # 0% P&L as default
            except:
                pass
        
        for symbol, pos in self.positions.items():
            pos.cycles += 1
            
            # üåç‚ö° EARTH RESONANCE EXIT URGENCY ‚ö°üåç
            # If field coherence is low, reduce TP threshold to exit faster
            effective_tp_mult = 1.0
            if earth_exit_urgency > 0 and CONFIG.get('EARTH_EXIT_URGENCY', True):
                # Reduce TP threshold by urgency percentage (e.g., 0.3 urgency = 70% of normal TP)
                effective_tp_mult = 1.0 - (earth_exit_urgency * 0.5)  # Max 50% reduction
            
            # üåç‚ö° HNC FREQUENCY EXIT OPTIMIZATION ‚ö°üåç
            if CONFIG.get('HNC_EXIT_ON_FREQUENCY_SHIFT', True) and CONFIG.get('ENABLE_HNC_FREQUENCY', True):
                try:
                    # Get current frequency for this asset
                    current_price = self.get_realtime_price(symbol)
                    if current_price:
                        hnc_state = self.auris.update_hnc_state(
                            symbol, current_price, 0, pos.coherence, 50
                        )
                        if hnc_state:
                            current_freq = hnc_state.get('hnc_frequency', 256)
                            entry_freq = pos.metadata.get('hnc_frequency', 256)
                            
                            # Exit if frequency shifted from harmonic to distortion
                            if entry_freq in [256, 512, 528, 639, 963] and current_freq == 440:
                                change_pct = (current_price - pos.entry_price) / pos.entry_price * 100 if pos.entry_price > 0 else 0.0
                                print(f"   üî¥ HNC EXIT {symbol}: Frequency shift {entry_freq:.0f}Hz‚Üí440Hz (distortion)")
                                to_close.append((symbol, "HNC_FREQ_SHIFT", change_pct, current_price))
                                continue
                except Exception as e:
                    pass  # Continue with normal checks
            
            # Get current price (prefer WebSocket)
            current_price = self.get_realtime_price(symbol)
            source = "WS"
            
            if current_price is None:
                # Fallback to ticker cache
                current_price = self.ticker_cache.get(symbol, {}).get('price')
                source = "CACHE"
                
            # If still None, force a fresh lookup for this specific symbol
            if current_price is None:
                try:
                    # Force single ticker lookup
                    if pos.exchange == 'binance':
                        ticker = self.client.get_ticker(symbol, exchange='binance')
                        if ticker:
                            current_price = float(ticker.get('lastPrice', 0))
                            source = "REST_FORCE_BINANCE"
                    else:
                        # Kraken logic
                        ticker_symbol = self._normalize_ticker_symbol(symbol)
                        ticker = self.client._ticker([ticker_symbol])
                        if ticker:
                            t_data = list(ticker.values())[0]
                            current_price = float(t_data.get('c', [0])[0])
                            source = "REST_FORCE_KRAKEN"
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Failed to force price check for {symbol}: {e}")

            # Final fallback
            if current_price is None or current_price == 0:
                current_price = pos.entry_price
                source = "ENTRY (STALE)"

            # üõ°Ô∏è SAFETY: Prevent division by zero
            if pos.entry_price is None or pos.entry_price == 0:
                logger.warning(f"‚ö†Ô∏è Position {symbol} has zero/null entry price - skipping")
                continue
                
            change_pct = (current_price - pos.entry_price) / pos.entry_price * 100

            # üçÑ MYCELIUM FEEDBACK LOOP: feed live position state into the network
            # Previously the mycelium only learned on close() which can be hours/days.
            # This allows the network to reflect current momentum/coherence in real time.
            try:
                if hasattr(self, 'mycelium') and self.mycelium is not None and hasattr(self.mycelium, 'add_signal'):
                    # Map position state to a [0,1] activation signal.
                    # Neutral=0.5, positive momentum pushes up, negative pushes down.
                    momentum_signal = 0.5
                    try:
                        momentum_signal = 0.5 + max(-0.5, min(0.5, (change_pct / 10.0)))
                    except Exception:
                        momentum_signal = 0.5

                    coherence_signal = pos.coherence if getattr(pos, 'coherence', None) is not None else 0.5
                    coherence_signal = max(0.0, min(1.0, coherence_signal))

                    # Blend coherence + momentum into one activation
                    activation = max(0.0, min(1.0, coherence_signal * 0.6 + momentum_signal * 0.4))
                    self.mycelium.add_signal(symbol, activation)
            except Exception:
                pass

            # ‚è±Ô∏è TIMEBOX: penny scalps must secure net profit quickly
            # NO-LOSS ETHOS: we NEVER force-close at a loss by default.
            # After the timebox, we only close if net penny profit is secured; otherwise we mark
            # the position as timebox-expired (bad setup) and penalize learning, but we keep holding.
            if CONFIG.get('ENABLE_TIMEBOX_EXIT', True):
                try:
                    max_hold_min = float(CONFIG.get('MAX_HOLD_MINUTES', 5) or 5)
                except Exception:
                    max_hold_min = 5.0

                if max_hold_min > 0:
                    hold_min = (time.time() - pos.entry_time) / 60.0
                    if hold_min >= max_hold_min:
                        exit_value = pos.quantity * current_price
                        gross_pnl = exit_value - pos.entry_value

                        # Determine penny target for this position
                        penny_threshold = None
                        penny_check = check_penny_exit(pos.exchange, pos.entry_value, gross_pnl, symbol)
                        penny_threshold = penny_check.get('threshold') if isinstance(penny_check, dict) else None
                        target_net = 0.01
                        if penny_threshold:
                            target_net = penny_threshold.get('target_net', target_net)
                        else:
                            fb = get_penny_threshold(pos.exchange, pos.entry_value)
                            if fb:
                                target_net = fb.get('target_net', target_net)

                        # Estimate net after costs
                        fee_rate = get_exchange_fee_rate(pos.exchange)
                        slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
                        spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
                        total_rate = fee_rate + slippage + spread
                        entry_fee = getattr(pos, 'entry_fee', 0.0) or 0.0
                        if entry_fee <= 0 and pos.entry_value > 0:
                            entry_fee = pos.entry_value * total_rate
                        exit_fee = exit_value * total_rate
                        net_pnl_est = gross_pnl - (entry_fee + exit_fee)

                        if net_pnl_est >= target_net:
                            # Deadline reached and net is secured -> take it immediately.
                            to_close.append((symbol, "TIMEBOX_PROFIT", change_pct, current_price))
                            continue

                        # Deadline reached but net is NOT secured -> HOLD (no-loss default)
                        try:
                            if not hasattr(pos, 'metadata') or pos.metadata is None:
                                pos.metadata = {}
                            pos.metadata['timebox_expired'] = True
                            pos.metadata['timebox_expired_at'] = time.time()
                        except Exception:
                            pass
                        print(f"   ‚è±Ô∏è TIMEBOX EXPIRED (HOLD): {symbol} held {hold_min:.1f}m (net ${net_pnl_est:.4f} < ${target_net:.4f})")

                        # Penalize the network so we stop selecting similar setups.
                        try:
                            if hasattr(self, 'mycelium') and self.mycelium is not None and hasattr(self.mycelium, 'learn'):
                                # Negative reinforcement (small) for failing the timebox.
                                self.mycelium.learn(symbol, -0.5)
                        except Exception:
                            pass
            
            # üìä FEED POSITION DATA TO PROBABILITY MATRIX
            # This allows the matrix to validate predictions against real positions
            if self.prob_matrix and hasattr(self.prob_matrix, 'feed_position_data'):
                try:
                    # Provide net-after-costs context so the matrix can reason about
                    # "distance to penny" and timebox viability pre-close.
                    penny_threshold = None
                    try:
                        penny_threshold = get_penny_threshold(pos.exchange, pos.entry_value)
                    except Exception:
                        penny_threshold = None

                    target_net = 0.01
                    if isinstance(penny_threshold, dict):
                        target_net = float(penny_threshold.get('target_net', target_net))

                    fee_rate = get_exchange_fee_rate(pos.exchange)
                    slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
                    spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
                    total_rate = fee_rate + slippage + spread

                    self.prob_matrix.feed_position_data(
                        symbol=symbol,
                        exchange=pos.exchange,
                        entry_price=pos.entry_price,
                        entry_time=pos.entry_time,
                        quantity=pos.quantity,
                        entry_value=pos.entry_value,
                        current_price=current_price,
                        platform_timestamp=time.time(),  # Current sync time
                        is_historical=pos.is_historical,
                        momentum=change_pct,
                        coherence=pos.coherence,
                        trailing_stop_active=pos.trailing_stop_active,
                        highest_price=pos.highest_price,
                        timebox_expired=bool(getattr(pos, 'metadata', {}) and pos.metadata.get('timebox_expired', False)),
                        target_net=target_net,
                        total_rate=total_rate,
                        entry_fee=getattr(pos, 'entry_fee', 0.0) or None,
                    )
                except Exception as e:
                    logger.warning(f"Matrix position feed error for {symbol}: {e}")
            
            # üåü SIGNAL BROADCASTING: Scout positions broadcast market signals
            if pos.is_scout and abs(change_pct) > 0.5 and (time.time() - pos.last_signal_broadcast) > 30:
                # Scout broadcasts signal when it moves significantly
                direction = 'BUY' if change_pct > 0 else 'SELL'
                strength = min(1.0, abs(change_pct) / 5.0)  # 5% move = 1.0 strength
                
                signal = MarketSignal(
                    symbol=symbol,
                    direction=direction,
                    strength=strength,
                    momentum=change_pct,
                    coherence=pos.coherence,
                    timestamp=time.time(),
                    scout_id=pos.id
                )
                self.signal_broadcaster.broadcast_signal(signal)
                pos.last_signal_broadcast = time.time()
                print(f"   üê∫ SCOUT SIGNAL: {symbol} {direction} | Strength: {strength:.2f} | Momentum: {change_pct:+.2f}%")
            
            # üåü POSITION SPLITTING: Check if position should split
            position_value = pos.quantity * current_price
            if self.position_splitter.should_split(position_value, pos.entry_value, pos.generation):
                print(f"   üë∂ SPLIT READY: {symbol} (Gen {pos.generation}) - Value ${position_value:.2f} vs Entry ${pos.entry_value:.2f}")
                # We'll handle splitting after TP/SL checks to avoid complexity
            
            # Log status every 10 cycles or if significant change
            if pos.cycles % 10 == 0 or abs(change_pct) > 0.5:
                gen_marker = f" [G{pos.generation}]" if pos.generation > 0 else ""
                print(f"   üîç {symbol}{gen_marker}: Entry={pos.entry_price:.5f} Curr={current_price:.5f} ({source}) Pct={change_pct:+.2f}%")

            # Get Lattice Modifiers
            lattice_state = self.lattice.get_state()
            
            # üß† USE LEARNED TP/SL IF AVAILABLE (from probability matrix recommendations)
            # Handle lattice_state as dict or object
            tp_mod = lattice_state.get('tp_mod', 1.0) if isinstance(lattice_state, dict) else getattr(lattice_state, 'tp_mod', 1.0)
            sl_mod = lattice_state.get('sl_mod', 1.0) if isinstance(lattice_state, dict) else getattr(lattice_state, 'sl_mod', 1.0)
            
            if pos.learned_confidence in ('high', 'medium') and pos.learned_tp_pct is not None:
                # Use learned parameters with lattice modifier
                target_tp = (pos.learned_tp_pct * 100) * tp_mod  # Convert from decimal to %
                target_sl = (pos.learned_sl_pct * 100) * sl_mod if pos.learned_sl_pct else CONFIG['STOP_LOSS_PCT'] * sl_mod
                min_hold = pos.learned_hold_cycles if pos.learned_hold_cycles else CONFIG['MIN_HOLD_CYCLES']
                
                if pos.cycles % 20 == 0:
                    logger.info(f"   üß† {symbol}: Using LEARNED params - TP {target_tp:.1f}% / SL {target_sl:.1f}% / Hold {min_hold} (ExpWR: {pos.learned_win_rate*100:.0f}%)")
            else:
                # Use global CONFIG values
                target_tp = CONFIG['TAKE_PROFIT_PCT'] * tp_mod
                target_sl = CONFIG['STOP_LOSS_PCT'] * sl_mod
                min_hold = CONFIG['MIN_HOLD_CYCLES']
            
            # üåç‚ú® Apply Earth Resonance exit urgency to TP ‚ú®üåç
            # When field coherence is low, exit earlier with smaller profits
            if effective_tp_mult < 1.0:
                target_tp *= effective_tp_mult
                if pos.cycles % 20 == 0:
                    print(f"   üåç {symbol}: Earth urgency reducing TP to {target_tp:.2f}%")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # üîÆ PROBABILITY MATRIX EXIT SIGNALS - SURF THE WAVE! üîÆ
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # Check if matrix is now saying SELL for this position
            prob_exit_triggered = False
            if self.prob_matrix and CONFIG.get('ENABLE_PROB_MATRIX', True) and pos.cycles >= 3:
                try:
                    prob_signal = self.auris.get_probability_signal(
                        symbol=symbol,
                        price=current_price,
                        frequency=getattr(pos, 'hnc_frequency', 256),
                        momentum=change_pct,
                        coherence=pos.coherence,
                        is_harmonic=getattr(pos, 'hnc_harmonic', False),
                    )
                    prob_action = prob_signal.get('action', 'HOLD')
                    prob_probability = prob_signal.get('probability', 0.5)
                    prob_confidence = prob_signal.get('confidence', 0.0)
                    
                    # üö® MATRIX SAYS SELL - Time to exit if we're profitable
                    if prob_action in ['SELL', 'STRONG SELL'] and prob_confidence >= 0.5:
                        # Calculate gross P&L - penny threshold already handles fee math
                        exit_value = pos.quantity * current_price
                        gross_pnl = exit_value - pos.entry_value
                        
                        # üí∞ PENNY PROFIT CHECK FOR MATRIX EXITS
                        penny_check = check_penny_exit(pos.exchange, pos.entry_value, gross_pnl)
                        penny_threshold = penny_check.get('threshold')
                        
                        # üí∞ PENNY PROFIT OVERRIDE: Check if gross P&L meets penny target
                        if penny_threshold:
                            min_gross_win = penny_threshold.get('win_gte', 0.01)
                            target_net = penny_threshold.get('target_net', 0.01)
                            if gross_pnl >= min_gross_win:
                                fee_rate = get_exchange_fee_rate(pos.exchange)
                                slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
                                spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
                                total_rate = fee_rate + slippage + spread
                                entry_fee = getattr(pos, 'entry_fee', 0.0) or 0.0
                                if entry_fee <= 0 and pos.entry_value > 0:
                                    entry_fee = pos.entry_value * total_rate
                                exit_fee = exit_value * total_rate
                                net_pnl_est = gross_pnl - (entry_fee + exit_fee)

                                if net_pnl_est >= target_net:
                                    print(f"   üîÆ MATRIX EXIT (PENNY SECURED): {symbol} {prob_action} (prob={prob_probability:.0%}, conf={prob_confidence:.0%}) Net: ${net_pnl_est:.4f} >= ${target_net:.4f}")
                                    to_close.append((symbol, "MATRIX_SELL", change_pct, current_price))
                                    prob_exit_triggered = True
                                else:
                                    print(f"   üõë HOLDING {symbol}: Matrix exit blocked - net ${net_pnl_est:.4f} < ${target_net:.4f} (after costs)")
                            elif prob_action == 'STRONG SELL' and prob_confidence >= 0.7 and gross_pnl > -pos.entry_value * 0.01:
                                # Allow small loss (<1%) on STRONG SELL signals only
                                print(f"   üö® MATRIX FORCE EXIT: {symbol} STRONG SELL (conf={prob_confidence:.0%}) - Small loss ${gross_pnl:.2f}")
                                to_close.append((symbol, "MATRIX_FORCE", change_pct, current_price))
                                prob_exit_triggered = True
                            else:
                                print(f"   üõë HOLDING {symbol}: Matrix signal ignored - Penny Profit not met (${gross_pnl:.4f} < ${min_gross_win:.4f})")
                        else:
                            # Fallback: compute penny threshold on-the-fly
                            fb_threshold = get_penny_threshold(pos.exchange, pos.entry_value)
                            if fb_threshold:
                                min_gross_win = fb_threshold.get('win_gte', 0.01)
                                if gross_pnl >= min_gross_win:
                                    print(f"   üîÆ MATRIX EXIT: {symbol} {prob_action} (prob={prob_probability:.0%}, conf={prob_confidence:.0%}) Gross: ${gross_pnl:.4f}")
                                    to_close.append((symbol, "MATRIX_SELL", change_pct, current_price))
                                    prob_exit_triggered = True
                except Exception as e:
                    pass  # Continue with normal checks
            
            # Skip normal TP/SL checks if matrix already triggered exit
            if prob_exit_triggered:
                continue

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # üí∞ PENNY PROFIT TP/SL - DOLLAR-BASED EXIT LOGIC üí∞
            # üáÆüá™üéØ THE SNIPER MAKES THE KILLS THROUGH THE ECOSYSTEM
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # Calculate gross P&L for penny profit check
            exit_value = pos.quantity * current_price
            gross_pnl = exit_value - pos.entry_value
            
            # üéØ Check penny profit thresholds - SNIPER BRAIN ACTIVE
            penny_check = check_penny_exit(pos.exchange, pos.entry_value, gross_pnl, symbol)
            penny_threshold = penny_check.get('threshold')
            
            # üáÆüá™ Sniper wisdom for the kill
            sniper_wisdom = penny_check.get('sniper_wisdom')
            
            if penny_threshold:
                # üí∞ PENNY PROFIT MODE - Use dollar thresholds
                if penny_check['should_tp']:
                    # üáÆüá™üéØ SNIPER KILL! Only when NET profit after costs is secured.
                    min_gross_win = penny_threshold.get('win_gte', 0.01)
                    target_net = penny_threshold.get('target_net', 0.01)
                    fee_rate = get_exchange_fee_rate(pos.exchange)
                    slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
                    spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
                    total_rate = fee_rate + slippage + spread
                    entry_fee = getattr(pos, 'entry_fee', 0.0) or 0.0
                    if entry_fee <= 0 and pos.entry_value > 0:
                        entry_fee = pos.entry_value * total_rate
                    exit_fee = exit_value * total_rate
                    net_pnl_est = gross_pnl - (entry_fee + exit_fee)

                    if net_pnl_est >= target_net and gross_pnl >= min_gross_win:
                        if sniper_wisdom:
                            print(f"   üéØ SNIPER LOCKED: {symbol} - \"{sniper_wisdom}\"")
                        to_close.append((symbol, "TP", change_pct, current_price))
                    else:
                        print(f"   üõ°Ô∏è HOLD {symbol}: net ${net_pnl_est:.4f} < ${target_net:.4f} (after costs)")
                elif penny_check['should_sl']:
                    # üõ°Ô∏è STOP LOSS - Quick exit to protect capital
                    # üáÆüá™ SNIPER MODE: Only 1 cycle minimum (was 5)
                    if pos.cycles >= 1:  # Sniper mode: fast stops
                        to_close.append((symbol, "SL", change_pct, current_price))
                    else:
                        logger.debug(f"Holding {symbol} SL - cycle {pos.cycles}/1")
                elif gross_pnl > 0:
                    # üí∞ PENNY PROFIT OVERRIDE: Ignore min_hold if we have profit!
                    # Check if we're at penny harvest level
                    min_gross_win = penny_threshold.get('win_gte', 0.01)
                    if gross_pnl >= min_gross_win:
                        target_net = penny_threshold.get('target_net', 0.01)
                        fee_rate = get_exchange_fee_rate(pos.exchange)
                        slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
                        spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
                        total_rate = fee_rate + slippage + spread
                        entry_fee = getattr(pos, 'entry_fee', 0.0) or 0.0
                        if entry_fee <= 0 and pos.entry_value > 0:
                            entry_fee = pos.entry_value * total_rate
                        exit_fee = exit_value * total_rate
                        net_pnl_est = gross_pnl - (entry_fee + exit_fee)

                        if net_pnl_est >= target_net:
                            print(f"   üåæ PENNY HARVEST: {symbol} net ${net_pnl_est:.4f} >= ${target_net:.4f}")
                            to_close.append((symbol, "HARVEST", change_pct, current_price))
                        else:
                            print(f"   üõ°Ô∏è HOLD {symbol}: harvest blocked - net ${net_pnl_est:.4f} < ${target_net:.4f} (after costs)")
            else:
                # Fallback to percentage-based TP/SL
                # üîß FIX: Don't use fallback % stops - ALWAYS compute penny threshold
                # Recalculate with fallback entry value
                fallback_entry = pos.entry_value if pos.entry_value > 0 else (pos.quantity * pos.entry_price)
                penny_check_retry = check_penny_exit(pos.exchange, fallback_entry, gross_pnl)
                penny_threshold = penny_check_retry.get('threshold')
                
                if penny_threshold:
                    # Use computed penny thresholds even as fallback
                    if penny_check_retry['should_tp']:
                        # üáÆüá™ SNIPER KILL!
                        to_close.append((symbol, "TP", change_pct, current_price))
                    elif penny_check_retry['should_sl'] and pos.cycles >= 1:  # üáÆüá™ SNIPER: fast stops
                        to_close.append((symbol, "SL", change_pct, current_price))
                else:
                    # Last resort: only TP at +1.8%, NEVER stop out early
                    if change_pct >= target_tp:
                        to_close.append((symbol, "TP", change_pct, current_price))
                    # üîß FIX: Removed automatic SL at -1.5% - wait for penny SL instead
                    elif change_pct > 0:
                        # üí∞ PENNY PROFIT OVERRIDE: Compute threshold on-the-fly
                        # Use penny threshold instead of manual fee calculation
                        fb_threshold = get_penny_threshold(pos.exchange, pos.entry_value)
                        if fb_threshold:
                            min_gross_win = fb_threshold.get('win_gte', 0.01)
                            target_net = fb_threshold.get('target_net', 0.01)
                            if gross_pnl >= min_gross_win:
                                print(f"   üåæ PENNY HARVEST: {symbol} gross ${gross_pnl:.4f} >= ${min_gross_win:.4f} -> NET ~${target_net:.2f}")
                                to_close.append((symbol, "HARVEST", change_pct, current_price))
                
        for symbol, reason, pct, price in to_close:
            self.close_position(symbol, reason, pct, price)
    
    def rebalance_portfolio(self, opportunities: List[Dict]) -> float:
        """
        Dynamic portfolio rebalancing - sell underperformers to buy better opportunities.
        Returns: Amount of capital freed up for new trades.
        """
        if not CONFIG['ENABLE_REBALANCING']:
            return 0.0
            
        if not opportunities:
            return 0.0
            
        freed_capital = 0.0
        to_rebalance = []
        
        # Find positions that are underperforming and held long enough
        for symbol, pos in self.positions.items():
            if pos.cycles < CONFIG['MIN_HOLD_CYCLES']:
                continue  # Don't sell too quickly
                
            # Get current price
            current_price = self.get_realtime_price(symbol)
            if current_price is None:
                current_price = self.ticker_cache.get(symbol, {}).get('price', pos.entry_price)
            if current_price is None or current_price == 0:
                continue
            if pos.entry_price <= 0:
                continue
                
            change_pct = (current_price - pos.entry_price) / pos.entry_price * 100
            
            # Check if position is underperforming
            if change_pct < CONFIG['REBALANCE_THRESHOLD']:
                # Check if there's a better opportunity
                best_opp = opportunities[0] if opportunities else None
                if best_opp and best_opp.get('score', 0) > 80:
                    # Calculate if swapping would be profitable
                    # Expected gain from new position vs current loss
                    current_value = pos.quantity * current_price
                    swap_cost = current_value * (CONFIG['KRAKEN_FEE'] * 2 + CONFIG['SLIPPAGE_PCT'])
                    
                    # Expected gain from best opportunity
                    expected_gain = current_value * (CONFIG['TAKE_PROFIT_PCT'] / 100) * CONFIG['DEFAULT_WIN_PROB']
                    
                    if expected_gain > swap_cost:
                        to_rebalance.append((symbol, change_pct, current_price, current_value))
        
        # Execute rebalancing (sell underperformers)
        for symbol, change_pct, price, value in to_rebalance[:2]:  # Max 2 rebalances per cycle
            print(f"   üîÑ REBALANCING: Selling {symbol} ({change_pct:+.2f}%) to free ¬£{value:.2f}")
            self.close_position(symbol, "REBALANCE", change_pct, price)
            freed_capital += value
            
        return freed_capital
            
    def close_position(self, symbol: str, reason: str, pct: float, price: float):
        """Close a position"""
        # Don't pop yet! Wait for confirmation.
        if symbol not in self.positions:
            return
            
        pos = self.positions[symbol]
        
        # ÔøΩ SMART EXCHANGE CORRECTION: If position has wrong exchange, fix it!
        # This prevents errors like trying to sell DOGEUSDC on Kraken
        correct_exchange = self._detect_exchange_for_symbol(symbol, pos.exchange)
        if correct_exchange != pos.exchange.lower():
            print(f"   üîß Exchange correction: {symbol} was {pos.exchange.upper()} ‚Üí {correct_exchange.upper()}")
            pos.exchange = correct_exchange
        
        # ÔøΩüöÄ CANCEL SERVER-SIDE ORDERS (Kraken/Alpaca native TP/SL) before manual close
        if not self.dry_run and pos.exchange.lower() in ['kraken', 'alpaca']:
            try:
                # Cancel stop-loss order if exists (for Alpaca, this might be OCO ID)
                if pos.server_sl_order_id:
                    self.client.cancel_order(pos.exchange, pos.server_sl_order_id)
                    logger.info(f"Cancelled server SL order {pos.server_sl_order_id} for {symbol}")
                
                # Cancel take-profit order if exists (Kraken only, Alpaca uses OCO)
                if pos.server_tp_order_id:
                    self.client.cancel_order(pos.exchange, pos.server_tp_order_id)
                    logger.info(f"Cancelled server TP order {pos.server_tp_order_id} for {symbol}")
                
                # Cancel trailing stop order if exists
                if pos.server_trailing_order_id:
                    self.client.cancel_order(pos.exchange, pos.server_trailing_order_id)
                    logger.info(f"Cancelled server trailing order {pos.server_trailing_order_id} for {symbol}")
            except Exception as e:
                logger.warning(f"Failed to cancel server orders for {symbol}: {e}")
        
        # üåü CHECK EXIT GATE: Only sell if profitable
        if not self.should_exit_trade(pos, price, reason):
            return  # Hold position, don't sell at a loss
        
        # üßπ DUST PROTECTION: Check actual balance on exchange to prevent "Insufficient Balance" and clean dust
        if not self.dry_run:
            try:
                # Infer base asset
                base_asset = symbol
                # Sort quotes by length desc to match longest first (e.g. FDUSD before USD)
                sorted_quotes = sorted(CONFIG['QUOTE_CURRENCIES'], key=len, reverse=True)
                for quote in sorted_quotes:
                    if symbol.endswith(quote):
                        base_asset = symbol[:-len(quote)]
                        break
                
                # Get actual free balance from the specific exchange client
                # We need to route this to the correct exchange client instance
                free_balance = 0.0
                if isinstance(self.client, MultiExchangeClient):
                    if pos.exchange in self.client.clients:
                        free_balance = self.client.clients[pos.exchange].get_balance(base_asset)
                elif hasattr(self.client, 'get_balance'):
                    free_balance = self.client.get_balance(base_asset)
                
                if free_balance > 0:
                    # Case 1: Actual balance is LESS than tracked (e.g. fees deducted from asset)
                    if free_balance < pos.quantity:
                        # If it's within 10% (fees are small), assume it's fee deduction and adjust
                        if free_balance > pos.quantity * 0.90:
                            print(f"   üßπ Adjusting sell qty for {symbol}: {pos.quantity:.8f} -> {free_balance:.8f} (Fees/Dust)")
                            pos.quantity = free_balance
                        else:
                            # Significant difference - safer to sell what we have to close the position
                            print(f"   ‚ö†Ô∏è Balance mismatch for {symbol}: Tracked {pos.quantity:.8f}, Actual {free_balance:.8f}. Selling Actual.")
                            pos.quantity = free_balance
                    
                    # Case 2: Actual balance is slightly MORE than tracked (leftover dust)
                    # Clean it up if it's within 5% excess
                    elif free_balance > pos.quantity and free_balance < pos.quantity * 1.05:
                        print(f"   üßπ Cleaning dust for {symbol}: {pos.quantity:.8f} -> {free_balance:.8f}")
                        pos.quantity = free_balance
            except Exception as e:
                print(f"   ‚ö†Ô∏è Failed to check balance for {symbol}: {e}")

        # EXECUTE TRADE - Use unified confirmation for all exchanges
        success = False
        if not self.dry_run:
            try:
                # Use unified trade confirmation for proper handling across exchanges
                confirmation = self.trade_confirmation.submit_order(
                    pos.exchange, symbol, 'SELL', quantity=pos.quantity
                )
                
                status = confirmation.get('status', '').upper()
                order_id = confirmation.get('order_id')
                
                if status in ['FILLED', 'ACCEPTED', 'OPEN', 'CLOSED']:
                    success = True
                    logger.info(f"Trade confirmed: {pos.exchange}/{symbol} -> {order_id}")
                elif status == 'REJECTED' and confirmation.get('pre_flight'):
                    print(f"   üóëÔ∏è Dust detected for {symbol}: {confirmation.get('error')}. Removing from active tracking.")
                    # Remove from active positions to stop infinite loop
                    self.positions.pop(symbol, None)
                    self.save_state()  # üîÑ Save state after dust removal
                    return
                else:
                    print(f"   ‚ö†Ô∏è Sell failed for {symbol}: {status}. Retrying next cycle.")
                    return # Don't remove position, try again later
            except Exception as e:
                print(f"   ‚ö†Ô∏è Sell execution error for {symbol}: {e}")
                return # Don't remove position, try again later
        else:
            success = True # Dry run always succeeds
            
        # Only remove if successful
        if success:
            self.positions.pop(symbol)
            # üîÑ IMMEDIATE STATE SAVE: Persist position removal right away!
            try:
                self.save_state()
                logger.info(f"üíæ State saved after closing {symbol}")
            except Exception as e:
                logger.warning(f"State save failed after close: {e}")
            
            # ‚öîÔ∏è WAR STRATEGY: COMPLETE RAID TRACKING ‚öîÔ∏è
            # Record how long we held and if we hit penny profit target
            if WAR_STRATEGY_AVAILABLE and WAR_STRATEGIST:
                try:
                    # Calculate bars held (assuming 1-min bars)
                    bars_held = int((time.time() - pos.entry_time) / 60)
                    exit_value = pos.quantity * price
                    
                    completed_raid = complete_raid(symbol, price, exit_value, bars_held)
                    if completed_raid:
                        if completed_raid.was_quick_kill:
                            print(f"   ‚ö° QUICK KILL SUCCESS! {bars_held} bars - Penny profit achieved!")
                        elif completed_raid.was_penny_profit:
                            print(f"   üí∞ PENNY PROFIT! Took {bars_held} bars ({bars_held/60:.1f}min)")
                        else:
                            print(f"   ‚è±Ô∏è Raid duration: {bars_held} bars ({bars_held/60:.1f}min) - No penny profit")
                except Exception as e:
                    logger.warning(f"War Strategy raid complete error: {e}")
        
        # üìê Calculate P&L using the same model as penny profit threshold formula
        # The formula r = ((1 + P/A) / (1-f)¬≤) - 1 treats fees as multiplicative factors
        # So we must calculate NET P&L the same way for consistency
        #
        # Entry: paid A, received A√ó(1-f) worth of crypto (fee deducted)
        # Exit: crypto now worth exit_value, we receive exit_value√ó(1-f) (fee deducted)
        # Net = exit_value√ó(1-f) - A  (we already paid A on entry)
        #
        # Since the threshold already accounts for all fees, we compute ACTUAL net P&L here
        
        exit_value = pos.quantity * price
        gross_pnl = exit_value - pos.entry_value
        
        # Get the combined fee rate used in penny threshold calculation
        fee_rate = get_exchange_fee_rate(pos.exchange)
        slippage = CONFIG.get('SLIPPAGE_PCT', 0.0020)
        spread = CONFIG.get('SPREAD_COST_PCT', 0.0010)
        total_rate = fee_rate + slippage + spread
        
        # Calculate actual fees (linear approximation for accounting purposes)
        # Entry fee was already calculated on pos.entry_fee using entry_value
        exit_fee = exit_value * total_rate  # All costs on exit leg
        total_expenses = pos.entry_fee + exit_fee
        
        net_pnl = gross_pnl - total_expenses
        
        # Calculate hold time
        exit_time = time.time()
        hold_time_sec = exit_time - pos.entry_time
        hold_time_min = hold_time_sec / 60.0
        
        # üåä RESONANCE HOLDING: Don't exit before MIN_HOLD_MINUTES unless emergency
        # From miner blueprint: 50+ min hold times achieve best efficiency
        # üí∞ PENNY PROFIT OVERRIDE: If we have a penny profit, we take it regardless of time!
        is_penny_profitable = net_pnl >= 0.01
        
        # TIMEBOXED MODE: never block exits with resonance holding.
        try:
            max_hold_min = float(CONFIG.get('MAX_HOLD_MINUTES', 5) or 5)
        except Exception:
            max_hold_min = 5.0

        if hold_time_min < MIN_HOLD_MINUTES and hold_time_min < max_hold_min and not is_penny_profitable and reason not in ['TIMEBOX', 'TIMEBOX_PROFIT']:
            pnl_pct = ((price - pos.entry_price) / pos.entry_price * 100) if pos.entry_price > 0 else 0
            # Only exit early on stops (-5%) or massive gains (+20%)
            if reason not in ['STOP_LOSS', 'CIRCUIT_BREAKER'] and abs(pnl_pct) < 20:
                logger.debug(f"üåä {symbol}: Holding for resonance ({hold_time_min:.1f}/{MIN_HOLD_MINUTES} min), PnL {pnl_pct:+.1f}%")
                return  # Keep position open
        
        # üìä FEED POSITION CLOSE TO PROBABILITY MATRIX üìä
        # This helps the matrix validate predictions and learn from outcomes
        if self.prob_matrix and hasattr(self.prob_matrix, 'feed_position_close'):
            try:
                # Align matrix outcome metrics with penny-profit ethos.
                penny_threshold = None
                try:
                    penny_threshold = get_penny_threshold(pos.exchange, pos.entry_value)
                except Exception:
                    penny_threshold = None

                target_net = 0.01
                if isinstance(penny_threshold, dict):
                    target_net = float(penny_threshold.get('target_net', target_net))

                penny_hit = bool(net_pnl >= target_net)

                try:
                    max_hold_min_for_matrix = float(CONFIG.get('MAX_HOLD_MINUTES', 5) or 5)
                except Exception:
                    max_hold_min_for_matrix = 5.0

                quick_kill = bool(penny_hit and hold_time_min > 0 and hold_time_min <= max_hold_min_for_matrix)

                timebox_expired = False
                try:
                    timebox_expired = bool(getattr(pos, 'metadata', {}) and pos.metadata.get('timebox_expired', False))
                except Exception:
                    timebox_expired = False

                self.prob_matrix.feed_position_close(
                    symbol=symbol,
                    exit_price=price,
                    realized_pnl=net_pnl,
                    exit_reason=reason,
                    platform_timestamp=exit_time,
                    target_net=target_net,
                    penny_hit=penny_hit,
                    quick_kill=quick_kill,
                    max_hold_minutes=max_hold_min_for_matrix,
                    hold_duration_mins=hold_time_min,
                    timebox_expired=timebox_expired,
                )
                logger.info(f"Matrix outcome recorded: {symbol} PnL={net_pnl:.2f} reason={reason}")
                
                # üß† PUBLISH THOUGHT: TRADE CLOSED üß†
                if THOUGHT_BUS_AVAILABLE and THOUGHT_BUS:
                    THOUGHT_BUS.publish(Thought(
                        source="unified_ecosystem",
                        topic="execution.order.close",
                        payload={
                            "symbol": symbol,
                            "side": "SELL",
                            "price": price,
                            "quantity": pos.quantity,
                            "pnl": net_pnl,
                            "reason": reason,
                            "hold_time_min": hold_time_min
                        }
                    ))
                
                # üîÆ CONTINUOUS LEARNING: Validate prediction vs actual outcome
                # This is the core feedback loop that improves forecast accuracy
                if hasattr(self.prob_matrix, 'validate_and_learn'):
                    try:
                        # Determine actual direction from P&L
                        actual_direction = "BULLISH" if net_pnl > 0 else ("BEARISH" if net_pnl < 0 else "NEUTRAL")
                        
                        # Get what the matrix predicted for this symbol
                        if symbol in self.prob_matrix.matrices:
                            matrix = self.prob_matrix.matrices[symbol]
                            predicted_direction = matrix.day_plus_1.predicted_direction if matrix.day_plus_1 else "NEUTRAL"
                            confidence = matrix.confidence_score if hasattr(matrix, 'confidence_score') else 0.5
                            
                            # Validate and learn
                            validation = self.prob_matrix.validate_and_learn(
                                symbol=symbol,
                                predicted_direction=predicted_direction,
                                actual_direction=actual_direction,
                                confidence=confidence
                            )
                            
                            if validation['validated']:
                                accuracy = validation.get('accuracy', 0.5) * 100
                                trend = validation.get('trend', 'UNKNOWN')
                                logger.info(f"üîÆ {symbol} validation: predicted {predicted_direction}, actual {actual_direction}, accuracy now {accuracy:.0f}% ({trend})")
                    except Exception as e:
                        logger.debug(f"Matrix learning error for {symbol}: {e}")
            except Exception as e:
                logger.warning(f"Matrix position close feed error for {symbol}: {e}")
        
        # üìä LOG TRADE EXIT FOR PROBABILITY MATRIX VALIDATION üìä
        if TRADE_LOGGER_AVAILABLE and trade_logger:
            try:
                pnl_pct = (net_pnl / pos.entry_value * 100) if pos.entry_value > 0 else 0
                trade_logger.log_trade_exit(
                    trade_id=f"{symbol}_{pos.entry_time:.0f}",
                    exit_data={
                        'symbol': symbol,
                        'exit_price': price,
                        'exit_time': exit_time,
                        'exit_value': exit_value,
                        'gross_pnl': gross_pnl,
                        'net_pnl': net_pnl,
                        'pnl_pct': pnl_pct,
                        'fees': total_expenses,
                        'reason': reason,
                        'hold_time_seconds': hold_time_sec,
                    }
                )
            except Exception as e:
                logger.warning(f"Failed to log trade exit for {symbol}: {e}")
        
        # Release symbol exposure
        if symbol in self.tracker.symbol_exposure:
            del self.tracker.symbol_exposure[symbol]
        
        # üåü Return capital to pool with profit
        self.capital_pool.deallocate(symbol, pos.entry_value, net_pnl)
        
        # Record trade with platform attribution
        self.tracker.record_trade(
            net_pnl=net_pnl, 
            fees=total_expenses, 
            symbol=symbol, 
            reason=reason, 
            hold_time_sec=hold_time_sec,
            platform=pos.exchange,
            volume=exit_value
        )
        # üß† Feed kill data to unified sniper brain for telemetry
        self._record_sniper_kill(pos, net_pnl)
        
        # Feed learning back to Mycelium Network
        # Learn on REALIZED NET outcome (after costs), not raw price-change %.
        # This aligns the network with the ethos: net pennies and no-loss by default.
        try:
            net_pct_for_mycelium = (net_pnl / pos.entry_value * 100) if pos.entry_value > 0 else 0.0
        except Exception:
            net_pct_for_mycelium = 0.0
        self.mycelium.learn(symbol, net_pct_for_mycelium)
        
        # üêò Record trade result in Elephant Memory
        self.elephant_memory.record(symbol, net_pnl)
        
        # üß† Record trade in Adaptive Learning Engine WITH NEWS/KNOWLEDGE CORRELATION
        ticker_snapshot = self.ticker_cache.get(symbol, {}) if hasattr(self, 'ticker_cache') else {}
        news_context = getattr(self, '_last_news_sentiment', {})
        ADAPTIVE_LEARNER.enhanced_record_trade({
            'symbol': symbol,
            'entry_price': pos.entry_price,
            'exit_price': price,
            'pnl': net_pnl,
            'frequency': getattr(pos, 'frequency', 256),
            'coherence': pos.coherence,
            'score': getattr(pos, 'score', 50),
            'entry_time': pos.entry_time,
            'exit_time': time.time(),
            'hnc_action': getattr(pos, 'hnc_action', 'HOLD'),
            'probability': getattr(pos, 'probability', 0.5),
            'reason': reason,
            'exchange': pos.exchange,
            'hold_time_sec': hold_time_sec,
            # Inject latest ticker context so adaptive learning can correlate
            'ticker_price': ticker_snapshot.get('price'),
            'ticker_change24h': ticker_snapshot.get('change24h'),
            'ticker_volume': ticker_snapshot.get('volume'),
            'ticker_source': ticker_snapshot.get('source', 'unknown'),
            # üì∞ NEWS CORRELATION CONTEXT - Learn from market sentiment at trade time
            'news_sentiment': news_context.get('sentiment', 0.0),
            'news_label': news_context.get('label', 'unknown'),
            'news_confidence': news_context.get('confidence', 0.0),
        })
        
        # üåä CASCADE AMPLIFIER - Update win/loss streak for signal amplification
        pnl_pct = (net_pnl / pos.entry_value * 100) if pos.entry_value > 0 else 0
        if net_pnl > 0:
            CASCADE_AMPLIFIER.record_win(pnl_pct / 100)
        else:
            CASCADE_AMPLIFIER.record_loss(pnl_pct / 100)
        
        # üåê MULTI-EXCHANGE LEARNING - All Systems Learn Together üåê
        asset_class = 'crypto'  # Default
        if pos.exchange == 'capital':
            asset_class = 'cfd'
        elif pos.exchange == 'alpaca':
            asset_class = 'stocks'
        self.multi_exchange.record_trade_result(
            exchange=pos.exchange,
            symbol=symbol,
            pnl=net_pnl,
            asset_class=asset_class,
            frequency=getattr(pos, 'frequency', 432),
            coherence=pos.coherence
        )
        
        # üîÆ NEXUS PREDICTOR LEARNING - Update patterns from trade outcome üîÆ
        if self.nexus_predictor is not None:
            try:
                entry_prediction = {
                    'direction': 'LONG',  # We only go long currently
                    'probability': getattr(pos, 'nexus_prob', 0.5),
                    'edge': getattr(pos, 'nexus_edge', 0.0),
                    'patterns_triggered': getattr(pos, 'nexus_patterns', []),
                }
                self.nexus_predictor.record_trade_outcome(
                    entry_prediction=entry_prediction,
                    was_profitable=(net_pnl > 0),
                    pnl_pct=pnl_pct
                )
            except Exception as e:
                pass  # Silent fail
        
        # üåâ Record trade in bridge for cross-system tracking
        if self.bridge_enabled and self.bridge:
            self.bridge.record_trade(
                profit=gross_pnl,
                fee=total_expenses,
                success=(net_pnl > 0)
            )
            # Unregister position from bridge ledger
            self.bridge.unregister_position(pos.exchange, symbol)
        
        icon = "‚úÖ" if net_pnl > 0 else "‚ùå"
        # Dynamic currency symbol
        curr_sym = "¬£" if CONFIG['BASE_CURRENCY'] == 'GBP' else "‚Ç¨" if CONFIG['BASE_CURRENCY'] == 'EUR' else "$"
        gen_marker = f" [G{pos.generation}]" if pos.generation > 0 else ""
        print(f"   {icon} CLOSE {symbol:12s}{gen_marker} | {reason} {pct:+.2f}% | Net: {curr_sym}{net_pnl:+.2f} | Pool: {curr_sym}{self.capital_pool.total_profits:+.2f} | WR: {self.tracker.win_rate:.1f}%")
        # Refresh equity to keep tracker in sync with realised trade
        self.refresh_equity()
        
    def _get_node_icon(self, node: str) -> str:
        """Get emoji for dominant node"""
        icons = {
            'Tiger': 'üêÖ', 'Falcon': 'ü¶Ö', 'Hummingbird': 'üê¶',
            'Dolphin': 'üê¨', 'Deer': 'ü¶å', 'Owl': 'ü¶â',
            'Panda': 'üêº', 'CargoShip': 'üö¢', 'Clownfish': 'üê†'
        }
        return icons.get(node, 'üéØ')

    def print_portfolio_report(self):
        """Print detailed portfolio report by exchange"""
        print("\n   üìä PORTFOLIO REPORT")
        print("   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        
        try:
            all_balances = self.client.get_all_balances()
            total_val = 0.0
            alpaca_val = 0.0  # Track Alpaca separately (analytics only)
            base = CONFIG['BASE_CURRENCY']
            
            for exchange, balances in all_balances.items():
                # Mark Alpaca as analytics-only
                if exchange.lower() == 'alpaca':
                    print(f"   üìä {exchange.upper()} (Analytics Only - Paper):")
                else:
                    print(f"   üè¶ {exchange.upper()}:")
                has_bal = False
                exchange_total = 0.0
                for asset, amount in balances.items():
                    try:
                        amount = float(amount)
                        if amount > 0:
                            has_bal = True
                            # Estimate value
                            val = 0.0
                            try:
                                # Clean asset name for conversion
                                clean_asset = asset.replace('Z', '')
                                if clean_asset.startswith('X') and len(clean_asset) > 3:
                                    clean_asset = clean_asset[1:]
                                if asset.startswith('LD'): # Binance Earn
                                    clean_asset = asset[2:]
                                    
                                val = self.client.convert_to_quote(exchange, clean_asset, amount, base)
                            except:
                                pass
                            
                            exchange_total += val
                            
                            # Add to appropriate total
                            if exchange.lower() == 'alpaca':
                                alpaca_val += val
                            else:
                                total_val += val
                                
                            print(f"      - {asset}: {amount:.8f} (~{val:.2f} {base})")
                    except:
                        pass
                if not has_bal:
                    print("      (Empty)")
            
            print("   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
            print(f"   üí∞ Trading Capital: {total_val:.2f} {base}")
            if alpaca_val > 0:
                print(f"   üìä Alpaca (Analytics): {alpaca_val:.2f} {base} (not included)")
            print("   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Failed to generate portfolio report: {e}")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üíì HEARTBEAT - Periodic status output
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def print_heartbeat(self):
        """Print a periodic heartbeat with key metrics."""
        now = datetime.now().strftime("%H:%M:%S")
        uptime_mins = (time.time() - self.start_time) / 60
        
        # Calculate position stats
        total_value = 0.0
        total_pnl = 0.0
        for symbol, pos in self.positions.items():
            rt_price = self.get_realtime_price(symbol)
            price = rt_price if rt_price else pos.entry_price
            current_val = pos.quantity * price
            pnl = current_val - pos.entry_value
            total_value += current_val
            total_pnl += pnl
        
        # Get win rate from tracker
        win_rate = (self.tracker.wins / self.tracker.total_trades * 100) if self.tracker.total_trades > 0 else 0
        
        # Get symbol cache stats
        cache_stats = self.get_symbol_cache_stats()
        
        # Get probability matrix stats if available
        matrix_stats = ""
        if self.prob_matrix:
            try:
                summary = self.prob_matrix.get_active_positions_summary()
                win_stats = self.prob_matrix.get_position_win_rate()
                matrix_stats = f" | Matrix: {summary['count']} tracked, {win_stats.get('trades', 0)} outcomes"
            except:
                pass
        
        print(f"\n   üíì HEARTBEAT [{now}] Uptime: {uptime_mins:.0f}m | "
              f"Positions: {len(self.positions)} | Value: ¬£{total_value:.2f} | "
              f"PnL: ¬£{total_pnl:+.2f} | Win: {win_rate:.0f}% ({self.tracker.wins}W/{self.tracker.losses}L)"
              f"{matrix_stats}")
        if hasattr(self, 'sniper_brain') and self.sniper_brain:
            sniper_status = self.sniper_brain.get_status()
            bridge_flag = "LINKED" if self._sniper_bridge_ready else "PENDING"
            print(f"   üéØ Sniper Brain: {bridge_flag} | Kills {sniper_status['wins']}W/{sniper_status['losses']}L (today {sniper_status['kills_today']}) | Size ${sniper_status['position_size']:.2f}")
        if hasattr(self, 'sniper_coverage') and self.sniper_coverage:
            linked_platforms = len(self.sniper_coverage.get('platforms', {}))
            print(f"   üî≠ Scout Bridge: {linked_platforms} exchanges | Scouts deployed: {self.scouts_deployed}")
        
        # üõ°Ô∏è IMMUNE SYSTEM STATUS - Probability Matrix Health Prediction
        if hasattr(self, 'immune_system') and self.immune_system:
            try:
                immune_summary = self.immune_system.get_immune_summary()
                health_icon = "üü¢" if immune_summary['status'] == 'HEALTHY' else "üü°" if immune_summary['status'] == 'WATCH' else "üü†" if immune_summary['status'] == 'WARNING' else "üî¥"
                trend_icon = "üìà" if immune_summary['trend'] == 'IMPROVING' else "üìâ" if immune_summary['trend'] == 'DEGRADING' else "‚û°Ô∏è"
                print(f"   üõ°Ô∏è Immune System: {health_icon} {immune_summary['health_score']:.0f}% {immune_summary['status']} | "
                      f"{trend_icon} {immune_summary['trend']} ({immune_summary['trend_confidence']:.0%}) | "
                      f"Auto-heals: {immune_summary['auto_heals']} | Accuracy: {immune_summary['predictions_accuracy']:.0f}%")
            except Exception as e:
                logger.debug(f"Immune status error: {e}")
        
        # üåÄ MEDICINE WHEEL FREQUENCY MESSAGE - What is the market saying?
        try:
            # Get current dominant frequency from recent trades or market state
            dominant_freq = self._get_dominant_market_frequency()
            freq_name = self._get_frequency_name(dominant_freq)
            message = self._translate_frequency_message(dominant_freq)
            print(f"\n   üåÄ MEDICINE WHEEL [{dominant_freq:.0f}Hz - {freq_name}]:")
            print(f"      {message}")
        except Exception as e:
            logger.debug(f"Frequency message error: {e}")
    
    def _get_dominant_market_frequency(self) -> float:
        """
        Calculate the dominant market frequency from recent activity.
        This is the 'voice' of the market right now.
        """
        # Try to get from global harmonic field
        if hasattr(self, 'harmonic_field') and self.harmonic_field:
            try:
                state = self.harmonic_field.get_composite_signal()
                if state and 'dominant_frequency' in state:
                    return state['dominant_frequency']
            except:
                pass
        
        # Calculate from recent position frequencies
        frequencies = []
        for symbol in list(self.positions.keys())[:10]:
            try:
                price = self.get_realtime_price(symbol)
                if price:
                    history = self._price_history.get(symbol, [])
                    if len(history) >= 2:
                        ratio = price / history[0][1] if history[0][1] > 0 else 1.0
                        phi = 1.618
                        freq = max(256.0, min(963.0, 432.0 * (ratio ** phi)))
                        frequencies.append(freq)
            except:
                continue
        
        if frequencies:
            return sum(frequencies) / len(frequencies)
        
        # Default to cosmic harmony
        return 432.0

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Main Loop
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    def run_one_cycle(self):
        """Run a single trading cycle"""
        self.iteration += 1
        now = datetime.now().strftime("%H:%M:%S")
        
        print(f"\\n{'‚îÅ'*70}")
        print(f"üîÑ Cycle {self.iteration} - {now} [{self.scan_direction}]")
        print(f"{'‚îÅ'*70}")

        # Refresh aggregated state periodically (every 10 minutes)
        try:
            last_agg = self.state_aggregator.aggregated_state.get('last_aggregation', 0)
            if time.time() - last_agg > 600:
                self.state_aggregator.load_all_sources()
        except Exception:
            pass
        
        # üè• ECOSYSTEM HEALTH CHECK (every 10 cycles)
        if self.iteration % 10 == 0:
            health = self.auris.get_system_health_report()
            print(f"\\nüì° Ecosystem Health: {health['overall_health']}")
            if health['communication']['systems_active'] < 2:
                print("   ‚ö†Ô∏è  WARNING: Less than 2 systems active!")
        
        # üåâ Sync with Bridge
        if self.bridge_enabled:
            self.sync_bridge()
            self.check_bridge_commands()
        
        # Market Pulse Analysis
        if self.iteration % 5 == 1: # Every 5 cycles
            try:
                pulse = self.market_pulse.analyze_market()
                # Update Capital Pool with Sentiment
                c_score = pulse['crypto_sentiment']['avg_change_24h']
                s_score = pulse['stock_sentiment']['avg_change_24h']
                avg_sentiment = (c_score + s_score) / 2
                self.capital_pool.update_sentiment(avg_sentiment)
            except Exception as e:
                print(f"   ‚ö†Ô∏è Market Pulse Error: {e}")

        # üåê‚ö° GLOBAL HARMONIC FIELD UPDATE ‚ö°üåê
        # Feed all 42 data sources into the unified field every cycle
        omega_signal = None
        if self.global_harmonic_field:
            try:
                # Gather data from all sources
                fear_greed = getattr(self, 'macro_snapshot', None)
                fg_value = fear_greed.crypto_fear_greed if fear_greed else 50
                
                # BTC price from ticker cache
                btc_price = self.ticker_cache.get('BTCUSD', {}).get('price', 100000)
                btc_change = self.ticker_cache.get('BTCUSD', {}).get('change24h', 0)
                
                # Get quantum brain state if available
                quantum_state = None
                if self.brain:
                    try:
                        brain_state = self.brain.get_unified_state()
                        quantum_state = {
                            'unified_coherence': brain_state.get('unified_coherence', 0.5),
                            'planetary_gamma': brain_state.get('planetary_gamma', 0.5),
                            'probability_edge': brain_state.get('probability_edge', 0),
                            'cascade_multiplier': brain_state.get('cascade_multiplier', 1.0),
                            'is_optimal_window': brain_state.get('optimal_window', False),
                        }
                    except:
                        pass
                
                # Get Auris state
                auris_state = None
                if hasattr(self.auris, 'get_auris_state'):
                    try:
                        a_state = self.auris.get_auris_state()
                        auris_state = {
                            'auris_dolphin': a_state.get('dolphin', 0.5),
                            'auris_owl': a_state.get('owl', 0.5),
                            'piano_lambda': getattr(self.auris, 'piano_lambda', 1.0),
                            'piano_coherence': getattr(self.auris, 'piano_coherence', 0.5),
                            'rainbow_state': getattr(self.enhancement_layer, 'rainbow_state', 'LOVE') if self.enhancement_layer else 'LOVE',
                        }
                    except:
                        pass
                
                # Get Mycelium state
                mycelium_state = {
                    'mycelium_coherence': self.mycelium.get_network_coherence() if self.mycelium else 0.5,
                    'mycelium_agents': len(self.mycelium.hives) if self.mycelium else 0,
                }
                
                # Get market state
                market_state = {
                    'btc_change_24h': btc_change,
                    'news_sentiment': self._last_news_sentiment.get('score', 0.5) if hasattr(self, '_last_news_sentiment') else 0.5,
                    'win_rate': self.tracker.win_rate / 100.0 if self.tracker.win_rate else 0.5,
                }
                
                # üéØ Get Probability Matrix state (HNC Probability Integration)
                probability_state = None
                if self.prob_matrix:
                    try:
                        # Get best available probability signal
                        prob_opps = self.prob_matrix.get_high_probability_opportunities(
                            min_probability=0.55, min_confidence=0.4
                        )
                        if prob_opps:
                            best = prob_opps[0]
                            probability_state = {
                                'probability': best.get('probability', 0.5),
                                'confidence': best.get('confidence', 0.0),
                                'modifier': best.get('modifier', 1.0),
                                'h1_state': best.get('h1_state', 'UNKNOWN'),
                                'action': best.get('action', 'HOLD'),
                                'historical_win_rate': 0.5,
                                'high_conviction_count': len(prob_opps),
                                'consensus_strength': 0.5,
                            }
                        # Get win rate stats from probability matrix
                        win_stats = self.prob_matrix.get_position_win_rate()
                        if probability_state:
                            probability_state['historical_win_rate'] = win_stats.get('win_rate', 0.5)
                    except Exception as e:
                        logger.debug(f"Probability state error: {e}")
                
                # Update the field with all data (including Probability Matrix!)
                omega_signal = self.global_harmonic_field.update_all(
                    fear_greed=fg_value,
                    btc_price=btc_price,
                    btc_change=btc_change,
                    quantum_state=quantum_state,
                    auris_state=auris_state,
                    mycelium_state=mycelium_state,
                    market_state=market_state,
                    probability_state=probability_state,  # üéØ HNC Probability Matrix!
                )
                
                # Print field status every 10 cycles
                if self.iteration % 10 == 0:
                    omega = omega_signal.get('omega', 0.5)
                    direction = omega_signal.get('direction', 'NEUTRAL')
                    confidence = omega_signal.get('confidence', 0.5)
                    emoji = 'üöÄ' if direction == 'STRONG_BUY' else 'üìà' if direction == 'BUY' else 'üìâ' if direction == 'SELL' else 'üîª' if direction == 'STRONG_SELL' else '‚öñÔ∏è'
                    print(f"   üåê‚ö° HARMONIC FIELD: Œ©={omega:.4f} {emoji} {direction} (Confidence: {confidence:.1%})")
                
            except Exception as e:
                logger.debug(f"Harmonic field update error: {e}")

        # Refresh data
        self.refresh_tickers()
        print(f"   üìä Ticker cache: {len(self.ticker_cache)} symbols loaded")
        self.refresh_equity(mark_cycle=True)
        
        # Deploy scouts on first cycle if enabled
        if self.iteration == 1 and not self.scouts_deployed:
            self._deploy_scouts()
        
        # üíì Heartbeat every 5 cycles
        if self.iteration % 5 == 0:
            self.print_heartbeat()
        
        # Toggle scan direction
        self.scan_direction = 'Z‚ÜíA' if self.iteration % 2 == 0 else 'A‚ÜíZ'
        
        # Check positions
        self.check_positions()

        # Determine position capacity (None = unlimited)
        max_positions = get_max_positions_limit() or 10**9
        
        # Check network coherence
        network_coherence = self.mycelium.get_network_coherence()
        trading_paused = network_coherence < CONFIG['MIN_NETWORK_COHERENCE']

        # Pause new entries if probability reports are stale
        pfresh = self.state_aggregator.aggregated_state.get('probability_freshness', {})
        if pfresh.get('stale'):
            trading_paused = True
            newest = pfresh.get('newest_minutes')
            newest_str = f"{newest:.1f}m" if isinstance(newest, (int, float)) else "unknown"
            print(f"   ‚ö†Ô∏è Probability data stale ({newest_str}); skipping new entries this cycle")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # üéØ‚ö° TURBO HUNTER - PROACTIVELY SEEK 90%+ WIN RATE OPPORTUNITIES ‚ö°üéØ
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # "It already knows what's gonna happen - HUNT the 90% winners!"
        # Every cycle, actively scan for ELITE setups that match historical patterns
        # Execute IMMEDIATELY when found - complete cycle in ~1 minute target
        turbo_trades = 0
        if CONFIG.get('ENABLE_TURBO_HUNT', True) and not trading_paused and not self.tracker.trading_halted:
            if len(self.positions) < max_positions:
                try:
                    elite_opps = self._turbo_hunt_90_percent()
                    if elite_opps:
                        slots_available = max_positions - len(self.positions)
                        for elite in elite_opps[:min(3, slots_available)]:
                            print(f"   ‚ö°üéØ TURBO EXECUTE: {elite['symbol']} | {elite.get('hunt_reason', 'ELITE')}")
                            self.open_position(elite)
                            turbo_trades += 1
                        if turbo_trades > 0:
                            print(f"   üéØ TURBO HUNT: Executed {turbo_trades} elite trades!")
                except Exception as e:
                    logger.warning(f"Turbo hunt error: {e}")
        
        # Update Lattice State
        raw_opps = self.find_opportunities()
        l_state = self.lattice.update(raw_opps)
        self._sync_queen_external_state(l_state)
        
        # Apply Triadic Envelope Protocol
        all_opps = self.lattice.filter_signals(raw_opps)
        
        # Rebalance
        if all_opps and max_positions < 10**9 and len(self.positions) >= max_positions // 2:
            freed = self.rebalance_portfolio(all_opps)
            if freed > 0: self.refresh_equity()

        # Find opportunities
        if len(self.positions) < max_positions and not self.tracker.trading_halted and not trading_paused:
            # üéØ TARGET FILL RATE: Actively try to maintain 1/3 positions filled
            target_positions = int(max_positions * CONFIG.get('TARGET_FILL_RATE', 0.33))
            current_positions = len(self.positions)
            under_target = current_positions < target_positions
            
            if all_opps:
                if under_target:
                    print(f"\\n   üéØ FILLING MODE: {current_positions}/{target_positions} target ({current_positions}/{max_positions_label()} max)")
                    print(f"   üîç Actively seeking {target_positions - current_positions} more positions...")
                print(f"\\n   üîÆ Top Opportunities: {len(all_opps)} found")
                for opp in all_opps[:5]:
                    print(f"      {opp['symbol']:12s} +{opp['change24h']:5.1f}% | Œì={opp['coherence']:.2f} | Score: {opp['score']}")
            
            # If under target, be more aggressive - take more opportunities per cycle
            if under_target:
                slots_to_fill = min(target_positions - current_positions, 3)  # Fill up to 3 per cycle
            else:
                slots_to_fill = 1  # Normal mode: 1 at a time
            
            for opp in all_opps[:min(slots_to_fill, max_positions - current_positions)]:
                self.open_position(opp)
                
        # Show positions - ENHANCED with LADDER ETA
        if self.positions:
            print(f"\n   üìä ACTIVE POSITIONS ({len(self.positions)}/{max_positions_label()}):")
            print(f"   {'‚îÄ'*85}")
            print(f"      {'ASSET':<8} | {'EXCH':<4} | {'ENTRY':>10} | {'P&L':>12} | {'HOLD':>6} | {'ETA':>8} | LADDERS")
            print(f"   {'‚îÄ'*85}")
            
            for symbol, pos in self.positions.items():
                rt = self.get_realtime_price(symbol)
                price = rt if rt else pos.entry_price
                pct = (price - pos.entry_price) / pos.entry_price * 100 if pos.entry_price > 0 else 0.0
                pnl_val = (price - pos.entry_price) * pos.quantity if pos.entry_price > 0 else 0.0
                
                # Platform/Exchange
                exch = getattr(pos, 'exchange', 'kraken').upper()[:3]
                
                # Entry value
                entry_val = pos.entry_value if pos.entry_value > 0 else pos.entry_price * pos.quantity
                
                # Hold time
                hold_sec = time.time() - pos.entry_time
                hold_str = f"{hold_sec/60:.1f}m" if hold_sec < 3600 else f"{hold_sec/3600:.1f}h"
                
                # ü™ú LADDER CONTRIBUTIONS TO ETA - Each ladder helps estimate arrival time
                eta_str = "‚àû"
                prob_pct = 0
                ladders = []
                
                try:
                    # Get Kill Scanner ETA (base calculation)
                    scanner = get_active_scanner()
                    scanner_key = f"{pos.exchange}:{symbol}"
                    if scanner_key in scanner.targets:
                        target = scanner.targets[scanner_key]
                        if target.eta_to_kill < float('inf'):
                            eta_str = f"{target.eta_to_kill:.0f}s" if target.eta_to_kill < 60 else f"{target.eta_to_kill/60:.1f}m"
                        prob_pct = target.probability_of_kill * 100
                except:
                    pass
                
                # üß† Brain ladder contribution
                try:
                    brain_rec = ECOSYSTEM_BRAIN.get_trading_recommendation()
                    if brain_rec.get('action') == 'BUY' and brain_rec.get('confidence', 0) > 0.5:
                        ladders.append('üß†+')  # Brain accelerating
                    elif brain_rec.get('action') == 'REDUCE':
                        ladders.append('üß†-')  # Brain decelerating
                except:
                    pass
                
                # üîÆ Matrix ladder contribution  
                try:
                    if hasattr(self, 'prob_matrix') and self.prob_matrix:
                        sig = self.prob_matrix.get_signal(symbol)
                        if sig and sig.get('probability', 0.5) > 0.6:
                            ladders.append('üîÆ+')
                        elif sig and sig.get('probability', 0.5) < 0.4:
                            ladders.append('üîÆ-')
                except:
                    pass
                
                # üéµ HNC Frequency ladder
                try:
                    hnc_data = self.asset_frequencies.get(symbol, {})
                    if hnc_data.get('is_harmonic'):
                        ladders.append('üéµ+')
                    freq = hnc_data.get('frequency', 432)
                    if 435 <= freq <= 445:  # Distortion zone
                        ladders.append('üéµ-')
                except:
                    pass
                
                # üìà Momentum ladder
                if pct > 0.5:
                    ladders.append('üìà+')
                elif pct < -0.5:
                    ladders.append('üìà-')
                
                # üé≤ Monte Carlo enhanced indicator
                try:
                    scanner = get_active_scanner()
                    scanner_key = f"{pos.exchange}:{symbol}"
                    if scanner_key in scanner.targets:
                        target = scanner.targets[scanner_key]
                        if hasattr(target, 'mc_simulations') and target.mc_simulations > 0:
                            ladders.append('üé≤')  # MC enhanced
                except:
                    pass
                
                # P&L color indicator
                pnl_icon = "üü¢" if pnl_val > 0 else "üî¥" if pnl_val < 0 else "‚ö™"
                
                # Extract base asset
                asset = symbol.replace('USD', '').replace('GBP', '').replace('EUR', '').replace('USDT', '')[:6]
                
                # Ladder string (show what's helping/hurting ETA)
                ladder_str = ''.join(ladders) if ladders else "‚Äî"
                
                icon = self._get_node_icon(pos.dominant_node)
                print(f"      {icon} {asset:<6} | {exch:<4} | ${entry_val:>8.2f} | {pnl_icon} {pnl_val:>+7.4f} | {hold_str:>6} | {eta_str:>5} {prob_pct:>2.0f}% | {ladder_str}")
            
            print(f"   {'‚îÄ'*85}")
            print(f"   ü™ú Ladders: üß†Brain üîÆMatrix üéµHNC üìàMomentum üé≤MonteCarlo  (+)=faster (-)=slower")
                
        # Stats
        runtime = (time.time() - self.start_time) / 60
        cycle_pnl = self.total_equity_gbp - self.tracker.cycle_equity_start
        
        print(f"\n   üíé Portfolio: ¬£{self.total_equity_gbp:.2f} ({self.tracker.total_return:+.2f}%)")
        print(f"   üìà Cycle P&L: ¬£{cycle_pnl:+.2f}")
        print(f"   ‚è±Ô∏è Runtime: {runtime:.1f} min | Positions: {len(self.positions)}")
        
        self.save_state()

    def _place_order_from_intent(self, symbol: str, side: str, qty: float):
        """
        This is the ONLY place ExecutionModule touches your exchange.
        Maps cognition intents to real orders.
        
        ‚ö†Ô∏è IMPORTANT: Uses quote_qty (notional value) instead of base qty to ensure
        we meet minimum order requirements ($5 on Kraken).
        
        üîí FIXED: Now properly checks CASH BALANCE (liquid funds) not total equity.
        Total equity includes value of crypto holdings - you can't use that to buy more!
        
        ‚öîÔ∏è MULTI-BATTLEFIELD: Routes to exchange with funds using smart detection.
        Will try alternate exchanges if primary has no funds.
        """
        try:
            # ‚öîÔ∏è MULTI-BATTLEFIELD: Detect correct exchange for this symbol
            primary_exchange = self._detect_exchange_for_symbol(symbol, None)
            
            # ‚öîÔ∏è Get battlefield config
            battlefields = CONFIG.get('BATTLEFIELDS', {})
            
            # Build list of exchanges to try (primary first, then fallbacks)
            exchanges_to_try = [primary_exchange]
            
            # Add fallback exchanges that could support this symbol
            symbol_upper = symbol.upper()
            is_crypto = not any(p in symbol_upper for p in ['US500', 'US100', 'UK100', 'DE40', 'OIL', 'GOLD'])
            
            if is_crypto:
                # Crypto can go to Binance, Kraken, or Alpaca
                for ex in ['binance', 'kraken', 'alpaca']:
                    if ex != primary_exchange and battlefields.get(ex, {}).get('enabled', False):
                        exchanges_to_try.append(ex)
            else:
                # CFDs go to Capital.com only
                if 'capital' not in exchanges_to_try:
                    exchanges_to_try.append('capital')
            
            # Try each exchange until one works
            for exchange in exchanges_to_try:
                bf_config = battlefields.get(exchange, {})
                
                if not bf_config.get('enabled', True):
                    continue
                
                # Get exchange-specific minimum from config
                min_order_usd = bf_config.get('min_trade_usd', 6.0)
                
                # üîí Get CASH BALANCE for this specific exchange
                available_capital = self._get_exchange_cash_balance(exchange)
                
                # Skip this exchange if insufficient funds for BUY
                if side.lower() == 'buy' and available_capital < min_order_usd:
                    logger.debug(f"Skipping {exchange} for {symbol} - insufficient funds: ¬£{available_capital:.2f}")
                    continue
                
                # Use 2% of available capital per trade, minimum $6
                position_size_usd = max(min_order_usd, available_capital * 0.02)
                
                # Cap at reasonable amount and what's actually available
                position_size_usd = min(position_size_usd, 50.0, available_capital * 0.95)
                
                # Skip if we can't meet minimums
                if side.lower() == 'buy' and position_size_usd < min_order_usd:
                    continue
                
                # üéØ Found an exchange with funds - place order
                logger.debug(f"Routing {symbol} to {exchange} (¬£{available_capital:.2f} available)")
                
                result = self.trade_confirmation.submit_order(
                    exchange=exchange,
                    symbol=symbol,
                    side=side.upper(),
                    quote_qty=position_size_usd
                )
                
                return result
            
            # No exchange had sufficient funds
            return {"error": "insufficient_funds", "symbol": symbol, "side": side, "available": 0, "tried": exchanges_to_try}
            
        except Exception as e:
            return {"error": str(e), "symbol": symbol, "side": side, "qty": qty}

    def _on_execution_order_result(self, t: Thought) -> None:
        """
        Receives JSON results of orders, lets you store positions / telemetry.
        """
        data = t.payload
        intent = data.get("intent", {})
        order_result = data.get("order_result", {})
        
        # Log the execution thought
        symbol = intent.get("symbol", "UNKNOWN")
        side = intent.get("side", "UNKNOWN")
        
        if "error" not in order_result:
            print(f"   üß†‚úÖ Cognition executed: {symbol} {side}")
        else:
            error = order_result.get('error', 'Unknown')
            # Don't spam logs for insufficient funds - this is expected when capital is low
            if error == 'insufficient_funds':
                # Only log occasionally, not every single signal
                if not hasattr(self, '_last_insufficient_warn') or time.time() - self._last_insufficient_warn > 60:
                    available = order_result.get('available', 0)
                    print(f"   üß†üí∞ Cognition paused: Insufficient capital (¬£{available:.2f} available)")
                    self._last_insufficient_warn = time.time()
            else:
                print(f"   üß†‚ùå Cognition failed: {symbol} {side} - {error}")

    def _on_news_sentiment(self, t: Thought) -> None:
        """
        Receives news sentiment analysis from the NewsFeed module.
        Can influence trading decisions and risk management.
        Feeds into AdaptiveLearningEngine for correlation learning.
        """
        analysis = t.payload.get("analysis", {})
        sentiment_label = analysis.get("sentiment_label", "neutral")
        confidence = analysis.get("confidence", 0.0)
        avg_sentiment = analysis.get("average_sentiment", 0.0)
        
        # Store for use in trading decisions
        self._last_news_sentiment = {
            'sentiment': avg_sentiment,
            'label': sentiment_label,
            'confidence': confidence,
            'timestamp': t.ts
        }
        
        # üìö FEED INTO ADAPTIVE LEARNER FOR CORRELATION LEARNING
        try:
            ADAPTIVE_LEARNER.record_news_sentiment({
                'sentiment': avg_sentiment,
                'label': sentiment_label,
                'confidence': confidence,
                'crypto_sentiment': t.payload.get('signals', {}).get('crypto_sentiment', 0.0),
                'stock_sentiment': t.payload.get('signals', {}).get('stock_sentiment', 0.0),
                'risk_level': t.payload.get('signals', {}).get('risk_level', 'normal'),
            })
        except Exception as e:
            logger.debug(f"Could not record news to learner: {e}")
        
        # If highly confident bearish news, consider reducing position sizes
        if sentiment_label == "bearish" and confidence >= 0.6:
            logger.info(f"üì∞üêª Bearish news detected (conf={confidence:.2f}) - flagging for caution")
        elif sentiment_label == "bullish" and confidence >= 0.6:
            logger.info(f"üì∞üêÇ Bullish news detected (conf={confidence:.2f}) - market favorable")

    def _on_news_alert(self, t: Thought) -> None:
        """
        Receives individual news alerts for extreme sentiment articles.
        """
        alert = t.payload.get("alert", {})
        title = alert.get("title", "")
        sentiment = alert.get("sentiment", 0.0)
        sentiment_label = alert.get("sentiment_label", "neutral")
        
        if abs(sentiment) >= 0.7:
            logger.info(f"üì∞üö® NEWS ALERT [{sentiment_label.upper()}]: {title[:60]}...")

    def _on_knowledge_result(self, t: Thought) -> None:
        """
        Receives knowledge query results from the Knowledge Base.
        Feeds into AdaptiveLearningEngine for learning correlation.
        """
        query = t.payload.get("query", "")
        results_count = t.payload.get("results_count", 0)
        top_result = t.payload.get("top_result", "")
        
        # üìö FEED INTO ADAPTIVE LEARNER
        if results_count > 0:
            try:
                ADAPTIVE_LEARNER.record_knowledge_event({
                    'topic': query,
                    'articles_found': results_count,
                    'top_result': top_result,
                    'type': 'query'
                })
            except Exception as e:
                logger.debug(f"Could not record knowledge to learner: {e}")
        
        if results_count > 0:
            logger.debug(f"üìö Knowledge query '{query}': {results_count} results (top: {top_result})")

    def _on_research_complete(self, t: Thought) -> None:
        """
        Receives autonomous research completion notifications.
        Feeds into AdaptiveLearningEngine for knowledge correlation.
        """
        topic = t.payload.get("topic", "")
        articles_found = t.payload.get("articles_found", 0)
        key_concepts = t.payload.get("key_concepts", [])
        
        # üìö FEED INTO ADAPTIVE LEARNER
        try:
            ADAPTIVE_LEARNER.record_knowledge_event({
                'topic': topic,
                'articles_found': articles_found,
                'key_concepts': key_concepts,
                'type': 'autonomous_research'
            })
        except Exception as e:
            logger.debug(f"Could not record research to learner: {e}")
        
        logger.info(f"üìöüî¨ Research complete: '{topic}' - {articles_found} articles, concepts: {key_concepts[:3]}")

    def _on_wisdom_insight(self, t: Thought) -> None:
        """
        Receives wisdom insights from the Wisdom Scanner.
        Ancient wisdom from 11 civilizations enriching trading decisions.
        Feeds into AdaptiveLearningEngine for deep pattern correlation.
        """
        civilization = t.payload.get("civilization", "")
        topic = t.payload.get("topic", "")
        relevance = t.payload.get("relevance", 0.0)
        application = t.payload.get("application", "")
        
        # üìö FEED INTO ADAPTIVE LEARNER
        try:
            ADAPTIVE_LEARNER.record_knowledge_event({
                'type': 'ancient_wisdom',
                'civilization': civilization,
                'topic': topic,
                'relevance': relevance,
                'application': application
            })
        except Exception as e:
            logger.debug(f"Could not record wisdom to learner: {e}")
        
        if relevance >= 0.7:
            logger.info(f"üìöüåç High-relevance wisdom [{civilization.upper()}]: {topic} (r={relevance:.2f})")

    def _on_consciousness_expansion(self, t: Thought) -> None:
        """
        Receives consciousness expansion notifications when wisdom scans complete.
        """
        message = t.payload.get("message", "")
        logger.info(f"üìöüåç‚ú® {message}")

    def _bootstrap_24h_historical(self) -> None:
        """
        üìä BOOTSTRAP 24H HISTORICAL DATA
        
        Loads 24 hours of historical market data so the system has context
        about where the market has been before making trading decisions.
        This populates price_history for technical analysis and momentum detection.
        """
        print("\nüìä BOOTSTRAPPING 24H HISTORICAL DATA...")
        print("   This ensures the system knows market context before trading\n")
        
        try:
            # Get Binance client for historical data
            binance_client = None
            if hasattr(self.client, 'binance') and self.client.binance:
                binance_client = self.client.binance
            elif hasattr(self.client, 'clients'):
                binance_client = self.client.clients.get('binance')
            
            if not binance_client:
                print("   ‚ö†Ô∏è Binance client not available for historical data")
                return
            
            # Check if client has get_24h_historical method
            if not hasattr(binance_client, 'get_24h_historical'):
                print("   ‚ö†Ô∏è Historical data method not available")
                return
            
            # Get top trading pairs from our ticker cache
            top_pairs = []
            if self.ticker_cache:
                usdc_pairs = [k for k in self.ticker_cache.keys() if k.endswith('USDC')]
                # Sort by volume if available
                usdc_pairs_with_vol = []
                for pair in usdc_pairs:
                    ticker = self.ticker_cache.get(pair, {})
                    vol = float(ticker.get('quoteVolume', ticker.get('volume', 0)) or 0)
                    usdc_pairs_with_vol.append((pair, vol))
                usdc_pairs_with_vol.sort(key=lambda x: x[1], reverse=True)
                top_pairs = [p[0] for p in usdc_pairs_with_vol[:30]]
            
            if not top_pairs:
                top_pairs = ['BTCUSDC', 'ETHUSDC', 'SOLUSDC', 'BNBUSDC', 'XRPUSDC']
            
            # Fetch 24h historical data
            historical = binance_client.get_24h_historical(symbols=top_pairs, interval='1h')
            
            # Populate price history for each symbol
            loaded_count = 0
            for symbol, klines in historical.items():
                if klines:
                    # Extract close prices for price_history
                    closes = [k['close'] for k in klines]
                    self.price_history[symbol] = closes
                    
                    # Also cache latest price
                    if closes:
                        self.realtime_prices[symbol] = closes[-1]
                    
                    loaded_count += 1
            
            print(f"   ‚úÖ Loaded 24h history for {loaded_count} symbols")
            print(f"   üìà Price history populated: {list(historical.keys())[:5]}...")
            
            # Log statistics
            if historical:
                first_symbol = list(historical.keys())[0]
                first_klines = historical[first_symbol]
                if first_klines:
                    oldest = first_klines[0].get('timestamp', 0)
                    newest = first_klines[-1].get('timestamp', 0)
                    hours_of_data = (newest - oldest) / (1000 * 60 * 60) if oldest and newest else 0
                    print(f"   ‚è∞ Historical span: ~{hours_of_data:.1f} hours of data")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Historical bootstrap failed: {e}")
            logger.warning(f"24h historical bootstrap failed: {e}")
        
        print("")

    def run(self, interval: float = 2.0, target_profit_gbp: float = None, max_minutes: float = None):
        """Main trading loop - üî• BEAST MODE: 2 second cycles for MAXIMUM SPEED!

        Args:
            interval: Seconds to sleep between cycles. (DEFAULT NOW 2s - FASTER!)
            target_profit_gbp: If provided, stop when net P&L (current_equity - initial_equity) >= target.
            max_minutes: If provided, stop after this many minutes of runtime.
        """
        # üõ†Ô∏è CRITICAL: Compute REAL wallet balance BEFORE banner!
        # This fixes the "Fake $1000 Balance" bug by detecting actual portfolio value first.
        total, cash, holdings = self.compute_total_equity()
        if self.tracker.initial_balance == 1000.0 and self.tracker.total_trades == 0:
            if abs(total - 1000.0) > 1.0 and total > 0:
                print(f"\n   ‚öñÔ∏è  AUTO-CORRECTING BALANCE: ${self.tracker.initial_balance:.2f} -> ${total:.2f} (Actual Wallet)\n")
                self.tracker.initial_balance = total
                self.tracker.first_start_balance = total
                self.tracker.balance = total
                self.tracker.peak_balance = total
                self.tracker.equity_baseline = total
                self.tracker.portfolio_equity = total
                self.tracker.cash_balance = cash
                self.total_equity_gbp = total
                self.cash_balance_gbp = cash
        
        self.banner()
        
        print("üêô Connecting to Unified Ecosystem...")
        self.print_portfolio_report()
        
        pair_count = self.refresh_tickers()
        print(f"‚úÖ Connected! {pair_count} pairs loaded")
        
        # üìä 24H HISTORICAL BOOTSTRAP: Load market context before trading
        self._bootstrap_24h_historical()
        
        # üß†üìà BRAIN SYNC: Load historical trades from exchange for learning
        if not self.dry_run:
            try:
                sync_result = sync_exchange_trades_to_brain()
                if sync_result.get('status') == 'success':
                    logger.info(f"üß† Brain synced with {sync_result['trades_synced']} historical trades (WR: {sync_result['win_rate']:.1f}%)")
            except Exception as e:
                logger.warning(f"üß† Brain sync skipped: {e}")
        
        # üåæ STARTUP HARVESTER: Sell existing assets if profitable
        if not self.dry_run and CONFIG.get('HARVEST_ON_STARTUP', True):
            self.harvest_existing_assets()
        
        # üîÑ POSITION SYNC: Reconcile stored positions with actual exchange balances
        # This fixes state drift where positions are sold but state file is stale
        if not self.dry_run:
            self.sync_positions_with_exchange()
        
        # üêò MEMORY RECONCILIATION: Cure "System Amnesia"
        # Reconstructs lost trade history using the Memory Core
        if not self.dry_run:
            print("   üêò Reconciling memory with reality...")
            try:
                all_balances = self.client.get_all_balances() or {}
                wallet_assets: Dict[str, float] = {}
                if isinstance(all_balances, dict):
                    for _exchange, balances in all_balances.items():
                        if not isinstance(balances, dict):
                            continue
                        for asset, qty in balances.items():
                            try:
                                q = float(qty or 0)
                            except Exception:
                                q = 0.0
                            if q:
                                wallet_assets[asset] = wallet_assets.get(asset, 0.0) + q

                self.memory.reconcile_with_reality(
                    wallet_assets=wallet_assets,
                    trade_history_callback=self._fetch_origin_trade,
                )
            except Exception as e:
                logger.warning(f"üåÄ Memory reconciliation skipped: {e}")

        # Find initial opportunities for WebSocket
        initial_opps = self.find_opportunities()
        # üî• UNLEASHED: Watch 200 pairs instead of 15 - MAXIMUM SIGNAL CAPTURE!
        symbols_to_watch = [o['symbol'] for o in initial_opps[:200]]
        
        # Add major pairs for base currency - MEGA EXPANDED LIST!
        base = CONFIG['BASE_CURRENCY']
        # ü§ë GREEDY HOE MODE: ALL THE ALTCOINS! Every shitcoin that moves!
        major_bases = [
            # üèÜ TOP 20 BY MARKET CAP
            'BTC', 'ETH', 'XBT', 'BNB', 'SOL', 'XRP', 'ADA', 'DOGE', 'AVAX', 'DOT',
            'LINK', 'MATIC', 'SHIB', 'LTC', 'BCH', 'ATOM', 'UNI', 'XLM', 'ETC', 'FIL',
            # üöÄ DEFI TOKENS  
            'AAVE', 'MKR', 'CRV', 'COMP', 'SNX', 'YFI', 'SUSHI', '1INCH', 'BAL', 'LDO',
            # üéÆ GAMING & METAVERSE
            'SAND', 'MANA', 'AXS', 'ENJ', 'GALA', 'IMX', 'RONIN', 'ILV', 'MAGIC',
            # üîÆ LAYER 2 & NEW CHAINS
            'ARB', 'OP', 'MATIC', 'IMX', 'STRK', 'ZK', 'SCROLL', 'BASE', 'LINEA',
            # üåä NEW HOT ALTS
            'APT', 'SUI', 'SEI', 'TIA', 'INJ', 'PYTH', 'JUP', 'JTO', 'WEN', 'BOME',
            # üêï MEME COINS - WHERE THE DEGENS PLAY!
            'PEPE', 'WIF', 'BONK', 'FLOKI', 'TURBO', 'BRETT', 'MOG', 'POPCAT', 'NEIRO',
            # üíé AI TOKENS
            'FET', 'AGIX', 'OCEAN', 'RNDR', 'TAO', 'AKT', 'ARKM', 'PRIME', 'ALI',
            # üì¶ INFRASTRUCTURE
            'GRT', 'AR', 'HNT', 'THETA', 'STX', 'KAS', 'QNT', 'VET', 'HBAR', 'ICP',
            # üîí PRIVACY COINS
            'XMR', 'ZEC', 'DASH', 'SCRT',
            # üåç MISC ALTS
            'NEAR', 'ALGO', 'EOS', 'XTZ', 'EGLD', 'FLOW', 'MINA', 'KAVA', 'ROSE', 'ZIL'
        ]
        for base_asset in major_bases:
            for quote in ['USD', 'GBP', 'EUR', 'USDT', 'USDC', 'BTC', 'ETH', 'BNB']:
                pair = f"{base_asset}{quote}"
                # Only add if it's a valid pair in our ticker cache
                if pair not in symbols_to_watch and pair in self.ticker_cache:
                    symbols_to_watch.append(pair)
                # Also try reverse for some pairs (though rare in standard naming)
                # or alternative naming conventions if needed
                
        print(f"\nüî¥ü§ë GREEDY HOE MODE: Starting WebSocket for {len(symbols_to_watch)} pairs!")
        self.start_websocket(symbols_to_watch)
        
        initial_equity = self.total_equity_gbp
        start_ts = time.time()

        # ÔøΩ START PROBABILITY GENERATOR - Auto-regenerates every 15 seconds
        if self.probability_generator:
            self.probability_generator.start(ecosystem=self)
            print("   üìä Probability Report Generator STARTED (background thread - 15s cycles)")

        # ÔøΩüöÄ Force deploy scouts before entering the loop (guarantees first shot)
        if not self.scouts_deployed and CONFIG['DEPLOY_SCOUTS_IMMEDIATELY']:
            self._deploy_scouts()

        try:
            while True:
                self.iteration += 1
                now = datetime.now().strftime("%H:%M:%S")

                # üçÑ Constant nerve-system pulse (state shared + persisted)
                self._mycelium_heartbeat(note='cycle')
                
                # ÔøΩ‚öîÔ∏è WAR BAND UPDATE: Autonomous Scout & Sniper ‚öîÔ∏èüèπ
                if hasattr(self, 'war_band'):
                    self.war_band.update()
                
                # ÔøΩüåä SURGE WINDOW CHECK: Synchronize with Zero Point Field
                is_surge = self.memory.is_surge_window_active()
                surge_status = "üåä SURGE ACTIVE" if is_surge else "Waiting for Surge"
                
                print(f"\n{'‚îÅ'*70}")
                print(f"üîÑ Cycle {self.iteration} - {now} [{self.scan_direction}] - {surge_status}")
                print(f"{'‚îÅ'*70}")

                # üî¶ Miner Lighthouse hook: if miner Œì is firing, override thresholds aggressively
                lighthouse_active = False
                try:
                    if hasattr(self, 'miner_optimizer') and hasattr(self.miner_optimizer, 'platypus'):
                        miner_gamma = getattr(self.miner_optimizer.platypus, 'Gamma_t', 0.5)
                        lighthouse_active = miner_gamma >= 0.99
                except Exception:
                    lighthouse_active = False
                if lighthouse_active:
                    # Lower the entry Œì threshold during lighthouse and boost sizing
                    try:
                        # These attributes may not exist in all builds; guard each usage
                        setattr(self, 'min_entry_gamma', 0.20)
                        setattr(self, 'position_size_multiplier', 2.73)
                        # Informational log for operators
                        logger.info("üî¶ MINER LIGHTHOUSE ACTIVE - TRADING WITH 273% BOOST! (Œì>=0.99)")
                    except Exception:
                        pass
                
                # üß†üåç UNIFIED BRAIN WISDOM CYCLE (via Brain Bridge)
                # Brain runs EVERY cycle - autonomous cognition always active
                if self.brain:
                    try:
                        # Only print header every 10 cycles to reduce noise
                        if self.iteration % 10 == 1:
                            print("\n   üß†üåç UNIFIED BRAIN WISDOM CYCLE...")
                        
                        # Build quantum context from available sources
                        quantum_ctx = None
                        if hasattr(self, 'miner_optimizer') and self.miner_optimizer:
                            qbrain = getattr(self.miner_optimizer, 'brain', None)
                            if qbrain:
                                quantum_ctx = {
                                    'quantum_coherence': qbrain.state.unified_coherence,
                                    'planetary_gamma': qbrain.state.planetary_gamma,
                                    'cascade_multiplier': qbrain.state.cascade_multiplier,
                                    'is_lighthouse': qbrain.state.is_optimal_window,
                                    'piano_lambda': qbrain.state.piano_lambda,
                                    'harmonic_signal': qbrain.state.harmonic_signal,
                                    'signal_confidence': qbrain.state.signal_confidence,
                                }
                        
                        # Run brain cycle through the bridge (handles bidirectional sync)
                        result = self.brain_bridge.run_wisdom_cycle(self.brain, quantum_ctx)
                        
                        # Get trading recommendation from brain
                        brain_rec = self.brain_bridge.get_trading_recommendation()
                        
                        if result:
                            # Display unified status
                            self.brain_bridge.display_status()
                            
                            # Apply brain recommendation to position sizing
                            brain_mult = brain_rec.get('position_multiplier', 1.0)
                            brain_action = brain_rec.get('action', 'HOLD')
                            
                            if brain_action == 'BUY':
                                self.position_size_multiplier = max(self.position_size_multiplier, brain_mult)
                                print(f"   üß†üìà BRAIN BOOST: Position sizing = {self.position_size_multiplier:.2f}x")
                            elif brain_action == 'REDUCE':
                                self.position_size_multiplier = min(self.position_size_multiplier, brain_mult)
                                print(f"   üß†üìâ BRAIN CAUTION: Position sizing = {self.position_size_multiplier:.2f}x")
                            
                            # Update cascade amplifier with brain gamma
                            CASCADE_AMPLIFIER.update_lighthouse(self.brain_bridge._planetary_gamma)
                            
                            # Legacy prediction display
                            prediction = self.brain.get_latest_prediction()
                            if prediction:
                                print(f"   üß† PREDICTION: {prediction['direction']} (Conf: {prediction['confidence']}%)")
                            
                            # Dream insights (preserved)
                            if hasattr(self.brain, 'dream_engine'):
                                # Get F&G from brain bridge, default change to 0
                                current_fng = getattr(self.brain_bridge, '_fear_greed', 50)
                                current_change = 0.0  # Default - actual change computed in brain cycle
                                dream_response = self.brain.dream_engine.get_prepared_response(current_change, current_fng)
                                if dream_response:
                                    print(f"   üí≠ DREAM: {dream_response['action']}")
                                    
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è Brain cycle error: {e}")

                # üåâ Sync with Bridge
                if self.bridge_enabled:
                    self.sync_bridge()
                    self.check_bridge_commands()
                
                # Market Pulse Analysis
                if self.iteration % 5 == 1: # Every 5 cycles
                    try:
                        pulse = self.market_pulse.analyze_market()
                        
                        # Update Capital Pool with Sentiment
                        c_score = pulse['crypto_sentiment']['avg_change_24h']
                        s_score = pulse['stock_sentiment']['avg_change_24h']
                        avg_sentiment = (c_score + s_score) / 2
                        self.capital_pool.update_sentiment(avg_sentiment)
                        
                        print("\n   üåç GLOBAL MARKET PULSE")
                        print(f"   ‚îú‚îÄ Crypto Sentiment: {pulse['crypto_sentiment']['label']} ({c_score:.2f}%)")
                        print(f"   ‚îú‚îÄ Stock Sentiment:  {pulse['stock_sentiment']['label']} ({s_score:.2f}%)")
                        print(f"   ‚îú‚îÄ üè¶ Capital Pool:  Reserve adjusted to {self.capital_pool.reserved / self.capital_pool.total_equity * 100:.1f}% based on sentiment {avg_sentiment:.2f}")
                        
                        if pulse['arbitrage_opportunities']:
                            print(f"   ‚îú‚îÄ ‚ö° {len(pulse['arbitrage_opportunities'])} Arbitrage Opps Found!")
                            top_arb = pulse['arbitrage_opportunities'][0]
                            print(f"   ‚îÇ  Best: {top_arb['asset']} ({top_arb['spread_pct']:.2f}%) - Buy {top_arb['buy_at']['source']} / Sell {top_arb['sell_at']['source']}")
                        else:
                            print("   ‚îú‚îÄ ‚ö° No significant arbitrage detected")
                        
                        # üåê Cross-Exchange Arbitrage Scan
                        try:
                            arb_opps = self.arb_scanner.get_top_opportunities(3)
                            if arb_opps:
                                print(f"   ‚îú‚îÄ üîÄ Cross-Exchange Arbitrage:")
                                for arb in arb_opps[:2]:
                                    # Apply CASCADE + Œ∫t boost if lighthouse is active
                                    boosted_pct = arb.get('net_profit_pct', 0.0)
                                    if lighthouse_active:
                                        boosted_pct = boosted_pct * 10.0 * 2.73
                                    print(f"   ‚îÇ  {arb['symbol']}: Buy {arb['buy_exchange']} ‚Üí Sell {arb['sell_exchange']} ({boosted_pct:.2f}% net{' ‚ö° BOOST' if lighthouse_active else ''})")
                        except Exception as arb_err:
                            logger.debug(f"Arbitrage scan error: {arb_err}")
                            
                        print(f"   ‚îî‚îÄ Top Gainer: {pulse['top_gainers'][0]['symbol']} ({pulse['top_gainers'][0]['priceChangePercent']:.1f}%)")
                        print("")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è Market Pulse Error: {e}")

                # üì∞ NEWS FEED POLLING (World News API)
                # Poll periodically to avoid rate limits but keep sentiment fresh
                if self.news_feed:
                    self._news_poll_counter += 1
                    if self._news_poll_counter >= self._news_poll_interval:
                        self._news_poll_counter = 0
                        try:
                            import asyncio
                            # Run async poll synchronously
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                news_result = loop.run_until_complete(self.news_feed.poll_and_publish())
                                
                                if news_result.get('status') == 'success':
                                    sentiment_analysis = news_result.get('sentiment_analysis', {})
                                    signals = news_result.get('signals', {})
                                    
                                    # Display news sentiment
                                    sentiment_label = sentiment_analysis.get('sentiment_label', 'unknown')
                                    avg_sentiment = sentiment_analysis.get('average_sentiment', 0.0)
                                    confidence = sentiment_analysis.get('confidence', 0.0)
                                    article_count = news_result.get('articles_processed', 0)
                                    
                                    # Color code based on sentiment
                                    if sentiment_label == 'bullish':
                                        sentiment_icon = 'üìà'
                                    elif sentiment_label == 'bearish':
                                        sentiment_icon = 'üìâ'
                                    else:
                                        sentiment_icon = 'üìä'
                                    
                                    print(f"\n   üì∞ WORLD NEWS DIGEST ({article_count} articles)")
                                    print(f"   ‚îú‚îÄ {sentiment_icon} Overall Sentiment: {sentiment_label.upper()} ({avg_sentiment:+.3f})")
                                    print(f"   ‚îú‚îÄ Confidence: {confidence:.1%}")
                                    
                                    # Domain sentiments
                                    crypto_sent = signals.get('crypto_sentiment', 0.0)
                                    stock_sent = signals.get('stock_sentiment', 0.0)
                                    print(f"   ‚îú‚îÄ Crypto News: {crypto_sent:+.3f} | Stock News: {stock_sent:+.3f}")
                                    
                                    # Risk level
                                    risk_level = signals.get('risk_level', 'normal')
                                    if risk_level == 'high':
                                        print(f"   ‚îú‚îÄ ‚ö†Ô∏è NEWS RISK LEVEL: HIGH - Consider reducing exposure")
                                    elif risk_level == 'elevated':
                                        print(f"   ‚îú‚îÄ ‚ö° NEWS RISK LEVEL: ELEVATED")
                                    
                                    # Show alerts if any
                                    alerts = signals.get('alerts', [])
                                    if alerts:
                                        print(f"   ‚îî‚îÄ üö® {len(alerts)} sentiment alerts published")
                                    else:
                                        print(f"   ‚îî‚îÄ No extreme sentiment alerts")
                                    
                                    # Store news sentiment for trading decisions
                                    self._last_news_sentiment = {
                                        'sentiment': avg_sentiment,
                                        'label': sentiment_label,
                                        'confidence': confidence,
                                        'risk_level': risk_level,
                                        'crypto_sentiment': crypto_sent,
                                        'timestamp': datetime.now().isoformat()
                                    }
                                    
                            finally:
                                loop.close()
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è News Feed Error: {e}")

                # üìö KNOWLEDGE BASE RESEARCH (Wikipedia API)
                # Autonomous research on trading topics periodically
                if self.knowledge_base:
                    self._knowledge_research_counter += 1
                    if self._knowledge_research_counter >= self._knowledge_research_interval:
                        self._knowledge_research_counter = 0
                        try:
                            # Research a trading-relevant topic
                            import random
                            research_topics = [
                                "Market volatility", "Trading psychology", "Risk management",
                                "Technical analysis", "Cryptocurrency", "Market sentiment",
                                "Economic indicators", "Federal Reserve policy"
                            ]
                            topic = random.choice(research_topics)
                            
                            # Run research in background to not block trading
                            import threading
                            def background_research():
                                try:
                                    result = self.knowledge_base.autonomous_research(topic, depth=1)
                                    if result['articles']:
                                        logger.debug(f"üìö Background research on '{topic}': {len(result['articles'])} articles")
                                except Exception as e:
                                    logger.debug(f"Knowledge research error: {e}")
                            
                            threading.Thread(target=background_research, daemon=True).start()
                            
                            # Show brief status
                            status = self.knowledge_base.get_status()
                            cache_size = status['cache']['size']
                            if cache_size > 0 and self.iteration % 100 == 0:
                                print(f"\n   üìö KNOWLEDGE BASE STATUS")
                                print(f"   ‚îú‚îÄ Cache: {cache_size} articles")
                                print(f"   ‚îú‚îÄ API calls: {status['metrics']['api_calls']}")
                                print(f"   ‚îî‚îÄ Researching: {topic}")
                                
                        except Exception as e:
                            logger.debug(f"Knowledge base error: {e}")

                # Refresh data
                self.refresh_tickers()
                print(f"   üìä Ticker cache: {len(self.ticker_cache)} symbols loaded")
                
                # üîÆ VALIDATE PENDING PREDICTIONS üîÆ
                # Check predictions that are due for validation
                try:
                    def get_price(exchange, symbol):
                        """Get current price for validation."""
                        # Try ticker cache first
                        if symbol in self.ticker_cache:
                            return self.ticker_cache[symbol].get('price', 0)
                        # Try realtime prices
                        if symbol in self.realtime_prices:
                            return self.realtime_prices[symbol]
                        return None
                    
                    validated = self.prediction_validator.validate_predictions(get_price)
                    if validated:
                        accurate_count = sum(1 for v in validated if v['is_accurate'])
                        direction_count = sum(1 for v in validated if v['direction_correct'])
                        print(f"   üîÆ Validated {len(validated)} predictions: {accurate_count} accurate, {direction_count} direction correct")
                    
                    # Every 20 cycles, show full accuracy report
                    if self.iteration % 20 == 0 and self.prediction_validator.get_validated_count() > 0:
                        print(self.prediction_validator.get_accuracy_summary())
                    
                    # üß† Every 50 cycles, show adaptive learning summary
                    if self.iteration % 50 == 0:
                        print(ADAPTIVE_LEARNER.get_learning_summary())
                        
                except Exception as e:
                    logger.debug(f"Prediction validation error: {e}")
                
                self.refresh_equity(mark_cycle=True)
                
                # üåâ Sync with bridge (capital, positions, commands)
                self.sync_bridge()
                self.check_bridge_commands()
                
                # Deploy scouts on first cycle if enabled
                if self.iteration == 1 and not self.scouts_deployed:
                    self._deploy_scouts()
                
                # Toggle scan direction for fair scheduling (A‚ÜíZ / Z‚ÜíA)
                self.scan_direction = 'Z‚ÜíA' if self.iteration % 2 == 0 else 'A‚ÜíZ'
                
                # Check positions
                self.check_positions()
                
                # Check network coherence - pause if too low
                network_coherence = self.mycelium.get_network_coherence()
                trading_paused = network_coherence < CONFIG['MIN_NETWORK_COHERENCE']
                
                # Check WebSocket health
                ws_stale = (time.time() - self.ws_last_message) > CONFIG['WS_HEARTBEAT_TIMEOUT']
                if ws_stale and self.ws_connected:
                    print("   ‚ö†Ô∏è WebSocket appears stale, falling back to REST")
                
                # Update Lattice State (Global Physics)
                raw_opps = self.find_opportunities()
                l_state = self.lattice.update(raw_opps)

                # ==== COGNITION TICK (system talks to itself via JSON) ====
                # Build market snapshot for cognition system
                # Use top 100 symbols to avoid overwhelming
                cognition_symbols = list(self.ticker_cache.keys())[:100]
                market_by_symbol = {}
                
                for sym in cognition_symbols:
                    if sym in self.ticker_cache:
                        ticker = self.ticker_cache[sym]
                        # Get price history if available, else just current price
                        prices = self.price_history.get(sym, [ticker['price']])[-20:]
                        
                        # Calculate momentum and gamma from your existing data
                        momentum = ticker.get('change24h', 0.0)
                        
                        # Try to get coherence from existing opportunity data
                        gamma = 0.5  # default
                        # We can look up in raw_opps if available
                        for opp in raw_opps:
                            if opp['symbol'] == sym:
                                gamma = opp.get('coherence', 0.5)
                                break
                        
                        market_by_symbol[sym] = {
                            "closes": prices,
                            "momentum": momentum,
                            "gamma": gamma,
                            "price": ticker['price'],
                            "volume": ticker['volume'],
                        }
                
                # Publish snapshot - this triggers the entire cognition chain
                self.thought_bus.publish(Thought(
                    source="ecosystem",
                    topic="market.snapshot",
                    payload={
                        "universe": cognition_symbols,
                        "market_by_symbol": market_by_symbol,
                    },
                ))
                
                # Run immune scan post cognition tick
                if hasattr(self, 'immune_system'):
                    self.immune_system.scan_and_heal()
                
                # Apply Triadic Envelope Protocol to filter signals
                all_opps = self.lattice.filter_signals(raw_opps)

                # Dynamic Portfolio Rebalancing - sell underperformers if better opportunities exist
                freed_capital = 0.0
                max_positions = get_max_positions_limit() or 10**9
                if all_opps and max_positions < 10**9 and len(self.positions) >= max_positions // 2:
                    freed_capital = self.rebalance_portfolio(all_opps)
                    if freed_capital > 0:
                        self.refresh_equity()  # Update cash after rebalancing

                # Find opportunities (if not halted or paused)
                if len(self.positions) < max_positions and not self.tracker.trading_halted and not trading_paused:
                    # üìä LOG MARKET SWEEP FOR FULL COVERAGE VALIDATION üìä
                    if TRADE_LOGGER_AVAILABLE and trade_logger:
                        try:
                            opportunities_entered = min(len(all_opps), max_positions - len(self.positions))
                            opportunities_rejected = len(raw_opps) - len(all_opps)
                            
                            # Count rejection reasons
                            rejection_reasons = defaultdict(int)
                            if hasattr(self, 'last_opportunity_filters'):
                                rejection_reasons.update(self.last_opportunity_filters)
                            
                            # Get frequency distribution
                            harmonic_freqs = []
                            hissing_freqs = []
                            total_coherence = []
                            
                            for opp in raw_opps:
                                if opp.get('hnc_is_harmonic', False):
                                    harmonic_freqs.append(opp.get('hnc_frequency', 256))
                                elif opp.get('hnc_frequency', 256) == 440:
                                    hissing_freqs.append(440)
                                total_coherence.append(opp.get('coherence', 0.5))
                            
                            avg_coherence = statistics.mean(total_coherence) if total_coherence else 0.5
                            
                            # Get node distribution
                            node_dist = defaultdict(int)
                            for opp in all_opps:
                                node_dist[opp.get('dominant_node', 'Unknown')] += 1
                            
                            trade_logger.log_market_sweep({
                                'total_opportunities_found': len(raw_opps),
                                'opportunities_entered': opportunities_entered,
                                'opportunities_rejected': opportunities_rejected,
                                'rejection_reasons': dict(rejection_reasons),
                                'harmonic_frequencies': harmonic_freqs,
                                'hissing_frequencies': hissing_freqs,
                                'average_coherence': avg_coherence,
                                'system_flux': opp.get('flux_direction', 'NEUTRAL') if all_opps else 'NEUTRAL',
                                'dominant_node_distribution': dict(node_dist),
                            })
                        except Exception as e:
                            logger.warning(f"Failed to log market sweep: {e}")
                    
                    if all_opps:
                        purity = self.lattice.get_field_purity()
                        purity_icon = "üü¢" if purity > 0.9 else "üü†" if purity > 0.5 else "üî¥"
                        nexus_status = "üîÆ NEXUS" if self.nexus_predictor else ""
                        print(f"\n   üîÆ Top Opportunities (Triadic Filtered | Purity: {purity_icon} {purity*100:.1f}%) {nexus_status}:")
                        for opp in all_opps[:5]:
                            icon = self._get_node_icon(opp['dominant_node'])
                            lock = "üîí" if opp.get('memory_locked') else "üîì"
                            nexus_info = f"| üîÆ{opp.get('nexus_prob', 0.5)*100:.0f}%" if self.nexus_predictor else ""
                            print(f"      {icon} {opp['symbol']:12s} +{opp['change24h']:5.1f}% | Œì={opp['coherence']:.2f} | Score: {opp['score']} {nexus_info} {lock}")
                    
                    # During lighthouse, increase position size and allow more entries using available capital
                    for opp in all_opps[:max_positions - len(self.positions)]:
                        if lighthouse_active:
                            try:
                                # Use up to 50% of available cash per new entry burst, scaled by Œ∫t boost
                                available_cash = self.cash_balance_gbp
                                burst_cap = max(0.0, available_cash * 0.50)
                                setattr(self, 'position_size_multiplier', 2.73)
                                # Pass a hint to position sizer via opp context
                                opp['lighthouse_burst_cap'] = burst_cap
                                opp['cascade_multiplier'] = 10.0
                                opp['kappa_t'] = 2.73
                            except Exception:
                                pass
                        self.open_position(opp)
                        
                # Show positions - ENHANCED FULL DETAILS WITH LADDER ETA
                if self.positions:
                    print(f"\n   üìä ACTIVE POSITIONS ({len(self.positions)}/{max_positions_label()}):")
                    print(f"   {'‚îÄ'*95}")
                    print(f"      {'ASSET':6s} ‚îÇ {'EX':3s} ‚îÇ {'ENTRY $':>10s} ‚îÇ {'P&L':>12s} ‚îÇ {'HOLD':>5s} ‚îÇ {'ETA':>10s} ‚îÇ {'LADDERS':12s}")
                    print(f"   {'‚îÄ'*95}")
                    for symbol, pos in self.positions.items():
                        rt = self.get_realtime_price(symbol)
                        if pos.entry_price <= 0:
                            pct = 0.0
                            price = 0.0
                            src = "‚ö†Ô∏è"
                        elif rt:
                            price = rt
                            pct = (rt - pos.entry_price) / pos.entry_price * 100
                            src = "üî¥"  # Live price
                        else:
                            cached = self.ticker_cache.get(symbol, {}).get('price', pos.entry_price)
                            price = cached
                            pct = (cached - pos.entry_price) / pos.entry_price * 100 if pos.entry_price > 0 else 0.0
                            src = "‚ö™"  # Cached price
                        
                        # Calculate P&L value
                        pnl_val = (price - pos.entry_price) * pos.quantity if pos.entry_price > 0 else 0.0
                        
                        # Platform/Exchange
                        exch = getattr(pos, 'exchange', 'kraken').upper()[:3]
                        
                        # Entry value
                        entry_val = pos.entry_value if pos.entry_value > 0 else pos.entry_price * pos.quantity
                        
                        # Hold time
                        hold_sec = time.time() - pos.entry_time
                        hold_str = f"{hold_sec/60:.0f}m" if hold_sec < 3600 else f"{hold_sec/3600:.1f}h"
                        
                        # ü™ú LADDER CONTRIBUTIONS - What's helping reach penny profit gate
                        ladders = []
                        eta_str = "---"
                        prob_pct = 0
                        
                        # Kill Scanner ETA
                        try:
                            scanner = get_active_scanner()
                            scanner_key = f"{(pos.exchange or '').lower()}:{symbol}"
                            if scanner_key in scanner.targets:
                                target = scanner.targets[scanner_key]
                                prob_pct = target.probability_of_kill * 100
                                if target.eta_to_kill < float('inf'):
                                    eta_str = f"{target.eta_to_kill:.0f}s" if target.eta_to_kill < 60 else f"{target.eta_to_kill/60:.1f}m"
                                elif prob_pct > 80:
                                    eta_str = "NOW!"
                        except:
                            pass

                        # üçÑ Mycelium ladder (Queen + per-symbol activation)
                        try:
                            if hasattr(self, 'mycelium') and self.mycelium is not None:
                                queen = self.mycelium.get_queen_signal() if hasattr(self.mycelium, 'get_queen_signal') else 0.0
                                activation = None
                                if hasattr(self.mycelium, 'activations') and isinstance(self.mycelium.activations, dict):
                                    activation = self.mycelium.activations.get(symbol)

                                # Prefer per-symbol activation when available; otherwise fall back to queen bias.
                                if activation is not None:
                                    if activation >= 0.60:
                                        ladders.append('üçÑ‚Üë')
                                    elif activation <= 0.40:
                                        ladders.append('üçÑ‚Üì')
                                else:
                                    if queen >= 0.30:
                                        ladders.append('üçÑ‚Üë')
                                    elif queen <= -0.30:
                                        ladders.append('üçÑ‚Üì')
                        except:
                            pass
                        
                        # üß† Brain ladder
                        try:
                            brain_rec = ECOSYSTEM_BRAIN.get_trading_recommendation()
                            if brain_rec.get('action') == 'BUY' and brain_rec.get('confidence', 0) > 0.5:
                                ladders.append('üß†‚Üë')
                            elif brain_rec.get('action') == 'REDUCE':
                                ladders.append('üß†‚Üì')
                        except:
                            pass
                        
                        # üîÆ Matrix ladder
                        try:
                            if hasattr(self, 'prob_matrix') and self.prob_matrix:
                                sig = self.prob_matrix.get_signal(symbol)
                                if sig and sig.get('probability', 0.5) > 0.6:
                                    ladders.append('üîÆ‚Üë')
                                elif sig and sig.get('probability', 0.5) < 0.4:
                                    ladders.append('üîÆ‚Üì')
                        except:
                            pass
                        
                        # üéµ HNC Frequency ladder
                        try:
                            hnc_data = self.asset_frequencies.get(symbol, {})
                            if hnc_data.get('is_harmonic'):
                                ladders.append('üéµ‚Üë')
                            freq = hnc_data.get('frequency', 432)
                            if 435 <= freq <= 445:
                                ladders.append('üéµ‚Üì')
                        except:
                            pass
                        
                        # üìà Momentum ladder
                        if pct > 0.3:
                            ladders.append('üìà‚Üë')
                        elif pct < -0.3:
                            ladders.append('üìà‚Üì')
                        
                        # üé≤ Monte Carlo enhanced indicator
                        try:
                            scanner = get_active_scanner()
                            scanner_key = f"{pos.exchange}:{symbol}"
                            if scanner_key in scanner.targets:
                                target = scanner.targets[scanner_key]
                                if hasattr(target, 'mc_simulations') and target.mc_simulations > 0:
                                    ladders.append('üé≤')  # MC enhanced
                        except:
                            pass
                        
                        # üîó Domino chain indicator
                        try:
                            from ira_sniper_mode import DOMINO_ENGINE
                            domino_boost, domino_active = DOMINO_ENGINE.get_domino_boost(symbol)
                            if domino_active and domino_boost > 1.0:
                                ladders.append(f'üîó‚Üë')  # Domino chain boost active
                        except:
                            pass
                        
                        # P&L color indicator
                        pnl_icon = "üü¢" if pnl_val > 0 else "üî¥" if pnl_val < 0 else "‚ö™"
                        
                        # Extract base asset
                        asset = symbol.replace('USD', '').replace('GBP', '').replace('EUR', '').replace('USDT', '')[:6]
                        
                        ladder_str = ''.join(ladders) if ladders else "‚Äî"
                        eta_full = f"{eta_str} {prob_pct:.0f}%" if prob_pct > 0 else eta_str
                        
                        icon = self._get_node_icon(pos.dominant_node)
                        print(f"      {icon}{asset:6s} ‚îÇ {exch:3s} ‚îÇ ${entry_val:>9.2f} ‚îÇ {pnl_icon}${pnl_val:>+9.4f} ‚îÇ {hold_str:>5s} ‚îÇ {eta_full:>10s} ‚îÇ {ladder_str}")
                    
                    print(f"   {'‚îÄ'*95}")
                    print(f"   ü™ú Ladders: üçÑMycelium üß†Brain üîÆMatrix üéµHNC üìàMomentum üé≤MonteCarlo üîóDomino  (‚Üë)=faster (‚Üì)=slower")
                        
                # Stats
                rt_count = len(self.realtime_prices)
                runtime = (time.time() - self.start_time) / 60
                ws_health = 'üü¢' if (self.ws_connected and not ws_stale) else ('üü°' if self.ws_connected else 'üî¥')
                
                # Calculate cycle P&L
                cycle_pnl = self.total_equity_gbp - self.tracker.cycle_equity_start
                cycle_pnl_pct = (cycle_pnl / self.tracker.cycle_equity_start * 100) if self.tracker.cycle_equity_start > 0 else 0
                cycle_icon = "üìà" if cycle_pnl >= 0 else "üìâ"
                
                # Dynamic currency symbol
                curr_sym = "¬£" if CONFIG['BASE_CURRENCY'] == 'GBP' else "‚Ç¨" if CONFIG['BASE_CURRENCY'] == 'EUR' else "$"
                
                # Calculate average hold time
                avg_hold_min = 0.0
                if self.tracker.closed_positions > 0:
                    avg_hold_min = (self.tracker.total_hold_time_sec / self.tracker.closed_positions) / 60
                
                # Mode indicator
                mode_str = "üéØ HIGH-Œì" if CONFIG['HIGH_COHERENCE_MODE'] else "üî• AGGRESSIVE"
                lambda_str = "Œõ-Field" if CONFIG['ENABLE_LAMBDA_FIELD'] else "Classic"
                
                # üåü Swarm orchestrator stats - show BOTH capital tracking AND actual cash
                capital_available = self.capital_pool.get_available()  # This includes holdings value
                actual_cash = getattr(self, 'cash_balance_gbp', 0.0) or 0.0  # Actual liquid GBP
                cycle_profits = self.capital_pool.profits_this_cycle
                total_pool_profits = self.capital_pool.total_profits
                
                # Count scouts and generations
                scout_count = sum(1 for p in self.positions.values() if p.is_scout)
                max_gen = max([p.generation for p in self.positions.values()], default=0)
                split_count = len(self.position_splitter.split_history)
                
                # Latest signal info
                latest_signal = self.signal_broadcaster.get_latest_signal(max_age_seconds=60)
                signal_str = ""
                if latest_signal:
                    signal_str = f" | üê∫ Signal: {latest_signal.symbol} {latest_signal.direction} ({latest_signal.strength:.2f})"
                
                print(f"\n   üíé Portfolio: {curr_sym}{self.total_equity_gbp:.2f} ({self.tracker.total_return:+.2f}%) | Peak: {curr_sym}{self.tracker.peak_balance:.2f}")
                print(f"   üìâ Max DD: {self.tracker.max_drawdown:.1f}% | Current DD: {self.tracker.current_drawdown:.1f}%")
                print(f"   {cycle_icon} Cycle P&L: {curr_sym}{cycle_pnl:+.2f} ({cycle_pnl_pct:+.2f}%)")
                print(f"   üìà Trades: {self.tracker.total_trades} | Wins: {self.tracker.wins} | WR: {self.tracker.win_rate:.1f}% | Avg Hold: {avg_hold_min:.1f}m")
                print(f"   üçÑ Network Œì: {network_coherence:.2f} {'‚ö†Ô∏è PAUSED' if trading_paused else ''} | WS: {ws_health} ({rt_count})")
                
                # üîó MINER CONNECTION STATUS
                miner_status = MINER_CONNECTOR.get_status()
                if miner_status['connected']:
                    miner_uptime = miner_status['uptime']
                    miner_icon = "üåü" if MINER_CONNECTOR.is_lighthouse else "üîó"
                    print(f"   {miner_icon} Miner: CONNECTED ({miner_uptime:.0f}s) | Œì={MINER_CONNECTOR.planetary_gamma:.3f} | "
                          f"Œ®={MINER_CONNECTOR.unified_coherence:.3f} | Cascade={MINER_CONNECTOR.cascade_multiplier:.2f}x")
                
                # üåç GAIA LATTICE DISPLAY - HNC CARRIER WAVE DYNAMICS üåç
                # Handle l_state as dict or object
                phase = l_state.get('phase', 'UNKNOWN') if isinstance(l_state, dict) else getattr(l_state, 'phase', 'UNKNOWN')
                frequency = l_state.get('frequency', 0) if isinstance(l_state, dict) else getattr(l_state, 'frequency', 0)
                field_purity = l_state.get('field_purity', 0) if isinstance(l_state, dict) else getattr(l_state, 'field_purity', 0)
                carrier_strength = l_state.get('carrier_strength') if isinstance(l_state, dict) else getattr(l_state, 'carrier_strength', None)
                nullification_pct = l_state.get('nullification_pct') if isinstance(l_state, dict) else getattr(l_state, 'nullification_pct', None)
                emergent_432 = l_state.get('emergent_432') if isinstance(l_state, dict) else getattr(l_state, 'emergent_432', None)
                risk_mod_display = l_state.get('risk_mod', 1.0) if isinstance(l_state, dict) else getattr(l_state, 'risk_mod', 1.0)
                tp_mod_display = l_state.get('tp_mod', 1.0) if isinstance(l_state, dict) else getattr(l_state, 'tp_mod', 1.0)
                
                gaia_icon = "üíú" if phase == "GAIA_RESONANCE" else ("‚ö°" if phase == "CARRIER_ACTIVE" else "üî¥")
                carrier_str = f"Carrier: {carrier_strength:.2f}œÜ" if carrier_strength is not None else ""
                nullification_str = f"Nullify: {nullification_pct:.0%}" if nullification_pct is not None else ""
                emergent_str = f"432Hz: {emergent_432:.0%}" if emergent_432 is not None else ""
                print(f"   üåê Gaia Lattice: {phase} ({frequency}Hz) {gaia_icon} | Purity: {field_purity*100:.0f}% | {carrier_str} | {emergent_str}")
                if nullification_str:
                    print(f"   üåç Carrier Wave: {nullification_str} | Risk: {risk_mod_display:.2f}x | TP: {tp_mod_display:.2f}x | {lambda_str}")
                # üåç‚ö° HNC Frequency Status ‚ö°üåç
                if CONFIG.get('ENABLE_HNC_FREQUENCY', True):
                    hnc_status = self.auris.get_hnc_status()
                    hnc_icon = "üü¢" if hnc_status['lighthouse_aligned'] else "üî¥"
                    print(f"   üåç HNC: {hnc_status['composite_freq']:.0f}Hz | {hnc_status['phase']} | Coherence: {hnc_status['triadic_coherence']:.0%} {hnc_icon} | Mod: √ó{hnc_status['position_modifier']:.2f}")
                    
                    # Show frequency distribution every 5 iterations
                    if self.iteration % 5 == 0:
                        dist = self.auris.get_frequency_distribution()
                        harmonic_count = self.auris.get_harmonic_count()
                        # Compact display
                        dist_parts = []
                        for band, count in dist.items():
                            if count > 0:
                                band_short = band.split('_')[1][:4]
                                dist_parts.append(f"{band_short}:{count}")
                        if dist_parts:
                            print(f"   üì° Freq Grid: {' | '.join(dist_parts[:6])} | üåà√ó{harmonic_count['harmonic']} ‚ö†Ô∏è√ó{harmonic_count['distortion']}")
                print(f"   üéÆ Mode: {mode_str} | Entry Œì: {CONFIG['ENTRY_COHERENCE']:.3f} | Exit Œì: {CONFIG['EXIT_COHERENCE']:.3f}")
                print(f"   üí∞ Compounded: {curr_sym}{self.tracker.compounded:.2f} | Harvested: {curr_sym}{self.tracker.harvested:.2f}")
                print(f"   üåü Pool P&L: {curr_sym}{total_pool_profits:+.2f} | üíµ Cash: {curr_sym}{actual_cash:.2f} | Scouts: {scout_count} | Splits: {split_count}{signal_str}")
                
                # üçÑüß† MYCELIUM NEURAL NETWORK STATUS
                try:
                    myc_state = self.mycelium.get_network_state()
                    queen_sig = myc_state.get('queen_signal', 0.0)
                    queen_emoji = "üëë" if queen_sig > 0.3 else "üë∏" if queen_sig > -0.3 else "üíÄ"
                    queen_dir = "BUY" if queen_sig > 0.1 else "SELL" if queen_sig < -0.1 else "HOLD"
                    hives = myc_state.get('hive_count', 0)
                    agents = myc_state.get('total_agents', 0)
                    gen = myc_state.get('generation', 0)
                    print(f"   üçÑ Mycelium: {hives} hives | {agents} agents | Gen {gen} | {queen_emoji} Queen: {queen_sig:+.2f} ‚Üí {queen_dir}")
                except Exception:
                    pass
                
                print(f"   ‚è±Ô∏è Runtime: {runtime:.1f} min | Positions: {len(self.positions)}/{max_positions_label()} | Max Gen: {max_gen}")
                
                if self.tracker.trading_halted:
                    print(f"   üõë TRADING HALTED: {self.tracker.halt_reason}")

                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                # Goal-based termination checks
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                elapsed_min = (time.time() - start_ts) / 60.0
                net_profit = self.total_equity_gbp - initial_equity
                if target_profit_gbp is not None and net_profit >= target_profit_gbp:
                    print("\nüéØ TARGET PROFIT REACHED")
                    print(f"   Initial Equity: ¬£{initial_equity:.2f}")
                    print(f"   Current Equity: ¬£{self.total_equity_gbp:.2f}")
                    print(f"   Net Profit:     ¬£{net_profit:.2f} (Goal ¬£{target_profit_gbp:.2f})")
                    break
                if max_minutes is not None and elapsed_min >= max_minutes:
                    print("\n‚è±Ô∏è SESSION TIME LIMIT REACHED")
                    print(f"   Runtime: {elapsed_min:.2f} min / {max_minutes:.2f} min limit")
                    print(f"   Net Profit: ¬£{net_profit:.2f} (Goal ¬£{target_profit_gbp if target_profit_gbp else 0:.2f})")
                    break
                
                # Save state every cycle for real-time data persistence
                self.save_state()
                logger.debug(f"State saved at iteration {self.iteration}")
                
                # üêï WATCHDOG HEARTBEAT: Write timestamp file for external monitoring
                try:
                    with open('.aureon_heartbeat', 'w') as hb:
                        hb.write(json.dumps({
                            'timestamp': time.time(),
                            'iteration': self.iteration,
                            'positions': len(self.positions),
                            'equity': self.total_equity_gbp,
                            'status': 'RUNNING'
                        }))
                except Exception:
                    pass  # Non-critical
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\n\nüêô Shutting down ecosystem...")
            # Stop probability generator
            if self.probability_generator:
                self.probability_generator.stop()
                print("   üìä Probability Generator stopped")
            self.save_state()
            print("   üíæ State saved for recovery")
            self.final_report()
        finally:
            # Ensure generator is stopped on any exit
            if self.probability_generator:
                try:
                    self.probability_generator.stop()
                except Exception:
                    pass
            if target_profit_gbp is not None or max_minutes is not None:
                # Compact goal session summary
                final_net = self.total_equity_gbp - initial_equity
                print("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê GOAL SESSION SUMMARY ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
                print(f"   Initial Equity: ¬£{initial_equity:.2f}")
                print(f"   Final Equity:   ¬£{self.total_equity_gbp:.2f}")
                print(f"   Net Profit:     ¬£{final_net:.2f}")
                if target_profit_gbp is not None:
                    pct_goal = (final_net / target_profit_gbp * 100) if target_profit_gbp > 0 else 0
                    print(f"   Goal Progress:  {pct_goal:.1f}% of ¬£{target_profit_gbp:.2f}")
                if max_minutes is not None:
                    print(f"   Runtime:        {(time.time()-start_ts)/60:.2f} min / {max_minutes:.2f} min limit")
                print("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
            
    def final_report(self):
        """Print final statistics"""
        print(f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          üêôüåå AUREON KRAKEN ECOSYSTEM - FINAL REPORT üååüêô               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

   Starting Balance:  ${self.tracker.initial_balance:.2f}
   Final Balance:     ${self.tracker.balance:.2f}
   üí∞ NET P&L:        ${self.tracker.balance - self.tracker.initial_balance:+.2f} ({self.tracker.total_return:+.2f}%)

   Total Trades:      {self.tracker.total_trades}
   Wins:              {self.tracker.wins}
   Losses:            {self.tracker.losses}
   üéØ WIN RATE:       {self.tracker.win_rate:.1f}%

   Total Fees:        ${self.tracker.total_fees:.2f}
   Max Drawdown:      {self.tracker.max_drawdown:.1f}%
   
   üí∞ 10-9-1 MODEL:
   ‚îú‚îÄ Compounded:     ${self.tracker.compounded:.2f}
   ‚îî‚îÄ Harvested:      ${self.tracker.harvested:.2f}
   
   üõ°Ô∏è RISK CONTROLS:
   ‚îú‚îÄ Max Drawdown:   {self.tracker.max_drawdown:.1f}% / {CONFIG['MAX_DRAWDOWN_PCT']:.1f}%
   ‚îú‚îÄ Position Sizing: {'Kelly Criterion' if CONFIG['USE_KELLY_SIZING'] else 'Fixed %'}
   ‚îî‚îÄ Circuit Breaker: {'üõë ACTIVATED' if self.tracker.trading_halted else '‚úÖ OK'}
""")
        
        # Print Nexus stats if available
        if self.nexus.enabled:
            nexus_stats = self.get_nexus_stats()
            hive_stats = nexus_stats.get('hive', {})
            print(f"""   üåå NEXUS INTEGRATION:
   ‚îú‚îÄ Signals Generated: {nexus_stats.get('signals_generated', 0)}
   ‚îú‚îÄ Signals Followed:  {nexus_stats.get('signals_followed', 0)}
   ‚îú‚îÄ Avg Coherence:     {nexus_stats.get('coherence_avg', 0):.4f}
   ‚îú‚îÄ Hive Generation:   {hive_stats.get('generation', 1)}
   ‚îî‚îÄ Child Hives:       {hive_stats.get('child_hives', 0)}
""")
        
        # üìä Print State Aggregator Summary (All JSON Sources)
        print("\n" + self.state_aggregator.get_summary())
        
        # Save aggregated state for next session
        self.state_aggregator.save_aggregated_state()
        
        # üåê Print Multi-Exchange Learning Summary üåê
        print("\n" + self.multi_exchange.get_learning_summary())
        
        # Print platform-specific metrics
        print(self.tracker.get_platform_summary())
        
        if self.tracker.win_rate >= 51 and self.tracker.net_profit > 0:
            print("   ‚úÖ GOAL ACHIEVED: 51%+ WR + NET PROFIT! ‚úÖ")
        else:
            print(f"   üìä Status: WR={self.tracker.win_rate:.1f}%, Net=${self.tracker.net_profit:+.2f}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MAIN ENTRY POINT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    # üõ°Ô∏è CRITICAL: Sanitize logging environment before starting
    # This removes any handlers added by imports (e.g. alpaca-py, urllib3)
    sanitize_logging_environment()

    # Configuration from environment
    dry_run = os.getenv('LIVE', '0') != '1'
    balance = float(os.getenv('BALANCE', 1000))
    interval = float(os.getenv('INTERVAL', 5))
    
    # Mining configuration
    enable_mining = os.getenv('ENABLE_MINING', '0') == '1'
    miner = None
    
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë  üêô AUREON KRAKEN ECOSYSTEM üêô                            ‚ïë
    ‚ïë                                                           ‚ïë
    ‚ïë  Usage:                                                   ‚ïë
    ‚ïë    LIVE=1 python aureon_kraken_ecosystem.py  # Live mode  ‚ïë
    ‚ïë    BALANCE=5000 python aureon_kraken_ecosystem.py         ‚ïë
    ‚ïë    INTERVAL=3 python aureon_kraken_ecosystem.py           ‚ïë
    ‚ïë                                                           ‚ïë
    ‚ïë  Mining (optional):                                       ‚ïë
    ‚ïë    ENABLE_MINING=1 MINING_WORKER=bc1q... python ...       ‚ïë
    ‚ïë    MINING_PLATFORM=braiins (or antpool, f2pool, nicehash) ‚ïë
    ‚ïë    OR:                                                    ‚ïë
    ‚ïë    MINING_POOL_HOST=stratum.pool.com                      ‚ïë
    ‚ïë    MINING_POOL_PORT=3333 MINING_THREADS=2                 ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    # Start background miner if enabled
    if enable_mining:
        try:
            from aureon_miner import AureonMiner, resolve_pool_config, KNOWN_POOLS
            
            worker = os.getenv('MINING_WORKER', '')
            password = os.getenv('MINING_PASSWORD', 'x')
            threads = int(os.getenv('MINING_THREADS', '1'))
            enable_all = os.getenv('MINING_ENABLE_ALL', '0') == '1'

            if not worker:
                print("    ‚ö†Ô∏è MINING_WORKER not set! Mining disabled.")
                print("    Set MINING_WORKER=your_btc_address.aureon")
            else:
                if enable_all:
                    print(f"    ‚õèÔ∏è Starting MULTI-POOL MINER: {worker}")
                    print(f"       Mode: ALL AVAILABLE PLATFORMS")
                    
                    # Initialize empty miner
                    miner = AureonMiner(threads=threads)
                    
                    # Add all known pools
                    for key, config in KNOWN_POOLS.items():
                        print(f"       Adding Pool: {config['desc']} ({config['host']})")
                        miner.add_pool(config['host'], config['port'], worker, password)
                        
                    if miner.start():
                        print(f"    ‚úÖ Multi-Pool Miner running on {threads} threads (distributed)")
                    else:
                        print("    ‚ùå Miner failed to start")
                        miner = None
                else:
                    # Single pool mode
                    platform = os.getenv('MINING_PLATFORM')
                    raw_host = os.getenv('MINING_POOL_HOST')
                    raw_port = os.getenv('MINING_POOL_PORT')
                    
                    pool_host, pool_port = resolve_pool_config(
                        platform=platform,
                        host=raw_host,
                        port=int(raw_port) if raw_port else None
                    )
                    
                    print(f"    ‚õèÔ∏è Starting background miner: {worker}")
                    print(f"       Pool: {pool_host}:{pool_port} ({platform or 'custom'})")
                    
                    miner = AureonMiner(pool_host, pool_port, worker, password, threads=threads)
                    if miner.start():
                        print(f"    ‚úÖ Miner running on {threads} thread(s)")
                    else:
                        print("    ‚ùå Miner failed to start")
                        miner = None

        except ImportError as e:
            print(f"    ‚ö†Ô∏è Mining module not available: {e}")
        except Exception as e:
            print(f"    ‚ùå Mining setup error: {e}")
    
    try:
        ecosystem = AureonKrakenEcosystem(
            initial_balance=balance,
            dry_run=dry_run
        )
        
        ecosystem.run(interval=interval)
    finally:
        # Stop miner on shutdown
        if miner:
            print("\n    üõë Stopping miner...")
            miner.stop()


if __name__ == "__main__":
    main()
