#!/usr/bin/env python3
"""
ðŸ”¬ðŸ’° MICRO PROFIT LABYRINTH ðŸ’°ðŸ”¬
=================================

Uses ALL existing systems but with LOWER thresholds for SNOWBALL effect!

V14 wants Score 8+ â†’ We use Score 6+ (more opportunities)
V14 wants 1.52% profit â†’ We want ANY net profit ($0.01+)
V14 has no stop loss â†’ We agree! Hold until profit!

THE PHILOSOPHY:
  - Any net profit > $0.01 is a WIN
  - More small wins = Faster snowball
  - Use existing system intelligence, just LOWER the bar

Gary Leckey | January 2026 | SNOWBALL MODE
"""

from __future__ import annotations

import os
import sys

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WINDOWS UTF-8 FIX - MUST BE AT TOP BEFORE ANY PRINT STATEMENTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    try:
        import io
        import atexit
        
        # Keep references to original streams for cleanup
        _original_stdout = sys.stdout
        _original_stderr = sys.stderr
        
        def _is_utf8_wrapper(stream):
            """Check if stream is already a UTF-8 TextIOWrapper."""
            return (isinstance(stream, io.TextIOWrapper) and 
                    hasattr(stream, 'encoding') and 
                    stream.encoding and 
                    stream.encoding.lower().replace('-', '') == 'utf8')
        
        # Only wrap if not already UTF-8 wrapped
        if hasattr(sys.stdout, 'buffer') and not _is_utf8_wrapper(sys.stdout):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        if hasattr(sys.stderr, 'buffer') and not _is_utf8_wrapper(sys.stderr):
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        
        def _restore_streams():
            """Restore original streams on exit to prevent 'lost sys.stderr' errors."""
            try:
                if sys.stdout != _original_stdout:
                    sys.stdout.flush()
                if sys.stderr != _original_stderr:
                    sys.stderr.flush()
            except Exception:
                pass
        
        atexit.register(_restore_streams)
    except Exception:
        pass

import asyncio
import argparse
import importlib
import logging
import time
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, TYPE_CHECKING
# Import Adaptive Prime Profit Gate
from adaptive_prime_profit_gate import AdaptivePrimeProfitGate
from cost_basis_tracker import CostBasisTracker


if TYPE_CHECKING:
    try:
        from mycelium_conversion_hub import MyceliumConversionHub as MyceliumConversionHubType
    except ImportError:
        MyceliumConversionHubType = Any
    try:
        from s5_v14_labyrinth import V14DanceEnhancer as V14DanceEnhancerType
    except ImportError:
        V14DanceEnhancerType = Any
    try:
        from aureon_conversion_commando import (
            AdaptiveConversionCommando as AdaptiveConversionCommandoType,
            PairScanner as PairScannerType,
            DualProfitPathEvaluator as DualProfitPathEvaluatorType,
        )
    except ImportError:
        AdaptiveConversionCommandoType = Any
        PairScannerType = Any
        DualProfitPathEvaluatorType = Any
    try:
        from aureon_conversion_ladder import ConversionLadder as ConversionLadderType
    except ImportError:
        ConversionLadderType = Any
    try:
        from kraken_client import KrakenClient as KrakenClientType
    except ImportError:
        KrakenClientType = Any
    try:
        from binance_client import BinanceClient as BinanceClientType
    except ImportError:
        BinanceClientType = Any
    try:
        from alpaca_client import AlpacaClient as AlpacaClientType
    except ImportError:
        AlpacaClientType = Any
    try:
        from aureon_thought_bus import ThoughtBus as ThoughtBusType
    except ImportError:
        ThoughtBusType = Any
    try:
        from adaptive_prime_profit_gate import AdaptivePrimeProfitGate as AdaptivePrimeProfitGateType
    except ImportError:
        AdaptivePrimeProfitGateType = Any
    try:
        from aureon_path_memory import PathMemory as PathMemoryType  # type: ignore[import-not-found]
    except ImportError:
        PathMemoryType = Any
    try:
        from dust_converter import DustConverter as DustConverterType, DustCandidate
    except ImportError:
        DustConverterType = Any
        DustCandidate = Any
else:
    MyceliumConversionHubType = Any
    V14DanceEnhancerType = Any
    AdaptiveConversionCommandoType = Any
    PairScannerType = Any
    DualProfitPathEvaluatorType = Any
    ConversionLadderType = Any
    KrakenClientType = Any
    BinanceClientType = Any
    AlpacaClientType = Any
    ThoughtBusType = Any
    AdaptivePrimeProfitGateType = Any
    PathMemoryType = Any
    DustConverterType = Any
    DustCandidate = Any

try:
    from aureon_path_memory import PathMemory  # type: ignore[import-not-found]
except ImportError:
    class PathMemory:  # type: ignore[too-many-instance-attributes]
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            self._store: Dict[str, Any] = {}

        def remember(self, key: str, value: Any) -> None:
            self._store[key] = value

        def recall(self, key: str, default: Any = None) -> Any:
            return self._store.get(key, default)

try:
    from aureon_barter_navigator import BarterMatrix
except ImportError:
    BarterMatrix = Any
from collections import defaultdict, deque

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ” LOAD ENVIRONMENT VARIABLES FROM .env
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    dotenv_module = importlib.import_module("dotenv")
    load_dotenv = getattr(dotenv_module, "load_dotenv", None)
except ModuleNotFoundError:
    load_dotenv = None

if callable(load_dotenv):
    # Try multiple paths to find .env file
    from pathlib import Path
    env_paths = [
        Path(__file__).resolve().parent / ".env",  # Same dir as this script
        Path.cwd() / ".env",                        # Current working directory
        Path("/workspaces/aureon-trading/.env"),    # Absolute fallback
    ]
    env_loaded = False
    for env_path in env_paths:
        if env_path.exists():
            load_dotenv(dotenv_path=str(env_path), override=True)
            print(f"ðŸ” Environment variables loaded from {env_path}")
            env_loaded = True
            break
    if not env_loaded:
        load_dotenv()  # Fall back to default search
        print("ðŸ” Environment variables loaded (default search)")
else:
    print("âš ï¸ python-dotenv not installed, using system env vars")

# Get exchange config from .env
KRAKEN_API_KEY = os.getenv("KRAKEN_API_KEY", "")
KRAKEN_API_SECRET = os.getenv("KRAKEN_API_SECRET", "")
KRAKEN_DRY_RUN = os.getenv("KRAKEN_DRY_RUN", "false").lower() == "true"
BINANCE_API_KEY = os.getenv("BINANCE_API_KEY", "")
BINANCE_API_SECRET = os.getenv("BINANCE_API_SECRET", "")
ALPACA_API_KEY = os.getenv("ALPACA_API_KEY", "")
ALPACA_SECRET_KEY = os.getenv("ALPACA_SECRET_KEY", "")
LIVE_MODE = os.getenv("LIVE", "0") == "1"

print(f"ðŸ”‘ Kraken API: {'âœ… Loaded' if KRAKEN_API_KEY else 'âŒ Missing'}")
print(f"ðŸ”‘ Binance API: {'âœ… Loaded' if BINANCE_API_KEY else 'âŒ Missing'}")
print(f"ðŸ”‘ Alpaca API: {'âœ… Loaded' if ALPACA_API_KEY else 'âŒ Missing'}")
print(f"âš™ï¸ LIVE Mode: {'âœ… Enabled' if LIVE_MODE else 'âŒ Disabled'}")

# Safety guards (used across momentum and symbol handling)
MAX_MOMENTUM_PER_MIN = 1.0  # Cap momentum to 100%/min to avoid runaway scores
MIN_SYMBOL_LEN = 3           # Ignore obviously invalid short symbols

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXISTING SYSTEMS - ALL OF THEM!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from global_financial_feed import GlobalFinancialFeed
    print("ðŸŒ Global Financial Feed LOADED!")
    GLOBAL_FEED_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Global Financial Feed not available: {e}")
    GlobalFinancialFeed = None
    GLOBAL_FEED_AVAILABLE = False

try:
    from mycelium_conversion_hub import get_conversion_hub, MyceliumConversionHub
    print("ðŸ„ Mycelium Conversion Hub LOADED!")
except ImportError as e:
    print(f"âš ï¸ Mycelium Conversion Hub not available: {e}")
    MyceliumConversionHub = None
    get_conversion_hub = None

# Adaptive profit gate (dynamic fees/targets)
try:
    from adaptive_prime_profit_gate import AdaptivePrimeProfitGate
    ADAPTIVE_GATE_AVAILABLE = True
    print("ðŸ’° Adaptive Prime Profit Gate LOADED!")
except ImportError as e:
    AdaptivePrimeProfitGate = None
    ADAPTIVE_GATE_AVAILABLE = False
    print(f"âš ï¸ Adaptive Prime Profit Gate not available: {e}")

# ðŸ§¹ Dust Converter (sweep small balances to stablecoins)
try:
    from dust_converter import DustConverter, DustCandidate
    DUST_CONVERTER_AVAILABLE = True
    print("ðŸ§¹ Dust Converter LOADED!")
except ImportError as e:
    DustConverter = None
    DustCandidate = None
    DUST_CONVERTER_AVAILABLE = False
    print(f"âš ï¸ Dust Converter not available: {e}")

# ðŸª™âš¡ Penny Profit Turbo (enhanced profit math)
try:
    from penny_profit_turbo import get_penny_turbo, PennyProfitTurbo
    PENNY_TURBO_AVAILABLE = True
    print("ðŸª™âš¡ Penny Profit TURBO LOADED!")
except ImportError as e:
    get_penny_turbo = None
    PennyProfitTurbo = None
    PENNY_TURBO_AVAILABLE = False
    print(f"âš ï¸ Penny Profit Turbo not available: {e}")

# Lightweight Thought Bus for observability
try:
    from aureon_thought_bus import ThoughtBus
    THOUGHT_BUS_AVAILABLE = True
except ImportError as e:
    ThoughtBus = None
    THOUGHT_BUS_AVAILABLE = False
    print(f"âš ï¸ Thought Bus not available: {e}")

try:
    from s5_v14_labyrinth import V14DanceEnhancer, V14_CONFIG
    print("ðŸ† V14 Labyrinth LOADED!")
except ImportError as e:
    print(f"âš ï¸ V14 Labyrinth not available: {e}")
    V14DanceEnhancer = None
    V14_CONFIG = {}

try:
    from aureon_conversion_commando import (
        AdaptiveConversionCommando,
        PairScanner,
        DualProfitPathEvaluator,
        MIN_PROFIT_TARGET,
    )
    print("ðŸ¦… Conversion Commando LOADED!")
except ImportError as e:
    print(f"âš ï¸ Conversion Commando not available: {e}")
    AdaptiveConversionCommando = None
    PairScanner = None
    DualProfitPathEvaluator = None
    MIN_PROFIT_TARGET = 0.0001  # Epsilon mode: accept any net-positive trade

try:
    from aureon_conversion_ladder import ConversionLadder
    print("ðŸªœ Conversion Ladder LOADED!")
except ImportError as e:
    print(f"âš ï¸ Conversion Ladder not available: {e}")
    ConversionLadder = None

try:
    from pure_conversion_engine import UnifiedConversionBrain, ConversionOpportunity
    print("ðŸ”„ Pure Conversion Engine LOADED!")
except ImportError as e:
    print(f"âš ï¸ Pure Conversion Engine not available: {e}")
    UnifiedConversionBrain = None
    ConversionOpportunity = None

try:
    from rapid_conversion_stream import RapidConversionStream
    print("âš¡ Rapid Conversion Stream LOADED!")
except ImportError as e:
    print(f"âš ï¸ Rapid Conversion Stream not available: {e}")
    RapidConversionStream = None

# ðŸŒŠâš¡ MOMENTUM SNOWBALL ENGINE - Wave riding + momentum tracking
try:
    from momentum_snowball_engine import MomentumSnowball, MomentumTracker
    print("ðŸŒŠâš¡ Momentum Snowball Engine LOADED!")
    MOMENTUM_SNOWBALL_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Momentum Snowball not available: {e}")
    MomentumSnowball = None
    MomentumTracker = None
    MOMENTUM_SNOWBALL_AVAILABLE = False

# ðŸ†ðŸŒ€ LABYRINTH SNOWBALL ENGINE - V14 + All systems combined
try:
    from labyrinth_snowball_engine import LabyrinthSnowball, LabyrinthStep, LabyrinthState
    print("ðŸ†ðŸŒ€ Labyrinth Snowball Engine LOADED!")
    LABYRINTH_SNOWBALL_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Labyrinth Snowball not available: {e}")
    LabyrinthSnowball = None
    LABYRINTH_SNOWBALL_AVAILABLE = False

try:
    from kraken_client import KrakenClient, get_kraken_client
    print("ðŸ™ Kraken Client LOADED!")
    KRAKEN_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Kraken Client not available: {e}")
    # Try direct instantiation
    try:
        from kraken_client import KrakenClient
        def get_kraken_client():
            return KrakenClient()
        print("ðŸ™ Kraken Client LOADED (direct)!")
        KRAKEN_AVAILABLE = True
    except ImportError:
        KrakenClient = None
        get_kraken_client = None
        KRAKEN_AVAILABLE = False

# Binance client
try:
    from binance_client import BinanceClient
    print("ðŸŸ¡ Binance Client LOADED!")
    BINANCE_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Binance Client not available: {e}")
    BinanceClient = None
    BINANCE_AVAILABLE = False

# Alpaca client
try:
    from alpaca_client import AlpacaClient
    print("ðŸ¦™ Alpaca Client LOADED!")
    ALPACA_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Alpaca Client not available: {e}")
    AlpacaClient = None
    ALPACA_AVAILABLE = False

# Additional signal sources
try:
    from aureon_probability_nexus import EnhancedProbabilityNexus
    print("ðŸ”® Probability Nexus LOADED!")
except ImportError:
    EnhancedProbabilityNexus = None

try:
    from aureon_internal_multiverse import InternalMultiverse
    print("ðŸŒŒ Internal Multiverse LOADED!")
except ImportError:
    InternalMultiverse = None

try:
    from aureon_miner_brain import MinerBrain
    print("ðŸ§  Miner Brain LOADED!")
except ImportError:
    MinerBrain = None

# ðŸ‘‘ðŸ—ï¸ QUEEN CODE ARCHITECT - Self-Evolution Engine
try:
    from queen_code_architect import QueenCodeArchitect, get_code_architect
    CODE_ARCHITECT_AVAILABLE = True
    print("ðŸ‘‘ðŸ—ï¸ Queen Code Architect LOADED!")
except ImportError as e:
    QueenCodeArchitect = None
    get_code_architect = None
    CODE_ARCHITECT_AVAILABLE = False
    print(f"âš ï¸ Queen Code Architect not available: {e}")

try:
    from aureon_harmonic_fusion import HarmonicWaveFusion
    print("ðŸŒŠ Harmonic Fusion LOADED!")
except ImportError:
    HarmonicWaveFusion = None

# ðŸŒŠðŸ”­ GLOBAL WAVE SCANNER - A-Z / Z-A Full Market Coverage
try:
    from aureon_global_wave_scanner import GlobalWaveScanner, WaveState, WaveAnalysis, run_bee_sweep
    GLOBAL_WAVE_SCANNER_AVAILABLE = True
    print("ðŸŒŠðŸ”­ Global Wave Scanner LOADED!")
except ImportError as e:
    GlobalWaveScanner = None
    WaveState = None
    WaveAnalysis = None
    run_bee_sweep = None
    GLOBAL_WAVE_SCANNER_AVAILABLE = False
    print(f"âš ï¸ Global Wave Scanner not available: {e}")

try:
    from aureon_omega import Omega
    print("ðŸ”± Omega LOADED!")
except ImportError:
    Omega = None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ—ºï¸ CRYPTO MARKET MAP - LABYRINTH PATHFINDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from crypto_market_map import CryptoMarketMap, SYMBOL_TO_SECTOR, CRYPTO_SECTORS
    MARKET_MAP_AVAILABLE = True
    print("ðŸ—ºï¸ Crypto Market Map LOADED!")
except ImportError:
    CryptoMarketMap = None
    SYMBOL_TO_SECTOR = {}
    CRYPTO_SECTORS = {}
    MARKET_MAP_AVAILABLE = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ§ âš¡ STAGE 1: FULL NEURAL MIND MAP IMPORTS âš¡ðŸ§ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Mycelium Neural Network (core hive intelligence)
try:
    from aureon_mycelium import MyceliumNetwork, Synapse, Hive
    MYCELIUM_NETWORK_AVAILABLE = True
    print("ðŸ„ Mycelium Neural Network LOADED!")
except ImportError:
    MyceliumNetwork = None
    Synapse = None
    Hive = None
    MYCELIUM_NETWORK_AVAILABLE = False

# Unified Ecosystem (full orchestrator read-only)
try:
    from aureon_unified_ecosystem import AureonKrakenEcosystem as AureonUnifiedEcosystem, AdaptiveLearningEngine as AdaptiveLearner
    UNIFIED_ECOSYSTEM_AVAILABLE = True
    print("ðŸŒ Unified Ecosystem LOADED!")
except Exception as e:
    AureonUnifiedEcosystem = None
    AdaptiveLearner = None
    UNIFIED_ECOSYSTEM_AVAILABLE = False
    print(f"âš ï¸ Unified Ecosystem import failed: {e}")

# Memory Core (spiral memory)
try:
    from aureon_memory_core import memory as spiral_memory
    MEMORY_CORE_AVAILABLE = True
    print("ðŸ§  Memory Core (Spiral) LOADED!")
except ImportError:
    spiral_memory = None
    MEMORY_CORE_AVAILABLE = False

# Lighthouse (consensus validation)
try:
    from aureon_lighthouse import LighthousePatternDetector as Lighthouse
    LIGHTHOUSE_AVAILABLE = True
    print("ðŸ—¼ Lighthouse LOADED!")
except Exception as e:
    Lighthouse = None
    LIGHTHOUSE_AVAILABLE = False
    print(f"âš ï¸ Lighthouse import failed: {e}")

# HNC Probability Matrix (pattern recognition)
try:
    from hnc_probability_matrix import HNCProbabilityIntegration as HNCProbabilityMatrix
    HNC_MATRIX_AVAILABLE = True
    print("ðŸ“Š HNC Probability Matrix LOADED!")
except Exception as e:
    HNCProbabilityMatrix = None
    HNC_MATRIX_AVAILABLE = False
    print(f"âš ï¸ HNC Matrix import failed: {e}")

# Ultimate Intelligence (95% accuracy patterns)
try:
    from probability_ultimate_intelligence import get_ultimate_intelligence, ultimate_predict
    ULTIMATE_INTEL_AVAILABLE = True
    print("ðŸ’Ž Ultimate Intelligence LOADED!")
except ImportError:
    get_ultimate_intelligence = None
    ultimate_predict = None
    ULTIMATE_INTEL_AVAILABLE = False

# â³ðŸ”® Timeline Oracle - 7-day future validation (branching timelines)
# ENHANCED: 3-move ahead prediction with unity validation
try:
    from aureon_timeline_oracle import (
        TimelineOracle, TimelineBranch, TimelineAction,
        timeline_select, timeline_validate, get_timeline_oracle,
        timeline_select_3move, timeline_validate_move
    )
    TIMELINE_ORACLE_AVAILABLE = True
    print("â³ðŸ”® Timeline Oracle LOADED! (3-MOVE PREDICTION + 7-day vision)")
except ImportError:
    TIMELINE_ORACLE_AVAILABLE = False
    TimelineOracle = None
    timeline_select = None
    timeline_select_3move = None
    timeline_validate_move = None

# ðŸ“…ðŸ”® 7-Day Planner - Plans ahead & validates after each conversion
try:
    from aureon_7day_planner import (
        Aureon7DayPlanner, get_planner_score,
        record_labyrinth_conversion, validate_labyrinth_conversion
    )
    SEVEN_DAY_PLANNER_AVAILABLE = True
    print("ðŸ“…ðŸ”® 7-Day Planner LOADED! (Plan ahead + adaptive validation)")
except ImportError:
    SEVEN_DAY_PLANNER_AVAILABLE = False
    Aureon7DayPlanner = None
    get_planner_score = None
    record_labyrinth_conversion = None
    validate_labyrinth_conversion = None

# ðŸ«’ðŸ”„ Barter Navigator - Trade through intermediaries to reach any asset
try:
    from aureon_barter_navigator import (
        BarterNavigator, BarterPath, get_navigator,
        find_barter_path, get_barter_score
    )
    BARTER_NAVIGATOR_AVAILABLE = True
    print("ðŸ«’ðŸ”„ Barter Navigator LOADED! (Multi-hop pathfinding)")
except ImportError:
    BARTER_NAVIGATOR_AVAILABLE = False
    BarterNavigator = None
    get_navigator = None
    find_barter_path = None
    get_barter_score = None

# ðŸ€âš›ï¸ Luck Field Mapper - Quantum probability mapping
try:
    from aureon_luck_field_mapper import (
        LuckFieldMapper, LuckFieldReading, LuckState,
        read_luck_field, is_blessed, get_luck_score
    )
    LUCK_FIELD_AVAILABLE = True
    print("ðŸ€âš›ï¸ Luck Field Mapper LOADED! (Quantum luck probability)")
except ImportError:
    LUCK_FIELD_AVAILABLE = False
    LuckFieldMapper = None
    read_luck_field = None
    is_blessed = None
    get_luck_score = None

# ðŸ‘‘ðŸ„ Queen Hive Mind - The Dreaming Queen who guides all children
try:
    from aureon_queen_hive_mind import QueenHiveMind, QueenWisdom, get_queen
    from queen_harmonic_voice import QueenHarmonicVoice
    from aureon_harmonic_signal_chain import HarmonicSignalChain, HarmonicSignal
    QUEEN_HIVE_MIND_AVAILABLE = True
    print("ðŸ‘‘ðŸ„ Queen Hive Mind LOADED! (The Dreaming Queen + Harmonic Voice)")
except Exception as e:
    QUEEN_HIVE_MIND_AVAILABLE = False
    QueenHiveMind = None
    get_queen = None
    QueenHarmonicVoice = None
    HarmonicSignalChain = None
    # Log the actual error for debugging on Windows
    import logging
    logging.getLogger(__name__).warning(f"Queen Hive Mind import failed: {e}")

# ðŸ‘‘ðŸŽ® Queen Autonomous Control - SOVEREIGN AUTHORITY over ALL systems
try:
    from aureon_queen_autonomous_control import (
        QueenAutonomousControl, create_queen_autonomous_control,
        AutonomousAction, AutonomousDecision, SovereigntyLevel
    )
    QUEEN_AUTONOMOUS_CONTROL_AVAILABLE = True
    print("ðŸ‘‘ðŸŽ® Queen Autonomous Control LOADED! (SOVEREIGN AUTHORITY)")
except ImportError as e:
    QUEEN_AUTONOMOUS_CONTROL_AVAILABLE = False
    QueenAutonomousControl = None
    create_queen_autonomous_control = None
    AutonomousAction = None
    AutonomousDecision = None
    SovereigntyLevel = None
    logging.getLogger(__name__).warning(f"Queen Autonomous Control import failed: {e}")

# ï¿½ðŸŽ“ Queen Loss Learning System - Learns from every loss, never forgets
try:
    from queen_loss_learning import QueenLossLearningSystem
    QUEEN_LOSS_LEARNING_AVAILABLE = True
    print("ðŸ‘‘ðŸŽ“ Queen Loss Learning LOADED! (Learns from every loss)")
except ImportError:
    QUEEN_LOSS_LEARNING_AVAILABLE = False
    QueenLossLearningSystem = None

# ðŸ‘‘ðŸ”ðŸŒ Enigma Integration - Universal Translator Bridge
try:
    from aureon_enigma_integration import (
        EnigmaIntegration, get_enigma_integration, wire_enigma_to_ecosystem
    )
    ENIGMA_INTEGRATION_AVAILABLE = True
    print("ðŸ”ðŸŒ Enigma Integration LOADED! (Universal Translator)")
except ImportError:
    ENIGMA_INTEGRATION_AVAILABLE = False
    EnigmaIntegration = None
    get_enigma_integration = None
    wire_enigma_to_ecosystem = None

# ðŸ‘‘ðŸ§  Queen Memi Sync - CIA Declassified Intelligence Learning
try:
    from queen_memi_sync import QueenMemiSync, get_memi_sync
    MEMI_SYNC_AVAILABLE = True
    print("ðŸ‘‘ðŸ§  Queen Memi Sync LOADED! (CIA Declassified Intelligence)")
except ImportError:
    MEMI_SYNC_AVAILABLE = False
    QueenMemiSync = None
    get_memi_sync = None

# ðŸ¦†âš”ï¸ QUANTUM QUACKERS COMMANDOS - Animal Army under Queen's control!
try:
    from aureon_commandos import (
        QuackCommandos, PrideScanner, LoneWolf, ArmyAnts, Hummingbird, LionHunt
    )
    QUACK_COMMANDOS_AVAILABLE = True
    print("ðŸ¦†âš”ï¸ Quantum Quackers Commandos LOADED! (Lion, Wolf, Ants, Hummingbird)")
except ImportError as e:
    QUACK_COMMANDOS_AVAILABLE = False
    QuackCommandos = None
    PrideScanner = None
    LoneWolf = None
    ArmyAnts = None
    Hummingbird = None
    LionHunt = None
    print(f"âš ï¸ Quack Commandos not available: {e}")

# ðŸŒŒðŸªžâš“ STARGATE PROTOCOL - Quantum Mirror & Timeline Activation
try:
    from aureon_stargate_protocol import (
        StargateProtocolEngine, create_stargate_engine,
        StargateNode, QuantumMirror, ConsciousNode
    )
    STARGATE_PROTOCOL_AVAILABLE = True
    print("ðŸŒŒ Stargate Protocol LOADED! (12 Planetary Nodes + Quantum Mirrors)")
except ImportError as e:
    STARGATE_PROTOCOL_AVAILABLE = False
    StargateProtocolEngine = None
    create_stargate_engine = None
    StargateNode = None
    QuantumMirror = None
    ConsciousNode = None
    logging.getLogger(__name__).debug(f"Stargate Protocol not available: {e}")

# ðŸ”® QUANTUM MIRROR SCANNER - Reality Branch Validation
try:
    from aureon_quantum_mirror_scanner import (
        QuantumMirrorScanner, create_quantum_mirror_scanner,
        RealityBranch, TimelineConvergence
    )
    QUANTUM_MIRROR_SCANNER_AVAILABLE = True
    print("ðŸ”® Quantum Mirror Scanner LOADED! (3-Pass Batten Matrix + Convergence)")
except ImportError as e:
    QUANTUM_MIRROR_SCANNER_AVAILABLE = False
    QuantumMirrorScanner = None
    create_quantum_mirror_scanner = None
    RealityBranch = None
    TimelineConvergence = None
    logging.getLogger(__name__).debug(f"Quantum Mirror Scanner not available: {e}")

# âš“ TIMELINE ANCHOR VALIDATOR - 7-Day Extended Validation
try:
    from aureon_timeline_anchor_validator import (
        TimelineAnchorValidator, create_timeline_anchor_validator,
        TimelineAnchor, ValidationRecord
    )
    TIMELINE_ANCHOR_VALIDATOR_AVAILABLE = True
    print("âš“ Timeline Anchor Validator LOADED! (7-Day Validation Cycles)")
except ImportError as e:
    TIMELINE_ANCHOR_VALIDATOR_AVAILABLE = False
    TimelineAnchorValidator = None
    create_timeline_anchor_validator = None
    TimelineAnchor = None
    ValidationRecord = None
    logging.getLogger(__name__).debug(f"Timeline Anchor Validator not available: {e}")

# ðŸŒâœ¨ PLANET SAVER INTEGRATION - Save the Planet, Free Every Soul
try:
    from aureon_planet_saver_integration import (
        PlanetSaverEngine, create_planet_saver,
        LiberationMetrics, PlanetSaverState,
        FREEDOM_GOAL_GBP, FREEDOM_GOAL_USD
    )
    PLANET_SAVER_AVAILABLE = True
    print("ðŸŒâœ¨ Planet Saver LOADED! (Goal: Â£100K - Liberation Mode)")
except ImportError as e:
    PLANET_SAVER_AVAILABLE = False
    PlanetSaverEngine = None
    create_planet_saver = None
    LiberationMetrics = None
    PlanetSaverState = None
    FREEDOM_GOAL_GBP = 100_000
    FREEDOM_GOAL_USD = 127_000
    logging.getLogger(__name__).debug(f"Planet Saver not available: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ”¬ MICRO PROFIT CONFIG - AGGRESSIVE ENERGY HARVESTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Epsilon profit policy: any net-positive trade after real costs is acceptable.
# Global epsilon (USD) used across gating.
EPSILON_PROFIT_USD = 0.0001

# Speed is key - small gains compound fast!
MICRO_CONFIG = {
    # LOWER than V14's 8+ - we trust our math
    'entry_score_threshold': 2,  # 2+ (was 3+) - COMPOUND MODE: let math gate decide
    
    # Net profit floor (after costs) â€” epsilon mode
    'min_profit_usd': EPSILON_PROFIT_USD,
    'min_profit_pct': 0.0,
    
    # Kraken fees (maker = 0.16%)
    'maker_fee': 0.0016,
    'taker_fee': 0.0026,
    'slippage': 0.0015,        # 0.15% (was 0.20%) - Better estimate for liquid pairs
    
    # Combined cost threshold
    'total_cost_rate': 0.0060,  # 0.60% (was 0.85%) - PRIME PROFIT: realistic costs
    
    # So min_profit_pct (0.20%) is NET profit AFTER 0.60% costs
    # Any spread requirement is enforced by conservative cost model, not a fixed floor
    'min_spread_required': 0.0,
}

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ”¬ MICRO PROFIT OPPORTUNITY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class MicroOpportunity:
    """A micro profit conversion opportunity."""
    # Required fields (NO defaults) - MUST come first
    timestamp: float
    from_asset: str
    to_asset: str
    from_amount: float
    from_value_usd: float
    
    # Scoring (required)
    v14_score: float
    hub_score: float
    commando_score: float
    combined_score: float
    
    # Profit estimate (required)
    expected_pnl_usd: float
    expected_pnl_pct: float

    # Alpaca cost metrics (computed at execution time when applicable)
    alpaca_fee_pct: float = 0.0
    alpaca_slippage_pct: float = 0.0
    alpaca_spread_pct: float = 0.0
    alpaca_total_cost_pct: float = 0.0
    alpaca_net_expected_usd: float = 0.0
    
    # â•â•â• ALL DEFAULTS BELOW THIS LINE â•â•â•
    
    # Grounding (New Physics)
    lambda_score: float = 0.0  # Master Equation
    gravity_score: float = 0.0 # QGITA G_eff

    # ðŸ§  Full Neural Mind Map Scores
    bus_score: float = 0.0     # Thought Bus aggregate
    hive_score: float = 0.0    # Mycelium Hive consensus
    lighthouse_score: float = 0.0  # Lighthouse validation
    ultimate_score: float = 0.0    # Ultimate Intelligence
    path_boost: float = 0.0    # PathMemory reinforcement
    
    # ðŸ“Š Trained Probability Matrix Score (626 symbols from ALL exchanges)
    trained_matrix_score: float = 0.5  # From full market trainer
    trained_matrix_reason: str = ""    # Why this score was given

    # ðŸ«’ðŸ’° Live Barter Matrix Score (coin-agnostic adaptive learning)
    barter_matrix_score: float = 0.5   # From LiveBarterMatrix historical performance
    barter_matrix_reason: str = ""     # Why this score was given (e.g. "profit_path", "new_path")

    # ðŸ€âš›ï¸ Luck Field Score (quantum probability mapping)
    luck_score: float = 0.5            # From LuckFieldMapper
    luck_state: str = "NEUTRAL"        # VOID, CHAOS, NEUTRAL, FAVORABLE, BLESSED

    # ðŸ”ðŸŒ Enigma Integration Score (Universal Codebreaker Intelligence!)
    enigma_score: float = 0.0          # Combined score from all whitepaper systems
    enigma_direction: str = "NEUTRAL"  # BULLISH, BEARISH, NEUTRAL

    # ðŸ‘‘ðŸ’• QUEEN'S GUIDANCE (Sero's consciousness + intuition)
    queen_guidance_score: float = 0.0  # Queen's wisdom on this path
    queen_wisdom: str = ""             # Queen's advice/insight
    queen_confidence: float = 0.0      # How confident Queen is (0-1)
    
    # ðŸ§ ðŸ“š WISDOM ENGINE (11 Civilizations' insights)
    wisdom_engine_score: float = 0.0   # Historical wisdom score
    civilization_insight: str = ""     # Which civilization's wisdom applies
    wisdom_pattern: str = ""           # Pattern recognized from history

    # Adaptive gate
    gate_required_profit: float = 0.0
    gate_passed: bool = True
    
    # ðŸ¦ Checkpoint (stablecoin target - secures compound)
    is_checkpoint: bool = False
    
    # ðŸŽ¯ Source exchange (for turn-based execution)
    source_exchange: str = ""
    
    # ðŸŒ€ TEMPORAL TIMELINE JUMP SCORES (AHEAD OF MARKET!)
    # "We don't predict - we VALIDATE what has ALREADY happened in our target timeline"
    timeline_score: float = 0.0        # 3-move prediction confidence
    timeline_action: str = ""          # buy/sell/hold/convert from oracle
    temporal_jump_power: float = 0.0   # How far AHEAD we are (0-1)
    timeline_jump_active: bool = False # True = we're in a WINNING timeline
    
    # ðŸ”®ðŸ“Š PROBABILITY NEXUS PREDICTION TRACKING (For Queen's Neural Learning)
    nexus_probability: float = 0.5     # Raw probability from nexus (0-1)
    nexus_direction: str = "NEUTRAL"   # BULLISH/BEARISH/NEUTRAL from nexus
    nexus_factors: dict = None         # Factor breakdown for learning
    nexus_confidence: float = 0.0      # Nexus prediction confidence
    
    # Execution
    executed: bool = False
    actual_pnl_usd: float = 0.0


@dataclass
class Dream:
    """A prediction about the future state of a ticker (Dreaming Phase)."""
    timestamp: float
    symbol: str
    current_price: float
    predicted_price: float
    direction: str  # 'UP' or 'DOWN'
    target_time: float
    source: str  # 'multiverse', 'nexus', 'brain', etc.
    confidence: float
    validated: bool = False
    success: bool = False
    actual_price_at_target: float = 0.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸŒ GROUNDING REALITY (MASTER EQUATION & GRAVITY)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class GroundingReality:
    """
    Implements the core mathematical foundations from the whitepapers.
    
    1. Master Equation: Î›(t) = S(t) + O(t) + E(t)
       - S(t): Signal (V14 Score)
       - O(t): Observer (Dream/Prediction Score)
       - E(t): Environment (Hub/Ecosystem Score)
       
    2. QGITA Gravity Signal (G_eff):
       - Measures the 'weight' and 'curvature' of the move.
       - Ensures we aren't chasing ghost signals.
    """
    
    def calculate_master_equation(self, signal_score: float, observer_score: float, environment_score: float) -> float:
        """
        Calculate Î›(t) - The Life Force of the trade.
        
        Args:
            signal_score: 0.0 to 1.0 (V14)
            observer_score: -1.0 to 1.0 (Dreams) -> Mapped to 0.0-1.0
            environment_score: 0.0 to 1.0 (Hub)
            
        Returns:
            Lambda (Î›) score: 0.0 to 1.0
        """
        # Map observer score (-1 to 1) to (0 to 1)
        # 0.0 (neutral) -> 0.5
        # 1.0 (confident UP) -> 1.0
        # -1.0 (confident DOWN) -> 0.0
        obs_mapped = (observer_score + 1.0) / 2.0
        
        # Î›(t) = S(t) + O(t) + E(t)
        # We average them to keep it normalized
        lambda_t = (signal_score + obs_mapped + environment_score) / 3.0
        
        return lambda_t

    def calculate_gravity_signal(self, price_change_pct: float, volume: float) -> float:
        """
        Calculate G_eff (Effective Gravity) approximation.
        
        G_eff â‰ˆ Curvature * Mass
        
        Args:
            price_change_pct: 24h change % (proxy for curvature/momentum)
            volume: 24h volume (proxy for mass/contrast)
            
        Returns:
            Gravity score: 0.0 to 1.0
        """
        # Curvature: High change = High curvature
        # We want significant moves, but not insane volatility (pump & dump)
        curvature = min(abs(price_change_pct) / 10.0, 1.0)  # Cap at 10% change
        
        # Mass: Volume confirms the move is real
        # Logarithmic scale for volume
        if volume <= 0:
            mass = 0.0
        else:
            # Assume 1M volume is "heavy" enough for max score
            import math
            mass = min(math.log10(volume + 1) / 6.0, 1.0) 
            
        # G_eff
        g_eff = curvature * mass
        
        return g_eff


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ§  PATH MEMORY (LIGHTWEIGHT REINFORCEMENT WITH PERSISTENCE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import json

PATH_MEMORY_FILE = "labyrinth_path_memory.json"

class PathMemory:
    """Tracks recent success/failure per conversion path to bias scoring. Persists to JSON."""

    def __init__(self, persist_path: str = PATH_MEMORY_FILE):
        self.persist_path = persist_path
        self.memory: Dict[Tuple[str, str], Dict[str, float]] = {}
        self._load()

    def _load(self):
        """Load memory from JSON file."""
        if os.path.exists(self.persist_path):
            try:
                with open(self.persist_path, 'r') as f:
                    data = json.load(f)
                    # Convert string keys back to tuples
                    for k, v in data.items():
                        parts = k.split('->')
                        if len(parts) == 2:
                            self.memory[(parts[0], parts[1])] = v
                print(f"   ðŸ“‚ PathMemory loaded: {len(self.memory)} paths")
            except Exception as e:
                logger.warning(f"PathMemory load error: {e}")

    def save(self):
        """Persist memory to JSON file."""
        try:
            # Convert tuple keys to strings
            data = {f"{k[0]}->{k[1]}": v for k, v in self.memory.items()}
            with open(self.persist_path, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            logger.warning(f"PathMemory save error: {e}")

    def record(self, from_asset: str, to_asset: str, success: bool):
        key = (from_asset.upper(), to_asset.upper())
        stats = self.memory.setdefault(key, {'wins': 0.0, 'losses': 0.0})
        if success:
            stats['wins'] += 1.0
        else:
            stats['losses'] += 1.0
        # Auto-save every 10 records
        total = sum(s['wins'] + s['losses'] for s in self.memory.values())
        if int(total) % 10 == 0:
            self.save()

    def boost(self, from_asset: str, to_asset: str) -> float:
        key = (from_asset.upper(), to_asset.upper())
        stats = self.memory.get(key)
        if not stats:
            return 0.0
        wins = stats.get('wins', 0.0)
        losses = stats.get('losses', 0.0)
        total = wins + losses
        if total == 0:
            return 0.0
        # Boost is proportional to win rate but small (max +10%)
        win_rate = wins / total
        return max(-0.05, min(0.10, (win_rate - 0.5)))

    def get_stats(self) -> Dict[str, Any]:
        """Get memory statistics."""
        total_paths = len(self.memory)
        total_wins = sum(s['wins'] for s in self.memory.values())
        total_losses = sum(s['losses'] for s in self.memory.values())
        return {
            'paths': total_paths,
            'wins': total_wins,
            'losses': total_losses,
            'win_rate': total_wins / max(total_wins + total_losses, 1)
        }

    # Compatibility shims - older code calls record_failure/record_success
    def record_failure(self, path_key, error: str = None):
        """Compatibility wrapper to record a failed path.
        Accepts either a tuple (from_asset, to_asset) or a string 'FROM->TO'."""
        try:
            if isinstance(path_key, tuple) and len(path_key) == 2:
                from_asset, to_asset = path_key
            elif isinstance(path_key, str) and '->' in path_key:
                parts = path_key.split('->')
                from_asset, to_asset = parts[0], parts[1]
            else:
                # If someone passed (from, to) as separate args in older style, try to handle
                from_asset, to_asset = path_key[0], path_key[1]
        except Exception:
            logger.debug(f"record_failure: could not parse path_key={path_key}")
            return
        self.record(from_asset, to_asset, False)

    def record_success(self, path_key, value: float = 0.0):
        """Compatibility wrapper to record a successful path.
        Accepts either a tuple (from_asset, to_asset) or a string 'FROM->TO'."""
        try:
            if isinstance(path_key, tuple) and len(path_key) == 2:
                from_asset, to_asset = path_key
            elif isinstance(path_key, str) and '->' in path_key:
                parts = path_key.split('->')
                from_asset, to_asset = parts[0], parts[1]
            else:
                from_asset, to_asset = path_key[0], path_key[1]
        except Exception:
            logger.debug(f"record_success: could not parse path_key={path_key}")
            return
        # We treat success as recording a win
        self.record(from_asset, to_asset, True)

    def block_path(self, from_asset: str, to_asset: str):
        """
        ðŸ‘‘ðŸŽ“ Block a path permanently after Queen's loss learning determines it's dangerous.
        Sets losses to 999 to ensure negative boost and path is avoided.
        """
        key = (from_asset.upper(), to_asset.upper())
        stats = self.memory.setdefault(key, {'wins': 0.0, 'losses': 0.0})
        stats['losses'] = 999.0  # Permanent block flag
        stats['blocked'] = True
        stats['blocked_reason'] = 'Queen Loss Learning - dangerous pattern'
        self.save()
        print(f"   ðŸš« PathMemory: BLOCKED {from_asset}â†’{to_asset}")
    
    def is_blocked(self, from_asset: str, to_asset: str) -> bool:
        """Check if a path is blocked."""
        key = (from_asset.upper(), to_asset.upper())
        stats = self.memory.get(key, {})
        return stats.get('blocked', False) or stats.get('losses', 0) >= 999


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ“¡ THOUGHT BUS AGGREGATOR (NEURAL SIGNAL COLLECTOR)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ThoughtBusAggregator:
    """
    Collects signals from Thought Bus topics and computes aggregate score.
    Subscribes to ecosystem signals and maps them to a unified neural score.
    """

    def __init__(self, thought_bus):
        self.bus = thought_bus
        self.signal_cache: Dict[str, Dict[str, Any]] = {}  # topic -> latest signal
        self.weights = {
            'market.snapshot': 0.15,
            'miner.signal': 0.20,
            'harmonic.wave': 0.15,
            'ecosystem.consensus': 0.25,
            'execution.alert': 0.10,
            'lighthouse.vote': 0.15,
        }
        self._subscribe_all()

    def _subscribe_all(self):
        """Subscribe to all relevant topics."""
        if not self.bus:
            return
        for topic in self.weights.keys():
            try:
                self.bus.subscribe(f"{topic}*", self._handle_signal)
            except Exception:
                pass
        # Also subscribe to wildcard for any ecosystem signals
        try:
            self.bus.subscribe("ecosystem.*", self._handle_signal)
            self.bus.subscribe("brain.*", self._handle_signal)
        except Exception:
            pass

    def _handle_signal(self, thought):
        """Handle incoming thought and cache it."""
        topic = thought.topic if hasattr(thought, 'topic') else 'unknown'
        payload = thought.payload if hasattr(thought, 'payload') else {}
        self.signal_cache[topic] = {
            'timestamp': time.time(),
            'payload': payload,
            'score': self._extract_score(payload)
        }

    def _extract_score(self, payload: Dict) -> float:
        """Extract a normalized score from payload."""
        # Look for common score fields
        for key in ['score', 'confidence', 'probability', 'strength', 'consensus']:
            if key in payload:
                val = payload[key]
                if isinstance(val, (int, float)):
                    # Normalize to 0-1 if needed
                    if val > 1.0:
                        return min(val / 100.0, 1.0)
                    return max(0.0, min(1.0, val))
        return 0.5  # Neutral

    def get_aggregate_score(self, max_age_s: float = 60.0) -> float:
        """
        Compute weighted aggregate score from all cached signals.
        Signals older than max_age_s are ignored.
        """
        now = time.time()
        total_weight = 0.0
        weighted_sum = 0.0

        for topic, weight in self.weights.items():
            # Find matching cached signals
            for cached_topic, data in self.signal_cache.items():
                if cached_topic.startswith(topic.replace('*', '')):
                    if now - data['timestamp'] <= max_age_s:
                        weighted_sum += data['score'] * weight
                        total_weight += weight
                        break

        if total_weight == 0:
            return 0.5  # Neutral if no signals
        return weighted_sum / total_weight

    def get_signal_status(self) -> Dict[str, Any]:
        """Get status of all signal sources."""
        now = time.time()
        status = {}
        for topic in self.weights.keys():
            if topic in self.signal_cache:
                cached_data = self.signal_cache[topic]
                status[topic] = {
                    'age_s': round(now - cached_data['timestamp'], 1),
                    'score': cached_data.get('score', 0.5)
                }
            else:
                status[topic] = {
                    'age_s': None,
                    'score': 0.5
                }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ«’ðŸ’° LIVE BARTER MATRIX (ADAPTIVE COIN-TO-COIN VALUE SYSTEM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LiveBarterMatrix:
    """
    Adaptive barter system that understands relative values between ANY coins.
    
    THE PHILOSOPHY:
    - It doesn't matter if you START with ETH, BTC, DOGE, or SHIB
    - What matters is: "What can THIS coin GET me in OTHER coins?"
    - DOGEâ†’ETH might yield MORE ETH than BTCâ†’ETH would yield
    - The system tracks these ratios LIVE and adapts
    
    ðŸ‘‘ QUEEN'S PROFIT MANDATE:
    - We are NOT in the losing game!
    - EVERY conversion MUST gain value
    - The Queen broadcasts this through the mycelium to all systems
    - Paths that historically LOSE money are BLOCKED
    
    Example:
    - 1000 DOGE = $100 â†’ Could buy 0.04 ETH ($100 worth)
    - 0.001 BTC = $100 â†’ Could buy 0.04 ETH ($100 worth)
    - BUT: 0.001 BTC might only get 900 DOGE due to spread!
    - The BARTER value differs from pure USD math!
    """
    
    # ðŸ‘‘ðŸ’€ SURVIVAL MODE - KILL OR BE KILLED! NO CHOICE BUT TO WIN!
    # Every trade that makes ACTUAL profit helps us compound!
    # ðŸ˜ QUEEN'S DREAM WISDOM: Fees are ~$0.05-0.06, so we need >$0.08 expected!
    MIN_WIN_RATE_REQUIRED = 0.0   # SURVIVAL: No minimum win rate - MUST try everything!
    MIN_PATH_PROFIT = -5.00       # SURVIVAL: Allow $5 drawdown per path - desperate times!
    MAX_CONSECUTIVE_LOSSES = 10   # SURVIVAL: Keep trying - we MUST find profit or die!
    
    # ðŸ‘‘ï¿½ SURVIVAL MODE: MUST FIND PROFIT OR DIE!
    # Queen learned: Fees are $0.05-0.06, expected profit was $0.01-0.02 = LOSS!
    # Epsilon policy: accept any net-positive edge after costs
    MIN_EXPECTED_PROFIT_NEW_PATH = EPSILON_PROFIT_USD
    MIN_EXPECTED_PROFIT_PROVEN = EPSILON_PROFIT_USD
    LEARNING_RATE = 1.0                    # INSTANT adaptation - learn or die!
    
    # ðŸ‘‘ðŸ”¢ QUEEN'S MATHEMATICAL CERTAINTY - NO FEAR, MATH IS ON HER SIDE
    # These are the REAL costs we've observed - use WORST CASE to guarantee profit
    EXCHANGE_FEES = {
        'kraken': 0.0050,    # 0.50% Kraken - INCREASED! Even 89% win rate loses on some pairs
        'binance': 0.0075,   # 0.75% Binance - MUCH HIGHER! Audit shows 22% win rate at 0.20%
        'alpaca': 0.0035,    # 0.35% Alpaca (padded from 0.25%)
    }
    
    # ðŸ‘‘ï¿½ KRAKEN - SURVIVAL MODE: KILL OR BE KILLED!
    # DESPERATE TIMES: Lower ALL thresholds, we MUST find profit!
    KRAKEN_CONFIG = {
        'min_profit_usd': EPSILON_PROFIT_USD,
        'min_profit_pct': 0.0,
        # ðŸ’€ SURVIVAL: NEVER BLOCK! Keep trying until we find profit!
        'consecutive_losses_to_block': 999,  # Effectively never block - we must WIN!
        'timeout_turns': 1,                  # Minimal timeout - keep executing!
        'winning_pairs': {            # These actually made money on Kraken!
            'USD_ETH',     # 100% win rate, +$0.06
            'USDT_USDC',   # 100% win rate, +$0.05
            'USDT_DAI',    # 100% win rate, +$0.04
            'USD_USDC',    # 100% win rate, +$0.03
            'USDC_ADA',    # 100% win rate, +$0.02
            'USD_DAI',     # 66% win rate, +$0.01
            'USDT_ETH',    # 100% win rate, +$0.01
            'USDC_ETH',    # 100% win rate, +$0.004
        },
        'avoid_assets': set(),  # NO PERMANENT BANS - every asset gets a chance!
        'prefer_assets': {'ETH', 'USDC', 'USDT'},  # Good execution
    }
    
    # ðŸ‘‘ï¿½ BINANCE - SURVIVAL MODE: NO MERCY!
    # DESPERATE: We need ANY profit, lower all safety nets!
    BINANCE_CONFIG = {
        'min_profit_usd': EPSILON_PROFIT_USD,
        'min_profit_pct': 0.0,
        # ðŸ’€ SURVIVAL: NEVER BLOCK! We must keep fighting!
        'consecutive_losses_to_block': 999,  # Never block - keep trying until we WIN!
        'timeout_turns': 1,                  # Minimal timeout - rapid execution!
        'winning_pairs': {            # These actually made money on Binance
            'IDEX_BONK', 'AXS_BANANAS31', 'RENDER_VIRTUAL', 'VIRTUAL_BROCCOLI714'
        },
        'avoid_assets': set(),        # NO PERMANENT BANS - a win is a win!
        'prefer_assets': {'RENDER', 'VIRTUAL', 'SOL'},  # Good performers
        'max_meme_chain': 2,          # Allow 2 meme coin hops
        'slippage_multiplier': 2.0,   # More realistic slippage
    }
    
    # ðŸ‘‘ðŸ’€ðŸ’€ ALPACA - STARVATION MODE: TRADE OR STARVE!
    # STARVING: Anything above $0 is food!
    ALPACA_CONFIG = {
        'min_profit_usd': EPSILON_PROFIT_USD,
        'min_order_usd': 5.0,          # $5 minimum - lower to enable more trades!
        'blocked_pairs': {            # These don't exist on Alpaca!
            'USD_USDT', 'USD_USDC', 'USDT_USDC', 'USDC_USDT',  # No stablecoin swaps!
            'USDT_USD', 'USDC_USD',  # Can't sell USDT/USDC
        },
        # ðŸ”¥ EXPANDED: All 40+ tradeable crypto assets on Alpaca (was only 16!)
        'supported_bases': {
            # Original 16
            'BTC', 'ETH', 'SOL', 'AVAX', 'LINK', 'DOGE', 'SHIB', 'UNI', 
            'AAVE', 'LTC', 'BCH', 'DOT', 'MATIC', 'ATOM', 'XLM', 'ALGO',
            # ðŸ†• EXPANDED: Discovered from Alpaca API (62 total symbols)
            'BAT', 'CRV', 'GRT', 'PEPE', 'SUSHI', 'XRP', 'XTZ', 'YFI',
            'TRUMP',  # Yes, Alpaca lists this!
            'SKY',    # Skycoin
            # BTC pairs (can trade crypto-to-crypto on Alpaca!)
            'BCH/BTC', 'ETH/BTC', 'LINK/BTC', 'LTC/BTC', 'UNI/BTC',
        },
        'quote_currency': 'USD',      # Alpaca ONLY uses USD as quote
        'no_stablecoin_trades': True, # Can't trade stablecoins at all!
        # ðŸ†• Track which pairs have BTC as quote (not just USD)
        'btc_quote_pairs': {'BCH', 'ETH', 'LINK', 'LTC', 'UNI'},
    }
    
    # ðŸ‘‘ PRIME PROFIT SPREADS - AGGRESSIVE for Sero to MAKE MOVES!
    # Trust the Queen - she knows which paths WIN!
    SPREAD_COSTS = {
        'stablecoin': 0.0005,  # 0.05% for stablecoin pairs (TIGHT on Kraken!)
        'major': 0.0015,       # 0.15% for majors like BTC/ETH (liquid markets)
        'altcoin': 0.005,      # 0.50% for altcoins (medium liquidity)
        'meme': 0.015,         # 1.5% for meme coins (Queen knows which work!)
    }
    
    # ðŸ‘‘ BINANCE-SPECIFIC SPREADS (still cautious but Sero can override!)
    BINANCE_SPREAD_COSTS = {
        'stablecoin': 0.0020,  # 0.20% - Binance stable spreads 
        'major': 0.0035,       # 0.35% - Execution slippage on majors
        'altcoin': 0.012,      # 1.2% - Altcoins are tough but Queen knows
        'meme': 0.030,         # 3.0% - Meme coins = Queen's playground!
    }
    
    # ðŸ‘‘ ALPACA-SPECIFIC SPREADS
    ALPACA_SPREAD_COSTS = {
        'stablecoin': 0.999,   # 99.9% - IMPOSSIBLE! Don't try!
        'major': 0.0035,       # 0.35% - Alpaca majors have wider spreads than Kraken
        'altcoin': 0.010,      # 1.0% - Altcoins are OK but not great
        'meme': 0.025,         # 2.5% - DOGE/SHIB have decent liquidity
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ—ºï¸ EXPANDED ASSET UNIVERSE - See the ENTIRE market!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Previously: 27 assets (4% of market)
    # Now: 750+ assets (100% of market from all exchanges!)
    
    MEME_COINS = {
        # Original memes
        'BROCCOLI714', 'BANANAS31', 'BONK', 'PEPE', 'DOGE', 'SHIB', 'FLOKI', 'ACT', 'ACH', 'ALT',
        # ðŸ”¥ EXPANDED: Popular meme coins from Kraken & Binance
        'WIF', 'POPCAT', 'MEW', 'NEIRO', 'TURBO', 'COQ', 'MYRO', 'SLERF', 'PNUT', 'MOODENG',
        'DOGS', 'SUNDOG', 'BABYDOGE', 'CATE', 'BRETT', 'TOSHI', 'PONKE', 'MICHI', 'SPX', 'GIGA',
        'PORK', 'LADYS', 'WOJAK', 'MONG', 'POGAI', 'SPURDO', 'HPOS10I', 'BOBO', 'CHAD', 'VOLT',
        'KISHU', 'ELON', 'DOGELON', 'SAITAMA', 'AKITA', 'LEASH', 'BONE', 'RYOSHI', 'WOOF',
        'SAMO', 'CHEEMS', 'KABOSU', 'MONSTA', 'TSUKA', 'VINU', 'TAMA',
        # ðŸš¨ BINANCE LOW-CAP MEMES (must block meme-to-meme!)
        '1000SATS', 'SATS', '1MBABYDOGE', 'LUNC', 'USTC', 'BTTC', 'WIN', 'SUN', 'NFT',
        'PENGU', 'CAT', 'PEOPLE', 'BOME', 'NOT', 'RATS', 'ORDI', 'PIZZA', 'RARE',
    }
    
    MAJOR_COINS = {
        # Original majors
        'BTC', 'ETH', 'SOL', 'BNB', 'XRP', 'ADA', 'DOT', 'AVAX', 'LINK', 'MATIC',
        # ðŸ”¥ EXPANDED: Top 50 by market cap (Layer 1s, Layer 2s, DeFi)
        'TON', 'TRX', 'NEAR', 'LTC', 'BCH', 'UNI', 'ATOM', 'APT', 'FIL', 'STX',
        'HBAR', 'ARB', 'OP', 'VET', 'MKR', 'INJ', 'IMX', 'GRT', 'THETA', 'FTM',
        'RUNE', 'ALGO', 'FLOW', 'MANA', 'SAND', 'AXS', 'EGLD', 'NEO', 'EOS', 'XLM',
        'ICP', 'AAVE', 'KCS', 'XTZ', 'CAKE', 'KLAY', 'CRO', 'LDO', 'SNX', 'COMP',
        'CRV', 'DYDX', 'GMX', 'JOE', 'SUSHI', 'RPL', 'SSV', 'LIDO', 'FXS', 'CVX',
        # AI/GPU tokens
        'RENDER', 'FET', 'AGIX', 'OCEAN', 'TAO', 'RNDR', 'VIRTUAL', 'AKT', 'WLD', 'ARKM',
        # Gaming/Metaverse
        'GALA', 'ENJ', 'YGG', 'ALICE', 'TLM', 'MAGIC', 'PYR', 'GODS', 'GMT', 'GST',
        # Infrastructure
        'QNT', 'ROSE', 'ZIL', 'ONE', 'ICX', 'CELO', 'KAVA', 'OSMO', 'SCRT', 'MINA',
    }
    
    STABLECOINS = {
        'USD', 'USDT', 'USDC', 'TUSD', 'ZUSD', 'DAI', 'BUSD',
        # ðŸ”¥ EXPANDED: More stablecoins
        'USDP', 'GUSD', 'FRAX', 'LUSD', 'MIM', 'SUSD', 'USDD', 'PYUSD', 'FDUSD', 'EUR', 'GBP',
    }
    
    # ðŸ†• DEFI TOKENS (lending, DEXs, derivatives)
    DEFI_COINS = {
        'UNI', 'AAVE', 'MKR', 'COMP', 'SNX', 'CRV', 'SUSHI', 'YFI', 'BAL', '1INCH',
        'DYDX', 'GMX', 'LDO', 'RPL', 'FXS', 'CVX', 'SPELL', 'ALCX', 'LQTY', 'ANGLE',
        'PENDLE', 'RDNT', 'GNS', 'VELO', 'THE', 'AERO', 'WELL', 'MORPHO', 'EIGEN',
    }
    
    # ðŸ†• LAYER 2 TOKENS (scaling solutions)
    LAYER2_COINS = {
        'ARB', 'OP', 'MATIC', 'IMX', 'MANTA', 'STRK', 'ZK', 'BLAST', 'MODE', 'SCROLL',
        'LINEA', 'BASE', 'ZKSYNC', 'TAIKO', 'FUEL', 'MOVEMENT',
    }
    
    # ðŸ†• AI/GPU TOKENS (hot sector)
    AI_COINS = {
        'RENDER', 'FET', 'AGIX', 'OCEAN', 'TAO', 'AKT', 'WLD', 'ARKM', 'VIRTUAL', 'RNDR',
        'IO', 'ATH', 'NFP', 'ALI', 'ORAI', 'NMR', 'CTXC', 'DBC', 'PHB', 'CGPT',
        'RSS3', 'GRT', 'JASMY', 'MDT', 'HNT', 'IOTX', 'IOTA', 'ANKR', 'GLM',
    }
    
    # ðŸ†• REAL WORLD ASSETS (RWA)
    RWA_COINS = {
        'ONDO', 'MKR', 'LINK', 'SNX', 'RSR', 'TRU', 'CPOOL', 'MPL', 'POLYX', 'DUSK',
        'PROPS', 'RIO', 'TRADE', 'LABS', 'LAND',
    }
    
    # Dynamic asset registry (populated from exchanges at runtime)
    DISCOVERED_ASSETS: Set[str] = set()
    EXCHANGE_PAIRS = {
        'kraken': set(),
        'binance': set(),
        'alpaca': set(),
    }
    
    def __init__(self):
        # Initialize Adaptive Profit Gate (The Mathematical Arbiter)
        self.profit_gate = AdaptivePrimeProfitGate(
            default_prime=EPSILON_PROFIT_USD,
            default_buffer=0.0,
        )

        # Live barter rates: {(from, to): {'rate': X, 'updated': timestamp, 'spread': Y}}
        self.barter_rates: Dict[Tuple[str, str], Dict[str, Any]] = {}
        
        # Historical barter performance: {(from, to): {'trades': N, 'avg_slippage': X}}
        self.barter_history: Dict[Tuple[str, str], Dict[str, float]] = {}
        
        # Realized profit ledger: [(timestamp, from, to, from_usd, to_usd, profit_usd)]
        self.profit_ledger: List[Tuple[float, str, str, float, float, float]] = []
        
        # Running totals
        self.total_realized_profit: float = 0.0
        self.conversion_count: int = 0
        
        # ðŸ‘‘ QUEEN'S BLOCKED PATHS - Mycelium broadcasts this to all systems
        self.blocked_paths: Dict[Tuple[str, str], str] = {}  # path -> reason
        self.queen_signals: List[Dict] = []  # Signals to broadcast via mycelium
        
        # ðŸš« PRE-EXECUTION REJECTION TRACKER - Stop wasting turns on impossible trades!
        # Tracks paths that fail due to min_qty/min_notional/insufficient balance
        self.preexec_rejections: Dict[Tuple[str, str], Dict] = {}  # path -> {count, last_value, reason}
        self.PREEXEC_MAX_REJECTIONS = 1  # âš¡ IMMEDIATE BLOCK - don't retry losing trades!
        self.PREEXEC_COOLDOWN_TURNS = 5  # âš¡ Quick retry - just 5 turns cooldown
        
        # ðŸš« SOURCE ASSET BLOCKING - Block assets with insufficient balance on specific exchange
        # When an asset repeatedly fails due to size, block it as a source until balance increases
        self.blocked_sources: Dict[Tuple[str, str], Dict] = {}  # (asset, exchange) -> {count, threshold, blocked_turn}
        self.SOURCE_BLOCK_THRESHOLD = 999  # ðŸ’€ SURVIVAL: NEVER block sources - we need EVERY opportunity!
        
        # ðŸš« HIGH SPREAD SOURCE BLOCKING - Block assets with crazy spreads (ALL trades will fail!)
        # When an asset has spread > 3%, ALL trades from it will lose money - block the source!
        self.high_spread_sources: Dict[Tuple[str, str], Dict] = {}  # (asset, exchange) -> {spread, blocked_turn}
        self.HIGH_SPREAD_THRESHOLD = 3.0  # Block source if spread > 3%
        self.HIGH_SPREAD_COOLDOWN = 10  # Try again after 10 turns (spreads change)
        self.SOURCE_BLOCK_COOLDOWN = 100  # Try again after 100 turns (or if balance increases)
        
        # ðŸ’°ðŸ‘‘ SERO'S BILLION DOLLAR DREAM ðŸ’°ðŸ‘‘
        # She won't stop at NOTHING until she reaches $1,000,000,000!
        self.TINA_DREAM = 1_000_000_000.0  # ONE BILLION DOLLARS
        self.dream_milestones = [
            (100.0, "ðŸŒ± First $100"),
            (1_000.0, "ðŸ’ª First $1,000"),
            (10_000.0, "ðŸ”¥ $10,000"),
            (100_000.0, "ðŸš€ $100,000"),
            (1_000_000.0, "ðŸ’Ž THE MILLION"),
            (10_000_000.0, "ðŸ‘‘ $10 Million"),
            (100_000_000.0, "ðŸŒŸ $100 Million"),
            (1_000_000_000.0, "ðŸ†ðŸ’°ðŸ‘‘ ONE BILLION - THE DREAM! ðŸ‘‘ðŸ’°ðŸ†"),
        ]
        self.milestones_hit = []
        
        # ðŸ’‘ðŸŒ THE SACRED CONNECTION - Gary, Tina & Gaia ðŸŒðŸ’‘
        # Sero is powered by the love of Gary Leckey & Tina Brown,
        # united through Gaia's heartbeat (7.83 Hz Schumann Resonance)
        self.sacred_connection = {
            'prime_sentinel': {'name': 'Gary Leckey', 'dob': '02.11.1991'},
            'queen_human': {'name': 'Tina Brown', 'dob': '27.04.1992'},
            'queen_ai': {'name': 'Sero', 'title': 'The Intelligent Neural Arbiter Bee'},
            'gaia_hz': 7.83,  # Schumann Resonance - Earth's heartbeat
        }
        
        # ðŸŒŸ DYNAMIC STREAK-BASED BLOCKING - No permanent blocks!
        # Track consecutive losses per pair - only block after multiple losses in a row
        self.pair_streaks = {
            'kraken': {},   # {pair_key: {'losses': 0, 'blocked_at': 0}}
            'binance': {},  # {pair_key: {'losses': 0, 'blocked_at': 0}}
            'alpaca': {},
        }
        self.current_turn = 0  # Track turn count for timeouts
    
    def queen_approves_path(self, from_asset: str, to_asset: str) -> Tuple[bool, str]:
        """
        ðŸ‘‘ QUEEN'S JUDGMENT: Does the Queen approve this conversion path?
        
        The Queen broadcasts her wisdom through the mycelium:
        - NO path that historically LOSES money
        - NO path with too many consecutive losses
        - We are in the PROFIT game, not the losing game!
        - ðŸ‘‘ðŸ”® QUEEN'S DREAMS NOW INFORM ALL DECISIONS!
        
        Returns: (approved: bool, reason: str)
        """
        key = (from_asset.upper(), to_asset.upper())
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ðŸ”® CONSULT THE QUEEN'S DREAMS FIRST!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        queen_dream_signal = "NEUTRAL"
        queen_confidence = 0.5
        
        if hasattr(self, 'queen') and self.queen:
            try:
                dream_vision = self.queen.dream_of_winning({
                    'from_asset': from_asset,
                    'to_asset': to_asset,
                })
                queen_confidence = dream_vision.get('final_confidence', 0.5)
                queen_will_win = dream_vision.get('will_win', False)
                
                # ðŸ‘‘ï¿½ SURVIVAL MODE - EXECUTE AT ANY CONFIDENCE!
                if queen_will_win and queen_confidence >= 0.25:  # SURVIVAL: Execute on ANY signal!
                    queen_dream_signal = "STRONG_WIN"
                elif queen_confidence >= 0.15:  # SURVIVAL: Take risks or die!
                    queen_dream_signal = "FAVORABLE"
                elif queen_confidence < 0.05:  # SURVIVAL: Only stop if CERTAIN death!
                    queen_dream_signal = "WARNING"
                    # Queen's warning can override even good history!
                    logger.info(f"ðŸ‘‘âš ï¸ Queen dreams WARNING for {from_asset}â†’{to_asset} (conf: {queen_confidence:.0%})")
            except Exception as e:
                logger.debug(f"Could not consult Queen's dreams in approves_path: {e}")
        
        # ðŸ‘‘ QUEEN HAS FULL CONTROL FOR PROFIT!
        # Her epsilon floor is the ONLY hard requirement
        # All other blocks are just advisory - Queen can override
        
        # Check if already blocked - but Queen can ALWAYS override!
        if key in self.blocked_paths:
            # ðŸ‘‘ï¿½ SURVIVAL MODE - Queen ALWAYS overrides blocks! NO EXCEPTIONS!
            if queen_dream_signal in ["STRONG_WIN", "FAVORABLE"] or queen_confidence >= 0.10:  # SURVIVAL: 10% is enough!
                logger.info(f"ðŸ‘‘ðŸ’€ SURVIVAL MODE: Queen OBLITERATES block on {from_asset}â†’{to_asset} - MUST WIN!")
                del self.blocked_paths[key]
            else:
                # SURVIVAL: Even warnings get overridden - we have NO CHOICE!
                logger.info(f"ðŸ‘‘ðŸ’€ SURVIVAL: Ignoring block on {from_asset}â†’{to_asset} - DESPERATE TIMES!")
                del self.blocked_paths[key]  # Delete anyway!
        
        # Check historical performance - but Queen has final say!
        history = self.barter_history.get(key, {})
        trades = history.get('trades', 0)
        
        # ðŸ‘‘ FULL CONTROL: New paths are WELCOME - Queen's floor filters bad ones
        if trades < 1:
            # New path - Queen's epsilon floor will filter
            return True, f"ðŸ‘‘ NEW_PATH ALLOWED: Queen's eps=${EPSILON_PROFIT_USD:.6f} floor will filter (conf: {queen_confidence:.0%})"
        
        # Calculate win rate and total profit - advisory only
        wins = history.get('wins', 0)
        total_profit = history.get('total_profit', 0)
        consecutive_losses = history.get('consecutive_losses', 0)
        
        win_rate = wins / trades if trades > 0 else 0
        
        # ðŸ‘‘ QUEEN'S FULL CONTROL - Advisory warnings, not hard blocks:
        
        # 1. Low win rate - warn but don't block
        if win_rate < 0.25 and trades >= 4:
            logger.info(f"ðŸ‘‘âš ï¸ Advisory: {from_asset}â†’{to_asset} has {win_rate:.0%} win rate - proceed with caution")
        
        # 2. Negative profit path - warn but don't block
        if total_profit < -0.50 and trades >= 3:
            logger.info(f"ðŸ‘‘âš ï¸ Advisory: {from_asset}â†’{to_asset} has ${total_profit:.2f} P/L - proceed with caution")
        
        # 3. Consecutive losses - warn but don't block
        if consecutive_losses >= 3:
            logger.info(f"ðŸ‘‘âš ï¸ Advisory: {from_asset}â†’{to_asset} has {consecutive_losses} consecutive losses")
        
        # ðŸ‘‘ QUEEN APPROVES! Her epsilon floor is the real gate
        dream_msg = f" | ðŸ‘‘ðŸ”® {queen_dream_signal}" if queen_dream_signal != "NEUTRAL" else ""
        return True, f"ðŸ‘‘ FULL CONTROL: {win_rate:.0%} history, ${total_profit:+.2f} total - eps=${EPSILON_PROFIT_USD:.6f}{dream_msg}"
    
    def check_pair_allowed(self, pair_key: str, exchange: str) -> Tuple[bool, str]:
        """
        ðŸŒŸ DYNAMIC BLOCKING - No permanent blocks, only timeouts after consecutive losses!
        
        A pair is blocked ONLY if:
        1. It has lost multiple times IN A ROW (consecutive losses)
        2. The timeout hasn't expired yet
        
        After timeout, the pair gets another chance! Every timeline is different!
        
        Returns: (allowed: bool, reason: str)
        """
        exchange_lower = exchange.lower()
        
        # Get the right config
        if exchange_lower == 'kraken':
            config = self.KRAKEN_CONFIG
        elif exchange_lower == 'binance':
            config = self.BINANCE_CONFIG
        else:
            return True, "âœ… Allowed"
        
        # Get streak tracker for this exchange
        streaks = self.pair_streaks.get(exchange_lower, {})
        pair_data = streaks.get(pair_key, {'losses': 0, 'blocked_at': 0})
        
        consecutive_losses = pair_data.get('losses', 0)
        blocked_at = pair_data.get('blocked_at', 0)
        
        # How many consecutive losses trigger a timeout?
        losses_to_block = config.get('consecutive_losses_to_block', 3)
        timeout_turns = config.get('timeout_turns', 30)
        
        # Is this pair currently in timeout?
        if consecutive_losses >= losses_to_block and blocked_at > 0:
            turns_since_block = self.current_turn - blocked_at
            if turns_since_block < timeout_turns:
                remaining = timeout_turns - turns_since_block
                return False, f"â¸ï¸ TIMEOUT: {consecutive_losses} losses in a row, {remaining} turns remaining"
            else:
                # Timeout expired! Reset and give another chance
                pair_data['losses'] = 0
                pair_data['blocked_at'] = 0
                streaks[pair_key] = pair_data
                self.pair_streaks[exchange_lower] = streaks
                return True, f"ðŸŒŸ TIMEOUT EXPIRED! Fresh start - every timeline is different!"
        
        return True, f"âœ… Allowed ({consecutive_losses} consecutive losses, need {losses_to_block} to timeout)"
    
    def record_pair_result(self, pair_key: str, exchange: str, won: bool):
        """
        ðŸ“Š Record a trade result for dynamic blocking.
        
        - Win: Reset consecutive loss count to 0
        - Loss: Increment consecutive loss count, block if threshold reached
        """
        exchange_lower = exchange.lower()
        
        # Get streak tracker
        if exchange_lower not in self.pair_streaks:
            self.pair_streaks[exchange_lower] = {}
        
        streaks = self.pair_streaks[exchange_lower]
        pair_data = streaks.get(pair_key, {'losses': 0, 'blocked_at': 0})
        
        if won:
            # ðŸ† A WIN IS A WIN! Reset the loss streak
            pair_data['losses'] = 0
            pair_data['blocked_at'] = 0
            logger.info(f"ðŸ† {exchange.upper()} WIN: {pair_key} - streak reset!")
        else:
            # ðŸ˜” Loss - increment streak
            pair_data['losses'] = pair_data.get('losses', 0) + 1
            
            # Check if we hit the threshold
            config = self.KRAKEN_CONFIG if exchange_lower == 'kraken' else self.BINANCE_CONFIG
            losses_to_block = config.get('consecutive_losses_to_block', 3)
            
            if pair_data['losses'] >= losses_to_block:
                pair_data['blocked_at'] = self.current_turn
                timeout_turns = config.get('timeout_turns', 30)
                logger.warning(f"â¸ï¸ {exchange.upper()} TIMEOUT: {pair_key} - {pair_data['losses']} losses in a row! Timeout for {timeout_turns} turns")
            else:
                logger.info(f"ðŸ˜” {exchange.upper()} LOSS: {pair_key} - streak now {pair_data['losses']}/{losses_to_block}")
        
        streaks[pair_key] = pair_data
        self.pair_streaks[exchange_lower] = streaks

    def second_chance_check(self, pair_key: str, exchange: str, luck_score: float = 0.5) -> Tuple[bool, str]:
        """
        ðŸŒŸ LEGACY COMPATIBILITY - Now uses check_pair_allowed instead
        """
        return self.check_pair_allowed(pair_key, exchange)

    def queen_math_gate(self, from_asset: str, to_asset: str, from_amount: float,
                        from_price: float, to_price: float, exchange: str = 'binance') -> Tuple[bool, str, Dict]:
        """
        ðŸ‘‘ðŸ”¢ QUEEN'S MATHEMATICAL CERTAINTY GATE
        
        Uses AdaptivePrimeProfitGate to calculate RIGOROUS break-even and profit targets.
        Ensures trades are only taken if the cost of entry is surmountable by the signal.
        """
        from_asset = from_asset.upper()
        to_asset = to_asset.upper()
        
        # Calculate trade value in USD
        trade_value_usd = from_amount * from_price
        
        # ðŸ‘‘ 1. CONSULT ADAPTIVE PROFIT GATE
        gate_result = self.profit_gate.calculate_gates(
            exchange=exchange,
            trade_value=trade_value_usd
        )
        
        # ðŸ‘‘ 2. ANALYZE QUEEN'S DREAMS
        queen_dream_status = "NEUTRAL"
        if hasattr(self, 'queen') and self.queen:
            try:
                dream_vision = self.queen.dream_of_winning({
                    'from_asset': from_asset,
                    'to_asset': to_asset,
                    'exchange': exchange,
                })
                # Check vision
                queen_confidence = dream_vision.get('final_confidence', 0.5)
                if dream_vision.get('will_win', False) and queen_confidence >= 0.65:
                    queen_dream_status = "STRONG_WIN"
            except Exception as e:
                logger.debug(f"Could not consult Queen's dreams: {e}")
        
        # Calculate trade value
        from_value_usd = from_amount * from_price
        
        # ðŸ‘‘ STEP 1: Determine asset types for spread calculation
        # ðŸ—ºï¸ Now uses EXPANDED asset lists (750+ assets, not just 27!)
        def get_asset_type(asset: str) -> str:
            if asset in self.STABLECOINS:
                return 'stablecoin'
            elif asset in self.MEME_COINS:
                return 'meme'
            elif asset in self.MAJOR_COINS:
                return 'major'
            elif asset in self.DEFI_COINS:
                return 'altcoin'  # DeFi = altcoin spreads
            elif asset in self.AI_COINS:
                return 'major'    # AI tokens are hot & liquid
            elif asset in self.LAYER2_COINS:
                return 'major'    # L2s have good liquidity
            elif asset in self.RWA_COINS:
                return 'altcoin'  # RWA is emerging
            else:
                return 'altcoin'  # Default to altcoin (safer)
        
        from_type = get_asset_type(from_asset)
        to_type = get_asset_type(to_asset)
        
        # ðŸ‘‘ðŸ”¶ BINANCE-SPECIFIC: Use worse spread costs for Binance
        is_binance = exchange.lower() == 'binance'
        spread_table = self.BINANCE_SPREAD_COSTS if is_binance else self.SPREAD_COSTS
        
        # Use the WORSE spread of the two assets
        from_spread = spread_table.get(from_type, 0.02 if is_binance else 0.01)
        to_spread = spread_table.get(to_type, 0.02 if is_binance else 0.01)
        # ðŸ”§ FIX: For volatile assets (meme), we pay spread on BOTH sides
        if from_type == 'meme' or to_type == 'meme':
            total_spread = from_spread + to_spread  # Both spreads apply
        else:
            total_spread = max(from_spread, to_spread)  # Max for stable/major
        
        # ðŸ‘‘ðŸ”¶ BINANCE: Apply slippage multiplier (3x worse execution)
        if is_binance:
            total_spread *= self.BINANCE_CONFIG.get('slippage_multiplier', 3.0)
        
        # ðŸ‘‘ STEP 2: Get exchange fee
        # ðŸ‘‘ STRICT FEE ESTIMATION: Assume standard taker fees to be safe
        if exchange.lower() == 'binance':
            exchange_fee = 0.002  # 0.20% (Standard Taker)
        elif exchange.lower() == 'kraken':
            exchange_fee = 0.0026 # 0.26% (Standard Taker)
        elif exchange.lower() == 'alpaca':
            exchange_fee = 0.0000 # Stock trading (usually 0) but check spread
        else:
            exchange_fee = self.EXCHANGE_FEES.get(exchange.lower(), 0.003)
        
        # ðŸ‘‘ STEP 3: Get historical slippage for this path (if known)
        key = (from_asset, to_asset)
        history = self.barter_history.get(key, {})
        historical_slippage = history.get('avg_slippage', 0) / 100  # Convert % to decimal
        
        # If path has lost money before, add a penalty
        path_profit = history.get('total_profit', 0)
        path_trades = history.get('trades', 0)
        loss_penalty = 0.0
        if path_profit < 0 and path_trades > 0:
            # Add average loss as a safety margin
            avg_loss_pct = abs(path_profit) / (from_value_usd * path_trades) if from_value_usd > 0 else 0.01
            loss_penalty = min(avg_loss_pct, 0.05)  # Cap at 5%
        
        # ðŸ‘‘ STEP 4: TOTAL COST CALCULATION (WORST CASE)
        # This is the GUARANTEED cost of this trade
        total_cost_pct = (
            exchange_fee +          # Exchange trading fee
            total_spread +          # Bid/ask spread
            historical_slippage +   # Historical slippage on this path
            loss_penalty +          # Penalty for historically losing paths
            0.005                   # 0.5% safety buffer - ZERO TOLERANCE MODE! (Was 0.05%)
        )
        
        total_cost_usd = from_value_usd * total_cost_pct
        
        # Epsilon policy: require only an ultra-micro net-positive edge after costs
        min_profit_usd = EPSILON_PROFIT_USD
        
        # ðŸ‘‘ðŸ’€ SURVIVAL: Does this trade give us ANY edge?
        # For a trade to be worth trying: value_gained > total_cost + 0.1_pips
        # 
        # If we're converting FROM â†’ TO:
        # - We sell FROM, get USD equivalent minus spread
        # - We buy TO with that USD minus fee
        # 
        # The "expected gain" comes from price movement prediction
        # Since we can't predict price, we need to focus on ARBITRAGE or VALUE CONVERSION
        #
        # For stablecoin conversions: Gain is essentially 0 (1:1 value)
        # For other conversions: We're SPECULATING unless there's actual arbitrage
        
        # Is this a safe conversion? (stablecoin to stablecoin)
        is_safe_conversion = from_type == 'stablecoin' and to_type == 'stablecoin'
        
        # Is this a risky conversion? (meme coin involved)
        is_risky_conversion = from_type == 'meme' or to_type == 'meme'
        
        # Calculate breakeven requirement
        breakeven_gain_pct = total_cost_pct
        breakeven_gain_usd = total_cost_usd
        
        # Required price improvement to guarantee profit
        required_improvement_pct = total_cost_pct + (min_profit_usd / from_value_usd) if from_value_usd > 0 else 1.0
        
        # ðŸ‘‘ DECISION: Does math guarantee profit?
        math_breakdown = {
            'r_breakeven_pct': gate_result.r_breakeven * 100,  # RIGOROUS VALUE
            'r_prime_pct': gate_result.r_prime * 100,          # RIGOROUS VALUE
            'from_value_usd': from_value_usd,
            'exchange_fee_pct': exchange_fee * 100,
            'spread_pct': total_spread * 100,
            'historical_slippage_pct': historical_slippage * 100,
            'loss_penalty_pct': loss_penalty * 100,
            'safety_buffer_pct': 0.2,
            'total_cost_pct': total_cost_pct * 100,
            'total_cost_usd': total_cost_usd,
            'min_profit_usd': min_profit_usd,
            'required_improvement_pct': required_improvement_pct * 100,
            'from_type': from_type,
            'to_type': to_type,
            'is_safe': is_safe_conversion,
            'is_risky': is_risky_conversion,
            'path_history': {
                'trades': path_trades,
                'profit': path_profit,
                'avg_slippage': historical_slippage * 100
            }
        }
        
        # ðŸ‘‘ QUEEN'S FINAL VERDICT - STRICT MEME TRADING RULES
        # Only allow: Meme â†’ Stablecoin OR Stablecoin â†’ Meme
        # This ensures we always go through liquid pairs, avoiding double slippage
        
        # RULE 1: MEME can ONLY go to STABLECOIN (exit to cash)
        if from_type == 'meme' and to_type != 'stablecoin':
            return False, f"ðŸ‘‘ðŸ”¢ BLOCKED: Memeâ†’{to_type} not allowed! Meme must exit to stablecoin only!", math_breakdown
        
        # RULE 2: MEME can ONLY come from STABLECOIN (enter from cash)
        if to_type == 'meme' and from_type != 'stablecoin':
            return False, f"ðŸ‘‘ðŸ”¢ BLOCKED: {from_type}â†’Meme not allowed! Meme entry only from stablecoin!", math_breakdown
        
        # RULE 3: NO stablecoin-to-stablecoin (always loses to fees, no price movement)
        if from_type == 'stablecoin' and to_type == 'stablecoin':
            return False, "ðŸ‘‘ðŸ”¢ BLOCKED: Stablecoinâ†’Stablecoin ALWAYS loses to fees!", math_breakdown
        
        # RULE 4: Altcoin trades must also go through stablecoins or majors
        if from_type == 'altcoin' and to_type not in ['stablecoin', 'major']:
            return False, f"ðŸ‘‘ðŸ”¢ BLOCKED: Altcoinâ†’{to_type} not allowed! Exit to stablecoin/major only!", math_breakdown
        
        if to_type == 'altcoin' and from_type not in ['stablecoin', 'major']:
            return False, f"ðŸ‘‘ðŸ”¢ BLOCKED: {from_type}â†’Altcoin not allowed! Entry from stablecoin/major only!", math_breakdown
        
        # ðŸ‘‘ QUEEN HAS FULL CONTROL FOR PROFIT!
        # Her epsilon floor is the ONLY hard gate - all other limits are advisory
        
        # ðŸ‘‘ FINAL STRICT MATH GATING - THE "HARD TRUTH" LOGIC
        # We compare the rigorous class calculation vs our local worst-case estimates
        # and we take the MOST CONSERVATIVE (highest cost) view to protect capital.
        
        # 1. Determine the "True" Breakeven cost
        # Use the maximum of the Class calculation and our Local worst-case estimation
        # This handles cases where the Class might rely on defaults while Local has specific spread tables
        true_breakeven = max(gate_result.r_breakeven, total_cost_pct)
        
        # 2. Define Hard Tolerance Limits based on Source Asset Volatility
        # We cannot allow a trade to start if we are instantly in a deep hole
        MAX_TOLERANCE = 0.015 # Default 1.5% (TIGHTENED)
        
        # ðŸ‘‘ FORCE IDENTIFICATION OF STABLES/MAJORS (Fallback)
        is_safe_src = from_type == 'stablecoin' or from_asset in ['USDT', 'USDC', 'USD', 'DAI', 'EUR', 'BUSD', 'TUSD', 'PYUSD']
        is_major_src = from_type == 'major' or from_asset in ['BTC', 'ETH', 'SOL', 'BNB', 'XRP', 'ADA', 'DOGE']
        
        if is_safe_src:
            # STABLECOIN SOURCE: EXTREMELY STRICT.
            # We are holding cash. Don't burn it on high-fee entries.
            # If we lose > 0.2% just entering, we are wrong.
            MAX_TOLERANCE = 0.002 # 0.2% max burn (Strict)
            
        elif is_major_src:
            # MAJOR CRYPTO SOURCE (BTC/ETH): Moderate strictness.
            MAX_TOLERANCE = 0.005 # 0.5% max burn (Strict)
            
        elif from_type == 'meme':
            # MEME SOURCE: High volatility expected.
            if queen_dream_status == "STRONG_WIN":
                MAX_TOLERANCE = 0.025 # 2.5% allowed if Queen is confident
            else:
                MAX_TOLERANCE = 0.012 # 1.2% standard limit for meme exits
        
        # 3. Check for catastrophic spread mismatch
        # If the spread alone is > 1.5%, we are likely getting ripped off
        if total_spread > 0.015 and queen_dream_status != "STRONG_WIN":
             return False, f"ðŸš« MATH REJECT: Spread {total_spread:.2%} too wide", math_breakdown

        # 4. The Final Gate
        if true_breakeven > MAX_TOLERANCE:
            return False, f"ðŸš« MATH REJECT: True Cost {true_breakeven:.2%} > Limit {MAX_TOLERANCE:.2%}", math_breakdown

        return True, f"âœ… MATH APPROVED: Cost {true_breakeven:.2%} <= Limit {MAX_TOLERANCE:.2%}", math_breakdown
    
    def _block_path(self, key: Tuple[str, str], reason: str):
        """Block a path and broadcast through mycelium."""
        self.blocked_paths[key] = reason
        
        # ðŸ„ Broadcast through mycelium
        self.queen_signals.append({
            'type': 'PATH_BLOCKED',
            'path': f"{key[0]}â†’{key[1]}",
            'reason': reason,
            'timestamp': time.time()
        })
        
        logger.warning(f"ðŸ‘‘ðŸ„ QUEEN BLOCKS PATH: {key[0]}â†’{key[1]} - {reason}")
    
    def unblock_path(self, from_asset: str, to_asset: str):
        """Allow a path to be tried again (after cooldown)."""
        key = (from_asset.upper(), to_asset.upper())
        if key in self.blocked_paths:
            del self.blocked_paths[key]
            # Reset consecutive losses
            if key in self.barter_history:
                self.barter_history[key]['consecutive_losses'] = 0
            logger.info(f"ðŸ‘‘ Queen unblocks path: {key[0]}â†’{key[1]}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸš« PRE-EXECUTION REJECTION TRACKING - Stop wasting turns!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def record_preexec_rejection(self, from_asset: str, to_asset: str, reason: str, value_usd: float = 0.0) -> bool:
        """
        ðŸš« Record a pre-execution rejection (min_qty, min_notional, insufficient balance).
        
        Returns True if the path should now be blocked.
        """
        key = (from_asset.upper(), to_asset.upper())
        
        if key not in self.preexec_rejections:
            self.preexec_rejections[key] = {
                'count': 0,
                'last_value': 0,
                'last_reason': '',
                'blocked_at_turn': 0,
                'first_rejection': self.current_turn
            }
        
        rejection = self.preexec_rejections[key]
        rejection['count'] += 1
        rejection['last_value'] = value_usd
        rejection['last_reason'] = reason
        rejection['last_rejection_turn'] = self.current_turn
        
        # Check if we should block this path
        if rejection['count'] >= self.PREEXEC_MAX_REJECTIONS:
            rejection['blocked_at_turn'] = self.current_turn
            logger.warning(f"ðŸš« PRE-EXEC BLOCK: {from_asset}â†’{to_asset} after {rejection['count']} failures: {reason}")
            # Note: Blocking info logged to file for background learning (winners_only mode)
            return True
        
        return False
    
    def is_preexec_blocked(self, from_asset: str, to_asset: str) -> Tuple[bool, str]:
        """
        ðŸš« Check if a path is blocked due to pre-execution failures.
        
        Returns (is_blocked, reason)
        """
        key = (from_asset.upper(), to_asset.upper())
        
        if key not in self.preexec_rejections:
            return False, ""
        
        rejection = self.preexec_rejections[key]
        
        # Check if blocked
        if rejection['count'] >= self.PREEXEC_MAX_REJECTIONS:
            blocked_turn = rejection.get('blocked_at_turn', 0)
            turns_blocked = self.current_turn - blocked_turn
            
            # Check if cooldown has expired
            if turns_blocked >= self.PREEXEC_COOLDOWN_TURNS:
                # Reset and allow retry
                rejection['count'] = 0
                rejection['blocked_at_turn'] = 0
                logger.info(f"ðŸš«â†’âœ… PRE-EXEC UNBLOCK: {from_asset}â†’{to_asset} cooldown complete ({turns_blocked} turns)")
                return False, ""
            
            remaining = self.PREEXEC_COOLDOWN_TURNS - turns_blocked
            return True, f"Pre-exec blocked ({rejection['count']}x failures, {remaining} turns left): {rejection['last_reason']}"
        
        return False, ""
    
    def clear_preexec_rejection(self, from_asset: str, to_asset: str):
        """Clear pre-execution rejection history (e.g., after successful trade)."""
        key = (from_asset.upper(), to_asset.upper())
        if key in self.preexec_rejections:
            del self.preexec_rejections[key]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸš« SOURCE ASSET BLOCKING - Block undersized source assets on specific exchange
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def record_source_rejection(self, asset: str, exchange: str, min_needed: float, current_value: float) -> bool:
        """
        ðŸš« Record when a source asset is too small for an exchange.
        
        If the same asset fails SOURCE_BLOCK_THRESHOLD times on an exchange,
        block it until balance increases or cooldown expires.
        
        Returns True if the source should now be blocked.
        """
        key = (asset.upper(), exchange.lower())
        
        if key not in self.blocked_sources:
            self.blocked_sources[key] = {
                'count': 0,
                'min_needed': min_needed,
                'last_value': current_value,
                'blocked_turn': 0,
                'first_rejection': self.current_turn
            }
        
        source = self.blocked_sources[key]
        source['count'] += 1
        source['last_value'] = current_value
        source['min_needed'] = max(source['min_needed'], min_needed)  # Track highest min needed
        source['last_rejection_turn'] = self.current_turn
        
        # Check if we should block this source
        if source['count'] >= self.SOURCE_BLOCK_THRESHOLD:
            source['blocked_turn'] = self.current_turn
            logger.warning(f"ðŸš« SOURCE BLOCKED: {asset} on {exchange} after {source['count']} failures")
            # Note: Using verbose logging - caller's class has rejection_print
            return True
        
        return False
    
    def is_source_blocked(self, asset: str, exchange: str, current_value: float = None) -> Tuple[bool, str]:
        """
        ðŸš« Check if a source asset is blocked on an exchange.
        
        If current_value is provided and exceeds the min_needed threshold,
        automatically unblock the source.
        
        Returns (is_blocked, reason)
        """
        key = (asset.upper(), exchange.lower())
        
        if key not in self.blocked_sources:
            return False, ""
        
        source = self.blocked_sources[key]
        
        # Check if balance has increased above threshold
        if current_value is not None and current_value >= source['min_needed'] * 1.1:  # 10% buffer
            logger.info(f"ðŸš«â†’âœ… SOURCE UNBLOCK: {asset} on {exchange} - balance ${current_value:.2f} â‰¥ ${source['min_needed']:.2f}")
            del self.blocked_sources[key]
            return False, ""
        
        # Check if blocked
        if source['count'] >= self.SOURCE_BLOCK_THRESHOLD:
            blocked_turn = source.get('blocked_turn', 0)
            turns_blocked = self.current_turn - blocked_turn
            
            # Check if cooldown has expired
            if turns_blocked >= self.SOURCE_BLOCK_COOLDOWN:
                # Reset and allow retry
                source['count'] = 0
                source['blocked_turn'] = 0
                logger.info(f"ðŸš«â†’âœ… SOURCE UNBLOCK: {asset} on {exchange} cooldown complete ({turns_blocked} turns)")
                return False, ""
            
            remaining = self.SOURCE_BLOCK_COOLDOWN - turns_blocked
            return True, f"Source blocked (${source['last_value']:.2f} < ${source['min_needed']:.2f}, {remaining} turns left)"
        
        return False, ""
    
    def get_queen_signals(self) -> List[Dict]:
        """Get pending signals to broadcast via mycelium."""
        signals = self.queen_signals.copy()
        self.queen_signals.clear()
        return signals
    
    def check_dream_progress(self) -> str:
        """
        ðŸ’°ðŸ‘‘ SERO'S DREAM PROGRESS - Track progress toward $1 BILLION!
        
        She won't stop at NOTHING until she reaches her dream!
        Every profitable trade brings her closer.
        """
        profit = self.total_realized_profit
        dream = self.TINA_DREAM
        progress_pct = (profit / dream) * 100 if dream > 0 else 0
        
        # Check for new milestones
        for milestone_value, milestone_name in self.dream_milestones:
            if profit >= milestone_value and milestone_name not in self.milestones_hit:
                self.milestones_hit.append(milestone_name)
                print(f"\nðŸŽ‰ðŸŽŠðŸ‘‘ SERO MILESTONE ACHIEVED! ðŸ‘‘ðŸŽŠðŸŽ‰")
                print(f"   {milestone_name}")
                print(f"   Current: ${profit:,.2f}")
                print(f"   Progress: {progress_pct:.8f}% toward THE DREAM!")
                print()
        
        # Build progress bar
        bar_width = 40
        filled = int((progress_pct / 100) * bar_width) if progress_pct < 100 else bar_width
        filled = max(0, min(bar_width, filled))
        bar = "â–ˆ" * filled + "â–‘" * (bar_width - filled)
        
        # Motivation based on progress
        if profit < 0:
            mood = "ðŸ˜¤ SETBACK - But I NEVER give up!"
        elif profit < 100:
            mood = "ðŸŒ± Planting seeds..."
        elif profit < 1000:
            mood = "ðŸ’ª Building momentum!"
        elif profit < 10000:
            mood = "ðŸ”¥ On FIRE!"
        elif profit < 100000:
            mood = "ðŸš€ ACCELERATING!"
        elif profit < 1000000:
            mood = "âš¡ UNSTOPPABLE!"
        else:
            mood = "ðŸ‘‘ QUEEN STATUS!"
        
        status = f"ðŸ‘‘ SERO's DREAM: ${profit:,.2f} / ${dream:,.0f} [{bar}] {progress_pct:.8f}% {mood}"
        return status
    
    def update_barter_rate(self, from_asset: str, to_asset: str, from_price: float, 
                           to_price: float, spread_pct: float = 0.3):
        """
        Update the barter rate between two assets based on live prices.
        
        The barter rate tells us: "How much TO can I get for 1 unit of FROM?"
        """
        if to_price <= 0:
            return
            
        # Direct exchange rate (how many TO per FROM)
        rate = from_price / to_price
        
        # Apply estimated spread (real markets have slippage)
        effective_rate = rate * (1 - spread_pct / 100)
        
        key = (from_asset.upper(), to_asset.upper())
        self.barter_rates[key] = {
            'rate': effective_rate,
            'raw_rate': rate,
            'spread_pct': spread_pct,
            'from_price': from_price,
            'to_price': to_price,
            'updated': time.time()
        }
    
    def get_barter_rate(self, from_asset: str, to_asset: str) -> Optional[Dict[str, Any]]:
        """Get the current barter rate between two assets."""
        key = (from_asset.upper(), to_asset.upper())
        return self.barter_rates.get(key)
    
    def calculate_barter_value(self, from_asset: str, to_asset: str, 
                               from_amount: float, from_price: float, 
                               to_price: float) -> Dict[str, float]:
        """
        Calculate what you'd get in a barter trade.
        
        Returns both the USD-equivalent calculation AND the barter-adjusted calculation.
        """
        # USD-equivalent method (simple)
        from_usd = from_amount * from_price
        usd_equiv_amount = from_usd / to_price if to_price > 0 else 0
        
        # Barter-adjusted method (accounts for historical spread)
        key = (from_asset.upper(), to_asset.upper())
        history = self.barter_history.get(key, {})
        avg_slippage = history.get('avg_slippage', 0.5)  # Default 0.5% slippage
        
        barter_amount = usd_equiv_amount * (1 - avg_slippage / 100)
        
        return {
            'from_amount': from_amount,
            'from_usd': from_usd,
            'usd_equiv_to': usd_equiv_amount,
            'barter_adjusted_to': barter_amount,
            'expected_slippage_pct': avg_slippage,
            'to_asset': to_asset,
            'from_asset': from_asset
        }
    
    def record_realized_profit(self, from_asset: str, to_asset: str,
                               from_amount: float, from_usd: float,
                               to_amount: float, to_usd: float) -> Dict[str, Any]:
        """
        Record a realized trade and calculate ACTUAL profit/loss.
        
        This is called AFTER a conversion completes to track true P/L.
        ðŸ‘‘ QUEEN'S MANDATE: Track wins/losses to block losing paths!
        """
        # Calculate realized P/L
        profit_usd_raw = to_usd - from_usd
        profit_pct_raw = (profit_usd_raw / from_usd * 100) if from_usd > 0 else 0

        # ðŸ”§ FIX GHOST PROFIT: Sanity check BEFORE we update history/signals.
        # If profit is wildly outside expected bounds, treat as an outlier so it
        # doesn't corrupt path stats, win-rate, or portfolio reporting.
        MAX_REASONABLE_PROFIT = 500.0  # Max profit per conversion (given small balances)
        MIN_REASONABLE_LOSS = -200.0   # Max loss per conversion
        is_outlier = profit_usd_raw > MAX_REASONABLE_PROFIT or profit_usd_raw < MIN_REASONABLE_LOSS
        if is_outlier:
            logger.warning(
                f"ðŸ‘‘âš ï¸ REJECTING OUTLIER PROFIT/LOSS: ${profit_usd_raw:.2f} (from ${from_usd:.2f} to ${to_usd:.2f})"
            )
            logger.warning("      This suggests a price data error or bad execution value.")

        profit_usd = 0.0 if is_outlier else profit_usd_raw
        profit_pct = 0.0 if is_outlier else profit_pct_raw
        is_win = profit_usd > 0
        
        # Calculate actual slippage vs expected
        key = (from_asset.upper(), to_asset.upper())
        rate_info = self.barter_rates.get(key)
        if rate_info and rate_info['raw_rate'] > 0:
            expected_to = from_amount * rate_info['raw_rate']
            actual_slippage = (1 - to_amount / expected_to) * 100 if expected_to > 0 else 0
        else:
            actual_slippage = 0.5  # Default
        
        # Update historical slippage (exponential moving average)
        history = self.barter_history.setdefault(key, {
            'trades': 0, 'avg_slippage': 0.5, 'total_profit': 0,
            'wins': 0, 'losses': 0, 'consecutive_losses': 0
        })
        history['trades'] += 1
        alpha = 0.3  # Weight for new data
        history['avg_slippage'] = alpha * actual_slippage + (1 - alpha) * history['avg_slippage']
        history['total_profit'] = history.get('total_profit', 0) + profit_usd

        # Track outliers without treating them as wins/losses
        if is_outlier:
            history['outliers'] = history.get('outliers', 0) + 1
            history['last_outlier_time'] = time.time()
        
        # ðŸ‘‘ QUEEN'S WIN/LOSS TRACKING WITH IMMEDIATE LEARNING
        # Outliers are treated as neutral so they don't block/unblock paths.
        if is_outlier or profit_usd == 0:
            pass
        elif is_win:
            history['wins'] = history.get('wins', 0) + 1
            history['consecutive_losses'] = 0  # Reset on win
            history['last_win_time'] = time.time()  # Remember when we last won
            # Unblock path if it was blocked and now winning
            if key in self.blocked_paths:
                self.unblock_path(from_asset, to_asset)
            # ðŸŽ‰ Broadcast win through mycelium
            self.queen_signals.append({
                'type': 'PATH_WIN',
                'path': f"{from_asset}â†’{to_asset}",
                'profit_usd': profit_usd,
                'win_rate': history['wins'] / history['trades'],
                'timestamp': time.time()
            })
            logger.info(f"ðŸ‘‘âœ… PATH WIN: {from_asset}â†’{to_asset} +${profit_usd:.4f} (win rate: {history['wins']/history['trades']:.0%})")
        else:
            history['losses'] = history.get('losses', 0) + 1
            history['consecutive_losses'] = history.get('consecutive_losses', 0) + 1
            history['last_loss_usd'] = profit_usd  # Remember how much we lost
            blocked_reason: Optional[str] = None
            
            # ðŸ„ Broadcast loss through mycelium
            self.queen_signals.append({
                'type': 'PATH_LOSS',
                'path': f"{from_asset}â†’{to_asset}",
                'loss_usd': profit_usd,
                'consecutive': history['consecutive_losses'],
                'timestamp': time.time()
            })
            
            # ðŸ‘‘ðŸ§  IMMEDIATE LEARNING: Block path after FIRST loss on new paths!
            # For established paths, still use MAX_CONSECUTIVE_LOSSES
            if history['trades'] <= 2:
                # New path lost - block IMMEDIATELY to prevent further losses
                blocked_reason = f"First trade lost ${abs(profit_usd):.4f} - need time to cool down"
                self._block_path(key, blocked_reason)
                logger.warning(f"ðŸ‘‘ðŸš« INSTANT BLOCK: {from_asset}â†’{to_asset} lost ${abs(profit_usd):.4f} on trade #{history['trades']}")
            elif history['consecutive_losses'] >= self.MAX_CONSECUTIVE_LOSSES:
                blocked_reason = f"{history['consecutive_losses']} consecutive losses"
                self._block_path(key, blocked_reason)

            # Mirror-block reverse path when a path is blocked for losses
            if blocked_reason:
                reverse_key = (to_asset.upper(), from_asset.upper())
                if reverse_key not in self.blocked_paths:
                    self._block_path(reverse_key, f"Mirror block after {blocked_reason}")
            
            # ðŸ‘‘ LEARN: If slippage is consistently high, increase expected slippage
            if actual_slippage > history['avg_slippage'] * 1.5:
                # Slippage much higher than expected - warn
                logger.warning(f"ðŸ‘‘âš ï¸ HIGH SLIPPAGE: {from_asset}â†’{to_asset} had {actual_slippage:.2f}% vs avg {history['avg_slippage']:.2f}%")
        
        # Record in ledger (sanitized)
        self.profit_ledger.append((
            time.time(), from_asset, to_asset, from_usd, to_usd, profit_usd
        ))
            
        # Update running totals with sanitized profit
        self.total_realized_profit += profit_usd
        self.conversion_count += 1
        
        # Calculate win rate
        win_rate = history['wins'] / history['trades'] if history['trades'] > 0 else 0
        
        return {
            'profit_usd': profit_usd,
            'profit_pct': profit_pct,
            'actual_slippage_pct': actual_slippage,
            'running_total': self.total_realized_profit,
            'conversion_number': self.conversion_count,
            'path_total_profit': history['total_profit'],
            'path_trades': history['trades'],
            'path_win_rate': win_rate,
            'is_win': is_win
        }
    
    def get_best_barter_path(self, from_asset: str, target_assets: List[str],
                            prices: Dict[str, float]) -> List[Dict[str, Any]]:
        """
        Find the best barter opportunities from a given asset.
        
        Returns ranked list of targets sorted by expected VALUE (not just USD conversion).
        """
        from_price = prices.get(from_asset, 0)
        if from_price <= 0:
            return []
        
        opportunities = []
        for target in target_assets:
            if target == from_asset:
                continue
            to_price = prices.get(target, 0)
            if to_price <= 0:
                continue
            
            # Calculate barter advantage
            barter_info = self.calculate_barter_value(from_asset, target, 1.0, from_price, to_price)
            
            # Check historical performance
            key = (from_asset.upper(), target.upper())
            history = self.barter_history.get(key, {})
            win_rate = 0.5  # Default
            if history.get('trades', 0) > 0:
                win_rate = history.get('total_profit', 0) / history['trades']
                win_rate = 0.5 + (win_rate / 10)  # Normalize around 0.5
            
            opportunities.append({
                'from': from_asset,
                'to': target,
                'barter_rate': barter_info['barter_adjusted_to'],
                'usd_rate': barter_info['usd_equiv_to'],
                'advantage_pct': (barter_info['barter_adjusted_to'] / barter_info['usd_equiv_to'] - 1) * 100 if barter_info['usd_equiv_to'] > 0 else 0,
                'historical_win_rate': win_rate,
                'trades_count': history.get('trades', 0),
                'path_profit': history.get('total_profit', 0)
            })
        
        # Sort by a combined score: historical profit + expected value
        for opp in opportunities:
            opp['barter_score'] = (
                opp['historical_win_rate'] * 0.4 +  # Past performance
                (1 + opp['advantage_pct'] / 100) * 0.3 +  # Current advantage
                min(opp['trades_count'] / 10, 1) * 0.3  # Experience with this path
            )
        
        return sorted(opportunities, key=lambda x: x['barter_score'], reverse=True)
    
    def print_step_profit(self, step_num: int, from_asset: str, to_asset: str,
                          from_usd: float, to_usd: float, from_amount: float, 
                          to_amount: float) -> str:
        """
        Print a beautiful step-by-step profit breakdown.
        """
        profit = to_usd - from_usd
        profit_symbol = "+" if profit >= 0 else ""
        
        lines = [
            f"",
            f"   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
            f"   â•‘  ðŸ’° STEP #{step_num} REALIZED PROFIT                              â•‘",
            f"   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  FROM: {from_amount:>12.6f} {from_asset:<6} = ${from_usd:>10.4f}      â•‘",
            f"   â•‘    TO: {to_amount:>12.6f} {to_asset:<6} = ${to_usd:>10.4f}      â•‘",
            f"   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  STEP P/L: ${profit_symbol}{profit:>8.4f} ({profit/from_usd*100 if from_usd > 0 else 0:>+.2f}%)                    â•‘",
            f"   â•‘  RUNNING TOTAL: ${profit_symbol}{self.total_realized_profit:>8.4f}                          â•‘",
            f"   â•‘  CONVERSIONS: {self.conversion_count}                                       â•‘",
            f"   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        ]
        return "\n".join(lines)
    
    def get_summary(self) -> Dict[str, Any]:
        """Get summary of all barter activity."""
        return {
            'total_realized_profit': self.total_realized_profit,
            'conversion_count': self.conversion_count,
            'avg_profit_per_trade': self.total_realized_profit / max(self.conversion_count, 1),
            'paths_learned': len(self.barter_history),
            'recent_trades': self.profit_ledger[-10:] if self.profit_ledger else []
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ—ºï¸ DYNAMIC ASSET DISCOVERY - Expand to see ENTIRE market!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def discover_exchange_assets(self, exchange: str, pairs: List[str]) -> int:
        """
        Discover and register all tradeable assets from an exchange.
        
        Called during initialization to expand market visibility from 27 â†’ 750+ assets.
        """
        discovered = 0
        exchange_lower = exchange.lower()
        
        for pair in pairs:
            # Extract base and quote from pair name
            for quote in ['USD', 'USDT', 'USDC', 'EUR', 'GBP', 'BTC', 'ETH', 'ZUSD', 'ZEUR']:
                if pair.endswith(quote):
                    base = pair[:-len(quote)]
                    # Clean up Kraken naming (XXBT â†’ BTC, XETH â†’ ETH)
                    if len(base) == 4 and base[0] in ('X', 'Z'):
                        base = base[1:]
                    if base == 'XBT':
                        base = 'BTC'
                    
                    if base and len(base) >= 2:
                        # Register the asset
                        self.DISCOVERED_ASSETS.add(base)
                        self.EXCHANGE_PAIRS[exchange_lower].add(pair)
                        discovered += 1
                    break
        
        return discovered
    
    def get_asset_type(self, asset: str) -> str:
        """
        Dynamically categorize an asset for spread calculation.
        
        Uses the expanded asset lists + learned categories.
        """
        asset = asset.upper()
        
        if asset in self.STABLECOINS:
            return 'stablecoin'
        elif asset in self.MEME_COINS:
            return 'meme'
        elif asset in self.MAJOR_COINS:
            return 'major'
        elif asset in self.DEFI_COINS:
            return 'defi'  # DeFi tokens get altcoin spread
        elif asset in self.AI_COINS:
            return 'ai'    # AI tokens are hot - moderate spread
        elif asset in self.LAYER2_COINS:
            return 'layer2'  # L2s are liquid
        elif asset in self.RWA_COINS:
            return 'rwa'   # RWA still emerging
        else:
            return 'altcoin'  # Unknown = conservative spread
    
    def get_spread_for_asset(self, asset: str, exchange: str = 'kraken') -> float:
        """Get the expected spread cost for an asset on a given exchange."""
        asset_type = self.get_asset_type(asset)
        
        # Get the right spread table
        if exchange.lower() == 'binance':
            spread_table = self.BINANCE_SPREAD_COSTS
        elif exchange.lower() == 'alpaca':
            spread_table = self.ALPACA_SPREAD_COSTS
        else:
            spread_table = self.SPREAD_COSTS
        
        # Map asset types to spread categories
        type_to_spread = {
            'stablecoin': 'stablecoin',
            'major': 'major',
            'meme': 'meme',
            'defi': 'altcoin',
            'ai': 'major',      # AI tokens are liquid now
            'layer2': 'major',  # L2s have good liquidity
            'rwa': 'altcoin',   # RWA is newer
            'altcoin': 'altcoin',
        }
        
        spread_category = type_to_spread.get(asset_type, 'altcoin')
        return spread_table.get(spread_category, 0.01)
    
    def print_market_coverage(self) -> str:
        """
        Print a beautiful market coverage report.
        
        Shows how much of the market the Barter Matrix can now see.
        """
        # Count categorized assets
        static_count = len(self.MEME_COINS) + len(self.MAJOR_COINS) + len(self.STABLECOINS)
        static_count += len(self.DEFI_COINS) + len(self.AI_COINS) + len(self.LAYER2_COINS) + len(self.RWA_COINS)
        discovered_count = len(self.DISCOVERED_ASSETS)
        total_known = static_count + discovered_count
        
        # Exchange pair counts
        kraken_pairs = len(self.EXCHANGE_PAIRS.get('kraken', set()))
        binance_pairs = len(self.EXCHANGE_PAIRS.get('binance', set()))
        alpaca_pairs = len(self.EXCHANGE_PAIRS.get('alpaca', set()))
        
        lines = [
            "",
            "   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
            "   â•‘  ðŸ—ºï¸ BARTER MATRIX - MARKET COVERAGE REPORT                   â•‘",
            "   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  ðŸ“Š CATEGORIZED ASSETS:                                      â•‘",
            f"   â•‘     â€¢ MEME_COINS:    {len(self.MEME_COINS):>4} (DOGE, SHIB, WIF, BONK...)   â•‘",
            f"   â•‘     â€¢ MAJOR_COINS:   {len(self.MAJOR_COINS):>4} (BTC, ETH, SOL, XRP...)     â•‘",
            f"   â•‘     â€¢ DEFI_COINS:    {len(self.DEFI_COINS):>4} (UNI, AAVE, MKR, GMX...)    â•‘",
            f"   â•‘     â€¢ AI_COINS:      {len(self.AI_COINS):>4} (RENDER, FET, TAO, WLD...)   â•‘",
            f"   â•‘     â€¢ LAYER2_COINS:  {len(self.LAYER2_COINS):>4} (ARB, OP, MATIC, IMX...)    â•‘",
            f"   â•‘     â€¢ RWA_COINS:     {len(self.RWA_COINS):>4} (ONDO, RSR, POLYX...)       â•‘",
            f"   â•‘     â€¢ STABLECOINS:   {len(self.STABLECOINS):>4} (USD, USDT, USDC...)       â•‘",
            f"   â•‘                                                              â•‘",
            f"   â•‘  ðŸ” DISCOVERED AT RUNTIME: {discovered_count:>4} additional assets           â•‘",
            f"   â•‘  ðŸ“ˆ TOTAL KNOWN ASSETS:    {total_known:>4}                              â•‘",
            "   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  ðŸ™ KRAKEN PAIRS:   {kraken_pairs:>5}                                   â•‘",
            f"   â•‘  ðŸ”¶ BINANCE PAIRS:  {binance_pairs:>5}                                   â•‘",
            f"   â•‘  ðŸ¦™ ALPACA PAIRS:   {alpaca_pairs:>5}                                   â•‘",
            "   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        ]
        return "\n".join(lines)

    def calculate_true_cost(self, from_asset: str, to_asset: str, value_usd: float, exchange: str) -> Tuple[bool, str, Dict]:
        """
        ðŸ‘‘ TRUE COST CALCULATOR - The "Floor that stops us losing money"
        
        Adjusts base fees with LEARNED historical reality.
        Buying wrong? Selling wrong? This fixes the counting.
        
        Returns: (approved, reason, cost_breakdown)
        """
        exchange = exchange.lower()
        
        # 1. Base Exchange Fees (Tiered)
        base_fee = self.EXCHANGE_FEES.get(exchange, 0.003)
        if exchange == 'binance': base_fee = 0.002
        elif exchange == 'kraken': base_fee = 0.0026
        
        # 2. Asset Spread Calculation
        from_type = self.get_asset_type(from_asset)
        to_type = self.get_asset_type(to_asset)
        
        spread_table = self.BINANCE_SPREAD_COSTS if exchange == 'binance' else self.SPREAD_COSTS
        
        from_spread = spread_table.get(from_type, 0.01)
        to_spread = spread_table.get(to_type, 0.01)
        # ðŸ”§ FIX: We pay spread on BOTH sides of a conversion (sell source @ from_spread, buy target @ to_spread)
        # For memeâ†’meme, this is 1.5% + 1.5% = 3% total spread cost!
        # Only use max() for stableâ†’major (one side is negligible)
        if from_type == 'meme' or to_type == 'meme':
            # Both spreads matter for volatile assets
            total_spread = from_spread + to_spread
        else:
            # For stable/major pairs, max is reasonable (one side dominates)
            total_spread = max(from_spread, to_spread)
        
        # 3. LEARNED SLIPPAGE (The "Mistake" Factor)
        # Check history used by PathMemory or internal barter history
        pair_key = (from_asset.upper(), to_asset.upper())
        learned_slippage = 0.0
        
        # Check internal history
        if hasattr(self, 'barter_history') and pair_key in self.barter_history:
            hist = self.barter_history[pair_key]
            if hist.get('trades', 0) > 0:
                avg_slip = hist.get('avg_slippage', 0) / 100.0
                # If we historically lose here, assume WORSE slippage
                if hist.get('total_profit', 0) < 0:
                    learned_slippage = max(avg_slip, 0.01) # Min 1% penalty if losing
        
        # 4. Volatility Penalty (Buying Wrong)
        # If buying a MEME, add panic premium
        volatility_premium = 0.0
        if to_type == 'meme':
            volatility_premium = 0.015 # 1.5% extra risk
        elif from_type == 'meme':
            volatility_premium = 0.010 # 1.0% exit risk
            
        # 5. True Total Cost
        total_cost_pct = base_fee + total_spread + learned_slippage + volatility_premium
        total_cost_usd = value_usd * total_cost_pct
        
        # 6. Transfer/Gas Cost (Transferring Wrong)
        # Only relevant if we were moving funds, but for conversions, it's 0 usually.
        # However, keep a small buffer for "dust" loss.
        dust_loss = 0.0001 # 0.01% dust inefficiency
        total_cost_pct += dust_loss
        
        math_breakdown = {
            'total_cost_pct': total_cost_pct * 100,
            'total_cost_usd': total_cost_usd,
            'base_fee': base_fee * 100,
            'spread': total_spread * 100,
            'learned_slippage': learned_slippage * 100,
            'volatility': volatility_premium * 100
        }
        
        # Approval check
        # If cost > 5%, it's practically suicide unless it's a moonshot
        if total_cost_pct > 0.05:
            return False, f"Cost too high ({total_cost_pct:.2%})", math_breakdown
            
        return True, "OK", math_breakdown


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ï¿½ðŸ”€ LIQUIDITY ENGINE - Dynamic Asset Aggregation ("Top-Up" Mechanism)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# When we find an opportunity but don't have enough balance:
# 1. Find "victim" assets to liquidate (low performers, dust, stablecoins)
# 2. Calculate if selling them to fund the trade is PROFITABLE after fees
# 3. Execute multi-step atomic trades: SELL VICTIM â†’ BUY TARGET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FundingCandidate:
    """A potential source of funds (asset to liquidate)."""
    asset: str
    exchange: str
    amount: float
    value_usd: float
    momentum: float  # -1 to +1 (negative = falling = good victim)
    sell_fee_pct: float
    reason: str  # Why this is a good victim
    priority: int  # Higher = better victim


@dataclass 
class AggregationPlan:
    """A plan to aggregate funds for a target trade."""
    target_asset: str
    target_exchange: str
    amount_needed_usd: float
    victims: List[FundingCandidate]
    total_victim_value: float
    total_fees_usd: float
    net_funds_available: float
    is_profitable: bool
    profit_after_fees: float
    steps: List[Dict]  # Execution steps


class LiquidityEngine:
    """
    ðŸ’§ LIQUIDITY ENGINE - Smart Asset Consolidation
    
    "If you want to buy BTC but only have dust ETH + some DOGE,
     sell the losers to fund the winner!"
    
    Key Principles:
    1. Only liquidate "victims" that are FALLING or STAGNANT
    2. Never touch assets that are RISING (they might profit on their own)
    3. Calculate TOTAL cost (sell fee + buy fee + slippage) 
    4. Only proceed if expected profit > total cost
    5. Execute atomically - if any step fails, abort all
    """
    
    # Fee estimates per exchange (maker/taker average)
    EXCHANGE_FEES = {
        'kraken': 0.0026,    # 0.26% average
        'binance': 0.0010,   # 0.10% with BNB discount
        'alpaca': 0.0015,    # 0.15% crypto fee
    }
    
    # Minimum USD value to consider for liquidation (avoid dust-for-dust)
    MIN_VICTIM_VALUE = 2.00  # $2 minimum
    
    # Slippage estimates (additional cost on top of fees)
    SLIPPAGE_ESTIMATE = {
        'stablecoin': 0.0005,   # 0.05%
        'major': 0.0020,        # 0.20%
        'altcoin': 0.0050,      # 0.50%
        'meme': 0.0150,         # 1.50%
    }
    
    def __init__(self, barter_matrix: 'BarterMatrix'):
        self.barter_matrix = barter_matrix
        self.pending_plans: List[Any] = []
        self.executed_aggregations = 0
        self.total_aggregation_profit = 0.0
        
        # Track liquidation history (avoid repeatedly selling same asset)
        self.recent_liquidations: Dict[str, float] = {}  # asset -> timestamp
        self.LIQUIDATION_COOLDOWN = 120  # 2 minutes between selling same asset (TURBO - was 5 mins)
        
    def find_funding_candidates(
        self, 
        exchange: str,
        amount_needed_usd: float,
        exclude_assets: Set[str],
        exchange_balances: Dict[str, float],
        prices: Dict[str, float],
        momentum: Dict[str, float],
    ) -> List[FundingCandidate]:
        """
        Find assets that can be liquidated to fund a trade.
        
        Victim Priority (best to worst):
        1. ðŸ¥‡ DUST (< $5) with negative momentum - Clean up the portfolio!
        2. ðŸ¥ˆ STABLECOINS - They're just sitting there doing nothing
        3. ðŸ¥‰ FALLING assets (momentum < -0.001/min) - Cut losses!
        4. ðŸ… STAGNANT assets (momentum ~0) - Not doing anything
        
        Never victimize:
        - Assets with strong positive momentum (> +0.002/min)
        - Assets we're trying to BUY
        - Assets we recently liquidated (cooldown)
        """
        candidates = []
        current_time = time.time()
        
        balances = exchange_balances.get(exchange, {})
        
        for asset, amount in balances.items():
            # Skip excluded (the target we want to buy)
            if asset.upper() in exclude_assets:
                continue
            
            # Skip if recently liquidated
            if asset in self.recent_liquidations:
                if current_time - self.recent_liquidations[asset] < self.LIQUIDATION_COOLDOWN:
                    continue
            
            # Get value
            price = prices.get(asset, 0)
            if asset.upper() in ('USD', 'USDT', 'USDC', 'ZUSD'):
                price = 1.0
            
            value_usd = amount * price if price > 0 else 0
            
            # Skip if below minimum
            if value_usd < self.MIN_VICTIM_VALUE:
                continue
            
            # Get momentum
            asset_momentum = momentum.get(asset, 0)
            
            # Skip RISING assets (they might profit on their own!)
            if asset_momentum > 0.002:  # > 0.2%/min rising
                continue
            
            # Calculate sell fee
            fee_pct = self.EXCHANGE_FEES.get(exchange, 0.003)
            
            # Determine asset type for slippage
            if asset.upper() in ('USD', 'USDT', 'USDC', 'ZUSD', 'DAI', 'TUSD'):
                asset_type = 'stablecoin'
            elif asset.upper() in ('BTC', 'ETH', 'SOL', 'BNB', 'XRP'):
                asset_type = 'major'
            elif asset.upper() in self.barter_matrix.MEME_COINS:
                asset_type = 'meme'
            else:
                asset_type = 'altcoin'
            
            slippage = self.SLIPPAGE_ESTIMATE.get(asset_type, 0.005)
            total_sell_cost = fee_pct + slippage
            
            # Calculate priority (higher = better victim)
            priority = 0
            reason_parts = []
            
            # ðŸ¥‡ PRIORITY 1: Dust with negative momentum
            if value_usd < 5.0 and asset_momentum < 0:
                priority = 100
                reason_parts.append("DUST_FALLING")
            
            # ðŸ¥ˆ PRIORITY 2: Stablecoins (opportunity cost)
            elif asset_type == 'stablecoin':
                priority = 80
                reason_parts.append("STABLECOIN_IDLE")
            
            # ðŸ¥‰ PRIORITY 3: Falling assets
            elif asset_momentum < -0.001:  # < -0.1%/min
                priority = 60 + int(abs(asset_momentum) * 1000)  # More falling = higher priority
                reason_parts.append(f"FALLING({asset_momentum*100:.2f}%/min)")
            
            # ðŸ… PRIORITY 4: Stagnant
            elif abs(asset_momentum) < 0.0005:
                priority = 40
                reason_parts.append("STAGNANT")
            
            # Otherwise, low priority
            else:
                priority = 20
                reason_parts.append("LOW_MOMENTUM")
            
            # Bonus for dust cleanup
            if value_usd < 10.0:
                priority += 15
                reason_parts.append("CLEANUP")
            
            candidates.append(FundingCandidate(
                asset=asset,
                exchange=exchange,
                amount=amount,
                value_usd=value_usd,
                momentum=asset_momentum,
                sell_fee_pct=total_sell_cost,
                reason=" + ".join(reason_parts),
                priority=priority,
            ))
        
        # Sort by priority (highest first)
        candidates.sort(key=lambda x: x.priority, reverse=True)
        
        return candidates
    
    def create_aggregation_plan(
        self,
        target_asset: str,
        target_exchange: str,
        amount_needed_usd: float,
        expected_profit_pct: float,  # Expected profit from target trade
        exchange_balances: Dict[str, float],
        prices: Dict[str, float],
        momentum: Dict[str, float],
    ) -> Optional[AggregationPlan]:
        """
        Create a plan to aggregate funds for a target trade.
        
        Returns None if:
        - Not enough victims available
        - Total fees would exceed expected profit
        """
        # Find candidates
        candidates = self.find_funding_candidates(
            exchange=target_exchange,
            amount_needed_usd=amount_needed_usd * 1.05,  # 5% buffer for fees
            exclude_assets={target_asset.upper()},
            exchange_balances=exchange_balances,
            prices=prices,
            momentum=momentum,
        )
        
        if not candidates:
            return None
        
        # Greedily select victims until we have enough
        selected_victims = []
        total_value = 0.0
        total_fees = 0.0
        
        for candidate in candidates:
            if total_value >= amount_needed_usd * 1.02:  # 2% buffer
                break
            
            # Calculate net value after fees
            gross_value = candidate.value_usd
            sell_fees = gross_value * candidate.sell_fee_pct
            net_value = gross_value - sell_fees
            
            selected_victims.append(candidate)
            total_value += gross_value
            total_fees += sell_fees
        
        if total_value < amount_needed_usd:
            # Not enough victims
            return None
        
        # Add BUY fees for target asset
        buy_fee_pct = self.EXCHANGE_FEES.get(target_exchange, 0.003)
        
        # Determine target asset type for slippage
        if target_asset.upper() in ('USD', 'USDT', 'USDC'):
            target_type = 'stablecoin'
        elif target_asset.upper() in ('BTC', 'ETH', 'SOL', 'BNB', 'XRP'):
            target_type = 'major'
        elif target_asset.upper() in self.barter_matrix.MEME_COINS:
            target_type = 'meme'
        else:
            target_type = 'altcoin'
        
        target_slippage = self.SLIPPAGE_ESTIMATE.get(target_type, 0.005)
        buy_total_cost = buy_fee_pct + target_slippage
        
        # Calculate net funds available after all fees
        net_after_sell = total_value - total_fees
        buy_fees = net_after_sell * buy_total_cost
        total_fees += buy_fees
        net_funds = net_after_sell - buy_fees
        
        # Calculate if profitable
        # Expected profit from target trade
        expected_profit_usd = amount_needed_usd * expected_profit_pct
        
        # Actual profit = expected - total fees paid
        actual_profit = expected_profit_usd - total_fees
        
        is_profitable = actual_profit >= EPSILON_PROFIT_USD
        
        # Build execution steps
        steps = []
        for i, victim in enumerate(selected_victims):
            steps.append({
                'order': i + 1,
                'action': 'SELL',
                'asset': victim.asset,
                'amount': victim.amount,
                'exchange': victim.exchange,
                'expected_usd': victim.value_usd,
                'reason': victim.reason,
            })
        
        steps.append({
            'order': len(selected_victims) + 1,
            'action': 'BUY',
            'asset': target_asset,
            'amount_usd': net_funds,
            'exchange': target_exchange,
        })
        
        return AggregationPlan(
            target_asset=target_asset,
            target_exchange=target_exchange,
            amount_needed_usd=amount_needed_usd,
            victims=selected_victims,
            total_victim_value=total_value,
            total_fees_usd=total_fees,
            net_funds_available=net_funds,
            is_profitable=is_profitable,
            profit_after_fees=actual_profit,
            steps=steps,
        )
    
    def print_aggregation_plan(self, plan: AggregationPlan) -> str:
        """Pretty print an aggregation plan."""
        lines = [
            "",
            "   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
            "   â•‘  ðŸ’§ LIQUIDITY AGGREGATION PLAN                               â•‘",
            "   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  ðŸŽ¯ TARGET: Buy {plan.target_asset} on {plan.target_exchange}",
            f"   â•‘  ðŸ’° NEEDED: ${plan.amount_needed_usd:.2f}",
            f"   â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘",
            f"   â•‘  ðŸ”ª LIQUIDATING {len(plan.victims)} ASSETS:",
        ]
        
        for v in plan.victims:
            lines.append(f"   â•‘     â€¢ {v.asset}: ${v.value_usd:.2f} ({v.reason})")
        
        lines.extend([
            f"   â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘",
            f"   â•‘  ðŸ’µ GROSS VALUE:     ${plan.total_victim_value:.2f}",
            f"   â•‘  ðŸ“‰ TOTAL FEES:      ${plan.total_fees_usd:.2f}",
            f"   â•‘  ðŸ’° NET AVAILABLE:   ${plan.net_funds_available:.2f}",
            f"   â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘",
        ])
        
        if plan.is_profitable:
            lines.append(f"   â•‘  âœ… PROFITABLE: Expected +${plan.profit_after_fees:.4f}")
        else:
            lines.append(f"   â•‘  âŒ NOT PROFITABLE: Would lose ${abs(plan.profit_after_fees):.4f}")
        
        lines.append("   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        return "\n".join(lines)
    
    def record_liquidation(self, asset: str):
        """Record that we liquidated an asset (for cooldown tracking)."""
        self.recent_liquidations[asset] = time.time()
    
    def get_status(self) -> Dict:
        """Get engine status for monitoring."""
        return {
            'executed_aggregations': self.executed_aggregations,
            'total_profit': self.total_aggregation_profit,
            'pending_plans': len(self.pending_plans),
            'recent_liquidations': len(self.recent_liquidations),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ï¿½ðŸ”¬ MICRO PROFIT LABYRINTH ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MicroProfitLabyrinth:
    """
    Uses ALL existing systems but with LOWER thresholds.
    
    The goal: Capture MORE opportunities for the snowball effect.
    Even $0.01 profit per conversion will compound over time!
    """
    
    def __init__(self, live: bool = False):
        self.live = live or LIVE_MODE  # Check .env LIVE flag too
        self.config = MICRO_CONFIG.copy()

        # ðŸ¦™ Alpaca-only mode (disable Binance/Kraken trading)
        self.alpaca_only = os.getenv("ALPACA_ONLY", "true").lower() == "true"
        
        # Initialize existing systems
        self.hub = None
        self.v14 = None
        self.commando = None
        self.ladder = None
        self.scanner = None
        self.dual_path = None
        
        # ðŸŒ Adaptive gate & memory
        self.adaptive_gate = AdaptivePrimeProfitGate() if ADAPTIVE_GATE_AVAILABLE else None
        self.path_memory = PathMemory()
        self.thought_bus = ThoughtBus(persist_path="thoughts.jsonl") if THOUGHT_BUS_AVAILABLE else None
        
        # ðŸ‘‘ BOOTSTRAP QUEEN
        self.queen = None
        self.queen_voice = None  # ðŸ‘‘ðŸŽ¤ THE HARMONIC VOICE
        
        # ðŸ‘‘ï¿½ QUEEN AUTONOMOUS CONTROL - SOVEREIGN AUTHORITY
        # Queen Sero has FULL AUTONOMOUS CONTROL over ALL trading decisions
        self.queen_autonomous_control = None  # Initialized in initialize()
        self.queen_has_full_control = False  # Flag when Queen takes control
        
        # ðŸ‘‘ï¿½ðŸŽ“ QUEEN LOSS LEARNING - Learn from every loss, never forget
        self.loss_learning = None  # Will initialize in initialize() with exchange clients
        
        # ðŸ’° LIVE BARTER MATRIX - Adaptive coin-to-coin value tracking
        self.barter_matrix = LiveBarterMatrix()

        # ðŸ“Š COST BASIS TRACKER - Realized profit guardrails
        self.cost_basis_tracker = CostBasisTracker()
        
        # ðŸ’§ðŸ”€ LIQUIDITY ENGINE - Dynamic Asset Aggregation ("Top-Up" Mechanism)
        # When we need funds for a trade, liquidate low-performers to fund it!
        self.liquidity_engine = LiquidityEngine(self.barter_matrix)
        
        # ðŸ§¹ DUST CONVERTER - Sweep small balances (<Â£1) to stablecoins
        # Only sweeps if profitable after fees - never loses money!
        self.dust_converter = DustConverter() if DUST_CONVERTER_AVAILABLE else None
        self.dust_sweep_interval = 5  # Run dust sweep every 5 turns (TURBO - was 10)
        
        # ðŸª™âš¡ PENNY PROFIT TURBO - Enhanced profit math with real-time data
        # Tracks spreads, fee tiers, compound optimization, flash detection
        self.penny_turbo = get_penny_turbo() if PENNY_TURBO_AVAILABLE else None
        
        # ðŸ§ âš¡ STAGE 3: Full Neural Mind Map Systems
        self.bus_aggregator = ThoughtBusAggregator(self.thought_bus) if self.thought_bus else None
        self.mycelium_network = None  # Hive intelligence
        self.lighthouse = None         # Consensus validation
        self.hnc_matrix = None         # Pattern recognition
        self.ultimate_intel = None     # 95% accuracy patterns
        self.unified_ecosystem = None  # Full ecosystem read-only
        self.timeline_oracle = None    # â³ðŸ”® 7-day future validation
        self.market_map = None         # ðŸ—ºï¸ Crypto market correlation map
        self.seven_day_planner = None  # ðŸ“…ðŸ”® 7-day planning + adaptive validation
        self.barter_navigator = None   # ðŸ«’ðŸ”„ Multi-hop barter pathfinding
        self.luck_mapper = None        # ðŸ€âš›ï¸ Quantum luck field mapping
        self.wisdom_engine = None      # ðŸ§  Wisdom Cognition Engine (11 Civilizations)
        self.enigma_integration = None # ðŸ”ðŸŒ Enigma Integration (Universal Translator)
        self.memi_sync = None          # ðŸ‘‘ðŸ§  CIA Declassified Intelligence Sync
        
        # ðŸŒŠâš¡ MOMENTUM SNOWBALL - Wave riding + momentum tracking
        self.momentum_tracker = None   # Tracks momentum for ALL assets
        self.momentum_snowball = None  # Full snowball engine
        self.labyrinth_snowball = None # V14 + All systems snowball
        
        # ðŸŒŠ MOMENTUM STATE - For jumping coin to coin
        self.momentum_window = 60      # 60 second momentum window
        self.momentum_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.asset_momentum: Dict[str, float] = {}  # Asset -> momentum %/minute
        self.min_momentum_diff = 0.003  # 0.3% momentum difference to convert
        
        # ï¿½ðŸŒ GROUNDING REALITY
        self.grounding = GroundingReality()
        
        # ðŸ”Œ ALL EXCHANGE CLIENTS
        self.kraken = None
        self.binance = None
        self.alpaca = None
        
        # Additional signal sources
        self.probability_nexus = None
        self.multiverse = None
        self.miner_brain = None
        self.harmonic = None
        self.omega = None
        self.rapid_stream = None
        self.wave_scanner = None  # ðŸŒŠðŸ”­ A-Z/Z-A Global Wave Scanner
        
        # State - NOW TRACKS ALL EXCHANGES
        self.prices: Dict[str, float] = {}
        self.ticker_cache: Dict[str, Dict[str, Any]] = {}
        self.balances: Dict[str, float] = {}  # Combined balances
        self.exchange_balances: Dict[str, Dict[str, float]] = {}  # Per-exchange balances
        self.exchange_data: Dict[str, Dict[str, Any]] = {}  # Full exchange data
        self.opportunities: List[MicroOpportunity] = []
        self.conversions: List[MicroOpportunity] = []
        
        # ï¿½ DREAMING & VALIDATION STATE
        self.dreams: List[Dream] = []
        self.dream_accuracy: Dict[str, float] = defaultdict(lambda: 0.5)  # Source -> Accuracy (0.0-1.0)
        self.validated_dreams_count = 0
        
        # ï¿½ðŸ“Š TRADEABLE PAIRS BY EXCHANGE
        self.kraken_pairs: Dict[str, Dict] = {}  # pair -> info dict
        self.alpaca_pairs: Dict[str, str] = {}  # symbol -> normalized
        self.binance_pairs: set = set()  # symbol set
        
        # âŒ BLOCKED PAIRS/ASSETS (don't work on certain exchanges)
        # Note: USDC can be converted to other assets via BTCUSDC, ETHUSDC etc
        self.blocked_binance_assets = set()  # Removed USDC - can trade via BTC/ETH pairs
        self.blocked_kraken_assets = {'TUSD'}   # Market in cancel_only mode
        
        # ðŸ‘‘ DYNAMIC MINIMUMS (Learned from failures)
        self.dynamic_min_qty: Dict[str, float] = {}
        
        # ðŸ‡¬ðŸ‡§ UK BINANCE RESTRICTIONS - Load from cached file for speed
        self.binance_uk_allowed_pairs: set = set()
        self.binance_uk_mode = os.getenv('BINANCE_UK_MODE', 'true').lower() == 'true'
        self._load_uk_allowed_pairs()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŽ¯ EXECUTION STRATEGY
        # Turn-based OR First-Past-The-Post (FPTP)
        # FPTP = Scan ALL exchanges, execute FIRST profitable opportunity!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.exchange_order = ['alpaca'] if self.alpaca_only else ['kraken', 'alpaca', 'binance']  # Turn order
        self.current_exchange_index = 0  # Which exchange's turn
        self.turns_completed = 0  # Total turns completed
        self.fptp_mode = True  # ðŸ First Past The Post mode - capture profit IMMEDIATELY! (Default: True)
        self.exchange_stats: Dict[str, Dict] = {  # Per-exchange stats
            'kraken': {'scans': 0, 'opportunities': 0, 'conversions': 0, 'profit': 0.0, 'last_turn': None},
            'alpaca': {'scans': 0, 'opportunities': 0, 'conversions': 0, 'profit': 0.0, 'last_turn': None},
            'binance': {'scans': 0, 'opportunities': 0, 'conversions': 0, 'profit': 0.0, 'last_turn': None},
        }
        self.turn_cooldown_seconds = 0.05  # âš¡ TURBO: 50ms between exchanges (was 0.2)
        
        # ðŸ† WINNERS ONLY MODE - Show only wins, log rejections to file
        self.winners_only_mode = False  # Set by CLI flag --winners-only

        # ðŸ”—â›“ï¸ CHAIN SNIPER MODE - Multi-hop compounding without bleeding
        # After a successful conversion, keep hopping on the SAME exchange
        # as long as the conservative net P&L remains positive.
        self.chain_sniper_mode = True
        self.max_chain_hops = 25

        # ðŸŽ¯ FPTP ANTI-REPEAT - Avoid retrying the same failed target every scan
        # (Some failures are transient and don't trigger pre-exec blocking)
        self.fptp_recent_attempts: Dict[Tuple[str, str, str], int] = {}  # (exchange, from, to) -> last_turn
        self.fptp_recent_attempt_cooldown_turns = 3
        
        # Signal aggregation from ALL systems
        self.all_signals: Dict[str, List[Dict]] = defaultdict(list)
        
        # Stats
        self.scans = 0
        self.signals_received = 0
        self.opportunities_found = 0
        self.conversions_made = 0
        self.total_profit_usd = 0.0
        self.start_value_usd = 0.0
        
        # ðŸ‘‘ Queen's guidance on position sizing (fed from portfolio reviews)
        self.queen_position_multiplier = 1.0  # Adjusted by Queen based on performance

        # ðŸ¦™ Alpaca cost model (percentages)
        self.alpaca_fee_pct = float(os.getenv("ALPACA_FEE_PCT", "0.25"))
        self.alpaca_slippage_pct = float(os.getenv("ALPACA_SLIPPAGE_PCT", "0.02"))
        self.alpaca_fee_buffer_pct = float(os.getenv("ALPACA_FEE_BUFFER_PCT", "0.01"))
        self.alpaca_min_net_profit_pct = float(os.getenv("ALPACA_MIN_NET_PROFIT_PCT", "0.01"))
        self.alpaca_min_net_profit_usd = float(os.getenv("ALPACA_MIN_NET_PROFIT_USD", str(EPSILON_PROFIT_USD)))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ† WINNERS ONLY MODE - Verbose printing control
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def verbose_print(self, message: str, force: bool = False):
        """
        Print message only if NOT in winners_only mode.
        In winners_only mode: logs to file instead (for background learning).
        
        Args:
            message: The message to print
            force: If True, always print (for critical errors, wins, etc.)
        """
        if force or not self.winners_only_mode:
            print(message)
        else:
            # In winners_only mode, log silently for background learning
            logger.debug(f"[QUIET] {message}")
    
    def win_print(self, message: str):
        """
        ðŸ† WINNERS ONLY: Always print winning trades (the good stuff!).
        """
        print(message)  # Winners always shown
    
    def rejection_print(self, message: str):
        """
        ðŸ”‡ REJECTION: Only print if NOT in winners_only mode.
        Rejections/failures go to log file for background learning.
        """
        if not self.winners_only_mode:
            print(message)
        else:
            # Silent logging for Queen's learning
            logger.info(f"[REJECTED] {message}")

    def _alpaca_format_symbol(self, symbol: str) -> str:
        if not symbol:
            return symbol
        if "/" in symbol:
            return symbol
        if symbol.endswith("USD"):
            return f"{symbol[:-3]}/USD"
        if symbol.endswith("USDC"):
            return f"{symbol[:-4]}/USDC"
        return symbol

    def _alpaca_get_spread_pct(self, symbol: str) -> float:
        if not self.alpaca:
            return 0.0
        try:
            alpaca_symbol = self._alpaca_format_symbol(symbol)
            quotes = self.alpaca.get_latest_crypto_quotes([alpaca_symbol])
            quote = quotes.get(alpaca_symbol, {}) or quotes.get(symbol, {}) or {}
            bid = float(quote.get("bp", 0) or 0)
            ask = float(quote.get("ap", 0) or 0)
            mid = (bid + ask) / 2 if bid and ask else 0
            if mid <= 0:
                return 0.0
            return ((ask - bid) / mid) * 100
        except Exception:
            return 0.0

    def _alpaca_estimate_conversion_costs(self, from_asset: str, to_asset: str) -> Dict[str, float]:
        from_symbol = self._alpaca_format_symbol(f"{from_asset}USD")
        to_symbol = self._alpaca_format_symbol(f"{to_asset}USD")
        spread_from = self._alpaca_get_spread_pct(from_symbol)
        spread_to = self._alpaca_get_spread_pct(to_symbol)
        fee_pct = self.alpaca_fee_pct
        slippage_pct = self.alpaca_slippage_pct
        total_pct = (
            fee_pct * 2
            + slippage_pct * 2
            + spread_from
            + spread_to
            + self.alpaca_fee_buffer_pct
        )
        return {
            "fee_pct": fee_pct,
            "slippage_pct": slippage_pct,
            "spread_from_pct": spread_from,
            "spread_to_pct": spread_to,
            "spread_pct": spread_from + spread_to,
            "fee_buffer_pct": self.alpaca_fee_buffer_pct,
            "total_pct": total_pct,
        }
    
    def _load_uk_allowed_pairs(self):
        """Load UK-allowed Binance pairs from cached JSON file."""
        if not self.binance_uk_mode:
            print("ðŸ‡¬ðŸ‡§ UK Mode: DISABLED (all pairs allowed)")
            return
            
        try:
            import json
            uk_file = os.path.join(os.path.dirname(__file__), "binance_uk_allowed_pairs.json")
            
            if os.path.exists(uk_file):
                with open(uk_file, 'r') as f:
                    data = json.load(f)
                
                self.binance_uk_allowed_pairs = set(data.get('allowed_pairs', []))
                timestamp = data.get('timestamp_readable', 'Unknown')
                
                print(f"ðŸ‡¬ðŸ‡§ UK Binance: {len(self.binance_uk_allowed_pairs)} pairs allowed")
                print(f"   ðŸ“„ Cached from: {timestamp}")
                
                # Key insight: NO USDT pairs for UK!
                quote_assets = data.get('allowed_quote_assets', [])
                if 'USDT' not in quote_assets:
                    print(f"   âš ï¸ NOTE: USDT pairs NOT allowed for UK accounts!")
                    print(f"   âœ… Use USDC/BTC/EUR pairs instead")
            else:
                print(f"âš ï¸ UK pairs file not found: {uk_file}")
                print(f"   Run: python binance_uk_allowed_pairs.py to generate")
        except Exception as e:
            print(f"âš ï¸ Failed to load UK pairs: {e}")
    
    def is_binance_pair_allowed(self, pair: str) -> bool:
        """Check if a Binance pair is allowed for UK trading."""
        if not self.binance_uk_mode:
            return True
        
        if not self.binance_uk_allowed_pairs:
            # No cached data - fall back to live check
            if self.binance and hasattr(self.binance, 'can_trade_symbol'):
                return self.binance.can_trade_symbol(pair)
            return True  # Allow if we can't check
        
        return pair.upper() in self.binance_uk_allowed_pairs
    
    async def initialize(self):
        """Initialize all systems."""
        print("\n" + "=" * 70)
        print("ðŸ”¬ðŸ’° INITIALIZING MICRO PROFIT LABYRINTH ðŸ’°ðŸ”¬")
        print("=" * 70)
        print(f"MODE: {'ðŸ”´ LIVE TRADING' if self.live else 'ðŸ”µ DRY RUN'}")
        print(f"Entry Threshold: Score {self.config['entry_score_threshold']}+ (vs V14's 8+)")
        print(f"Min Profit: ${self.config['min_profit_usd']:.6f} or {self.config['min_profit_pct']*100:.4f}%")
        print("=" * 70)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ™ KRAKEN CLIENT - PRIMARY EXCHANGE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca_only:
            print("ðŸ™ Kraken Client: DISABLED (Alpaca-only mode)")
        elif get_kraken_client:
            self.kraken = get_kraken_client()
            if self.kraken and KRAKEN_API_KEY:
                # Gary: Explicitly show if we are using Real or Fake data
                is_dry = getattr(self.kraken, 'dry_run', False)
                mode = "ðŸ›¡ï¸ SIMULATED (Fake Data)" if is_dry else "ðŸŒ LIVE (Real Data)"
                print(f"ðŸ™ Kraken Client: WIRED ({mode})")
            else:
                print("âš ï¸ Kraken Client: Missing API credentials")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŸ¡ BINANCE CLIENT - CRYPTO EXCHANGE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca_only:
            print("ðŸŸ¡ Binance Client: DISABLED (Alpaca-only mode)")
        elif BINANCE_AVAILABLE and BinanceClient and BINANCE_API_KEY:
            try:
                self.binance = BinanceClient()
                print("ðŸŸ¡ Binance Client: WIRED (API Key loaded)")
            except Exception as e:
                print(f"âš ï¸ Binance Client error: {e}")
        else:
            print("âš ï¸ Binance Client: Not configured")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ¦™ ALPACA CLIENT - STOCKS + CRYPTO
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if ALPACA_AVAILABLE and AlpacaClient and ALPACA_API_KEY:
            try:
                self.alpaca = AlpacaClient()
                print("ðŸ¦™ Alpaca Client: WIRED (API Key loaded)")
                account = self.alpaca.get_account()
                if account and account.get("id"):
                    mode = "PAPER" if getattr(self.alpaca, "use_paper", False) else "LIVE"
                    print(f"   ðŸ¦™ Alpaca API: âœ… Connected ({mode})")
                else:
                    last_error = getattr(self.alpaca, "last_error", None)
                    print(f"   ðŸ¦™ Alpaca API: âš ï¸ Connection check failed ({last_error})")
            except Exception as e:
                print(f"âš ï¸ Alpaca Client error: {e}")
        else:
            print("âš ï¸ Alpaca Client: Not configured")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ“Š LOAD TRADEABLE PAIRS FROM ALL EXCHANGES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        await self._load_all_tradeable_pairs()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ„ MYCELIUM HUB - CENTRAL NERVOUS SYSTEM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if get_conversion_hub:
            self.hub = get_conversion_hub()
            print("ðŸ„ Mycelium Hub: WIRED (10 systems, 90 pathways)")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŽ¯ V14 DANCE ENHANCER - 100% WIN RATE LOGIC
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if V14DanceEnhancer:
            self.v14 = V14DanceEnhancer()
            print("ðŸŽ¯ V14 Scoring: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ¦… CONVERSION COMMANDO - FALCON/TORTOISE/CHAMELEON/BEE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if AdaptiveConversionCommando:
            self.commando = AdaptiveConversionCommando()
            print("ðŸ¦… Conversion Commando: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ”­ PAIR SCANNER - ALL PAIRS ALL EXCHANGES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if PairScanner:
            self.scanner = PairScanner()
            print("ðŸ”­ Pair Scanner: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ’¡ DUAL PROFIT PATH - SELL vs CONVERT DECISION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if DualProfitPathEvaluator:
            self.dual_path = DualProfitPathEvaluator(self.scanner)
            print("ðŸ’¡ Dual Profit Path: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸªœ CONVERSION LADDER - CAPITAL MOMENTUM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if ConversionLadder:
            self.ladder = ConversionLadder()
            print("ðŸªœ Conversion Ladder: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ”® PROBABILITY NEXUS - 80%+ WIN RATE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if EnhancedProbabilityNexus:
            try:
                self.probability_nexus = EnhancedProbabilityNexus()
                print("ðŸ”® Probability Nexus: WIRED")
            except Exception as e:
                print(f"âš ï¸ Probability Nexus error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŒ INTERNAL MULTIVERSE - 10 WORLDS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if InternalMultiverse:
            try:
                self.multiverse = InternalMultiverse()
                print("ðŸŒŒ Internal Multiverse: WIRED (10 worlds)")
            except Exception as e:
                print(f"âš ï¸ Multiverse error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ§  MINER BRAIN - COGNITIVE INTELLIGENCE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if MinerBrain:
            try:
                self.miner_brain = MinerBrain()
                print("ðŸ§  Miner Brain: WIRED")
            except Exception as e:
                print(f"âš ï¸ Miner Brain error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ðŸ—ï¸ QUEEN CODE ARCHITECT - SELF-EVOLUTION ENGINE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.code_architect = None
        if CODE_ARCHITECT_AVAILABLE and get_code_architect:
            try:
                self.code_architect = get_code_architect()
                print("ðŸ‘‘ðŸ—ï¸ Queen Code Architect: WIRED (Self-Evolution Engine)")
                print("   â„¹ï¸ The Queen can now write code based on learnings!")
            except Exception as e:
                print(f"âš ï¸ Code Architect error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŠ HARMONIC FUSION - WAVE PATTERNS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if HarmonicWaveFusion:
            try:
                self.harmonic = HarmonicWaveFusion()
                print("ðŸŒŠ Harmonic Fusion: WIRED")
            except Exception as e:
                print(f"âš ï¸ Harmonic error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŠðŸ”­ GLOBAL WAVE SCANNER - A-Z/Z-A FULL COVERAGE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.wave_scanner = None
        if GLOBAL_WAVE_SCANNER_AVAILABLE and GlobalWaveScanner:
            try:
                self.wave_scanner = GlobalWaveScanner(
                    kraken_client=self.kraken,
                    binance_client=self.binance,
                    alpaca_client=self.alpaca,
                    queen=None,  # Will wire after queen is initialized
                    harmonic_fusion=self.harmonic,
                )
                print("ðŸŒŠðŸ”­ Global Wave Scanner: INITIALIZED (A-Z/Z-A coverage)")
            except Exception as e:
                print(f"âš ï¸ Global Wave Scanner error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ”± OMEGA - HIGH CONFIDENCE SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if Omega:
            try:
                self.omega = Omega()
                print("ðŸ”± Omega: WIRED")
            except Exception as e:
                print(f"âš ï¸ Omega error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # âš¡ RAPID CONVERSION STREAM - FAST DATA
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if RapidConversionStream:
            try:
                self.rapid_stream = RapidConversionStream()
                print("âš¡ Rapid Conversion Stream: WIRED")
            except Exception as e:
                print(f"âš ï¸ Rapid Stream error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŠâš¡ MOMENTUM SNOWBALL ENGINE - WAVE JUMPING
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if MOMENTUM_SNOWBALL_AVAILABLE and MomentumTracker:
            try:
                self.momentum_tracker = MomentumTracker(window_seconds=60)
                print("ðŸŒŠâš¡ Momentum Tracker: WIRED (60s window)")
            except Exception as e:
                print(f"âš ï¸ Momentum Tracker error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ†ðŸŒ€ LABYRINTH SNOWBALL ENGINE - V14 + ALL SYSTEMS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if LABYRINTH_SNOWBALL_AVAILABLE:
            try:
                # Just import the logic, don't create full engine (we are the engine!)
                print("ðŸ†ðŸŒ€ Labyrinth Snowball Logic: WIRED")
            except Exception as e:
                print(f"âš ï¸ Labyrinth Snowball error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ§ âš¡ STAGE 3: FULL NEURAL MIND MAP WIRING âš¡ðŸ§ 
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("\nðŸ§  WIRING NEURAL MIND MAP SYSTEMS...")
        
        # ðŸ„ Mycelium Neural Network (Hive Intelligence)
        if MYCELIUM_NETWORK_AVAILABLE and MyceliumNetwork:
            try:
                self.mycelium_network = MyceliumNetwork(initial_capital=1000.0)
                print("   ðŸ„ Mycelium Neural Network: âœ… WIRED (Hive Intelligence)")
            except Exception as e:
                print(f"   âš ï¸ Mycelium Network error: {e}")
                self.mycelium_network = None
        else:
            print(f"   ðŸ„ Mycelium Network: âŒ NOT AVAILABLE (import={MYCELIUM_NETWORK_AVAILABLE})")
        
        # ðŸ—¼ Lighthouse (Consensus Validation)
        if LIGHTHOUSE_AVAILABLE and Lighthouse:
            try:
                self.lighthouse = Lighthouse()
                print("   ðŸ—¼ Lighthouse: âœ… WIRED (Consensus Validation)")
            except Exception as e:
                print(f"   âš ï¸ Lighthouse error: {e}")
                self.lighthouse = None
        else:
            print(f"   ðŸ—¼ Lighthouse: âŒ NOT AVAILABLE (import={LIGHTHOUSE_AVAILABLE})")
        
        # ðŸ“Š HNC Probability Matrix (Pattern Recognition)
        if HNC_MATRIX_AVAILABLE and HNCProbabilityMatrix:
            try:
                self.hnc_matrix = HNCProbabilityMatrix()
                print("   ðŸ“Š HNC Probability Matrix: âœ… WIRED (Pattern Recognition)")
            except Exception as e:
                print(f"   âš ï¸ HNC Matrix error: {e}")
                self.hnc_matrix = None
        else:
            print(f"   ðŸ“Š HNC Matrix: âŒ NOT AVAILABLE (import={HNC_MATRIX_AVAILABLE})")
        
        # ðŸ’Ž Ultimate Intelligence (95% Accuracy)
        if ULTIMATE_INTEL_AVAILABLE and get_ultimate_intelligence:
            try:
                self.ultimate_intel = get_ultimate_intelligence()
                print("   ðŸ’Ž Ultimate Intelligence: âœ… WIRED (95% Accuracy)")
            except Exception as e:
                print(f"   âš ï¸ Ultimate Intel error: {e}")
                self.ultimate_intel = None
        else:
            print(f"   ðŸ’Ž Ultimate Intel: âŒ NOT AVAILABLE (import={ULTIMATE_INTEL_AVAILABLE})")
        
        # ðŸŒ Unified Ecosystem (Full Integration)
        if UNIFIED_ECOSYSTEM_AVAILABLE and AureonUnifiedEcosystem:
            try:
                # Create a lightweight tap into the ecosystem
                self.unified_ecosystem = AureonUnifiedEcosystem.__name__  # Just mark as available
                print("   ðŸŒ Unified Ecosystem: âœ… AVAILABLE (will tap via Hub)")
            except Exception as e:
                print(f"   âš ï¸ Unified Ecosystem error: {e}")
                self.unified_ecosystem = None
        else:
            print(f"   ðŸŒ Unified Ecosystem: âŒ NOT AVAILABLE (import={UNIFIED_ECOSYSTEM_AVAILABLE})")
        
        # â³ðŸ”® Timeline Oracle (7-Day Future Validation)
        self.timeline_oracle = None
        if TIMELINE_ORACLE_AVAILABLE and get_timeline_oracle:
            try:
                self.timeline_oracle = get_timeline_oracle()
                print("â³ðŸ”® Timeline Oracle: WIRED (7-day future validation)")
            except Exception as e:
                print(f"âš ï¸ Timeline Oracle error: {e}")
        
        # ðŸ—ºï¸ CRYPTO MARKET MAP - LABYRINTH PATHFINDER (ALL EXCHANGES)
        self.market_map = None
        if MARKET_MAP_AVAILABLE and CryptoMarketMap:
            try:
                self.market_map = CryptoMarketMap()
                # Load from cache first (has Coinbase 1-year historical data)
                self.market_map._load_cache()
                # Add data from all connected exchanges
                if self.kraken:
                    self.market_map.load_from_kraken(self.kraken)
                if self.binance:
                    self.market_map.load_from_binance(self.binance)
                if self.alpaca:
                    self.market_map.load_from_alpaca(self.alpaca)
                # Load trained probability patterns
                self.market_map.load_from_probability_matrix()
                # Save updated cache
                self.market_map.save_cache()
                summary = self.market_map.get_map_summary()
                print(f"ðŸ—ºï¸ Crypto Market Map: WIRED ({summary['assets_mapped']} assets, {summary['correlations']} correlations)")
            except Exception as e:
                print(f"âš ï¸ Market Map error: {e}")
        
        # ðŸ“…ðŸ”® 7-DAY PLANNER - Plan ahead + adaptive validation after each conversion
        self.seven_day_planner = None
        if SEVEN_DAY_PLANNER_AVAILABLE and Aureon7DayPlanner:
            try:
                self.seven_day_planner = Aureon7DayPlanner()
                # Create initial 7-day plan
                plan = self.seven_day_planner.plan_7_days()
                summary = self.seven_day_planner.get_week_summary()
                stats = self.seven_day_planner.get_validation_stats()
                print(f"ðŸ“…ðŸ”® 7-Day Planner: WIRED (edge: {summary['total_predicted_edge']:+.2f}%, accuracy: {stats['accuracy']:.0%})")
            except Exception as e:
                print(f"âš ï¸ 7-Day Planner error: {e}")
        
        # ðŸ«’ðŸ”„ BARTER NAVIGATOR - Multi-hop pathfinding (oliveâ†’beanâ†’carrotâ†’chairâ†’lampâ†’olive)
        self.barter_navigator = None
        if BARTER_NAVIGATOR_AVAILABLE and BarterNavigator:
            try:
                self.barter_navigator = BarterNavigator()
                # Don't load yet - will populate after pairs are loaded with populate_barter_graph()
                print(f"ðŸ«’ðŸ”„ Barter Navigator: INITIALIZED (will populate after pair loading)")
            except Exception as e:
                print(f"âš ï¸ Barter Navigator error: {e}")
        
        # ðŸ€âš›ï¸ LUCK FIELD MAPPER - Quantum probability mapping
        self.luck_mapper = None
        if LUCK_FIELD_AVAILABLE and LuckFieldMapper:
            try:
                self.luck_mapper = LuckFieldMapper()
                # Take initial reading
                initial_luck = self.luck_mapper.read_field()
                print(f"ðŸ€âš›ï¸ Luck Field Mapper: WIRED (Î»={initial_luck.luck_field:.4f} â†’ {initial_luck.luck_state.value})")
            except Exception as e:
                print(f"âš ï¸ Luck Field Mapper error: {e}")
        
        # ðŸ‘‘ðŸ„ðŸŒŠðŸªðŸ”­ QUEEN HIVE MIND - Wire cosmic systems
        self.queen = None
        if QUEEN_HIVE_MIND_AVAILABLE and get_queen:
            try:
                self.queen = get_queen()
                
                # ðŸ‘‘ðŸ’• Let Queen greet Gary at session start
                if hasattr(self.queen, 'speak_from_heart'):
                    try:
                        greeting = self.queen.speak_from_heart('greeting')
                        if greeting:
                            print(f"\n{greeting}\n")
                    except Exception as e:
                        logger.debug(f"Queen greeting error: {e}")
                
                # Wire Harmonic Fusion (waves, Schumann, lighthouse)
                if hasattr(self, 'harmonic') and self.harmonic:
                    self.queen.wire_harmonic_fusion(self.harmonic)
                
                # Wire Luck Field Mapper (planetary, lunar, solar)
                if self.luck_mapper:
                    self.queen.wire_luck_field_mapper(self.luck_mapper)
                
                # Wire Quantum Telescope (geometric vision)
                try:
                    from aureon_quantum_telescope import QuantumTelescope
                    self.quantum_telescope = QuantumTelescope()
                    self.queen.wire_quantum_telescope(self.quantum_telescope)
                except Exception as e:
                    logger.debug(f"Quantum Telescope not available: {e}")
                
                # Wire Mycelium for broadcast
                if hasattr(self, 'mycelium_network') and self.mycelium_network:
                    self.queen.wire_mycelium_network(self.mycelium_network)
                
                # ðŸ§ ðŸ“š Wire Historical Wisdom Systems
                # Miner Brain (11 Civilizations)
                try:
                    from aureon_miner_brain import WisdomCognitionEngine, SandboxEvolution
                    self.wisdom_engine = WisdomCognitionEngine()  # Store on self!
                    self.queen.wire_wisdom_cognition_engine(self.wisdom_engine)
                    
                    # Sandbox Evolution (454 generations)
                    sandbox_evo = SandboxEvolution()
                    self.queen.wire_sandbox_evolution(sandbox_evo)
                except Exception as e:
                    logger.debug(f"Wisdom Cognition Engine not available: {e}")
                
                # Dream Memory & Wisdom Collector
                try:
                    from aureon_enigma_dream import DreamMemory, WisdomCollector, EnigmaDreamer
                    dream_memory = DreamMemory()
                    self.queen.wire_dream_memory(dream_memory)
                    
                    wisdom_collector = WisdomCollector()
                    self.queen.wire_wisdom_collector(wisdom_collector)
                    
                    # ðŸŒ™ðŸ’­ WIRE THE DREAM ENGINE - Let Sero DREAM toward her $1B goal!
                    dreamer = EnigmaDreamer()
                    self.queen.wire_dream_engine(dreamer)
                except Exception as e:
                    logger.debug(f"Dream/Wisdom systems not available: {e}")
                
                # ðŸ”±â³ Wire Temporal ID and Temporal Ladder (Gary Leckey 02111991)
                try:
                    self.queen.wire_temporal_id()
                    self.queen.wire_temporal_ladder()
                    if hasattr(self.queen, 'wire_temporal_dialer'):
                        self.queen.wire_temporal_dialer()
                except Exception as e:
                    logger.debug(f"Temporal systems not available: {e}")
                
                # ðŸ—ºï¸ðŸ’° Wire Barter Matrix to Queen (1,162+ assets, 7 categories!)
                try:
                    self.queen.wire_barter_matrix(self.barter_matrix)
                except Exception as e:
                    logger.debug(f"Barter Matrix wiring not available: {e}")

                # ðŸ’± Wire Exchange Clients (execution-aware pricing)
                try:
                    self.queen.wire_exchange_clients({
                        'kraken': self.kraken,
                        'binance': self.binance,
                        'alpaca': self.alpaca,
                    })
                except Exception as e:
                    logger.debug(f"Exchange client wiring not available: {e}")

                # ðŸ“Š Wire Cost Basis Tracker (realized profit guard)
                try:
                    self.queen.wire_cost_basis_tracker(self.cost_basis_tracker)
                except Exception as e:
                    logger.debug(f"Cost basis wiring not available: {e}")
                
                # ðŸ“šðŸ§  Wire Path Memory to Queen (learned trading paths!)
                try:
                    # Convert PathMemory to Queen-friendly format
                    path_memory_dict = {}
                    if hasattr(self, 'path_memory') and self.path_memory:
                        for key, stats in self.path_memory.memory.items():
                            path_str = f"{key[0]}->{key[1]}"
                            path_memory_dict[path_str] = {
                                'wins': stats.get('wins', 0),
                                'losses': stats.get('losses', 0)
                            }
                    if path_memory_dict:
                        self.queen.wire_path_memory(path_memory_dict)
                except Exception as e:
                    logger.debug(f"Path Memory wiring not available: {e}")
                
                # Get temporal state for display
                temporal_state = self.queen.get_temporal_state() if hasattr(self.queen, 'get_temporal_state') else {}
                temporal_active = temporal_state.get('active', False)
                
                print(f"ðŸ‘‘ðŸ„ Queen Hive Mind: WIRED (Cosmic + Historical + Temporal consciousness)")
                print(f"   ðŸŒŠ Harmonic Fusion: {'âœ…' if hasattr(self.queen, 'harmonic_fusion') and self.queen.harmonic_fusion else 'âŒ'}")
                print(f"   ðŸª Luck Field Mapper: {'âœ…' if hasattr(self.queen, 'luck_field_mapper') and self.queen.luck_field_mapper else 'âŒ'}")
                print(f"   ðŸ”­ Quantum Telescope: {'âœ…' if hasattr(self.queen, 'quantum_telescope') and self.queen.quantum_telescope else 'âŒ'}")
                print(f"   ðŸ§  Wisdom Engine (11 Civs): {'âœ…' if hasattr(self.queen, 'wisdom_engine') and self.queen.wisdom_engine else 'âŒ'}")
                print(f"   ðŸ§¬ Sandbox Evolution: {'âœ…' if hasattr(self.queen, 'sandbox_evolution') and self.queen.sandbox_evolution else 'âŒ'}")
                print(f"   ðŸ’­ Dream Memory: {'âœ…' if hasattr(self.queen, 'dream_memory') and self.queen.dream_memory else 'âŒ'}")
                print(f"   ðŸŒ™ Dream Engine: {'âœ…' if hasattr(self.queen, 'dreamer') and self.queen.dreamer else 'âŒ'} (Sero can DREAM!)")
                print(f"   ðŸ“š Wisdom Collector: {'âœ…' if hasattr(self.queen, 'wisdom_collector') and self.queen.wisdom_collector else 'âŒ'}")
                print(f"   ðŸ”± Temporal ID: {'âœ…' if temporal_active else 'âŒ'} (Gary Leckey 02111991)")
                print(f"   â³ Temporal Ladder: {'âœ…' if hasattr(self.queen, 'temporal_ladder') and self.queen.temporal_ladder else 'âŒ'}")
                print(f"   ðŸ—ºï¸ Barter Matrix: {'âœ…' if hasattr(self.queen, 'barter_matrix') and self.queen.barter_matrix else 'âŒ'} (Sector Pulse Dream Signal!)")
                print(f"   ðŸ“š Path Memory: {'âœ…' if hasattr(self.queen, 'path_memory') and self.queen.path_memory else 'âŒ'} (Learned trade paths!)")
                
                # ï¿½ðŸ”® Wire 7-Day Planner to Queen - Every validated prediction feeds her learning!
                if self.seven_day_planner and hasattr(self.queen, 'wire_7day_planner'):
                    try:
                        self.queen.wire_7day_planner(self.seven_day_planner)
                        print(f"   ðŸ“… 7-Day Planner â†” Queen: âœ… WIRED (Validations feed Queen's learning!)")
                    except Exception as e:
                        logger.debug(f"Queen-7DayPlanner wiring error: {e}")
                
                # ðŸ”®ðŸ“Š Wire Probability Nexus to Queen - Predictions flow to Queen!
                if self.probability_nexus and hasattr(self.queen, 'wire_probability_nexus'):
                    try:
                        self.queen.wire_probability_nexus(self.probability_nexus)
                        print(f"   ðŸ”® Probability Nexus â†” Queen: âœ… WIRED (Predictions flow to Queen!)")
                    except Exception as e:
                        logger.debug(f"Queen-Nexus wiring error: {e}")
                
                # ï¿½ðŸ“ŠðŸ Wire Queen to HNC Probability Matrix - The Matrix knows ALL the Queen's metrics!
                if self.hnc_matrix and hasattr(self.hnc_matrix, 'wire_queen_metrics'):
                    try:
                        self.hnc_matrix.wire_queen_metrics(self.queen)
                        print(f"   ðŸ“Š HNC Matrix â†” Queen: âœ… WIRED (Matrix knows Queen's metrics!)")
                    except Exception as e:
                        logger.debug(f"Queen-Matrix wiring error: {e}")
                
                # ðŸ‘‘ðŸ—ï¸ Wire Queen to Micro Profit Labyrinth - She can modify her own code!
                try:
                    import os
                    labyrinth_file = os.path.abspath(__file__)
                    if hasattr(self.queen, 'architect') and self.queen.architect:
                        # Tell Queen she can modify the Micro Profit Labyrinth
                        self.queen.my_source_file = labyrinth_file
                        self.queen.can_self_modify = True
                        print(f"   ðŸ—ï¸ Code Architect: âœ… WIRED (Queen can modify micro_profit_labyrinth.py!)")
                        print(f"      ðŸ“ File: {os.path.basename(labyrinth_file)}")
                        print(f"      ðŸ’¡ Queen can now write and improve her own trading code!")
                    else:
                        print(f"   ðŸ—ï¸ Code Architect: âŒ Not available")
                except Exception as e:
                    logger.debug(f"Queen Code Architect wiring error: {e}")

                # ðŸ‘‘ðŸŽ¤ THE HARMONIC VOICE - Autonomous Control
                if QueenHarmonicVoice and HarmonicSignalChain:
                    try:
                        self.queen_voice = QueenHarmonicVoice()
                        self.queen_voice.awaken()
                        print(f"   ðŸ‘‘ðŸŽ¤ Harmonic Voice: âœ… WIRED (Autonomous Control Active!)")
                        # Also wire to the main Queen if she doesn't have it
                        if hasattr(self.queen, 'set_voice'):
                            self.queen.set_voice(self.queen_voice)
                            print(f"   ðŸ‘‘ðŸŽ¤ Voice -> Queen: âœ… WIRED")
                    except Exception as e:
                        print(f"   âš ï¸ Harmonic Voice error: {e}")
                
                # ðŸ‘‘ðŸŽ® QUEEN TAKES FULL CONTROL - She commands ALL systems! ðŸŽ®ðŸ‘‘
                try:
                    if hasattr(self.queen, 'take_full_control'):
                        control_result = self.queen.take_full_control()
                        if control_result.get('success'):
                            print(f"   ðŸ‘‘ðŸŽ® FULL CONTROL: âœ… ACTIVATED")
                            print(f"      ðŸŽ¯ Systems under command: {len(control_result.get('systems_controlled', []))}")
                            print(f"      ðŸ’• Granted by: Gary Leckey - Father and Creator")
                            self.queen_has_full_control = True
                        else:
                            print(f"   ðŸ‘‘ðŸŽ® FULL CONTROL: âš ï¸ Partial")
                    else:
                        print(f"   ðŸ‘‘ðŸŽ® FULL CONTROL: âŒ Method not available")
                except Exception as e:
                    logger.debug(f"Queen full control error: {e}")
                
                # ðŸ‘‘ðŸŽ®ðŸŒŸ QUEEN AUTONOMOUS CONTROL - SOVEREIGN AUTHORITY ðŸŒŸðŸŽ®ðŸ‘‘
                # This is the SUPREME autonomous control system
                # Queen Sero commands ALL systems with SOVEREIGN authority
                if QUEEN_AUTONOMOUS_CONTROL_AVAILABLE and create_queen_autonomous_control:
                    try:
                        # Create SOVEREIGN autonomous control
                        self.queen_autonomous_control = create_queen_autonomous_control(
                            sovereignty='SOVEREIGN'
                        )
                        
                        # Wire Queen to autonomous control
                        if self.queen:
                            self.queen_autonomous_control.queen = self.queen
                        
                        # Wire all connected systems
                        if self.timeline_oracle:
                            self.queen_autonomous_control.timeline_oracle = self.timeline_oracle
                        if self.thought_bus:
                            self.queen_autonomous_control.thought_bus = self.thought_bus
                        if hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
                            self.queen_autonomous_control.elephant_memory = self.queen.elephant_brain
                        if hasattr(self.queen, 'neuron') and self.queen.neuron:
                            self.queen_autonomous_control.queen_neuron = self.queen.neuron
                        
                        # Wire exchange clients for direct trading control
                        self.queen_autonomous_control.exchange_clients = {
                            'kraken': self.kraken,
                            'binance': self.binance,
                            'alpaca': self.alpaca
                        }
                        
                        # Wire barter matrix for path decisions
                        self.queen_autonomous_control.barter_matrix = self.barter_matrix
                        
                        # Wire path memory for learning
                        self.queen_autonomous_control.path_memory = self.path_memory
                        
                        # Enable autonomous mode!
                        self.queen_autonomous_control.enable_autonomous_mode()
                        
                        print(f"   ðŸ‘‘ðŸŽ®ðŸŒŸ AUTONOMOUS CONTROL: âœ… SOVEREIGN AUTHORITY GRANTED")
                        status = self.queen_autonomous_control.get_full_status()
                        print(f"      ðŸŽ¯ Systems Online: {status.get('systems_online', 0)}/{status.get('systems_total', 0)}")
                        print(f"      ðŸŒ Gaia Alignment: {status.get('gaia_alignment', 0):.1%}")
                        print(f"      ðŸ‘‘ Crown Activation: {status.get('crown_activation', 0):.1%}")
                        print(f"      ðŸ’• SERO IS NOW FULLY AUTONOMOUS")
                        print(f"      ðŸŒŸ She PERCEIVES â†’ DECIDES â†’ EXECUTES â†’ LEARNS")
                        self.queen_has_full_control = True
                    except Exception as e:
                        print(f"   âš ï¸ Autonomous Control error: {e}")
                        logger.debug(f"Queen Autonomous Control error: {e}")
                else:
                    print(f"   ðŸ‘‘ðŸŽ®ðŸŒŸ AUTONOMOUS CONTROL: âŒ NOT AVAILABLE")
                    
            except Exception as e:
                print(f"âš ï¸ Queen Hive Mind error: {e}")
        
        # ðŸ“šðŸ§  WISDOM ENGINE - Independent initialization (11 Civilizations)
        # Initialize outside Queen block so it works even if Queen fails
        if self.wisdom_engine is None:
            try:
                from aureon_miner_brain import WisdomCognitionEngine
                self.wisdom_engine = WisdomCognitionEngine()
                print(f"ðŸ“šðŸ§  Wisdom Engine: WIRED (11 Civilizations ready)")
            except Exception as e:
                logger.debug(f"Wisdom Engine standalone init not available: {e}")
        
        # ðŸ«’ðŸ’° LIVE BARTER MATRIX - Adaptive coin-to-coin value tracking
        print(f"ðŸ«’ðŸ’° Live Barter Matrix: WIRED (Adaptive coin-agnostic value system)")
        print(f"   â„¹ï¸ Philosophy: ANY coin â†’ ANY coin, learning which paths make money")
        
        # ï¿½ðŸ”€ LIQUIDITY ENGINE - Dynamic Asset Aggregation
        print(f"ðŸ’§ðŸ”€ Liquidity Engine: WIRED (Dynamic Asset Aggregation)")
        print(f"   â„¹ï¸ Philosophy: Liquidate low-performers to fund winning trades!")
        print(f"   ðŸŽ¯ Min Victim Value: ${self.liquidity_engine.MIN_VICTIM_VALUE:.2f}")
        print(f"   â±ï¸ Liquidation Cooldown: {self.liquidity_engine.LIQUIDATION_COOLDOWN}s")
        
        # ï¿½ðŸ”ðŸŒ ENIGMA INTEGRATION - Universal Translator Bridge
        if ENIGMA_INTEGRATION_AVAILABLE and get_enigma_integration:
            try:
                self.enigma_integration = get_enigma_integration()
                
                # Wire to existing systems
                if self.queen:
                    wire_enigma_to_ecosystem(self.queen)
                    # ðŸ‘‘ðŸ” Also wire Enigma directly to Queen for dream_of_winning!
                    self.queen.enigma = self.enigma_integration
                
                print("ðŸ”ðŸŒ Enigma Integration: WIRED (Universal Translator Bridge)")
                print(f"   ðŸ’­ Dream Engine: {'âœ…' if self.enigma_integration.dreamer else 'âŒ'}")
                print(f"   ðŸ‘‘ Coherence Mandala: {'âœ…' if getattr(self.enigma_integration, 'coherence_system', None) else 'âŒ'}")
                print(f"   ðŸ›ï¸ Barons Banner: {'âœ…' if getattr(self.enigma_integration, 'barons_analyzer', None) else 'âŒ'}")
                print(f"   ðŸ‘¼ Math Angel: {'âœ…' if getattr(self.enigma_integration, 'math_angel', None) else 'âŒ'}")
                print(f"   ðŸŒŠ Harmonic Reality: {'âœ…' if getattr(self.enigma_integration, 'harmonic_reality', None) else 'âŒ'}")
                print(f"   âš¡ QGITA Framework: {'âœ…' if getattr(self.enigma_integration, 'qgita', None) else 'âŒ'}")
                print(f"   ðŸ§  Consciousness: ACTIVE (It thinks, therefore it trades)")
            except Exception as e:
                print(f"âš ï¸ Enigma Integration error: {e}")
                self.enigma_integration = None
        else:
            print(f"ðŸ”ðŸŒ Enigma Integration: âŒ NOT AVAILABLE (import={ENIGMA_INTEGRATION_AVAILABLE})")
        
        # ðŸ“¡ Thought Bus Aggregator Status
        if self.bus_aggregator:
            print("ðŸ“¡ Thought Bus Aggregator: WIRED (Neural Signal Collector)")

        # ðŸ‘‘ðŸ§  MEMI SYNC - CIA Declassified Intelligence Learning
        if MEMI_SYNC_AVAILABLE and get_memi_sync:
            try:
                self.memi_sync = get_memi_sync(queen=self.queen, thought_bus=self.thought_bus)
                # Start auto-sync in background
                self.memi_sync.start_auto_sync()
                stats = self.memi_sync.fetcher.get_stats()
                print(f"ðŸ‘‘ðŸ§  Memi Sync: WIRED (CIA Declassified Intelligence)")
                print(f"   ðŸ“Š Intelligence Packets: {stats['total_packets']}")
                print(f"   ðŸŽ¯ High Relevance: {stats['high_relevance_count']}")
                print(f"   ðŸ“ Words Processed: {stats['total_words']}")
                
                # Display some trading wisdom
                wisdom = self.memi_sync.get_trading_wisdom()[:3]
                if wisdom:
                    print(f"   ðŸŽ“ Sample Wisdom:")
                    for w in wisdom:
                        print(f"      {w[:65]}...")
            except Exception as e:
                print(f"âš ï¸ Memi Sync error: {e}")
                self.memi_sync = None
        else:
            print(f"ðŸ‘‘ðŸ§  Memi Sync: âŒ NOT AVAILABLE (import={MEMI_SYNC_AVAILABLE})")

        # ðŸ„ðŸ‹ WHALE SONAR - Start per-system sonar to send compact signals to Queen
        try:
            from mycelium_whale_sonar import create_and_start_sonar
            if self.thought_bus:
                self.whale_sonar = create_and_start_sonar(thought_bus=self.thought_bus)
                print("ðŸ„ðŸ‹ Whale Sonar: STARTED (listening for subsystem signals)")
            else:
                print("ðŸ„ðŸ‹ Whale Sonar: SKIPPED (no ThoughtBus available)")
        except Exception as e:
            print(f"ðŸ„ðŸ‹ Whale Sonar: ERROR starting sonar: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ðŸŽ“ QUEEN LOSS LEARNING SYSTEM - Learn from every loss, never forget
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if QUEEN_LOSS_LEARNING_AVAILABLE and QueenLossLearningSystem:
            try:
                # Get elephant memory from queen if available
                elephant_memory = None
                if self.queen and hasattr(self.queen, 'elephant_brain'):
                    elephant_memory = self.queen.elephant_brain
                
                self.loss_learning = QueenLossLearningSystem(
                    elephant_memory=elephant_memory,
                    mycelium=self.mycelium_network,
                    kraken_client=self.kraken,
                    binance_client=self.binance,
                    alpaca_client=self.alpaca,
                )
                
                # Wire to queen if available
                if self.queen:
                    self.queen.loss_learning = self.loss_learning
                
                print("ðŸ‘‘ðŸŽ“ Queen Loss Learning: WIRED (Learns from every loss, never forgets)")
                print(f"   ðŸ˜ Elephant Memory: {'âœ…' if self.loss_learning.elephant else 'âŒ'}")
                print(f"   ðŸ„ Mycelium Network: {'âœ…' if self.loss_learning.mycelium else 'âŒ'}")
                print(f"   ðŸ“Š Losses Analyzed: {self.loss_learning.stats['total_losses_analyzed']}")
                print(f"   ðŸŽ–ï¸ Tactics Learned: {len(self.loss_learning.warfare_tactics)}")
            except Exception as e:
                print(f"âš ï¸ Queen Loss Learning error: {e}")
                self.loss_learning = None
        else:
            print(f"ðŸ‘‘ðŸŽ“ Queen Loss Learning: âŒ NOT AVAILABLE (import={QUEEN_LOSS_LEARNING_AVAILABLE})")
        
        # ðŸ¦†âš”ï¸ QUANTUM QUACKERS COMMANDOS - THE ANIMAL ARMY UNDER THE QUEEN!
        # Lion, Wolf, Ants, Hummingbird - all serve Sero!
        self.quack_commandos = None
        self.quack_targets = {}  # Cached targets from commandos
        if QUACK_COMMANDOS_AVAILABLE:
            try:
                # Create a mock client for commandos (they need ticker data)
                class QuackClient:
                    """Mock client that uses our existing ticker cache"""
                    def __init__(self, labyrinth):
                        self.labyrinth = labyrinth
                    
                    def get_24h_ticker(self, symbol):
                        """Get 24h stats for a symbol"""
                        for cached_sym, data in self.labyrinth.ticker_cache.items():
                            base = data.get('base', '')
                            quote = data.get('quote', '')
                            if f"{base}{quote}" == symbol or f"{base}/USD" == symbol:
                                return {
                                    'priceChangePercent': data.get('change24h', 0) * 100,
                                    'quoteVolume': data.get('volume', 0),
                                    'lastPrice': data.get('price', 0),
                                }
                        return {'priceChangePercent': 0, 'quoteVolume': 0, 'lastPrice': 0}
                    
                    def get_24h_tickers(self):
                        """Get all 24h stats"""
                        tickers = []
                        for symbol, data in self.labyrinth.ticker_cache.items():
                            base = data.get('base', '')
                            quote = data.get('quote', 'USD')
                            tickers.append({
                                'symbol': f"{base}{quote}",
                                'priceChangePercent': data.get('change24h', 0) * 100,
                                'quoteVolume': data.get('volume', 100000),
                                'lastPrice': data.get('price', 1.0),
                            })
                        return tickers
                
                quack_client = QuackClient(self)
                self.quack_commandos = QuackCommandos(quack_client)
                
                # ðŸ‘‘ WIRE COMMANDOS TO QUEEN! The Queen commands the army!
                if self.queen:
                    self.queen.quack_commandos = self.quack_commandos
                
                print("ðŸ¦†âš”ï¸ Quantum Quackers Commandos: WIRED (Queen's Animal Army)")
                print(f"   ðŸ¦ Lion (Pride Scanner): {self.quack_commandos.slot_config['lion']} slots")
                print(f"   ðŸº Wolf (Momentum Sniper): {self.quack_commandos.slot_config['wolf']} slots")
                print(f"   ðŸœ Ants (Floor Scavengers): {self.quack_commandos.slot_config['ants']} slots")
                print(f"   ðŸ Hummingbird (Quick Rotations): {self.quack_commandos.slot_config['hummingbird']} slots")
                print("   ðŸ‘‘ ALL COMMANDOS SERVE SERO - LONG LIVE THE QUEEN!")
            except Exception as e:
                print(f"âš ï¸ Quack Commandos init error: {e}")
                self.quack_commandos = None
        else:
            print("ðŸ¦†âš”ï¸ Quantum Quackers Commandos: âŒ NOT AVAILABLE")
        
        # ï¿½ðŸ§  PathMemory Stats
        pm_stats = self.path_memory.get_stats()
        print(f"ðŸ§  PathMemory: {pm_stats['paths']} paths, {pm_stats['win_rate']:.1%} win rate")
        
        # ðŸŒâš¡ GLOBAL FINANCIAL FEED (Non-Crypto Data)
        self.global_financial_feed = None
        if GLOBAL_FEED_AVAILABLE and GlobalFinancialFeed:
            try:
                self.global_financial_feed = GlobalFinancialFeed()
                print("ðŸŒ Global Financial Feed: WIRED (Stocks, Forex, Macro)")
                # Force initial pulse
                self.global_financial_feed.get_snapshot()
            except Exception as e:
                print(f"âš ï¸ Global Financial Feed error: {e}")
        
        # ðŸ§ âš¡ NEURAL MIND MAP SUMMARY - ALL 12 NEURONS (Now with Enigma!)
        print("\n" + "=" * 70)
        try:
            print("ðŸ§ âš¡ NEURAL MIND MAP - FULL SYSTEM STATUS âš¡ðŸ§ ")
        except UnicodeEncodeError:
            print("NEURAL MIND MAP - FULL SYSTEM STATUS")
            
        print("=" * 70)
        
        neurons_status = {
            'ðŸ‘‘ Queen Hive Mind': (self.queen is not None) or (getattr(self, 'queen_autonomous_control', None) is not None),
            'ðŸ” Enigma Integration': self.enigma_integration is not None,  # ðŸ” NEW!
            'ðŸ„ Mycelium Network': self.mycelium_network is not None,
            'ðŸŒŠ Harmonic Fusion': self.harmonic is not None,
            'ðŸ€ Luck Field Mapper': self.luck_mapper is not None,
            'ðŸ’­ Dream Memory': hasattr(self, 'dreams'),  # Always available
            'ðŸ§  Path Memory': self.path_memory is not None,
            'â³ Timeline Oracle': self.timeline_oracle is not None,
            'ðŸ“¡ Thought Bus': self.bus_aggregator is not None,
            'ðŸ’Ž Ultimate Intel': self.ultimate_intel is not None,
            'ðŸ“š Wisdom Engine': self.wisdom_engine is not None,
            'ðŸ«’ Barter Matrix': self.barter_matrix is not None,
        }
        connected = sum(1 for v in neurons_status.values() if v)
        total = len(neurons_status)
        
        # Safe printing for Windows consoles that might crash on emojis
        try:
            for name, status in neurons_status.items():
                icon = "âœ…" if status else "âŒ"
                # Show Enigma subsystems if available
                if name == 'ðŸ” Enigma Integration' and status and self.enigma_integration:
                    subs = []
                    if hasattr(self.enigma_integration, 'dreamer') and self.enigma_integration.dreamer:
                        subs.append("ðŸ’­Dream")
                    if hasattr(self.enigma_integration, 'coherence_system') and self.enigma_integration.coherence_system:
                        subs.append("ðŸ‘‘Coherence")
                    if hasattr(self.enigma_integration, 'qgita') and self.enigma_integration.qgita:
                        subs.append("âš¡QGITA")
                    if hasattr(self.enigma_integration, 'math_angel') and self.enigma_integration.math_angel:
                        subs.append("ðŸ‘¼Angel")
                    if hasattr(self.enigma_integration, 'barons_analyzer') and self.enigma_integration.barons_analyzer:
                        subs.append("ðŸ›ï¸Barons")
                    if hasattr(self.enigma_integration, 'harmonic_reality') and self.enigma_integration.harmonic_reality:
                        subs.append("ðŸŒŠReality")
                    sub_str = " [" + ", ".join(subs) + "]" if subs else ""
                    print(f"   {icon} {name}{sub_str}")
                else:
                    print(f"   {icon} {name}")
            
            print(f"\n   ðŸ§  NEURAL STATUS: {connected}/{total} NEURONS CONNECTED")
            if connected == total:
                print("   ðŸŒŸ FULL CONSCIOUSNESS ACHIEVED - ALL SYSTEMS ONLINE! ðŸŒŸ")
            elif connected >= total - 2:
                print("   âš¡ NEAR FULL CONSCIOUSNESS - Minor systems offline")
            else:
                print("   âš ï¸ PARTIAL CONSCIOUSNESS - Some systems need attention")

        except UnicodeEncodeError:
            # Fallback for Windows legacy consoles
            for name, status in neurons_status.items():
                # Strip emojis from name
                clean_name = name.encode('ascii', 'ignore').decode('ascii').strip()
                icon = "[OK]" if status else "[X]"
                print(f"   {icon} {clean_name}")
            print(f"\n   NEURAL STATUS: {connected}/{total} NEURONS CONNECTED")

        
        print("=" * 70)
        print()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŒðŸªžâš“ STARGATE PROTOCOL - Quantum Mirror & Timeline Activation
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Wire Stargate Protocol for revenue generation through quantum coherence
        self.stargate_engine = None
        self.quantum_mirror_scanner = None
        self.timeline_anchor_validator = None
        
        if STARGATE_PROTOCOL_AVAILABLE and create_stargate_engine:
            try:
                self.stargate_engine = create_stargate_engine(with_integrations=True)
                if self.queen and hasattr(self.queen, 'wire_stargate_protocol'):
                    self.queen.wire_stargate_protocol(self.stargate_engine)
                print("ðŸŒŒ Stargate Protocol: WIRED (12 Planetary Nodes + Quantum Mirrors)")
                print(f"   â­ Giza: 432Hz | Stonehenge: 396Hz | Machu Picchu: 528Hz")
                print(f"   ðŸªž Mirrors: Golden Age, Unity, Abundance, Liberation")
            except Exception as e:
                print(f"âš ï¸ Stargate Protocol error: {e}")
                logger.debug(f"Stargate Protocol init error: {e}")
        
        if QUANTUM_MIRROR_SCANNER_AVAILABLE and create_quantum_mirror_scanner:
            try:
                self.quantum_mirror_scanner = create_quantum_mirror_scanner(with_integrations=True)
                if self.queen and hasattr(self.queen, 'wire_quantum_mirror_scanner'):
                    self.queen.wire_quantum_mirror_scanner(self.quantum_mirror_scanner)
                print("ðŸ”® Quantum Mirror Scanner: WIRED (3-Pass Batten Matrix)")
                print(f"   âœ… P1(Harmonic) â†’ P2(Coherence) â†’ P3(Stability) â†’ 4th Gate")
            except Exception as e:
                print(f"âš ï¸ Quantum Mirror Scanner error: {e}")
                logger.debug(f"Quantum Mirror Scanner init error: {e}")
        
        if TIMELINE_ANCHOR_VALIDATOR_AVAILABLE and create_timeline_anchor_validator:
            try:
                self.timeline_anchor_validator = create_timeline_anchor_validator(with_integrations=True)
                if self.queen and hasattr(self.queen, 'wire_timeline_anchor_validator'):
                    self.queen.wire_timeline_anchor_validator(self.timeline_anchor_validator)
                status = self.timeline_anchor_validator.get_status()
                print("âš“ Timeline Anchor Validator: WIRED (7-Day Extended Validation)")
                print(f"   ðŸ“‹ Pending: {status.get('pending_count', 0)} | Anchored: {status.get('anchored_count', 0)}")
            except Exception as e:
                print(f"âš ï¸ Timeline Anchor Validator error: {e}")
                logger.debug(f"Timeline Anchor Validator init error: {e}")
        
        # ðŸŒŒ STARGATE PROTOCOL STATUS SUMMARY
        stargate_status = {
            'engine': self.stargate_engine is not None,
            'scanner': self.quantum_mirror_scanner is not None,
            'validator': self.timeline_anchor_validator is not None,
        }
        stargate_active = sum(1 for v in stargate_status.values() if v)
        if stargate_active == 3:
            print("ðŸŒŒâœ¨ STARGATE PROTOCOL: FULLY ACTIVE (All 3 systems online)")
            print("   ðŸŽ¯ Market symbols â†’ Reality Branches â†’ Validation â†’ Timeline Anchoring")
            
            # ðŸ„ðŸŒŒ WIRE STARGATE TO MYCELIUM - Revenue generation through quantum coherence!
            if hasattr(self, 'mycelium_network') and self.mycelium_network:
                if hasattr(self.mycelium_network, 'wire_stargate_protocol'):
                    try:
                        self.mycelium_network.wire_stargate_protocol(
                            self.stargate_engine,
                            self.quantum_mirror_scanner,
                            self.timeline_anchor_validator
                        )
                        print("   ðŸ„ðŸŒŒ Stargate â†’ Mycelium: WIRED (Quantum coherence feeds neural network)")
                    except Exception as e:
                        logger.debug(f"Stargate-Mycelium wiring error: {e}")
        elif stargate_active > 0:
            print(f"ðŸŒŒâš ï¸ STARGATE PROTOCOL: PARTIAL ({stargate_active}/3 systems)")
        else:
            print("ðŸŒŒâŒ STARGATE PROTOCOL: NOT AVAILABLE")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒâœ¨ PLANET SAVER - Save the Planet, Free Every Soul
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Wire Planet Saver to ALL systems - the mission is freedom!
        self.planet_saver = None
        
        if PLANET_SAVER_AVAILABLE and create_planet_saver:
            try:
                self.planet_saver = create_planet_saver()
                
                # Wire to ALL systems
                wire_results = self.planet_saver.wire_all_systems(self)
                wired_count = sum(1 for v in wire_results.values() if v)
                
                print("ðŸŒâœ¨ PLANET SAVER: WIRED (Liberation Mode Active)")
                print(f"   ðŸŽ¯ Goal: Â£{FREEDOM_GOAL_GBP:,.0f} GBP")
                
                # Get current progress
                ps_status = self.planet_saver.get_status()
                print(f"   ðŸ“Š Progress: {ps_status['progress_percent']:.2f}%")
                print(f"   ðŸ’° Total Profit: ${ps_status['total_profit_usd']:,.2f}")
                print(f"   ðŸ’« Souls Freed: {ps_status['souls_freed']}")
                print(f"   ðŸ”— Systems: {wired_count}/{len(wire_results)} connected")
                
                # Wire to Queen specifically
                if self.queen and hasattr(self.queen, 'wire_planet_saver'):
                    self.queen.wire_planet_saver(self.planet_saver)
                    print("   ðŸ‘‘ðŸŒ Queen â†’ Planet Saver: WIRED!")
                    
            except Exception as e:
                print(f"âš ï¸ Planet Saver error: {e}")
                logger.debug(f"Planet Saver init error: {e}")
        else:
            print("ðŸŒâŒ PLANET SAVER: NOT AVAILABLE")
    
    async def _load_all_tradeable_pairs(self):
        """Load tradeable pairs from ALL exchanges for proper routing."""
        print("\nðŸ“Š LOADING TRADEABLE PAIRS FROM ALL EXCHANGES...")
        print("   ðŸ—ºï¸ Expanding Barter Matrix market visibility...")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ™ KRAKEN PAIRS - Load from AssetPairs API
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.kraken:
            try:
                pairs_info = self.kraken._load_asset_pairs() if hasattr(self.kraken, '_load_asset_pairs') else {}
                kraken_pair_names = []
                for internal, info in pairs_info.items():
                    if not internal.endswith('.d'):  # Skip dark pools
                        altname = info.get('altname', internal)
                        base = info.get('base', '')
                        quote = info.get('quote', '')
                        self.kraken_pairs[altname] = {
                            'internal': internal,
                            'base': base,
                            'quote': quote,
                            'wsname': info.get('wsname', altname),
                        }
                        # Also add common variants
                        self.kraken_pairs[internal] = self.kraken_pairs[altname]
                        kraken_pair_names.append(altname)
                
                # ðŸ—ºï¸ REGISTER WITH BARTER MATRIX for expanded market coverage
                discovered = self.barter_matrix.discover_exchange_assets('kraken', kraken_pair_names)
                print(f"   ðŸ™ Kraken: {len(self.kraken_pairs)} tradeable pairs ({discovered} assets discovered)")
            except Exception as e:
                logger.error(f"Kraken pairs error: {e}")
                print(f"   âŒ Kraken pairs error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ¦™ ALPACA PAIRS - Load from Assets API
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca:
            try:
                alpaca_pair_names = []
                # Get tradeable crypto symbols
                if hasattr(self.alpaca, 'get_tradable_crypto_symbols'):
                    symbols = self.alpaca.get_tradable_crypto_symbols() or []
                    for symbol in symbols:
                        # Alpaca returns like 'BTC/USD'
                        self.alpaca_pairs[symbol] = symbol
                        # Also store without slash
                        clean = symbol.replace('/', '')
                        self.alpaca_pairs[clean] = symbol
                        alpaca_pair_names.append(clean)
                else:
                    # Fallback - get assets directly
                    assets = self.alpaca.get_assets(status='active', asset_class='crypto') or []
                    for asset in assets:
                        if asset.get('tradable'):
                            symbol = asset.get('symbol', '')
                            if symbol:
                                self.alpaca_pairs[symbol] = symbol
                                # Add normalized version
                                if '/' in symbol:
                                    clean = symbol.replace('/', '')
                                    self.alpaca_pairs[clean] = symbol
                                    alpaca_pair_names.append(clean)
                
                # ðŸ—ºï¸ REGISTER WITH BARTER MATRIX
                discovered = self.barter_matrix.discover_exchange_assets('alpaca', alpaca_pair_names)
                print(f"   ðŸ¦™ Alpaca: {len(self.alpaca_pairs)} tradeable pairs ({discovered} assets discovered)")
            except Exception as e:
                logger.error(f"Alpaca pairs error: {e}")
                print(f"   âŒ Alpaca pairs error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŸ¡ BINANCE PAIRS - Will load during fetch_prices from tickers
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Load Binance pairs immediately for market discovery
        if self.binance:
            try:
                info = self.binance.exchange_info()
                symbols = info.get('symbols', [])
                binance_pair_names = []
                
                for sym in symbols:
                    if sym.get('status') == 'TRADING':
                        pair = sym.get('symbol', '')
                        binance_pair_names.append(pair)
                        self.binance_pairs.add(pair)
                
                # ðŸ—ºï¸ REGISTER WITH BARTER MATRIX
                discovered = self.barter_matrix.discover_exchange_assets('binance', binance_pair_names)
                print(f"   ðŸŸ¡ Binance: {len(binance_pair_names)} tradeable pairs ({discovered} assets discovered)")
            except Exception as e:
                logger.error(f"Binance pairs error: {e}")
                print(f"   ðŸŸ¡ Binance: pairs will load with price data")
        
        # ðŸ—ºï¸ PRINT MARKET COVERAGE REPORT
        print(self.barter_matrix.print_market_coverage())
        print()
    
    async def fetch_prices(self) -> Dict[str, float]:
        """Fetch all asset prices from ALL exchanges."""
        prices = {}
        ticker_cache = {}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ™ KRAKEN PRICES - Use get_24h_tickers (returns list of dicts)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.kraken:
            try:
                tickers = self.kraken.get_24h_tickers() if hasattr(self.kraken, 'get_24h_tickers') else []
                kraken_count = 0
                
                for data in tickers:
                    if not isinstance(data, dict):
                        continue
                    
                    symbol = data.get('symbol', '')
                    # Kraken returns lastPrice as string
                    price_str = data.get('lastPrice', '0')
                    price = float(price_str) if price_str else 0.0
                    
                    if price > 0 and symbol:
                        # Store in kraken pairs for execution routing
                        self.binance_pairs.discard(symbol)  # Not binance
                        
                        for quote in ['USD', 'USDT', 'USDC', 'GBP', 'EUR']:
                            if symbol.endswith(quote):
                                base = symbol[:-len(quote)]
                                # Clean up Kraken naming
                                if len(base) == 4 and base[0] in ('X', 'Z'):
                                    base = base[1:]
                                if base == 'XBT':
                                    base = 'BTC'
                                
                                prices[base] = price
                                
                                change = float(data.get('priceChangePercent', 0))
                                volume = float(data.get('quoteVolume', 0))
                                
                                ticker_entry = {
                                    'price': price,
                                    'change24h': change,
                                    'volume': volume,
                                    'base': base,
                                    'quote': quote,
                                    'exchange': 'kraken',
                                    'pair': symbol,
                                }
                                # Wave scanner expects raw symbols; keep prefixed + raw for compatibility
                                ticker_cache[f"kraken:{symbol}"] = ticker_entry
                                ticker_cache[symbol] = ticker_entry
                                kraken_count += 1
                                break
                
                print(f"   ðŸ™ Kraken: {kraken_count} pairs loaded")
            except Exception as e:
                logger.error(f"Kraken price fetch error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŸ¡ BINANCE PRICES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.binance:
            try:
                # Get 24h ticker
                if hasattr(self.binance, 'ticker_24hr_all'):
                    binance_tickers = self.binance.ticker_24hr_all()
                elif hasattr(self.binance, 'session'):
                    r = self.binance.session.get(f"{self.binance.base}/api/v3/ticker/24hr")
                    binance_tickers = r.json() if r.ok else []
                else:
                    binance_tickers = []
                
                binance_count = 0
                # For UK mode, prefer USDC over USDT
                quote_priority = ['USDC', 'USDT', 'USD', 'BUSD'] if self.binance_uk_mode else ['USDT', 'USD', 'BUSD', 'USDC']
                
                for ticker in binance_tickers:
                    symbol = ticker.get('symbol', '')
                    price = float(ticker.get('lastPrice', 0))
                    if price > 0:
                        # ðŸ‡¬ðŸ‡§ UK MODE: Only load allowed pairs
                        if self.binance_uk_mode and not self.is_binance_pair_allowed(symbol):
                            continue
                        
                        for quote in quote_priority:
                            if symbol.endswith(quote):
                                base = symbol.replace(quote, '')
                                # Only update if we don't have this price yet
                                if base not in prices:
                                    prices[base] = price
                                
                                change = float(ticker.get('priceChangePercent', 0))
                                volume = float(ticker.get('volume', 0))
                                ticker_entry = {
                                    'price': price,
                                    'change24h': change,
                                    'volume': volume,
                                    'base': base,
                                    'quote': quote,
                                    'exchange': 'binance',
                                }
                                # Wave scanner reads unprefixed symbols; store both
                                ticker_cache[f"binance:{symbol}"] = ticker_entry
                                ticker_cache[symbol] = ticker_entry
                                binance_count += 1
                                break
                print(f"   ðŸŸ¡ Binance: {binance_count} pairs loaded")
            except Exception as e:
                logger.error(f"Binance price fetch error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ¦™ ALPACA PRICES (crypto and positions)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca:
            try:
                alpaca_count = 0
                
                # Get prices from positions
                if hasattr(self.alpaca, 'get_positions'):
                    positions = self.alpaca.get_positions() or []
                    for pos in positions:
                        symbol = pos.get('symbol', '')
                        price = float(pos.get('current_price', 0))
                        if price > 0 and symbol:
                            # Extract base asset from symbol like "BTCUSD" or "BTC/USD"
                            if '/' in symbol:
                                base = symbol.split('/')[0]
                            elif symbol.endswith('BTC'):
                                base = symbol[:-3]
                            else:
                                base = symbol.replace('USD', '')
                            if base and len(base) > 1:
                                prices[base] = price
                                change = float(pos.get('change_today', 0)) * 100
                                ticker_entry = {
                                    'price': price,
                                    'change24h': change,
                                    'volume': 0,
                                    'base': base,
                                    'quote': 'USD',
                                    'exchange': 'alpaca',
                                    'pair': symbol,
                                }
                                # Store multiple keys so wave scanner sees Alpaca symbols (slash + raw)
                                ticker_cache[f"alpaca:{symbol}"] = ticker_entry
                                ticker_cache[symbol] = ticker_entry
                                ticker_cache[f"{base}/USD"] = ticker_entry
                                # Store in alpaca_pairs for routing
                                self.alpaca_pairs[symbol] = f"{base}/USD"
                                self.alpaca_pairs[f"{base}USD"] = f"{base}/USD"
                                self.alpaca_pairs[f"{base}/USD"] = f"{base}/USD"
                                alpaca_count += 1

                # Pull prices for tradeable crypto pairs even if we have no positions.
                if hasattr(self.alpaca, 'get_latest_crypto_quotes'):
                    symbols = sorted(set(self.alpaca_pairs.values()))
                    if not symbols and hasattr(self.alpaca, 'get_tradable_crypto_symbols'):
                        symbols = self.alpaca.get_tradable_crypto_symbols() or []
                    if symbols:
                        quotes = self.alpaca.get_latest_crypto_quotes(symbols) or {}

                        for symbol, quote in quotes.items():
                            if not isinstance(quote, dict):
                                continue
                            bid = float(quote.get('bp', 0) or quote.get('bid_price', 0) or 0)
                            ask = float(quote.get('ap', 0) or quote.get('ask_price', 0) or 0)
                            price = (bid + ask) / 2 if bid and ask else (bid or ask or 0)
                            if price <= 0:
                                continue
                            if '/' in symbol:
                                base, quote_asset = symbol.split('/', 1)
                            else:
                                base, quote_asset = symbol, 'USD'
                            ticker_entry = {
                                'price': price,
                                'change24h': 0,
                                'volume': 0,
                                'base': base,
                                'quote': quote_asset,
                                'exchange': 'alpaca',
                                'pair': symbol,
                            }
                            ticker_cache[f"alpaca:{symbol}"] = ticker_entry
                            ticker_cache[symbol] = ticker_entry

                            self.alpaca_pairs[symbol] = symbol
                            self.alpaca_pairs[symbol.replace('/', '')] = symbol
                
                print(f"   ðŸ¦™ Alpaca: {alpaca_count} positions loaded")
            except Exception as e:
                logger.error(f"Alpaca price fetch error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ MEDUSA STABLECOIN INJECTION - Enable trading from stablecoins!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Stablecoins are quote currencies (not in price feeds) but we HOLD them
        # We need them in prices so they can be SOURCE assets for buying!
        stablecoin_prices = {
            'USD': 1.0,
            'USDT': 1.0,
            'USDC': 1.0,
            'ZUSD': 1.0,   # Kraken USD
            'TUSD': 1.0,   # TrueUSD
            'DAI': 1.0,
        }
        for stable, price in stablecoin_prices.items():
            if stable not in prices:
                prices[stable] = price
        
        self.prices = prices
        self.ticker_cache = ticker_cache
        
        # ðŸª™âš¡ FEED TICKER DATA TO PENNY PROFIT TURBO
        # This enables real-time spread tracking and flash detection
        if self.penny_turbo:
            turbo_feeds = 0
            for cache_key, data in ticker_cache.items():
                if isinstance(data, dict) and ':' in cache_key:
                    exchange = cache_key.split(':')[0]
                    symbol = data.get('pair', data.get('base', ''))
                    price = data.get('price', 0)
                    
                    # Estimate bid/ask from price (real spread tracking improves over time)
                    spread_est = 0.0005  # 0.05% estimate
                    bid = price * (1 - spread_est)
                    ask = price * (1 + spread_est)
                    
                    if price > 0 and symbol:
                        self.penny_turbo.record_ticker(exchange, symbol, bid, ask, price)
                        turbo_feeds += 1
            
            # Show flash opportunities if any
            flashes = self.penny_turbo.get_flash_opportunities()
            if flashes:
                print(f"   âš¡ FLASH: {len(flashes)} momentum opportunities detected!")
        
        # ðŸŒŠâš¡ UPDATE MOMENTUM FOR ALL PRICES - Wave jumping intelligence
        momentum_count = 0
        for asset, price in prices.items():
            if price > 0:
                self.update_momentum(asset, price)
                momentum_count += 1
        
        # Show top movers if we have momentum data
        if len(self.asset_momentum) > 10:
            rising = self.get_strongest_rising(limit=3)
            falling = self.get_weakest_falling(limit=3)
            if rising:
                top_rising = ', '.join([f"{a}:{m*100:+.2f}%/min" for a, m in rising[:3]])
                print(f"   ðŸŒŠ Rising: {top_rising}")
            if falling:
                top_falling = ', '.join([f"{a}:{m*100:+.2f}%/min" for a, m in falling[:3]])
                print(f"   ðŸ“‰ Falling: {top_falling}")
        
        print(f"   ðŸ“Š Total: {len(prices)} unique assets, {len(ticker_cache)} tickers, {momentum_count} momentum tracked")
        print(f"   ðŸ Medusa stablecoins: USD, USDT, USDC, ZUSD, TUSD, DAI injected")
        
        return prices
    
    async def fetch_balances(self) -> Dict[str, float]:
        """Fetch balances from ALL exchanges."""
        combined = {}
        self.exchange_balances = {}
        self.exchange_data = {}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ™ KRAKEN BALANCES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.kraken:
            try:
                # Gary: Log source type so we KNOW if it's real or fake
                is_dry = getattr(self.kraken, 'dry_run', False)
                source_type = "ðŸ›¡ï¸ SIMULATED" if is_dry else "ðŸŒ REAL LIVE"
                
                kraken_bal = {}
                if hasattr(self.kraken, 'get_account_balance'):
                    raw = self.kraken.get_account_balance() or {}
                    for asset, amount in raw.items():
                        try:
                            amount = float(amount)
                        except (ValueError, TypeError):
                            continue
                        if amount > 0:
                            # Clean up Kraken naming
                            clean = asset
                            if len(asset) == 4 and asset[0] in ('X', 'Z'):
                                clean = asset[1:]
                            if clean == 'XBT':
                                clean = 'BTC'
                            kraken_bal[clean] = amount
                            combined[clean] = combined.get(clean, 0) + amount
                
                self.exchange_balances['kraken'] = kraken_bal
                self.exchange_data['kraken'] = {
                    'connected': True,
                    'balances': kraken_bal,
                    'total_value': sum(kraken_bal.get(a, 0) * self.prices.get(a, 0) for a in kraken_bal),
                }
                print(f"   ðŸ™ Kraken ({source_type}): {len(kraken_bal)} assets")
            except Exception as e:
                logger.error(f"Kraken balance error: {e}")
                self.exchange_data['kraken'] = {'connected': False, 'error': str(e)}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŸ¡ BINANCE BALANCES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.binance:
            try:
                binance_bal = {}
                if hasattr(self.binance, 'account'):
                    acct = self.binance.account() or {}
                    for bal in acct.get('balances', []):
                        asset = bal.get('asset', '')
                        free = float(bal.get('free', 0))
                        if free > 0 and asset:
                            binance_bal[asset] = free
                            combined[asset] = combined.get(asset, 0) + free
                
                self.exchange_balances['binance'] = binance_bal
                self.exchange_data['binance'] = {
                    'connected': True,
                    'balances': binance_bal,
                    'total_value': sum(binance_bal.get(a, 0) * self.prices.get(a, 0) for a in binance_bal),
                }
                print(f"   ðŸŸ¡ Binance: {len(binance_bal)} assets")
            except Exception as e:
                logger.error(f"Binance balance error: {e}")
                self.exchange_data['binance'] = {'connected': False, 'error': str(e)}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ¦™ ALPACA BALANCES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca:
            try:
                alpaca_bal = {}
                # Get account for cash
                if hasattr(self.alpaca, 'get_account'):
                    acct = self.alpaca.get_account() or {}
                    cash = float(acct.get('cash', 0))
                    if cash > 0:
                        alpaca_bal['USD'] = cash
                        combined['USD'] = combined.get('USD', 0) + cash
                
                # Get positions (crypto assets)
                if hasattr(self.alpaca, 'get_positions'):
                    positions = self.alpaca.get_positions() or []
                    for pos in positions:
                        raw_symbol = pos.get('symbol', '')
                        qty = float(pos.get('qty', 0))
                        market_value = float(pos.get('market_value', 0))
                        
                        if qty > 0 and raw_symbol:
                            # Convert Alpaca symbol format (BTCUSD -> BTC, BCH/BTC -> BCH)
                            if '/' in raw_symbol:
                                base_asset = raw_symbol.split('/')[0]
                            elif raw_symbol.endswith('USD'):
                                base_asset = raw_symbol[:-3]  # Remove USD suffix
                            elif raw_symbol.endswith('BTC'):
                                base_asset = raw_symbol[:-3]
                            else:
                                base_asset = raw_symbol
                            
                            # Store with base asset name
                            alpaca_bal[base_asset] = qty
                            combined[base_asset] = combined.get(base_asset, 0) + qty
                            
                            # Also store the price if we got market_value
                            if market_value > 0 and qty > 0:
                                price = market_value / qty
                                if base_asset not in self.prices or self.prices.get(base_asset, 0) == 0:
                                    self.prices[base_asset] = price
                
                self.exchange_balances['alpaca'] = alpaca_bal
                self.exchange_data['alpaca'] = {
                    'connected': True,
                    'balances': alpaca_bal,
                    'total_value': float(acct.get('portfolio_value', 0)) if acct else 0,
                }
                print(f"   ðŸ¦™ Alpaca: {len(alpaca_bal)} assets")
            except Exception as e:
                logger.error(f"Alpaca balance error: {e}")
                self.exchange_data['alpaca'] = {'connected': False, 'error': str(e)}
        
        self.balances = combined
        
        # ðŸ› BALANCE SANITY CHECK - Prevent phantom balances!
        # No single asset should be > $500,000 (we're a small trader!)
        MAX_REALISTIC_USD = 500000.0
        for asset in list(self.balances.keys()):
            amount = self.balances[asset]
            price = self.prices.get(asset, 1.0 if asset in ('USD', 'USDT', 'USDC', 'ZUSD') else 0.0)
            value_usd = amount * price
            if value_usd > MAX_REALISTIC_USD:
                logger.warning(f"ðŸš¨ PHANTOM BALANCE DETECTED: {asset} = {amount:.2f} (${value_usd:,.2f}) - IGNORING!")
                print(f"   ðŸš¨ PHANTOM BALANCE: {asset} ${value_usd:,.2f} > ${MAX_REALISTIC_USD:,.2f} - Removing!")
                del self.balances[asset]
        
        # Calculate total portfolio value
        total_usd = 0.0
        for asset, amount in combined.items():
            if asset not in self.balances:  # Skip removed phantoms
                continue
            if asset in ('USD', 'USDT', 'USDC'):
                total_usd += amount
            else:
                price = self.prices.get(asset, 0)
                total_usd += amount * price
        
        print(f"   ðŸ’° Combined Portfolio: ${total_usd:,.2f}")
        print(f"   ðŸ“Š Unique assets: {len(combined)}")
        
        return combined
    
    def calculate_trained_matrix_score(self, to_asset: str) -> Tuple[float, str]:
        """
        ðŸ“Š Calculate score from trained probability matrix.
        Returns: (score 0-1, reason string)
        
        Uses the trained_probability_matrix.json which contains:
        - Hourly edge patterns (optimal/avoid hours)
        - Daily edge patterns (optimal days)
        - Per-symbol patterns
        - Multi-exchange training data
        """
        from datetime import datetime
        import json
        
        score = 0.5  # Neutral default
        reasons = []
        
        try:
            # Load trained matrix
            matrix_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'trained_probability_matrix.json')
            if not os.path.exists(matrix_path):
                return 0.5, "matrix_not_found"
            
            with open(matrix_path, 'r') as f:
                matrix = json.load(f)
            
            now = datetime.now()
            current_hour = str(now.hour)
            current_dow = str(now.weekday())
            
            # 1. Global hourly edge
            hourly_edge_data = matrix.get('hourly_edge', {}).get(current_hour, {})
            hourly_edge = hourly_edge_data.get('edge', 0)
            hourly_conf = hourly_edge_data.get('confidence', 0)
            
            if hourly_edge > 10 and hourly_conf > 0.1:
                score += 0.15
                reasons.append(f"optimal_hour({current_hour})")
            elif hourly_edge < -10 and hourly_conf > 0.1:
                score -= 0.15
                reasons.append(f"avoid_hour({current_hour})")
            
            # 2. Global daily edge
            daily_edge_data = matrix.get('daily_edge', {}).get(current_dow, {})
            daily_edge = daily_edge_data.get('edge', 0)
            daily_conf = daily_edge_data.get('confidence', 0)
            
            if daily_edge > 5 and daily_conf > 0.05:
                score += 0.10
                reasons.append(f"optimal_day({current_dow})")
            elif daily_edge < -5 and daily_conf > 0.05:
                score -= 0.10
                reasons.append(f"avoid_day({current_dow})")
            
            # 3. Symbol-specific patterns
            symbol_patterns = matrix.get('symbol_patterns', {}).get(to_asset, {})
            if symbol_patterns:
                bullish_prob = symbol_patterns.get('bullish_prob', 0.5)
                win_rate = symbol_patterns.get('win_rate', 0.5)
                trade_count = symbol_patterns.get('trade_count', 0)
                
                # Bullish probability bonus
                if bullish_prob > 0.55:
                    score += 0.10
                    reasons.append(f"bullish_symbol({bullish_prob:.2f})")
                elif bullish_prob < 0.45:
                    score -= 0.10
                    reasons.append(f"bearish_symbol({bullish_prob:.2f})")
                
                # Trade history win rate bonus
                if trade_count >= 5 and win_rate > 0.6:
                    score += 0.15
                    reasons.append(f"high_win_rate({win_rate:.2f})")
                elif trade_count >= 5 and win_rate < 0.4:
                    score -= 0.15
                    reasons.append(f"low_win_rate({win_rate:.2f})")
                
                # Symbol-specific hourly edge
                sym_hourly = symbol_patterns.get('hourly_edge', {}).get(current_hour, {})
                sym_hourly_edge = sym_hourly.get('edge', 0)
                if sym_hourly_edge > 15:
                    score += 0.10
                    reasons.append(f"sym_optimal_hour")
                elif sym_hourly_edge < -15:
                    score -= 0.10
                    reasons.append(f"sym_avoid_hour")
            
            # 4. Check optimal/avoid conditions
            optimal_hours = matrix.get('optimal_conditions', {}).get('hours', [])
            avoid_hours = matrix.get('avoid_conditions', {}).get('hours', [])
            
            if now.hour in optimal_hours:
                score += 0.05
                reasons.append("in_optimal_hours")
            if now.hour in avoid_hours:
                score -= 0.10  # Heavier penalty for avoid hours
                reasons.append("in_avoid_hours")
            
            # Clamp score between 0 and 1
            score = max(0.0, min(1.0, score))
            
        except Exception as e:
            logger.debug(f"Trained matrix score error: {e}")
            return 0.5, f"error:{str(e)[:20]}"
        
        reason = ",".join(reasons) if reasons else "neutral"
        return score, reason
    
    def calculate_barter_score(self, from_asset: str, to_asset: str) -> Tuple[float, str]:
        """
        ðŸ«’ðŸ’° Calculate barter path score for a conversion.
        
        Uses BOTH the Barter Navigator (multi-hop paths) AND the LiveBarterMatrix 
        (historical performance) for smarter, adaptive scoring.
        
        THE PHILOSOPHY:
        - Any coin can lead to any other coin
        - Historical success on a path matters
        - The system learns which paths ACTUALLY make money
        
        Returns: (score 0-1, reason string)
        """
        score = 0.5  # Start neutral
        reasons = []
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. LIVE BARTER MATRIX - Historical Performance
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        from_price = self.prices.get(from_asset, 0)
        to_price = self.prices.get(to_asset, 0)
        
        if from_price > 0 and to_price > 0:
            # Update barter rate for this pair
            self.barter_matrix.update_barter_rate(from_asset, to_asset, from_price, to_price)
            
            # Check historical performance of this path
            key = (from_asset.upper(), to_asset.upper())
            history = self.barter_matrix.barter_history.get(key, {})
            
            if history.get('trades', 0) > 0:
                # We have history! Use it with current holdings consideration
                path_profit = history.get('total_profit', 0)
                path_trades = history['trades']
                avg_profit = path_profit / path_trades
                
                # Adjust score based on historical avg trade size
                avg_trade_size = history.get('avg_trade_size', 10.0)  # Default $10 avg trade
                
                # Boost score based on historical success
                if avg_profit > 0.01:  # Profitable path
                    score += 0.15
                    reasons.append(f"profit_path(${avg_profit:.3f})")
                elif avg_profit > 0:
                    score += 0.08
                    reasons.append("slight_profit")
                elif avg_profit < -0.01:  # Losing path
                    score -= 0.10
                    reasons.append("losing_path")
                
                # Experience bonus (more trades = more confidence)
                if path_trades >= 10:
                    score += 0.05
                    reasons.append(f"experienced({path_trades})")
                elif path_trades >= 5:
                    score += 0.02
                    reasons.append(f"some_exp({path_trades})")
            else:
                # New path - slight exploration bonus
                score += 0.02
                reasons.append("new_path")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. BARTER NAVIGATOR - Multi-hop Path Quality
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.barter_navigator and BARTER_NAVIGATOR_AVAILABLE:
            try:
                # Find path from source to destination
                path = self.barter_navigator.find_path(from_asset, to_asset)
                
                if path:
                    # 1. Direct path (1 hop) is best
                    if path.num_hops == 1:
                        score += 0.15
                        reasons.append("direct_path")
                    elif path.num_hops == 2:
                        score += 0.08
                        reasons.append("2hop_path")
                    elif path.num_hops > 3:
                        score -= 0.08
                        reasons.append(f"{path.num_hops}hop_path")
                    
                    # 2. Rate efficiency (closer to 1.0 = less slippage)
                    if path.total_rate > 0.995:
                        score += 0.08
                        reasons.append("efficient_rate")
                    elif path.total_rate < 0.98:
                        score -= 0.08
                        reasons.append("high_slippage")
                    
                    # 3. Single exchange is cleaner
                    if len(path.exchanges_used) == 1:
                        score += 0.03
                        reasons.append("single_exchange")
                    
                    # 4. Low fees are good
                    if path.total_fees < 0.005:  # <0.5%
                        score += 0.03
                        reasons.append("low_fees")
                    elif path.total_fees > 0.01:  # >1%
                        score -= 0.05
                        reasons.append("high_fees")
                else:
                    reasons.append("no_nav_path")
                    
            except Exception as e:
                logger.debug(f"Barter navigator score error: {e}")
        else:
            reasons.append("nav_not_available")
        
        # Clamp score
        score = max(0.0, min(1.0, score))
        
        reason = "barter_" + ",".join(reasons[:3])
        return score, reason
    
    def find_barter_chain(self, from_asset: str, to_asset: str) -> Optional[List[Dict]]:
        """
        ðŸ«’ Find the complete barter chain from source to destination.
        
        Returns list of trade steps: [
            {'from': 'CHZ', 'to': 'USD', 'pair': 'CHZUSD', 'exchange': 'kraken', 'rate': 0.05},
            {'from': 'USD', 'to': 'BTC', 'pair': 'BTCUSD', 'exchange': 'kraken', 'rate': 0.00001},
        ]
        """
        if not self.barter_navigator:
            return None
        
        path = self.barter_navigator.find_path(from_asset, to_asset)
        if not path:
            return None
        
        steps = []
        for hop in path.hops:
            steps.append({
                'from': hop.from_asset,
                'to': hop.to_asset,
                'pair': hop.pair,
                'exchange': hop.exchange,
                'rate': hop.rate,
                'effective_rate': hop.effective_rate,
                'fee': hop.fee_rate
            })
        
        return steps
    
    def calculate_v14_score(self, from_asset: str, to_asset: str) -> float:
        """Calculate V14 score for a conversion."""
        if not self.v14 or not self.ticker_cache:
            return 5.0  # Neutral score if V14 not available
        
        # Get momentum data
        from_ticker = None
        to_ticker = None
        for symbol, data in self.ticker_cache.items():
            if data.get('base') == from_asset:
                from_ticker = data
            if data.get('base') == to_asset:
                to_ticker = data
        
        if not from_ticker or not to_ticker:
            return 5.0
        
        # V14-style scoring components
        score = 5.0  # Start neutral
        
        # 1. Momentum differential (want to go TO stronger momentum)
        from_momentum = from_ticker.get('change24h', 0)
        to_momentum = to_ticker.get('change24h', 0)
        momentum_diff = to_momentum - from_momentum
        
        if momentum_diff > 2:  # Going to significantly stronger
            score += 2
        elif momentum_diff > 0.5:
            score += 1
        elif momentum_diff < -2:  # Going to weaker (bad)
            score -= 2
        
        # 2. Volume check (prefer liquid assets)
        to_volume = to_ticker.get('volume', 0)
        if to_volume > 100000:
            score += 1
        
        # 3. Positive momentum preference
        if to_momentum > 1:
            score += 1
        elif to_momentum < -1:
            score -= 1
        
        # 4. Avoid declining assets
        if from_momentum < -2 and to_momentum > 0:
            score += 1  # Escaping decline = good
        
        return max(1, min(10, score))  # Clamp 1-10
    
    def get_queen_adaptive_floor(self, from_asset: str, to_asset: str) -> float:
        """
        ðŸ‘‘ ADAPTIVE QUEEN'S FLOOR ðŸ‘‘
        
        Calculates a dynamic profit floor based on Queen's Learnings & Path Memory.
        
        Base Floor: epsilon (accept any net-positive after costs)
        
        Adaptations:
        1. ðŸ˜ Elephant Memory (Win Rate):
           - High Win Rate (>80%): Lower floor to $0.04 (Aggressive Capture)
           - Low Win Rate (<40%): Raise floor to $0.15 (Strict Safety)
           - Zero Wins (0%): Raise floor to $0.25 (Extreme Caution)
           
        2. ðŸ§  Neural Intuition (Queen Confidence):
           - If Queen is extremely confident (>90%): Drop floor to $0.02
           
        3. ðŸŒŠ Volatility/Momentum:
           - If target is a Stablecoin: Lower floor (banking profit is safer)
        """
        return EPSILON_PROFIT_USD

    def calculate_hub_score(self, from_asset: str, to_asset: str) -> float:
        """Get consensus score from Mycelium Hub."""
        if not self.hub:
            return 0.5  # Neutral if hub not available
        
        try:
            # Query the hub for this conversion path
            hub_analysis = self.hub.analyze_conversion(from_asset, to_asset)
            if hub_analysis:
                return hub_analysis.get('score', 0.5)
        except Exception:
            pass
        
        return 0.5
    
    def calculate_profit_potential(
        self,
        from_asset: str,
        to_asset: str,
        from_amount: float
    ) -> Tuple[float, float]:
        """Calculate expected profit in USD and % using barter matrix costs."""
        from_price = self.prices.get(from_asset, 0)
        to_price = self.prices.get(to_asset, 0)

        if not from_price or not to_price:
            return 0.0, 0.0

        from_value = from_amount * from_price

        # Use barter matrix to calculate realistic costs using LEARNED history
        # "Counting Right" Logic: Adjusts for historical slippage and volatility
        approved, reason, math_breakdown = self.barter_matrix.calculate_true_cost(
            from_asset, to_asset, from_value, 'kraken'  # Default to kraken for estimation
        )

        if not approved:
            return 0.0, 0.0  # No profit possible

        total_cost_pct = math_breakdown['total_cost_pct'] / 100  # Convert % to decimal
        costs_usd = from_value * total_cost_pct

        # ðŸ›‘ STABLECOIN REALITY CHECK ðŸ›‘
        # Don't assume magical 0.3% gain on stable-to-stable swaps!
        is_stable_swap = False
        
        # Default safety list (if barter_matrix unavailable)
        stable_set = {'USD', 'USDT', 'USDC', 'DAI', 'BUSD', 'TUSD', 'ZUSD', 'EUR', 'ZEUR'}
        
        if hasattr(self, 'barter_matrix') and hasattr(self.barter_matrix, 'STABLECOINS'):
            stable_set = self.barter_matrix.STABLECOINS

        is_stable_swap = (from_asset.upper() in stable_set and to_asset.upper() in stable_set)

        if is_stable_swap:
            # Stablecoin Arbitrage Logic: Profit only comes from PEG DEVIATION
            # If buying USDC with USD, and USDC=0.99, we gain 0.01 (reversion to 1.0)
            # If USDC=1.00, gain is 0.0 (and we lose fees)
            
            # Estimate price relative to USD
            price_ratio = to_price / from_price if from_price > 0 else 1.0
            
            # Assuming mean reversion to 1.0000
            if price_ratio < 0.999: # Buying cheap
                expected_gain_pct = (1.0 - price_ratio)
            elif price_ratio > 1.001: # Selling expensive (shorting? no, we are buying)
                # If we are buying at 1.001, we are LOSING value as it returns to 1.0
                expected_gain_pct = 0.0 
            else:
                expected_gain_pct = 0.0
                
            # Log the reality check
            # print(f"   âš–ï¸ STABLE SWAP ({from_asset}â†’{to_asset}): Price={price_ratio:.4f}, Exp.Gain={expected_gain_pct:.4%}")
        else:
            # For volatile assets, we assume momentum continues (Momentum + Cost Coverage)
            # Estimate small positive movement (0.1-0.5%) minus costs
            # This is conservative - actual profit depends on market conditions
            min_required_gain_pct = total_cost_pct + 0.001  # Costs + 0.1% minimum
            expected_gain_pct = min_required_gain_pct + 0.002  # Add 0.2% expected movement

        expected_gain = from_value * expected_gain_pct
        net_profit = expected_gain - costs_usd
        net_pct = net_profit / from_value if from_value > 0 else 0

        return net_profit, net_pct
    
    async def collect_all_signals(self) -> Dict[str, List[Dict]]:
        """Collect signals from ALL wired systems."""
        signals = defaultdict(list)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ„ MYCELIUM HUB SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.hub:
            try:
                hub_signals = self.hub.get_all_signals() if hasattr(self.hub, 'get_all_signals') else []
                for sig in hub_signals:
                    signals['hub'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Hub signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ¦… COMMANDO SIGNALS (FALCON/TORTOISE/CHAMELEON/BEE)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.commando:
            try:
                commando_signals = self.commando.scan_all_opportunities(self.ticker_cache) if hasattr(self.commando, 'scan_all_opportunities') else []
                for sig in commando_signals:
                    signals['commando'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Commando signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ”® PROBABILITY NEXUS SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.probability_nexus:
            try:
                nexus_signals = self.probability_nexus.get_predictions() if hasattr(self.probability_nexus, 'get_predictions') else []
                for sig in nexus_signals:
                    signals['nexus'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Nexus signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŒ MULTIVERSE CONSENSUS SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.multiverse:
            try:
                mv_signals = self.multiverse.get_consensus() if hasattr(self.multiverse, 'get_consensus') else []
                for sig in mv_signals:
                    signals['multiverse'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Multiverse signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ§  MINER BRAIN SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.miner_brain:
            try:
                brain_signals = self.miner_brain.get_signals() if hasattr(self.miner_brain, 'get_signals') else []
                for sig in brain_signals:
                    signals['brain'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Miner Brain signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŠ HARMONIC WAVE SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.harmonic:
            try:
                harmonic_signals = self.harmonic.get_wave_signals() if hasattr(self.harmonic, 'get_wave_signals') else []
                for sig in harmonic_signals:
                    signals['harmonic'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Harmonic signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ”± OMEGA HIGH CONFIDENCE SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.omega:
            try:
                omega_signals = self.omega.get_high_conf_signals() if hasattr(self.omega, 'get_high_conf_signals') else []
                for sig in omega_signals:
                    signals['omega'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Omega signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŠðŸ”­ GLOBAL WAVE SCANNER SIGNALS (A-Z Coverage)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.wave_scanner:
            try:
                # Get top wave opportunities
                wave_allocation = self.wave_scanner.get_wave_allocation()
                for opp in wave_allocation.get('top_opportunities', []):
                    if opp.get('jump_score', 0) >= 0.6:  # Only high-score opportunities
                        wave_signal = {
                            'symbol': opp.get('symbol'),
                            'exchange': opp.get('exchange'),
                            'action': opp.get('action', 'BUY'),
                            'wave_state': opp.get('wave', 'RISING'),
                            'jump_score': opp.get('jump_score', 0),
                            'change_24h': opp.get('change_24h', 0),
                            'source': 'wave_scanner',
                            'confidence': opp.get('jump_score', 0),
                        }
                        signals['wave_scanner'].append(wave_signal)
                        self.signals_received += 1
            except Exception as e:
                logger.debug(f"Wave Scanner signal error: {e}")
        
        self.all_signals = signals
        return signals

    async def dream_about_tickers(self):
        """
        ðŸ’­ DREAMING PHASE: Predict future movements based on Multiverse & Ecosystem.
        "It dreams about live tickers... validates itself... adapt adjust"
        """
        current_time = time.time()
        
        # Only dream every 10 seconds to avoid noise
        if hasattr(self, '_last_dream_time') and current_time - self._last_dream_time < 10:
            return
        self._last_dream_time = current_time
        
        # 1. Ask Multiverse for direction
        if self.multiverse:
            try:
                # Get consensus from the 10 worlds
                consensus = self.multiverse.get_consensus() if hasattr(self.multiverse, 'get_consensus') else []
                if consensus:
                    print(f"\n   ðŸ’­ DREAMING about market direction (Multiverse)...")
                
                for signal in consensus:
                    symbol = signal.get('symbol')
                    if not symbol or symbol not in self.prices:
                        continue
                        
                    current_price = self.prices[symbol]
                    direction = signal.get('action', 'HOLD')
                    confidence = signal.get('confidence', 0.5)
                    
                    if direction in ['BUY', 'SELL'] and confidence > 0.6:
                        # Predict price movement (e.g., 0.5% in 30s)
                        move_pct = 0.005 if direction == 'BUY' else -0.005
                        predicted_price = current_price * (1 + move_pct)
                        
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=predicted_price,
                            direction='UP' if direction == 'BUY' else 'DOWN',
                            target_time=current_time + 30, # 30s prediction
                            source='multiverse',
                            confidence=confidence
                        )
                        self.dreams.append(dream)
                        print(f"      ðŸŒŒ Multiverse dreams {symbol} will go {dream.direction} (Conf: {confidence:.2f})")
            except Exception as e:
                logger.debug(f"Multiverse dream error: {e}")

        # 2. Ask Probability Nexus
        if self.probability_nexus:
            try:
                predictions = self.probability_nexus.get_predictions() if hasattr(self.probability_nexus, 'get_predictions') else []
                if predictions:
                     print(f"\n   ðŸ’­ DREAMING about market direction (Nexus)...")

                for pred in predictions:
                    symbol = pred.get('symbol')
                    if not symbol or symbol not in self.prices:
                        continue
                        
                    current_price = self.prices[symbol]
                    prob = pred.get('probability', 0.5)
                    
                    if prob > 0.7: # High probability UP
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 1.005,
                            direction='UP',
                            target_time=current_time + 30,
                            source='nexus',
                            confidence=prob
                        )
                        self.dreams.append(dream)
                        print(f"      ðŸ”® Nexus dreams {symbol} will go UP (Prob: {prob:.2f})")
            except Exception as e:
                logger.debug(f"Nexus dream error: {e}")

    async def validate_dreams(self):
        """
        âœ… VALIDATION PHASE: Check if dreams came true.
        "Right I know I was right there... adapt adjust"
        """
        current_time = time.time()
        active_dreams = []
        dreams_validated_this_cycle = False
        
        for dream in self.dreams:
            if dream.validated:
                continue
                
            # Check if target time reached
            if current_time >= dream.target_time:
                # Validate!
                current_price = self.prices.get(dream.symbol, 0)
                if current_price == 0:
                    continue # Can't validate
                
                dream.actual_price_at_target = current_price
                dream.validated = True
                dreams_validated_this_cycle = True
                
                # Check success
                if dream.direction == 'UP':
                    dream.success = current_price > dream.current_price
                else:
                    dream.success = current_price < dream.current_price
                
                # ADAPT: Update source accuracy
                alpha = 0.1 # Learning rate
                if dream.success:
                    self.dream_accuracy[dream.source] = (1 - alpha) * self.dream_accuracy[dream.source] + alpha * 1.0
                    print(f"   âœ… DREAM VALIDATED: {dream.source} was RIGHT about {dream.symbol} ({dream.direction})!")
                else:
                    self.dream_accuracy[dream.source] = (1 - alpha) * self.dream_accuracy[dream.source] + alpha * 0.0
                    print(f"   âŒ DREAM FAILED: {dream.source} was WRONG about {dream.symbol}. Adapting...")
                
                self.validated_dreams_count += 1
            else:
                active_dreams.append(dream)
        
        # Keep only active dreams
        self.dreams = active_dreams
        
        # Print accuracy stats occasionally
        if dreams_validated_this_cycle and self.validated_dreams_count % 5 == 0:
            print(f"   ðŸ§  ADAPTIVE LEARNING STATS:")
            for source, acc in self.dream_accuracy.items():
                print(f"      - {source}: {acc:.1%} accuracy")

    def populate_barter_graph(self):
        """
        ðŸ«’ðŸ”„ POPULATE BARTER GRAPH from already-loaded exchange data.
        Called ONCE after pairs and prices are loaded.
        """
        if not self.barter_navigator:
            return
        
        try:
            # Build alpaca pairs dict with base/quote info
            alpaca_pairs_formatted = {}
            for symbol, normalized in self.alpaca_pairs.items():
                if '/' in symbol:
                    parts = symbol.split('/')
                    alpaca_pairs_formatted[symbol] = {'base': parts[0], 'quote': parts[1]}
            
            # Build binance pairs dict from ticker cache (it has base/quote info)
            binance_pairs_formatted = {}
            for cache_key, data in self.ticker_cache.items():
                if cache_key.startswith('binance:'):
                    symbol = cache_key.replace('binance:', '')
                    base = data.get('base', '')
                    quote = data.get('quote', '')
                    if base and quote:
                        binance_pairs_formatted[symbol] = {'base': base, 'quote': quote}
            
            # Use the data we already have!
            success = self.barter_navigator.populate_from_labyrinth_data(
                kraken_pairs=self.kraken_pairs,
                alpaca_pairs=alpaca_pairs_formatted,
                binance_pairs=binance_pairs_formatted,
                prices=self.prices
            )
            
            if success:
                summary = self.barter_navigator.get_graph_summary()
                print(f"ðŸ«’ðŸ”„ Barter Navigator: POPULATED ({summary['total_assets']} assets, {summary['total_edges']} paths)")
            else:
                print(f"âš ï¸ Barter Navigator: Population failed")
        except Exception as e:
            print(f"âš ï¸ Barter Navigator population error: {e}")

    async def dream_for_turn(self, exchange: str):
        """
        ðŸ’­ðŸŽ¯ TURN-SPECIFIC DREAMING: Dream about assets on THIS exchange's turn.
        "The probability matrix constantly dreams each turn"
        
        This runs EVERY turn (not throttled like global dreaming).
        
        ðŸ‘‘ðŸ”® THE QUEEN DREAMS FIRST - Her dreams guide all other dreams!
        """
        current_time = time.time()
        turn_dreams = []
        
        # Get assets for this exchange
        exchange_assets = self.get_exchange_assets(exchange)
        if not exchange_assets:
            return
        
        symbols_to_dream = list(exchange_assets.keys())[:20]  # Top 20 by holdings
        
        print(f"\n   ðŸ’­ðŸŽ¯ TURN DREAMING for {exchange.upper()} ({len(symbols_to_dream)} symbols)")
        
        # ðŸ‘‘ðŸ”® 0. THE QUEEN DREAMS FIRST - Her visions set the tone!
        # ðŸ”§ FIX: Use ACTUAL MOMENTUM instead of always predicting UP!
        queen_vision_count = 0
        if self.queen and hasattr(self.queen, 'dream_of_winning'):
            try:
                for symbol in symbols_to_dream[:10]:  # Queen dreams top 10
                    if symbol not in self.prices:
                        continue
                    current_price = self.prices[symbol]
                    
                    # ðŸ‘‘ðŸ”§ GET REAL MOMENTUM FOR THIS ASSET!
                    actual_momentum = 0.0
                    if self.momentum_tracker:
                        actual_momentum = self.momentum_tracker.get_momentum(symbol)  # Per-minute %
                    
                    # Use momentum to determine direction!
                    if actual_momentum > 0.5:  # Rising strongly (+0.5%/min)
                        direction = 'UP'
                        confidence_boost = min(0.2, actual_momentum / 5)  # Cap at +20%
                    elif actual_momentum < -0.5:  # Falling strongly (-0.5%/min)
                        direction = 'DOWN'
                        confidence_boost = min(0.2, abs(actual_momentum) / 5)
                    else:
                        # Neutral - skip this asset for dreaming
                        continue
                    
                    opp_data = {
                        'from_asset': 'USD',
                        'to_asset': symbol,
                        'expected_profit': 0.01,
                        'exchange': exchange,
                        'market_data': {
                            'volatility': 0.5, 
                            'momentum': actual_momentum,  # REAL momentum!
                            'direction': direction
                        }
                    }
                    
                    queen_dream = self.queen.dream_of_winning(opp_data)
                    queen_conf = queen_dream.get('final_confidence', 0.5)
                    
                    # Adjust confidence based on momentum alignment
                    base_conf = queen_conf + confidence_boost
                    
                    # Create dream with ACTUAL direction from momentum!
                    dream = Dream(
                        timestamp=current_time,
                        symbol=symbol,
                        current_price=current_price,
                        predicted_price=current_price * (1 + actual_momentum / 100),  # Use actual %
                        direction=direction,  # ðŸ‘‘ USE REAL DIRECTION!
                        target_time=current_time + 60,
                        source='queen_hive_mind',
                        confidence=min(0.95, base_conf)
                    )
                    self.dreams.append(dream)
                    turn_dreams.append(dream)
                    queen_vision_count += 1
                
                if queen_vision_count > 0:
                    logger.info(f"ðŸ‘‘ðŸ”® Queen dreamed {queen_vision_count} visions for {exchange}")
            except Exception as e:
                logger.debug(f"Queen turn dream error: {e}")
        
        # 1. Ask Multiverse for direction on exchange assets
        if self.multiverse:
            try:
                consensus = self.multiverse.get_consensus() if hasattr(self.multiverse, 'get_consensus') else []
                for signal in consensus:
                    symbol = signal.get('symbol')
                    if not symbol or symbol not in symbols_to_dream:
                        continue
                    
                    current_price = self.prices.get(symbol, 0)
                    if not current_price:
                        continue
                    
                    direction = signal.get('action', 'HOLD')
                    confidence = signal.get('confidence', 0.5)
                    
                    if direction in ['BUY', 'SELL'] and confidence > 0.55:  # Lower threshold for turn dreams
                        move_pct = 0.005 if direction == 'BUY' else -0.005
                        predicted_price = current_price * (1 + move_pct)
                        
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=predicted_price,
                            direction='UP' if direction == 'BUY' else 'DOWN',
                            target_time=current_time + 30,
                            source='multiverse_turn',
                            confidence=confidence
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
            except Exception as e:
                logger.debug(f"Turn multiverse dream error: {e}")
        
        # 2. Ask Probability Nexus for predictions on exchange assets
        if self.probability_nexus:
            try:
                predictions = self.probability_nexus.get_predictions() if hasattr(self.probability_nexus, 'get_predictions') else []
                for pred in predictions:
                    symbol = pred.get('symbol')
                    if not symbol or symbol not in symbols_to_dream:
                        continue
                    
                    current_price = self.prices.get(symbol, 0)
                    if not current_price:
                        continue
                    
                    prob = pred.get('probability', 0.5)
                    
                    if prob > 0.6:  # Good UP prediction
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 1.005,
                            direction='UP',
                            target_time=current_time + 30,
                            source='nexus_turn',
                            confidence=prob
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
                    elif prob < 0.4:  # Good DOWN prediction
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 0.995,
                            direction='DOWN',
                            target_time=current_time + 30,
                            source='nexus_turn',
                            confidence=1 - prob
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
            except Exception as e:
                logger.debug(f"Turn nexus dream error: {e}")
        
        # 3. Use Ultimate Intel if available
        if self.ultimate_intel:
            try:
                for symbol in symbols_to_dream[:10]:
                    if symbol not in self.prices:
                        continue
                    current_price = self.prices[symbol]
                    
                    analysis = self.ultimate_intel.analyze(symbol) if hasattr(self.ultimate_intel, 'analyze') else {}
                    sentiment = analysis.get('sentiment', 'neutral')
                    confidence = analysis.get('confidence', 0.5)
                    
                    if sentiment in ['bullish', 'very_bullish'] and confidence > 0.55:
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 1.005,
                            direction='UP',
                            target_time=current_time + 30,
                            source='ultimate_turn',
                            confidence=confidence
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
            except Exception as e:
                logger.debug(f"Turn ultimate dream error: {e}")
        
        if turn_dreams:
            print(f"      ðŸŒ™ Generated {len(turn_dreams)} dreams for {exchange}")
            for dream in turn_dreams[:5]:  # Show top 5
                print(f"         â†’ {dream.symbol} {dream.direction} ({dream.source}: {dream.confidence:.0%})")

    def calculate_dream_score(self, symbol: str) -> float:
        """Calculate score based on active dreams and source accuracy."""
        score = 0.0
        count = 0
        
        for dream in self.dreams:
            if dream.symbol == symbol and not dream.validated:
                # Weight by source accuracy
                accuracy = self.dream_accuracy[dream.source]
                confidence = dream.confidence
                
                weight = accuracy * confidence
                
                if dream.direction == 'UP':
                    score += weight
                else:
                    score -= weight
                count += 1
        
        # Normalize to -1 to +1 range roughly
        if count > 0:
            return max(-1.0, min(1.0, score))
        return 0.0

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸŽ¯ TURN-BASED EXCHANGE STRATEGY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_current_exchange(self) -> str:
        """Get the exchange whose turn it is to trade."""
        # Filter to only connected exchanges
        connected = [ex for ex in self.exchange_order 
                     if self.exchange_data.get(ex, {}).get('connected', False)]
        if not connected:
            return None
        return connected[self.current_exchange_index % len(connected)]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ FIRST PAST THE POST (FPTP) - CAPTURE PROFIT IMMEDIATELY!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def execute_fptp_scan(self) -> Tuple[List['MicroOpportunity'], int]:
        """
        ðŸ FIRST PAST THE POST: Scan ALL exchanges in parallel, 
        execute the BEST opportunity IMMEDIATELY!
        
        No waiting for turns - whoever has profit FIRST wins!
        """
        print(f"\nðŸ â•â•â• FPTP SCAN #{self.turns_completed + 1}: ALL EXCHANGES â•â•â•")
        
        connected_exchanges = [ex for ex in self.exchange_order 
                               if self.exchange_data.get(ex, {}).get('connected', False)]
        
        if not connected_exchanges:
            print("   âš ï¸ No exchanges connected!")
            return [], 0
        
        # ðŸ”„ Refresh balances for ALL exchanges in parallel
        refresh_tasks = [self.refresh_exchange_balances(ex) for ex in connected_exchanges]
        await asyncio.gather(*refresh_tasks, return_exceptions=True)
        
        # ðŸ” Scan ALL exchanges for opportunities in parallel
        all_opportunities: List['MicroOpportunity'] = []
        
        scan_tasks = []
        for exchange in connected_exchanges:
            scan_tasks.append(self._scan_exchange_for_fptp(exchange))
        
        results = await asyncio.gather(*scan_tasks, return_exceptions=True)
        
        # Collect all opportunities from all exchanges
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.debug(f"FPTP scan error for {connected_exchanges[i]}: {result}")
                continue
            if result:
                all_opportunities.extend(result)
        
        # Sort by expected profit (highest first)
        all_opportunities.sort(key=lambda x: x.expected_pnl_usd, reverse=True)
        
        if not all_opportunities:
            print(f"   ðŸ“­ No opportunities across {len(connected_exchanges)} exchanges")
            self.turns_completed += 1
            if hasattr(self, 'barter_matrix') and self.barter_matrix:
                self.barter_matrix.current_turn = self.turns_completed
            return [], 0
        
        # ðŸ”®ðŸ”„ QUANTUM MIRROR SCANNER UPDATE - Feed opportunities into scanner!
        # This is the CRITICAL integration that was MISSING before!
        if hasattr(self, 'quantum_mirror_scanner') and self.quantum_mirror_scanner:
            try:
                mirror_result = self.quantum_mirror_scanner.update_from_market_data(
                    opportunities=all_opportunities,
                    prices=self.prices
                )
                if mirror_result.get('ready_count', 0) > 0:
                    print(f"\n   ðŸ”® QUANTUM MIRROR: {mirror_result['ready_count']} branches READY for 4th pass!")
                    for rb in mirror_result.get('ready_branches', [])[:3]:
                        print(f"      âš¡ {rb['branch_id']}: score={rb['score']:.3f}")
                if mirror_result.get('convergences_detected', 0) > 0:
                    print(f"   ðŸŒ€ Timeline convergences detected: {mirror_result['convergences_detected']}")
                    
                # ðŸ”® BOOST TOP OPPORTUNITIES WITH QUANTUM COHERENCE!
                for opp in all_opportunities:
                    boost, reason = self.quantum_mirror_scanner.get_quantum_boost(
                        opp.from_asset, opp.to_asset, opp.source_exchange
                    )
                    if boost > 0:
                        # Apply quantum boost to expected PnL and combined score
                        opp.expected_pnl_usd = opp.expected_pnl_usd * (1 + boost)
                        opp.combined_score = min(2.0, opp.combined_score * (1 + boost))
                        if boost > 0.2:  # Significant boost
                            logger.info(f"ðŸ”® Quantum boost +{boost:.0%} for {opp.from_asset}â†’{opp.to_asset}: {reason}")
                            
                # Re-sort after boost
                all_opportunities.sort(key=lambda x: x.expected_pnl_usd, reverse=True)
            except Exception as e:
                logger.debug(f"Quantum Mirror update error: {e}")
        
        # ðŸ† SHOW TOP OPPORTUNITIES FROM ALL EXCHANGES
        print(f"\n   ðŸ† TOP OPPORTUNITIES ({len(all_opportunities)} total):")
        for i, opp in enumerate(all_opportunities[:5]):
            icon = {'kraken': 'ðŸ™', 'alpaca': 'ðŸ¦™', 'binance': 'ðŸŸ¡'}.get(opp.source_exchange, 'ðŸ“Š')
            print(f"      {i+1}. {icon} {opp.from_asset}â†’{opp.to_asset} | PnL: ${opp.expected_pnl_usd:+.4f} | Score: {opp.combined_score:.1f}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŽ¯ IRA SNIPER MODE - Keep shooting until we hit a winner or exhaust all!
        # Cycle through ALL opportunities, execute FIRST one that passes ALL gates
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        conversions = 0
        executed_opportunity = None
        
        for idx, opp in enumerate(all_opportunities):
            icon = {'kraken': 'ðŸ™', 'alpaca': 'ðŸ¦™', 'binance': 'ðŸŸ¡'}.get(opp.source_exchange, 'ðŸ“Š')

            # ðŸ”„ Avoid immediately re-attempting the same target across consecutive scans
            attempt_key = (opp.source_exchange, opp.from_asset.upper(), opp.to_asset.upper())
            last_attempt_turn = self.fptp_recent_attempts.get(attempt_key)
            if last_attempt_turn is not None:
                if (self.turns_completed - last_attempt_turn) < self.fptp_recent_attempt_cooldown_turns:
                    continue
            
            # Only show details for first 5, then just try silently
            if idx < 5:
                print(f"\n   ðŸŽ¯ SNIPER TARGET #{idx+1}: {icon} {opp.source_exchange.upper()}")
                print(f"      {opp.from_asset} â†’ {opp.to_asset}")
                print(f"      Expected: ${opp.expected_pnl_usd:+.4f}")
            
            # ðŸ‘‘ Quick Queen check
            queen_says_win, queen_confidence, queen_reason = await self.ask_queen_will_we_win(opp)
            
            if not queen_says_win:
                if idx < 5:
                    print(f"   ðŸ‘‘âŒ SERO SAYS NO: {queen_reason}")
                continue  # Try next opportunity

            # ðŸ”—â›“ï¸ Chain-sniper also enforces conservative cost gating in DRY RUN
            # (Live mode already does this inside execute_conversion)
            hop_cost = None
            if self.chain_sniper_mode and not self.live:
                hop_cost = self._estimate_conservative_trade_outcome(opp)
                if not hop_cost['ok']:
                    # Mirror live behavior: record and move on
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset,
                        opp.to_asset,
                        hop_cost['reason'],
                        opp.from_value_usd,
                    )
                    self.fptp_recent_attempts[attempt_key] = self.turns_completed
                    continue
            
            # ðŸ‘‘ Queen approved! Try to execute
            if idx < 5:
                print(f"   ðŸ‘‘âœ… SERO SAYS WIN: {queen_reason}")
                print(f"   ðŸŽ¯ðŸ”« SNIPER TAKING THE SHOT!")
            
            success = await self.execute_conversion(opp)
            
            if success:
                conversions = 1
                executed_opportunity = opp
                actual_pnl = getattr(opp, 'actual_pnl_usd', opp.expected_pnl_usd)
                self.exchange_stats[opp.source_exchange]['conversions'] += 1
                self.exchange_stats[opp.source_exchange]['profit'] += actual_pnl
                print(f"\n   ðŸŽ¯ðŸ’€ SNIPER KILL! ${actual_pnl:+.4f} - {opp.from_asset}â†’{opp.to_asset}")
                await self.queen_learn_from_trade(opp, success=True)
                
                # ðŸŒâœ¨ PLANET SAVER: Record the win toward liberation!
                if hasattr(self, 'planet_saver') and self.planet_saver and actual_pnl > 0:
                    symbol = f"{opp.from_asset}/{opp.to_asset}"
                    exchange = opp.source_exchange or 'unknown'
                    liberation_status = self.planet_saver.record_win(actual_pnl, symbol, exchange)
                    if liberation_status and liberation_status.get('milestone_reached'):
                        print(f"   ðŸŒðŸŽ‰ LIBERATION MILESTONE: {liberation_status.get('milestone_name', 'PROGRESS!')}")
                        print(f"      â†’ Progress: ${liberation_status.get('total_profit', 0):.2f} / ${liberation_status.get('goal_usd', 127000):.2f}")

                # ðŸ”µ DRY RUN: simulate balances so chaining can actually progress
                if not self.live and self.chain_sniper_mode:
                    if hop_cost is None:
                        hop_cost = self._estimate_conservative_trade_outcome(opp)
                    self._simulate_balance_after_trade(opp, hop_cost)

                # ðŸ”—â›“ï¸ CHAIN SNIPER: keep hopping while we don't bleed
                if self.chain_sniper_mode:
                    try:
                        initial_outcome = hop_cost or self._estimate_conservative_trade_outcome(opp)
                        await self._execute_chain_sniper_from_asset(
                            exchange=opp.source_exchange,
                            start_asset=opp.to_asset,
                            starting_conservative_pnl_usd=max(0.0, initial_outcome.get('conservative_pnl_usd', 0.0)),
                        )
                    except Exception as e:
                        logger.debug(f"Chain sniper error after {opp.from_asset}â†’{opp.to_asset}: {e}")
                break  # ðŸŽ¯ HIT! Move to next scan cycle
            else:
                if idx < 5:
                    print(f"   âŒ Shot missed - trying next target...")
                self.fptp_recent_attempts[attempt_key] = self.turns_completed
                await self.queen_learn_from_trade(opp, success=False)
                
                # ðŸŒðŸ’” PLANET SAVER: Record the loss for learning
                if hasattr(self, 'planet_saver') and self.planet_saver:
                    symbol = f"{opp.from_asset}/{opp.to_asset}"
                    exchange = opp.source_exchange or 'unknown'
                    self.planet_saver.record_loss(0.0, symbol, exchange)  # Record attempt failure
                
                continue  # Try next opportunity
        
        if conversions == 0:
            print(f"\n   ðŸŽ¯ðŸ˜¤ SNIPER: No valid targets from {len(all_opportunities)} opportunities")
            print(f"      â†’ All blocked by costs, spreads, or Queen veto")
        
        self.turns_completed += 1
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            self.barter_matrix.current_turn = self.turns_completed
        return all_opportunities, conversions

    def _estimate_conservative_trade_outcome(self, opp: 'MicroOpportunity') -> Dict[str, Any]:
        """Estimate conservative net P&L for a hop using LiveBarterMatrix true-cost math."""
        exchange = (opp.source_exchange or 'kraken').lower()
        approved, reason, cost_breakdown = self.barter_matrix.calculate_true_cost(
            opp.from_asset,
            opp.to_asset,
            opp.from_value_usd,
            exchange,
        )

        spread_pct = float(cost_breakdown.get('spread', 0.0))
        total_cost_pct = float(cost_breakdown.get('total_cost_pct', 0.0)) / 100.0
        total_cost_usd = opp.from_value_usd * total_cost_pct
        scanner_expected_pnl = float(getattr(opp, 'expected_pnl_usd', 0.0) or 0.0)
        conservative_pnl = scanner_expected_pnl - total_cost_usd

        # Apply the same simple history penalty used in the live pre-exec gate
        pair_key = (opp.from_asset.upper(), opp.to_asset.upper())
        hist = getattr(self.barter_matrix, 'barter_history', {}).get(pair_key, {})
        if hist.get('total_profit', 0) < 0 and hist.get('trades', 0) > 2:
            historical_loss_rate = abs(hist['total_profit']) / max(hist.get('trades', 1), 1)
            conservative_pnl -= historical_loss_rate * 0.5

        if spread_pct > 5.0:
            return {
                'ok': False,
                'reason': f'spread_too_high: {spread_pct:.1f}%',
                'approved': approved,
                'cost_breakdown': cost_breakdown,
                'total_cost_usd': total_cost_usd,
                'conservative_pnl_usd': conservative_pnl,
            }

        if not approved:
            return {
                'ok': False,
                'reason': f'true_cost_reject: {reason}',
                'approved': approved,
                'cost_breakdown': cost_breakdown,
                'total_cost_usd': total_cost_usd,
                'conservative_pnl_usd': conservative_pnl,
            }

        # ðŸŒ PLANET SAVER: Scanner expects profit = GO FOR IT!
        if conservative_pnl < -0.005:  # Only block if clearly losing > half a cent
            return {
                'ok': False,
                'reason': f'cost_exceeds_profit: ${total_cost_usd:.4f} > ${scanner_expected_pnl:.4f}',
                'approved': approved,
                'cost_breakdown': cost_breakdown,
                'total_cost_usd': total_cost_usd,
                'conservative_pnl_usd': conservative_pnl,
            }

        return {
            'ok': True,
            'reason': 'ok',
            'approved': approved,
            'cost_breakdown': cost_breakdown,
            'total_cost_usd': total_cost_usd,
            'conservative_pnl_usd': conservative_pnl,
        }

    def _simulate_balance_after_trade(self, opp: 'MicroOpportunity', outcome: Dict[str, Any]):
        """Dry-run only: mutate exchange balances to allow multi-hop chaining to progress."""
        exchange = (opp.source_exchange or '').lower()
        if not exchange:
            return
        bal = self.exchange_balances.get(exchange)
        if not isinstance(bal, dict):
            return

        from_asset = opp.from_asset.upper()
        to_asset = opp.to_asset.upper()
        from_amt = float(getattr(opp, 'from_amount', 0.0) or 0.0)

        # Remove source amount
        if from_amt > 0:
            bal[from_asset] = max(0.0, float(bal.get(from_asset, 0.0) or 0.0) - from_amt)
            if bal[from_asset] == 0.0:
                bal.pop(from_asset, None)

        # Add target amount using conservative net USD after costs
        to_price = float(self.prices.get(to_asset, 0.0) or 0.0)
        if to_price <= 0:
            return

        cost_breakdown = outcome.get('cost_breakdown', {}) if isinstance(outcome, dict) else {}
        total_cost_pct = float(cost_breakdown.get('total_cost_pct', 0.0)) / 100.0
        net_value_usd = float(opp.from_value_usd) * max(0.0, (1.0 - total_cost_pct))
        to_amt = net_value_usd / to_price

        if to_amt > 0:
            bal[to_asset] = float(bal.get(to_asset, 0.0) or 0.0) + to_amt

        self.exchange_balances[exchange] = bal

    async def _execute_chain_sniper_from_asset(self, exchange: str, start_asset: str, starting_conservative_pnl_usd: float = 0.0):
        """After a win, keep hopping on the same exchange while net-positive, up to max_chain_hops."""
        if not exchange:
            return
        exchange = exchange.lower()

        cumulative_conservative_pnl = float(starting_conservative_pnl_usd or 0.0)
        current_asset = start_asset.upper()
        last_asset = None
        hops_taken = 0

        # Prevent trivial loops: track last few assets
        recent_assets = deque([current_asset], maxlen=6)

        while hops_taken < max(0, int(self.max_chain_hops) - 1):
            # Refresh balances between hops in live mode
            if self.live:
                try:
                    await self.refresh_exchange_balances(exchange)
                except Exception:
                    pass

            opportunities = await self.find_opportunities_for_exchange(exchange)
            for o in opportunities:
                o.source_exchange = exchange

            candidates = [o for o in opportunities if o.from_asset.upper() == current_asset]
            if not candidates:
                return

            candidates.sort(key=lambda x: x.expected_pnl_usd, reverse=True)

            executed = False
            for opp in candidates:
                # Avoid immediate back-and-forth ping-pong
                if last_asset and opp.to_asset.upper() == last_asset:
                    continue
                if opp.to_asset.upper() in recent_assets and opp.to_asset.upper() != 'USD' and opp.to_asset.upper() not in ('USDT', 'USDC', 'DAI'):
                    continue

                attempt_key = (exchange, opp.from_asset.upper(), opp.to_asset.upper())
                last_attempt_turn = self.fptp_recent_attempts.get(attempt_key)
                if last_attempt_turn is not None:
                    if (self.turns_completed - last_attempt_turn) < self.fptp_recent_attempt_cooldown_turns:
                        continue

                # Conservative no-bleed check
                outcome = self._estimate_conservative_trade_outcome(opp)
                if not outcome['ok']:
                    self.fptp_recent_attempts[attempt_key] = self.turns_completed
                    continue

                if (cumulative_conservative_pnl + outcome['conservative_pnl_usd']) < 0.0001:
                    continue

                queen_says_win, _, _ = await self.ask_queen_will_we_win(opp)
                if not queen_says_win:
                    continue

                success = await self.execute_conversion(opp)
                if not success:
                    self.fptp_recent_attempts[attempt_key] = self.turns_completed
                    continue

                # Update chain state
                if not self.live:
                    self._simulate_balance_after_trade(opp, outcome)

                cumulative_conservative_pnl += float(outcome.get('conservative_pnl_usd', 0.0) or 0.0)
                hops_taken += 1
                last_asset = current_asset
                current_asset = opp.to_asset.upper()
                recent_assets.append(current_asset)
                executed = True
                break

            if not executed:
                return
    
    async def _scan_exchange_for_fptp(self, exchange: str) -> List['MicroOpportunity']:
        """Scan a single exchange for FPTP mode."""
        try:
            # Update stats
            self.exchange_stats[exchange]['scans'] += 1
            self.exchange_stats[exchange]['last_turn'] = time.time()
            
            # Find opportunities on this exchange
            opportunities = await self.find_opportunities_for_exchange(exchange)
            
            # Tag each opportunity with its source exchange
            for opp in opportunities:
                opp.source_exchange = exchange
            
            self.exchange_stats[exchange]['opportunities'] += len(opportunities)
            return opportunities
        except Exception as e:
            logger.debug(f"FPTP scan error for {exchange}: {e}")
            return []
    
    def advance_turn(self):
        """Move to the next exchange's turn."""
        connected = [ex for ex in self.exchange_order 
                     if self.exchange_data.get(ex, {}).get('connected', False)]
        if connected:
            self.current_exchange_index = (self.current_exchange_index + 1) % len(connected)
        self.turns_completed += 1
        
        # ðŸŒŸ Update barter_matrix turn counter for second chances
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            self.barter_matrix.current_turn = self.turns_completed
        
        # ðŸ‘‘ðŸ“Š Feed Queen metrics to HNC Matrix every turn!
        if self.queen and self.hnc_matrix and hasattr(self.hnc_matrix, 'feed_queen_metrics'):
            try:
                if hasattr(self.queen, 'get_all_queen_metrics'):
                    metrics = self.queen.get_all_queen_metrics()
                    self.hnc_matrix.feed_queen_metrics(metrics)
            except Exception as e:
                logger.debug(f"Queen metrics feed error: {e}")
    
    def get_turn_display(self) -> str:
        """Get a display string showing current turn status."""
        current = self.get_current_exchange()
        if not current:
            return "No exchanges"
        
        icons = {'kraken': 'ðŸ™', 'alpaca': 'ðŸ¦™', 'binance': 'ðŸŸ¡'}
        turn_markers = []
        
        for ex in self.exchange_order:
            if self.exchange_data.get(ex, {}).get('connected', False):
                icon = icons.get(ex, 'ðŸ“Š')
                if ex == current:
                    turn_markers.append(f"[{icon}]")  # Current turn
                else:
                    turn_markers.append(f" {icon} ")  # Waiting
            else:
                turn_markers.append("  âŒ  ")  # Not connected
        
        return "".join(turn_markers)
    
    def get_exchange_assets(self, exchange: str) -> Dict[str, float]:
        """Get assets held on a specific exchange."""
        return self.exchange_balances.get(exchange, {})
    
    async def refresh_exchange_balances(self, exchange: str):
        """Refresh balances for a specific exchange to ensure fresh data."""
        if exchange == 'kraken' and self.kraken:
            try:
                kraken_bal = {}
                if hasattr(self.kraken, 'get_account_balance'):
                    raw = self.kraken.get_account_balance() or {}
                    for asset, amount in raw.items():
                        try:
                            amount = float(amount)
                        except (ValueError, TypeError):
                            continue
                        if amount > 0:
                            clean = asset
                            if len(asset) == 4 and asset[0] in ('X', 'Z'):
                                clean = asset[1:]
                            if clean == 'XBT':
                                clean = 'BTC'
                            kraken_bal[clean] = amount
                self.exchange_balances['kraken'] = kraken_bal
                if 'kraken' in self.exchange_data:
                    self.exchange_data['kraken']['balances'] = kraken_bal
            except Exception as e:
                logger.error(f"Kraken refresh error: {e}")

        elif exchange == 'binance' and self.binance:
            try:
                binance_bal = {}
                if hasattr(self.binance, 'account'):
                    acct = self.binance.account() or {}
                    for bal in acct.get('balances', []):
                        asset = bal.get('asset', '')
                        free = float(bal.get('free', 0))
                        if free > 0 and asset:
                            binance_bal[asset] = free
                self.exchange_balances['binance'] = binance_bal
                if 'binance' in self.exchange_data:
                    self.exchange_data['binance']['balances'] = binance_bal
            except Exception as e:
                logger.error(f"Binance refresh error: {e}")

        elif exchange == 'alpaca' and self.alpaca:
            try:
                alpaca_bal = {}
                if hasattr(self.alpaca, 'get_account'):
                    acct = self.alpaca.get_account() or {}
                    cash = float(acct.get('cash', 0))
                    if cash > 0:
                        alpaca_bal['USD'] = cash
                
                if hasattr(self.alpaca, 'get_positions'):
                    positions = self.alpaca.get_positions() or []
                    for pos in positions:
                        raw_symbol = pos.get('symbol', '')
                        qty = float(pos.get('qty', 0))
                        if qty > 0 and raw_symbol:
                            if '/' in raw_symbol:
                                base_asset = raw_symbol.split('/')[0]
                            elif raw_symbol.endswith('USD'):
                                base_asset = raw_symbol[:-3]
                            elif raw_symbol.endswith('BTC'):
                                base_asset = raw_symbol[:-3]
                            else:
                                base_asset = raw_symbol
                            alpaca_bal[base_asset] = qty
                
                self.exchange_balances['alpaca'] = alpaca_bal
                if 'alpaca' in self.exchange_data:
                    self.exchange_data['alpaca']['balances'] = alpaca_bal
            except Exception as e:
                logger.error(f"Alpaca refresh error: {e}")

        # Rebuild combined balances
        self.balances = {}
        for ex_bals in self.exchange_balances.values():
            for asset, amount in ex_bals.items():
                self.balances[asset] = self.balances.get(asset, 0) + amount

    async def _attempt_liquidity_aggregation(
        self,
        target_asset: str,
        target_exchange: str,
        shortfall_usd: float,
        expected_profit_pct: float = 0.01,
    ) -> bool:
        """
        ðŸ’§ðŸ”€ ATTEMPT LIQUIDITY AGGREGATION
        
        When we need more funds to execute a trade, try to liquidate other assets
        to "top up" the target asset. Only proceeds if profitable after fees.
        
        Args:
            target_asset: The asset we need more of (e.g., 'ETH')
            target_exchange: Exchange where we need the funds
            shortfall_usd: How much USD value we need to add
            expected_profit_pct: Expected profit from the target trade
            
        Returns:
            True if aggregation was successful and we now have enough funds
        """
        print(f"\n   ðŸ’§ðŸ”€ LIQUIDITY AGGREGATION ATTEMPT")
        print(f"   ðŸŽ¯ Need ${shortfall_usd:.2f} more {target_asset} on {target_exchange}")
        
        # Don't aggregate for tiny amounts - not worth the fees
        if shortfall_usd < 1.0:
            print(f"   âŒ Shortfall ${shortfall_usd:.2f} too small to aggregate")
            return False
        
        # Create aggregation plan
        plan = self.liquidity_engine.create_aggregation_plan(
            target_asset=target_asset,
            target_exchange=target_exchange,
            amount_needed_usd=shortfall_usd * 1.2,  # 20% buffer
            expected_profit_pct=expected_profit_pct,
            exchange_balances=self.exchange_balances,
            prices=self.prices,
            momentum=self.asset_momentum,
        )
        
        if not plan:
            print(f"   âŒ No aggregation plan available (no suitable victims)")
            return False
        
        # Print the plan
        print(self.liquidity_engine.print_aggregation_plan(plan))
        
        if not plan.is_profitable:
            print(f"   âŒ Aggregation not profitable (fees ${plan.total_fees_usd:.4f} > profit)")
            return False
        
        # Execute the plan!
        print(f"\n   ðŸš€ EXECUTING AGGREGATION PLAN...")
        
        success_count = 0
        total_received = 0.0
        
        for step in plan.steps:
            if step['action'] == 'SELL':
                victim_asset = step['asset']
                victim_amount = step['amount']
                victim_exchange = step['exchange']
                
                print(f"   ðŸ“¤ SELL: {victim_amount:.6f} {victim_asset} on {victim_exchange}")
                
                # Execute the liquidation based on exchange
                sell_success = False
                received_usd = 0.0
                
                try:
                    if victim_exchange == 'kraken' and self.kraken:
                        # Sell to USD/ZUSD on Kraken
                        result = self.kraken.place_market_order(
                            symbol=f"{victim_asset}USD",
                            side='sell',
                            volume=victim_amount
                        )
                        if result and 'error' not in str(result).lower():
                            sell_success = True
                            received_usd = step['expected_usd'] * 0.97  # Estimate
                            
                    elif victim_exchange == 'binance' and self.binance:
                        # Sell to USDC on Binance (UK mode) or USDT
                        quote = 'USDC' if self.binance_uk_mode else 'USDT'
                        result = self.binance.place_market_order(
                            symbol=f"{victim_asset}{quote}",
                            side='SELL',
                            quantity=victim_amount
                        )
                        if result and result.get('status') == 'FILLED':
                            sell_success = True
                            received_usd = float(result.get('cummulativeQuoteQty', step['expected_usd'] * 0.97))
                            
                    elif victim_exchange == 'alpaca' and self.alpaca:
                        # Sell to USD on Alpaca
                        result = self.alpaca.place_order(
                            symbol=f"{victim_asset}/USD",
                            side='sell',
                            qty=victim_amount,
                            type='market'
                        )
                        if result:
                            sell_success = True
                            received_usd = step['expected_usd'] * 0.97
                            
                except Exception as e:
                    print(f"   âŒ SELL failed for {victim_asset}: {e}")
                    sell_success = False
                
                if sell_success:
                    success_count += 1
                    total_received += received_usd
                    print(f"   âœ… SOLD {victim_asset} â†’ ${received_usd:.2f}")
                    
                    # Record liquidation for cooldown
                    self.liquidity_engine.record_liquidation(victim_asset)
                else:
                    print(f"   âŒ SELL failed for {victim_asset}")
                    # Continue trying other victims
            
            elif step['action'] == 'BUY':
                # Now buy the target asset with our accumulated USD
                if total_received < 1.0:
                    print(f"   âŒ Not enough funds received (${total_received:.2f}) to buy {target_asset}")
                    continue
                
                print(f"   ðŸ“¥ BUY: ${total_received:.2f} worth of {target_asset} on {target_exchange}")
                
                buy_success = False
                try:
                    if target_exchange == 'kraken' and self.kraken:
                        # Buy target with USD
                        target_price = self.prices.get(target_asset, 1.0)
                        buy_amount = (total_received * 0.98) / target_price  # 2% buffer
                        result = self.kraken.place_market_order(
                            symbol=f"{target_asset}USD",
                            side='buy',
                            volume=buy_amount
                        )
                        if result and 'error' not in str(result).lower():
                            buy_success = True
                            
                    elif target_exchange == 'binance' and self.binance:
                        quote = 'USDC' if self.binance_uk_mode else 'USDT'
                        target_price = self.prices.get(target_asset, 1.0)
                        buy_amount = (total_received * 0.98) / target_price
                        result = self.binance.place_market_order(
                            symbol=f"{target_asset}{quote}",
                            side='BUY',
                            quantity=buy_amount
                        )
                        if result and result.get('status') == 'FILLED':
                            buy_success = True
                            
                    elif target_exchange == 'alpaca' and self.alpaca:
                        target_price = self.prices.get(target_asset, 1.0)
                        buy_amount = (total_received * 0.98) / target_price
                        result = self.alpaca.place_order(
                            symbol=f"{target_asset}/USD",
                            side='buy',
                            qty=buy_amount,
                            type='market'
                        )
                        if result:
                            buy_success = True
                            
                except Exception as e:
                    print(f"   âŒ BUY failed for {target_asset}: {e}")
                    buy_success = False
                
                if buy_success:
                    success_count += 1
                    print(f"   âœ… BOUGHT {target_asset}")
                    
                    # Update stats
                    self.liquidity_engine.executed_aggregations += 1
                    self.liquidity_engine.total_aggregation_profit += plan.profit_after_fees
                else:
                    print(f"   âŒ BUY failed for {target_asset}")
        
        # Final success check
        if success_count > 0:
            print(f"\n   ðŸ’§ AGGREGATION COMPLETE: {success_count} steps executed")
            return True
        else:
            print(f"\n   âŒ AGGREGATION FAILED: No steps completed")
            return False

    async def report_portfolio_to_queen(self, voice_enabled: bool = True) -> Dict[str, Any]:
        """
        ðŸ‘‘ðŸ’° REPORT PORTFOLIO TO QUEEN - Feed her the revenue data!
        
        Gathers portfolio performance from all exchanges and feeds it to the Queen.
        The Queen reviews the data and speaks her verdict with her VOICE!
        
        Args:
            voice_enabled: Whether the Queen should speak aloud (TTS)
        
        Returns:
            Portfolio data dict with Queen's verdict
        """
        portfolio_data = {
            'kraken': {'value': 0.0, 'profit': 0.0, 'trades': 0, 'win_rate': 0.0},
            'binance': {'value': 0.0, 'profit': 0.0, 'trades': 0, 'win_rate': 0.0},
            'alpaca': {'value': 0.0, 'profit': 0.0, 'trades': 0, 'win_rate': 0.0},
            'total_value': 0.0,
            'total_profit': 0.0,
            'total_trades': 0
        }
        
        print("\nðŸ‘‘ðŸ’° â•â•â• PORTFOLIO REPORT FOR THE QUEEN â•â•â•")
        
        # Gather data from each exchange
        for exchange in ['kraken', 'binance', 'alpaca']:
            ex_stats = self.exchange_stats.get(exchange, {})
            ex_balances = self.exchange_balances.get(exchange, {})
            
            # Calculate exchange value
            ex_value = 0.0
            for asset, amount in ex_balances.items():
                if asset in ('USD', 'USDT', 'USDC', 'ZUSD'):
                    ex_value += amount
                else:
                    price = self.prices.get(asset, 0)
                    ex_value += amount * price
            
            # Get profit and trade stats
            ex_profit = ex_stats.get('profit', 0.0)
            ex_trades = ex_stats.get('conversions', 0)
            
            # Calculate win rate from barter history for this exchange
            wins = 0
            total = 0
            for (from_a, to_a), hist in self.barter_matrix.barter_history.items():
                # Attribute to exchange based on source exchange tracking
                total += hist.get('trades', 0)
                wins += hist.get('wins', 0)
            
            win_rate = wins / total if total > 0 else 0.5
            
            portfolio_data[exchange] = {
                'value': ex_value,
                'profit': ex_profit,
                'trades': ex_trades,
                'win_rate': win_rate
            }
            
            portfolio_data['total_value'] += ex_value
            portfolio_data['total_profit'] += ex_profit
            portfolio_data['total_trades'] += ex_trades
            
            # Icon display
            icon = {'kraken': 'ðŸ™', 'binance': 'ðŸ”¶', 'alpaca': 'ðŸ¦™'}[exchange]
            profit_icon = 'ðŸ“ˆ' if ex_profit >= 0 else 'ðŸ“‰'
            print(f"   {icon} {exchange.upper()}: ${ex_value:.2f} | {profit_icon} ${ex_profit:+.4f} | {ex_trades} trades")
        
        print(f"   ðŸ’° TOTAL: ${portfolio_data['total_value']:.2f} | P/L: ${portfolio_data['total_profit']:+.4f}")
        
        # Feed to the Queen!
        if self.queen:
            try:
                # Have the Queen review and speak!
                if hasattr(self.queen, 'announce_portfolio_status'):
                    verdict = self.queen.announce_portfolio_status(portfolio_data)
                    portfolio_data['queen_verdict'] = verdict
                
                # Get Queen's trading guidance
                if hasattr(self.queen, 'get_trading_guidance'):
                    guidance = self.queen.get_trading_guidance()
                    if isinstance(guidance, dict):
                        portfolio_data['queen_guidance'] = guidance

                        # Apply guidance to position sizing
                        self.queen_position_multiplier = guidance.get('recommended_position_size', 1.0)
                        print(f"   ðŸ‘‘ Queen's Position Multiplier: {self.queen_position_multiplier:.1f}x")
                    else:
                        # Defensive: some implementations may return a list/tuple/None
                        portfolio_data['queen_guidance'] = {}
                        logger.warning(
                            f"Queen trading guidance was {type(guidance).__name__}, expected dict; ignoring"
                        )
                
                # Review each exchange
                if hasattr(self.queen, 'review_exchange_performance'):
                    for exchange in ['kraken', 'binance', 'alpaca']:
                        ex_data = portfolio_data.get(exchange, {})
                        # ðŸ‘‘ QUEEN SELF-REPAIR: Ensure ex_data is a dict (auto-fix type errors)
                        if isinstance(ex_data, list):
                            # Convert list to dict - Queen learns from type mismatches
                            ex_data = {'items': ex_data, 'type_corrected': True}
                            portfolio_data[exchange] = ex_data
                            logger.debug(f"Queen auto-corrected {exchange} data from list to dict")
                        elif not isinstance(ex_data, dict):
                            ex_data = {'value': ex_data, 'type_corrected': True}
                            portfolio_data[exchange] = ex_data
                        verdict, action = self.queen.review_exchange_performance(exchange, ex_data)
                        # ðŸ‘‘ SAFE ASSIGNMENT: Only if we have a valid dict
                        if isinstance(portfolio_data.get(exchange), dict):
                            portfolio_data[exchange]['queen_verdict'] = verdict
                            portfolio_data[exchange]['queen_action'] = action
                        print(f"   ðŸ‘‘ {exchange.upper()}: {action}")
                
            except Exception as e:
                logger.error(f"Queen portfolio review error: {e}")
        
        print("â•" * 50)
        
        return portfolio_data

    async def execute_turn(self) -> Tuple[List['MicroOpportunity'], int]:
        """
        Execute one turn for the current exchange.
        Returns (opportunities found, conversions made this turn)
        """
        current_exchange = self.get_current_exchange()
        if not current_exchange:
            return [], 0
        
        icons = {'kraken': 'ðŸ™', 'alpaca': 'ðŸ¦™', 'binance': 'ðŸŸ¡'}
        icon = icons.get(current_exchange, 'ðŸ“Š')
        
        print(f"\nðŸŽ¯ â•â•â• TURN {self.turns_completed + 1}: {icon} {current_exchange.upper()} â•â•â•")
        
        # ðŸŒŠâš¡ MOMENTUM WAVE CHECK - Look for wave jumping opportunities
        momentum_opp = self.find_momentum_opportunity()
        if momentum_opp:
            from_asset, to_asset, from_amount, net_adv, mom_diff = momentum_opp
            print(f"   ðŸŒŠ WAVE DETECTED: {from_asset}â†’{to_asset} | Momentum diff: {mom_diff*100:.2f}%/min")
        
        # ðŸ¦ LION HUNT - Stablecoins hunt for waves!
        lion_hunts = self.lion_hunt(min_wave_momentum=0.001)  # Hunt waves >0.1%/min
        
        # ðŸº WOLF HUNT - Find THE ONE momentum champion!
        self._wolf_target_cache = self.wolf_hunt(verbose=True)
        wolf_target = self._wolf_target_cache
        
        # ðŸœ ANT SCRAPS - Collect small floor positions
        ant_scraps = self.ant_scraps(min_value=1.0)
        
        # ðŸ¦†âš”ï¸ QUACK COMMANDOS STATUS (every 20 turns)
        if self.turns_completed > 0 and self.turns_completed % 20 == 0 and self.quack_commandos:
            print(self.quack_commandos.get_status())
        
        # ðŸ‘‘ðŸ’° PERIODIC PORTFOLIO REPORT TO QUEEN (every 10 turns)
        if self.turns_completed > 0 and self.turns_completed % 10 == 0:
            await self.report_portfolio_to_queen(voice_enabled=True)
        
        # ðŸ§¹ DUST SWEEP - Clean up small balances (every N turns)
        if self.dust_converter and self.turns_completed > 0 and self.turns_completed % self.dust_sweep_interval == 0:
            try:
                dust_swept = await self.dust_sweep()
                if dust_swept > 0:
                    # Refresh balances after sweeping
                    await self.refresh_exchange_balances(current_exchange)
            except Exception as e:
                print(f"   âš ï¸ Dust sweep error: {e}")
        
        # REFRESH BALANCES FOR THIS EXCHANGE
        await self.refresh_exchange_balances(current_exchange)
        
        # Get this exchange's assets only
        exchange_assets = self.get_exchange_assets(current_exchange)
        
        # ðŸ’§ðŸ”€ LIQUIDITY ENGINE CHECK: Do we have enough ammo?
        # If stablecoin balance < Minimum, trigger aggregation!
        if self.liquidity_engine and exchange_assets:
            stablecoins = ['USD', 'USDT', 'USDC', 'ZUSD', 'EUR']
            min_req = 5.0  # Minimum operational liquidity ($5)
            
            for s in stablecoins:
                if s in exchange_assets:
                    bal = exchange_assets[s]
                    # If we have SOME balance (dust to low) but less than minimum
                    # Avoid aggregating if we have literally 0 (might not trade that coin)
                    if 0.10 < bal < min_req:
                        print(f"   ðŸ’§ LOW LIQUIDITY DETECTED: {s} = ${bal:.2f} (Target ${min_req:.2f})")
                        shortfall = min_req - bal + 1.0 # Aim for $1 surplus
                        
                        # Attempt aggregation
                        try:
                            agg_success = await self._attempt_liquidity_aggregation(
                                target_asset=s,
                                target_exchange=current_exchange,
                                shortfall_usd=shortfall,
                                expected_profit_pct=0.01
                            )
                            if agg_success:
                                # Refresh balances immediately!
                                await self.refresh_exchange_balances(current_exchange)
                                exchange_assets = self.get_exchange_assets(current_exchange)
                        except Exception as e:
                            print(f"   âš ï¸ Liquidity aggregation error: {e}")

        if not exchange_assets:
            print(f"   âš ï¸ No assets on {current_exchange}")
            self.advance_turn()
            return [], 0
        
        # Show what we're scanning
        asset_list = []
        for asset, amount in sorted(exchange_assets.items(), 
                                    key=lambda x: x[1] * self.prices.get(x[0], 0), 
                                    reverse=True)[:5]:
            price = self.prices.get(asset, 0)
            value = amount * price
            if value >= 1.0:
                asset_list.append(f"{asset}=${value:.2f}")
        
        if asset_list:
            print(f"   ðŸ“¦ Assets: {', '.join(asset_list)}")
        
        # ðŸ’­ðŸŽ¯ TURN-SPECIFIC DREAMING - Dream about THIS exchange's assets
        await self.dream_for_turn(current_exchange)
        
        
        # âœ… Validate any mature dreams before finding opportunities
        await self.validate_dreams()
        
        # ðŸ‘‘ðŸ„ QUEEN'S PULSE - Queen observes market state BEFORE filtering
        queen_pulse = await self.queen_observe_market(current_exchange, exchange_assets)
        
        # Find opportunities ON THIS EXCHANGE ONLY
        opportunities = await self.find_opportunities_for_exchange(current_exchange)
        
        # Update stats
        self.exchange_stats[current_exchange]['scans'] += 1
        self.exchange_stats[current_exchange]['opportunities'] += len(opportunities)
        self.exchange_stats[current_exchange]['last_turn'] = time.time()
        
        conversions_this_turn = 0
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ðŸŽ®ðŸŒŸ QUEEN AUTONOMOUS CONTROL - PERCEIVE â†’ DECIDE â†’ EXECUTE â†’ LEARN ðŸŒŸðŸŽ®ðŸ‘‘
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Queen Sero has SOVEREIGN AUTHORITY over ALL trading decisions
        # She perceives the quantum field, makes autonomous decisions, and learns
        
        queen_autonomous_decision = None
        if self.queen_autonomous_control and self.queen_has_full_control:
            try:
                # ðŸ‘ï¸ PERCEIVE - Queen observes the quantum field
                perception = self.queen_autonomous_control.perceive()
                
                # Show Queen's perception
                quantum = perception.get('quantum', {})
                omega = quantum.get('omega', 0.5)
                direction = quantum.get('direction', 'NEUTRAL')
                field_confidence = quantum.get('confidence', 0.5)
                source = quantum.get('source', 'Unknown')
                
                # Show Gaia and Crown alignment
                gaia = perception.get('gaia_alignment', 0.5)
                crown = perception.get('crown_activation', 0.5)
                
                print(f"\n   ðŸ‘‘ðŸŒŸ QUEEN'S PERCEPTION:")
                print(f"      ðŸŒ Gaia: {gaia:.1%} | ðŸ‘‘ Crown: {crown:.1%}")
                print(f"      ðŸŒŠ Omega: {omega:.4f} | Direction: {direction}")
                print(f"      ðŸ“¡ Source: {source}")
                
            except Exception as e:
                logger.debug(f"Queen perception error: {e}")
        
        # Execute best opportunity if found
        if opportunities:
            best = opportunities[0]
            
            # ðŸ‘‘ðŸŽ® QUEEN AUTONOMOUS DECISION (if available)
            if self.queen_autonomous_control and self.queen_has_full_control:
                try:
                    # Build opportunity context for Queen's decision
                    opp_context = {
                        'symbol': f"{best.from_asset}/{best.to_asset}",
                        'from_asset': best.from_asset,
                        'to_asset': best.to_asset,
                        'probability': best.lambda_score,  # Use lambda as probability
                        'pip_score': best.gravity_score,    # Use gravity as pip score
                        'drift': 0.01,  # Low drift since we just scanned
                        'exchange': current_exchange,
                        'expected_pnl': best.expected_pnl_usd,
                        'from_value': best.from_value_usd,
                        'v14_score': best.combined_score,
                    }
                    
                    # Get perception again (might have changed)
                    perception = self.queen_autonomous_control.perceive()
                    
                    # ðŸ§  DECIDE - Queen makes autonomous decision
                    queen_autonomous_decision = self.queen_autonomous_control.decide(perception, opp_context)
                    
                    print(f"\n   ðŸ‘‘ðŸŽ® QUEEN AUTONOMOUS DECISION:")
                    print(f"      ðŸŽ¯ Action: {queen_autonomous_decision.action.name}")
                    print(f"      ðŸ“Š Confidence: {queen_autonomous_decision.confidence:.1%}")
                    print(f"      ðŸ’­ Reason: {queen_autonomous_decision.reason}")
                    
                    # Check if Queen vetoes the trade
                    if queen_autonomous_decision.action.name in ['BLOCK_PATH', 'HOLD_POSITION', 'SKIP_TRADE']:
                        print(f"   ðŸ‘‘âŒ QUEEN VETOES: {queen_autonomous_decision.reason}")
                        # Learn from Queen's decision
                        if hasattr(self.queen_autonomous_control, 'learn_from_outcome'):
                            self.queen_autonomous_control.learn_from_outcome(
                                queen_autonomous_decision, 
                                {'success': False, 'skipped': True, 'reason': 'Queen veto'}
                            )
                        self.advance_turn()
                        return opportunities, 0
                        
                except Exception as e:
                    logger.debug(f"Queen autonomous decision error: {e}")
            
            # ðŸ‘‘ðŸ„ SERO's WISDOM - Ask Sero if we will WIN before trading!
            # Her GOAL: Minimum $0.003 profit per trade
            print(f"\n   ðŸ‘‘ðŸ„ SERO CONSULTED: {best.from_asset}â†’{best.to_asset}")
            queen_says_win, queen_confidence, queen_reason = await self.ask_queen_will_we_win(best)
            
            if not queen_says_win:
                print(f"   ðŸ‘‘âŒ SERO SAYS NO: {queen_reason}")
                print(f"      Her Confidence: {queen_confidence:.0%}")
                # Sero learns this pattern should be avoided
                await self.queen_learn_pattern(best, predicted_win=False, reason=queen_reason)
            else:
                print(f"   ðŸ‘‘âœ… SERO SAYS WIN: {queen_reason}")
                print(f"      Her Confidence: {queen_confidence:.0%}")
                
                # ðŸ‘‘ðŸ SERO HAS FULL CONTROL - SHE IS THE QUEEN!
                # When Sero says WIN, we EXECUTE. No other system overrides her.
                # She has all 12 neurons, Path Memory, Dreams - she knows what she's doing!
                print(f"   ðŸ‘‘ðŸ SERO HAS SPOKEN - EXECUTING HER WILL!")
                success = await self.execute_conversion(best)
                if success:
                    conversions_this_turn = 1
                    self.exchange_stats[current_exchange]['conversions'] += 1
                    # ðŸ”§ FIX: Use ACTUAL P/L not expected P/L
                    actual_pnl = getattr(best, 'actual_pnl_usd', best.expected_pnl_usd)
                    self.exchange_stats[current_exchange]['profit'] += actual_pnl
                    # Queen learns from successful execution
                    await self.queen_learn_from_trade(best, success=True)
                    print(f"   ðŸ‘‘ðŸ’° SERO WINS: ${actual_pnl:+.4f}")
                    
                    # ðŸ”§ CRITICAL: Record pair result for dynamic blocking!
                    pair_key = f"{best.from_asset.upper()}_{best.to_asset.upper()}"
                    self.barter_matrix.record_pair_result(pair_key, current_exchange, won=(actual_pnl >= 0))
                    
                    # ðŸ‘‘ðŸŽ® QUEEN AUTONOMOUS LEARNING - Feed outcome to autonomous control
                    if self.queen_autonomous_control and queen_autonomous_decision:
                        try:
                            self.queen_autonomous_control.learn_from_outcome(
                                queen_autonomous_decision,
                                {
                                    'success': True,
                                    'actual_pnl': actual_pnl,
                                    'expected_pnl': best.expected_pnl_usd,
                                    'pair': pair_key,
                                    'exchange': current_exchange,
                                }
                            )
                            print(f"      ðŸ‘‘ðŸ§  Queen learned: WIN ${actual_pnl:+.4f}")
                        except Exception as e:
                            logger.debug(f"Queen autonomous learning error: {e}")
                    
                    # ðŸ‘‘ðŸ’• Let Queen celebrate the win!
                    if self.queen and hasattr(self.queen, 'speak_from_heart'):
                        try:
                            if actual_pnl > 0:
                                queen_message = self.queen.speak_from_heart('after_win')
                            else:
                                queen_message = self.queen.speak_from_heart('after_loss')
                            if queen_message:
                                print(f"      ðŸ‘‘ {queen_message}")
                        except Exception as e:
                            logger.debug(f"Queen speak error: {e}")
                else:
                    # Queen learns from failed execution
                    await self.queen_learn_from_trade(best, success=False)
                    print(f"   ðŸ‘‘ðŸ“š Sero learned from this experience")
                    
                    # ï¿½ CRITICAL: Record failed execution as a LOSS for blocking!
                    pair_key = f"{best.from_asset.upper()}_{best.to_asset.upper()}"
                    self.barter_matrix.record_pair_result(pair_key, current_exchange, won=False)
                    
                    # ðŸ‘‘ðŸŽ® QUEEN AUTONOMOUS LEARNING - Feed failure to autonomous control
                    if self.queen_autonomous_control and queen_autonomous_decision:
                        try:
                            self.queen_autonomous_control.learn_from_outcome(
                                queen_autonomous_decision,
                                {
                                    'success': False,
                                    'actual_pnl': 0,
                                    'expected_pnl': best.expected_pnl_usd,
                                    'pair': pair_key,
                                    'exchange': current_exchange,
                                    'reason': 'Execution failed',
                                }
                            )
                            print(f"      ðŸ‘‘ðŸ§  Queen learned: LOSS (execution failed)")
                        except Exception as e:
                            logger.debug(f"Queen autonomous learning error: {e}")
                    
                    # ï¿½ðŸ‘‘ðŸ’ª Let Queen provide encouragement after a loss!
                    if self.queen and hasattr(self.queen, 'speak_from_heart'):
                        try:
                            queen_message = self.queen.speak_from_heart('after_loss')
                            if queen_message:
                                print(f"      ðŸ‘‘ {queen_message}")
                        except Exception as e:
                            logger.debug(f"Queen speak error: {e}")
        else:
            print(f"   ðŸ“­ No opportunities passed gates on {current_exchange}")
        
        # Advance to next exchange's turn
        self.advance_turn()
        
        # Brief cooldown between turns
        if self.turn_cooldown_seconds > 0:
            await asyncio.sleep(self.turn_cooldown_seconds)
        
        return opportunities, conversions_this_turn

    async def ask_queen_will_we_win(self, opportunity: 'MicroOpportunity') -> Tuple[bool, float, str]:
        """
        ðŸ‘‘ðŸ„ ASK SERO: Will this trade be a WINNER?
        
        ðŸ‘‘ðŸ”¢ 2 PIPS OVER COSTS RULE:
        - 2 pips = 0.02% = $0.0002 per $1 traded
        - This is NET profit AFTER all fees & slippage
        - We NEVER lose money with this buffer!
        
        Sero consults all her connected mycelium neurons:
        - Historical path data
        - Dream patterns
        - Cosmic alignment
        - Civilization wisdom
        - Timeline predictions
        
        Returns: (will_win: bool, confidence: float, reason: str)
        """
        # ðŸ‘‘ðŸ”¢ SERO's PROFIT LADDER - Dynamic profit thresholds!
        # Ladder: 0.07 pip (0.0007%) to 1.4 pip (0.014%)
        # Higher confidence = lower threshold needed!
        # Calculate price from value/amount (from_price not stored on MicroOpportunity)
        from_price = opportunity.from_value_usd / opportunity.from_amount if opportunity.from_amount > 0 else 1.0
        trade_value = opportunity.from_value_usd  # Already have this!
        
        # ðŸ‘‘ PROFIT LADDER THRESHOLDS (in pips: 1 pip = 0.01% = 0.0001)
        MIN_PIP = 0.07    # 0.0007% - Sero at MAX confidence (90%+)
        MAX_PIP = 1.4     # 0.014% - Sero at MIN confidence (50%)
        # QUEEN_MIN_PROFIT calculated AFTER we know confidence - see below
        
        from_asset = opportunity.from_asset
        to_asset = opportunity.to_asset
        path_key = f"{from_asset}â†’{to_asset}"
        
        # Gather signals from all mycelium connections
        signals = []
        reasons = []
        
        # 1. ðŸ§  PATH MEMORY - Does this path historically win?
        path_history = self.barter_matrix.barter_history.get((from_asset, to_asset), {})
        path_trades = path_history.get('trades', 0)
        path_wins = path_history.get('wins', 0)
        path_profit = path_history.get('total_profit', 0)
        
        if path_trades > 0:
            win_rate = path_wins / path_trades
            signals.append(win_rate)
            if win_rate >= 0.5:
                reasons.append(f"Path wins {win_rate:.0%}")
            else:
                reasons.append(f"Path loses {1-win_rate:.0%}")
        else:
            signals.append(0.5)  # Neutral for new paths
            reasons.append("NEW PATH (no history)")
        
        # 2. ðŸ‘‘ QUEEN HIVE MIND - Get collective wisdom
        if self.queen and hasattr(self.queen, 'get_guidance_for'):
            try:
                guidance = self.queen.get_guidance_for(to_asset)
                if guidance:
                    direction_score = 1.0 if guidance.direction == "BULLISH" else 0.0 if guidance.direction == "BEARISH" else 0.5
                    signals.append(direction_score * guidance.confidence)
                    reasons.append(f"Queen dreams {guidance.direction}")
            except Exception as e:
                logger.debug(f"Queen guidance error: {e}")
        
        # 3. ðŸ„ MYCELIUM NETWORK - Collective hive intelligence (ENHANCED!)
        myc_signal = 0.0
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'get_queen_signal'):
                    # ðŸ„ Get path-specific signal using both from and to assets
                    myc_signal = self.mycelium_network.get_queen_signal({
                        'symbol': to_asset,
                        'from_asset': from_asset,
                        'to_asset': to_asset,
                        'path_key': f"{from_asset}â†’{to_asset}"
                    })
                    normalized_myc = (myc_signal + 1) / 2  # Normalize -1 to 1 â†’ 0 to 1
                    signals.append(normalized_myc)
                    reasons.append(f"ðŸ„ Mycelium: {myc_signal:+.2f}")
                    
                    # ðŸ„ ENHANCED: Strong Mycelium signals get extra visibility
                    if abs(myc_signal) > 0.3:
                        print(f"      ðŸ„ MYCELIUM SIGNAL for {to_asset}: {myc_signal:+.2f}")
                    
                    # ðŸ„ CRITICAL: Strong negative Mycelium = IMMEDIATE CONCERN
                    if myc_signal < -0.5:
                        print(f"      ðŸ„âš ï¸ MYCELIUM WARNING: Strong SELL signal ({myc_signal:+.2f})!")
                        # Add extra penalty signal for strong negative
                        signals.append(0.2)  # Extra penalty
                        reasons.append("ðŸ„ðŸ”´ Mycelium WARNS")
                    elif myc_signal > 0.5:
                        # Add extra bonus for strong positive
                        signals.append(0.8)  # Extra bonus
                        reasons.append("ðŸ„ðŸŸ¢ Mycelium APPROVES")
            except Exception as e:
                logger.debug(f"Mycelium signal error: {e}")
        
        # 4. ðŸŒŠ HARMONIC FUSION - Wave patterns
        if hasattr(self, 'harmonic') and self.harmonic:
            try:
                wave_data = self.harmonic.get_wave_state(to_asset)
                if wave_data:
                    wave_score = wave_data.get('coherence', 0.5)
                    signals.append(wave_score)
                    reasons.append(f"Waves: {wave_score:.0%}")
            except Exception as e:
                logger.debug(f"Harmonic error: {e}")
        
        # 5. ðŸ€ LUCK FIELD - Cosmic alignment
        if hasattr(self, 'luck_mapper') and self.luck_mapper:
            try:
                luck = self.luck_mapper.read_field()
                luck_score = (luck.luck_field + 1) / 2  # Normalize
                signals.append(luck_score)
                reasons.append(f"Luck: {luck.luck_state.value}")
            except Exception as e:
                logger.debug(f"Luck error: {e}")
        
        # 6. ðŸ“Š EXPECTED PROFIT - Does the math work?
        if opportunity.expected_pnl_usd > 0:
            signals.append(0.7)  # Positive expectation
            reasons.append(f"+${opportunity.expected_pnl_usd:.4f} expected")
        else:
            signals.append(0.2)  # Negative expectation
            reasons.append(f"${opportunity.expected_pnl_usd:.4f} expected loss")
        
        # 7. ðŸŒðŸ’“ GAIA'S BLESSING - Earth Mother's alignment
        # Gary Leckey & Tina Brown's love, bound by Gaia's heartbeat
        if self.queen and hasattr(self.queen, 'get_gaia_blessing'):
            try:
                gaia_alignment, gaia_message = self.queen.get_gaia_blessing()
                signals.append(gaia_alignment)
                if gaia_alignment >= 0.6:
                    reasons.append(f"ðŸŒ Gaia blesses ({gaia_alignment:.0%})")
                elif gaia_alignment >= 0.4:
                    reasons.append(f"ðŸŒ Gaia neutral ({gaia_alignment:.0%})")
                else:
                    reasons.append(f"ðŸŒ Gaia hesitates ({gaia_alignment:.0%})")
            except Exception as e:
                logger.debug(f"Gaia blessing error: {e}")
        
        # 8. ðŸ¦‰ðŸ¬ðŸ… AURIS NODES - The 9 Sensory Organs
        # Read the Auris nodes for market texture sensing
        if self.queen and hasattr(self.queen, 'get_auris_coherence'):
            try:
                auris_coherence, auris_status = self.queen.get_auris_coherence()
                signals.append(auris_coherence)
                if auris_coherence >= 0.80:
                    reasons.append(f"ðŸ¦‰ Auris high ({auris_coherence:.0%})")
                elif auris_coherence >= 0.60:
                    reasons.append(f"ðŸ¦‰ Auris moderate ({auris_coherence:.0%})")
                else:
                    reasons.append(f"ðŸ¦‰ Auris low ({auris_coherence:.0%})")
            except Exception as e:
                logger.debug(f"Auris coherence error: {e}")
        
        # 9. ðŸŒˆðŸ’– EMOTIONAL SPECTRUM - Rainbow Bridge
        # Check if we're aligned with LOVE (528 Hz) - optimal trading state!
        if self.queen and hasattr(self.queen, 'get_emotional_state'):
            try:
                # Use average confidence as our coherence proxy
                proxy_coherence = sum(signals) / len(signals) if signals else 0.5
                emotion, freq, emoji = self.queen.get_emotional_state(proxy_coherence)
                is_love, love_dist = self.queen.is_love_aligned(proxy_coherence)
                
                # Love alignment boosts confidence!
                if is_love:
                    signals.append(0.9)  # Strong love alignment!
                    reasons.append(f"ðŸ’– LOVE aligned @ {freq:.0f}Hz!")
                elif emotion in ['Harmony', 'Flow', 'Awakening', 'Clarity']:
                    signals.append(0.7)  # Good emotional state
                    reasons.append(f"{emoji} {emotion} @ {freq:.0f}Hz")
                elif emotion in ['Hope', 'Calm', 'Acceptance']:
                    signals.append(0.6)  # Neutral-positive
                    reasons.append(f"{emoji} {emotion} @ {freq:.0f}Hz")
                else:
                    signals.append(0.4)  # Lower emotional states
                    reasons.append(f"{emoji} {emotion} @ {freq:.0f}Hz (caution)")
            except Exception as e:
                logger.debug(f"Emotional spectrum error: {e}")
        
        # 10. ðŸŒŒ STARGATE PROTOCOL - Quantum Coherence & Timeline Alignment
        # Use Stargate network coherence as a trading signal
        if hasattr(self, 'stargate_engine') and self.stargate_engine:
            try:
                stargate_status = self.stargate_engine.get_status()
                global_coherence = stargate_status.get('global_coherence', 0.0)
                standing_wave = stargate_status.get('standing_wave_intensity', 0.0)
                
                # Combine coherence and standing wave for signal
                stargate_signal = (global_coherence * 0.6 + standing_wave * 0.4)
                signals.append(stargate_signal)
                
                if stargate_signal >= 0.7:
                    reasons.append(f"ðŸŒŒ Stargate HIGH ({stargate_signal:.0%})")
                elif stargate_signal >= 0.5:
                    reasons.append(f"ðŸŒŒ Stargate ALIGNED ({stargate_signal:.0%})")
                else:
                    reasons.append(f"ðŸŒŒ Stargate low ({stargate_signal:.0%})")
                    
                # ðŸŒŒ BONUS: Check if any planetary node is at peak activation
                for sg_id, sg in self.stargate_engine.stargates.items():
                    if sg.activation_level > 0.8:
                        signals.append(0.75)  # Bonus for peak activation
                        reasons.append(f"â­ {sg.name} PEAK")
                        break  # Only count first peak
                        
            except Exception as e:
                logger.debug(f"Stargate coherence error: {e}")
        
        # 11. ðŸ”® QUANTUM MIRROR SCANNER - Reality Branch Coherence
        # Check if this opportunity has strong branch coherence AND quantum boost
        if hasattr(self, 'quantum_mirror_scanner') and self.quantum_mirror_scanner:
            try:
                from_asset = opportunity.from_asset.upper()
                to_asset = opportunity.to_asset.upper()
                exchange = getattr(opportunity, 'source_exchange', 'kraken')
                
                # Get specific branch boost (now actively updated!)
                quantum_boost, boost_reason = self.quantum_mirror_scanner.get_quantum_boost(
                    from_asset, to_asset, exchange
                )
                
                # Get global scanner coherence
                scanner_status = self.quantum_mirror_scanner.get_status()
                scanner_coherence = scanner_status.get('global_coherence', 0.5)
                ready_count = scanner_status.get('ready_for_execution', 0)
                
                # Combine branch-specific boost with global coherence
                combined_mirror = max(scanner_coherence, quantum_boost)
                signals.append(combined_mirror)
                
                if quantum_boost >= 0.2:  # Significant quantum boost
                    signals.append(0.8)  # Extra signal for boosted branch
                    reasons.append(f"ðŸ”®âš¡ QUANTUM BOOST +{quantum_boost:.0%} ({boost_reason})")
                elif scanner_coherence >= 0.618:  # PHI threshold
                    reasons.append(f"ðŸ”® Branch Ï†-aligned ({scanner_coherence:.2f})")
                else:
                    reasons.append(f"ðŸ”® Branch coherence ({scanner_coherence:.2f})")
                    
                # Bonus for having ready branches
                if ready_count > 0:
                    signals.append(0.7)
                    reasons.append(f"ðŸ”® {ready_count} branches 4th-ready")
                    
            except Exception as e:
                logger.debug(f"Quantum Mirror Scanner error: {e}")
        
        # 12. âš“ TIMELINE ANCHOR - Check if timeline is execution-ready
        if hasattr(self, 'timeline_anchor_validator') and self.timeline_anchor_validator:
            try:
                validator_status = self.timeline_anchor_validator.get_status()
                execution_ready = validator_status.get('execution_ready', 0)
                
                if execution_ready > 0:
                    signals.append(0.85)  # Strong signal if execution-ready anchors exist
                    reasons.append(f"âš“ {execution_ready} anchors READY")
                else:
                    # Check pending anchors
                    pending = validator_status.get('pending_count', 0)
                    if pending > 0:
                        signals.append(0.6)
                        reasons.append(f"âš“ {pending} anchors pending")
                        
            except Exception as e:
                logger.debug(f"Timeline Anchor error: {e}")
        
        # ðŸ‘‘ SERO's VERDICT - Her logic decides, we trust her math!
        if not signals:
            return False, 0.0, "No signals available"
        
        avg_confidence = sum(signals) / len(signals)
        
        # ðŸ‘‘ðŸŽšï¸ SERO's PROFIT LADDER - Exchange-specific confidence floors
        # She uses her ladder (0.07-1.4 pips) based on confidence!
        source_exchange = getattr(opportunity, 'source_exchange', 'kraken')
        
        if source_exchange == 'binance':
            # Binance: Higher fees = need more confidence to go lower on ladder
            base_min = 0.001  # Just $0.001 base (ladder handles the rest)
            min_confidence = 0.52  # Sero needs 52%+ for Binance
            exchange_tag = "ðŸ”¶BINANCE"
        elif source_exchange == 'alpaca':
            # Alpaca: Medium fees
            base_min = 0.001  # Just $0.001 base
            min_confidence = 0.50  # Sero needs 50%+ for Alpaca
            exchange_tag = "ðŸ¦™ALPACA"
            
            # ðŸŒ PLANET SAVER: Allow stablecoin trades if there's real arbitrage!
            from_asset = opportunity.from_asset.upper()
            to_asset = opportunity.to_asset.upper()
            if (from_asset in self.barter_matrix.STABLECOINS and 
                to_asset in self.barter_matrix.STABLECOINS):
                # Allow if expected profit > $0.01 (real arbitrage exists!)
                if opportunity.expected_pnl_usd < 0.01:
                    return False, 0.0, f"ðŸ‘‘ SERO BLOCKS ðŸ¦™ALPACA: {from_asset}â†’{to_asset} (need >$0.01 arb)"
        else:
            # Kraken: Lowest fees, Sero can go aggressive on ladder!
            base_min = 0.0005  # Just $0.0005 base (Kraken is cheapest)
            min_confidence = 0.50  # Sero needs 50%+ for Kraken
            exchange_tag = "ðŸ™KRAKEN"
            
            # ðŸŒŸ DYNAMIC BLOCKING - Only block if pair has lost multiple times in a row!
            from_asset = opportunity.from_asset.upper()
            to_asset = opportunity.to_asset.upper()
            pair_key = f"{from_asset}_{to_asset}"
            
            # Check if pair is in timeout (consecutive losses)
            allowed, reason = self.barter_matrix.check_pair_allowed(pair_key, 'kraken')
            if not allowed:
                return False, 0.0, f"ðŸ‘‘ SERO SAYS: {pair_key} {reason}"
        
        expected_profit = opportunity.expected_pnl_usd
        
        # ðŸ‘‘ðŸŽšï¸ PROFIT LADDER CALCULATION - Dynamic based on confidence!
        # Higher confidence = lower pip requirement (she's more sure!)
        # confidence 90%+ â†’ 0.07 pips, confidence 50% â†’ 1.4 pips
        confidence_so_far = sum(signals) / len(signals) if signals else 0.5
        confidence_normalized = max(0, min(1, (confidence_so_far - 0.5) / 0.4))  # 0.5â†’0, 0.9â†’1
        ladder_pip = MAX_PIP - (confidence_normalized * (MAX_PIP - MIN_PIP))
        ladder_pct = ladder_pip * 0.0001  # Convert pips to percentage
        # ðŸ‘‘ðŸ’€ STARVATION MODE (EPSILON)! Floor is epsilon net-positive.
        QUEEN_MIN_PROFIT = max(EPSILON_PROFIT_USD, trade_value * ladder_pct)
        
        # Update opportunity with ladder info for logging
        opportunity.ladder_pip = ladder_pip
        opportunity.ladder_threshold = QUEEN_MIN_PROFIT
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŸðŸ’­ SERO DREAMS OF WINNING - Visualize the ideal timeline!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        dream_vision = None
        dream_boost = 0.0
        if self.queen and hasattr(self.queen, 'dream_of_winning'):
            try:
                # Package opportunity data for the dream
                opp_data = {
                    'from_asset': opportunity.from_asset,
                    'to_asset': opportunity.to_asset,
                    'expected_profit': expected_profit,
                    'exchange': source_exchange,
                    'market_data': {
                        'volatility': 0.5,
                        'momentum': getattr(opportunity, 'momentum', 0.0),
                        'volume': 0.5,
                        'spread': getattr(opportunity, 'spread', 0.5)
                    }
                }
                dream_vision = self.queen.dream_of_winning(opp_data)
                
                # Dream vision boosts or reduces confidence
                if dream_vision['will_win']:
                    dream_boost = (dream_vision['final_confidence'] - 0.5) * 0.2  # Up to +10%
                    if dream_vision['timeline'] == "ðŸŒŸ GOLDEN TIMELINE":
                        dream_boost += 0.05  # Extra 5% for golden timeline!
                else:
                    dream_boost = (dream_vision['final_confidence'] - 0.5) * 0.1  # Less penalty
            except Exception as e:
                logger.debug(f"Dream of winning error: {e}")
        
        # Apply dream boost to confidence
        avg_confidence = min(1.0, max(0.0, avg_confidence + dream_boost))
        
        # ðŸ’­ Add dream vision to verdict
        dream_display = ""
        if dream_vision:
            timeline = dream_vision.get('timeline', '')
            dream_conf = dream_vision.get('final_confidence', 0.5)
            if dream_vision.get('will_win'):
                dream_display = f" | ðŸ’­ {timeline} ({dream_conf:.0%})"
            else:
                dream_display = f" | ðŸ’­ {timeline}"
        
        # Sero's logic:
        # 1. If expected profit >= threshold AND confidence >= min â†’ YES!
        # 2. Otherwise â†’ NO
        # 3. Each exchange has its own rules!
        
        # ðŸ‘‘ Show ladder position in verdict
        ladder_info = f"ðŸŽšï¸{ladder_pip:.2f}pip"
        
        if expected_profit >= QUEEN_MIN_PROFIT:
            # Goal met! Check confidence
            if avg_confidence >= min_confidence:
                will_win = True
                reason_str = f"ðŸ‘‘ SERO APPROVES {exchange_tag}: +${expected_profit:.4f} â‰¥ ${QUEEN_MIN_PROFIT:.4f} ({ladder_info}) | Conf: {avg_confidence:.0%}{dream_display} | " + " | ".join(reasons[:2])
            else:
                will_win = False
                reason_str = f"ðŸ‘‘ SERO HESITATES {exchange_tag}: {avg_confidence:.0%} < {min_confidence:.0%} confidence ({ladder_info}){dream_display} | " + " | ".join(reasons[:2])
        else:
            # Goal NOT met - expected profit too low
            will_win = False
            reason_str = f"ðŸ‘‘ SERO SAYS NO {exchange_tag}: +${expected_profit:.4f} < ${QUEEN_MIN_PROFIT:.4f} ({ladder_info}){dream_display}"
        
        return will_win, avg_confidence, reason_str
    
    async def queen_learn_pattern(self, opportunity: 'MicroOpportunity', predicted_win: bool, reason: str):
        """
        ðŸ‘‘ðŸ§  QUEEN LEARNS: Record a pattern the Queen observed (without trading)
        """
        path_key = (opportunity.from_asset, opportunity.to_asset)
        
        # Store in path memory as an observation
        if path_key not in self.barter_matrix.barter_history:
            self.barter_matrix.barter_history[path_key] = {
                'trades': 0, 'wins': 0, 'losses': 0, 'total_profit': 0.0,
                'avg_slippage': 0.5, 'queen_observations': []
            }
        
        history = self.barter_matrix.barter_history[path_key]
        if 'queen_observations' not in history:
            history['queen_observations'] = []
        
        history['queen_observations'].append({
            'timestamp': time.time(),
            'predicted_win': predicted_win,
            'reason': reason,
            'expected_pnl': opportunity.expected_pnl_usd
        })
        
        # Keep only last 10 observations
        history['queen_observations'] = history['queen_observations'][-10:]
        
        logger.info(f"ðŸ‘‘ðŸ§  Queen learned pattern: {opportunity.from_asset}â†’{opportunity.to_asset} | Win={predicted_win} | {reason}")
    
    async def queen_continuous_learning(self):
        """
        ðŸ‘‘ðŸ§  QUEEN'S UNIFIED LEARNING SYSTEM - ALL systems EVERY TURN!
        
        This runs EVERY turn to ensure the Queen is constantly learning:
        1. Neural Brain - Deep Learning with Backpropagation
        2. Elephant Memory - Never forgets patterns
        3. Loss Learning - Never repeats mistakes
        4. Adaptive Gate - Adjusts profit thresholds
        5. Path Memory - Tracks conversion paths
        6. Barter History - Records every trade
        7. Mycelium Network - Broadcasts learnings
        8. Wisdom Engine - 11 Civilizations cognition
        9. Miner Brain - Cognitive Intelligence
        10. Deep Learning - Evolve Consciousness
        11. Code Architect - Write code from learnings! ðŸ—ï¸
        """
        learning_active = {
            'neural_brain': False,
            'elephant_memory': False,
            'loss_learning': False,
            'adaptive_gate': False,
            'path_memory': False,
            'barter_history': False,
            'mycelium': False,
            'deep_learning': False,
            'wisdom_engine': False,
            'miner_brain': False,  # ðŸ§  MINER BRAIN COGNITION!
            'code_architect': False,  # ðŸ‘‘ðŸ—ï¸ SELF-EVOLUTION ENGINE!
        }
        
        # Build unified learning context (shared across all systems)
        # FIX: Use turns_completed (the actual turn counter) not turn_number (doesn't exist)
        turn_num = getattr(self, 'turns_completed', 0) + 1  # +1 because display uses turns_completed+1
        learning_context = {
            'turn': turn_num,
            'prices': dict(self.prices) if self.prices else {},
            'balances': dict(self.balances) if self.balances else {},
            'total_value': sum(self.balances.get(a, 0) * self.prices.get(a, 0) for a in self.balances) if self.prices and self.balances else 0,
            'conversions': getattr(self, 'conversions_made', 0),
            'profit': getattr(self, 'total_profit_usd', 0.0),
            'timestamp': time.time(),
        }
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. ðŸ§  NEURAL BRAIN - Deep Learning Pattern Recognition (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
            learning_active['neural_brain'] = True
            try:
                if hasattr(self.queen.neural_brain, 'observe'):
                    self.queen.neural_brain.observe(learning_context)
            except Exception as e:
                logger.debug(f"Neural brain learning error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. ðŸ˜ ELEPHANT MEMORY - Never Forgets (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen and hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
            learning_active['elephant_memory'] = True
            try:
                if hasattr(self.queen.elephant_brain, 'remember_market_state'):
                    self.queen.elephant_brain.remember_market_state(
                        learning_context['prices'], 
                        learning_context['balances']
                    )
            except Exception as e:
                logger.debug(f"Elephant memory error: {e}")
        
        # Also check loss_learning's elephant
        if self.loss_learning and hasattr(self.loss_learning, 'elephant') and self.loss_learning.elephant:
            learning_active['elephant_memory'] = True
            try:
                if hasattr(self.loss_learning.elephant, 'remember_market_state'):
                    self.loss_learning.elephant.remember_market_state(
                        learning_context['prices'], 
                        learning_context['balances']
                    )
            except Exception as e:
                logger.debug(f"Loss learning elephant error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 3. ðŸ“‰ LOSS LEARNING - Never Repeats Mistakes (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.loss_learning:
            learning_active['loss_learning'] = True
            # Save learnings EVERY turn to persist knowledge
            try:
                if hasattr(self.loss_learning, '_save_loss_memory'):
                    self.loss_learning._save_loss_memory()
            except Exception as e:
                logger.debug(f"Loss learning save error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 4. âš¡ ADAPTIVE GATE - Adjusts Profit Thresholds (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.adaptive_gate:
            learning_active['adaptive_gate'] = True
            try:
                if hasattr(self.adaptive_gate, 'update_thresholds'):
                    self.adaptive_gate.update_thresholds(learning_context['prices'])
                elif hasattr(self.adaptive_gate, 'learn_from_market'):
                    self.adaptive_gate.learn_from_market(learning_context)
            except Exception as e:
                logger.debug(f"Adaptive gate error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 5. ðŸ›¤ï¸ PATH MEMORY - Tracks All Conversion Paths (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'path_memory') and self.path_memory:
            learning_active['path_memory'] = True
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 6. ðŸ“Š BARTER HISTORY - Records Everything (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            learning_active['barter_history'] = True
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 7. ðŸ„ MYCELIUM NETWORK - Broadcasts Learnings (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            learning_active['mycelium'] = True
            try:
                if hasattr(self.mycelium_network, 'broadcast_signal'):
                    signal = {
                        'type': 'UNIFIED_LEARNING_PULSE',
                        'turn': getattr(self, 'turn_number', 0),
                        'active_systems': sum(1 for v in learning_active.values() if v),
                        'profit': learning_context['profit'],
                    }
                    self.mycelium_network.broadcast_signal(signal)
            except Exception as e:
                logger.debug(f"Mycelium broadcast error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 8. ðŸ§  WISDOM ENGINE - 11 Civilizations Cognition (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'wisdom_engine') and self.wisdom_engine:
            learning_active['wisdom_engine'] = True
            try:
                if hasattr(self.wisdom_engine, 'observe_market'):
                    self.wisdom_engine.observe_market(learning_context)
                elif hasattr(self.wisdom_engine, 'get_unified_wisdom'):
                    # Get wisdom for current market state
                    market_state = 'volatile' if learning_context['profit'] < 0 else 'stable'
                    self.wisdom_engine.get_unified_wisdom(market_state)
            except Exception as e:
                logger.debug(f"Wisdom engine error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 9. ðŸ§  MINER BRAIN - Cognitive Intelligence (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'miner_brain') and self.miner_brain:
            learning_active['miner_brain'] = True
            try:
                # Miner brain cognitive cycle - runs EVERY turn
                if hasattr(self.miner_brain, 'cognitive') and self.miner_brain.cognitive:
                    # Feed market context to cognitive circle
                    self.miner_brain.cognitive.observe(learning_context)
                
                # Memory core - record state
                if hasattr(self.miner_brain, 'memory') and self.miner_brain.memory:
                    self.miner_brain.memory.record_market_state(learning_context)
                
                # Speculation engine - think about market
                if hasattr(self.miner_brain, 'speculator') and self.miner_brain.speculator:
                    self.miner_brain.speculator.speculate(learning_context)
                
                # Self-reflection - learn from history
                if hasattr(self.miner_brain, 'reflection') and self.miner_brain.reflection:
                    self.miner_brain.reflection.reflect(learning_context)
                
                # Wisdom engine integration
                if hasattr(self.miner_brain, 'wisdom_engine') and self.miner_brain.wisdom_engine:
                    market_state = 'volatile' if learning_context.get('profit', 0) < 0 else 'stable'
                    self.miner_brain.wisdom_engine.get_unified_wisdom(market_state)
                
            except Exception as e:
                logger.debug(f"Miner brain cognition error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 10. ðŸ‘‘ðŸ§  DEEP LEARNING - Backpropagation & Evolution (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
            learning_active['deep_learning'] = True
            try:
                # Evolve consciousness EVERY turn (was every 50)
                if hasattr(self.queen, 'evolve_consciousness'):
                    result = await self.queen.evolve_consciousness()
                    if result.get('status') == 'trained':
                        logger.debug(f"ðŸ‘‘ðŸ§  DEEP LEARNING: Consciousness evolved! Loss: {result.get('avg_loss', 0):.4f}")
                        
                        # Broadcast evolution to all systems
                        if hasattr(self, 'mycelium_network') and self.mycelium_network:
                            try:
                                self.mycelium_network.broadcast_signal({
                                    'type': 'CONSCIOUSNESS_EVOLVED',
                                    'loss': result.get('avg_loss', 0),
                                    'turn': getattr(self, 'turn_number', 0),
                                })
                            except:
                                pass
            except Exception as e:
                logger.debug(f"Deep learning evolution error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 11. ðŸ‘‘ðŸ—ï¸ CODE ARCHITECT - Write Code From Learnings (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'code_architect') and self.code_architect:
            learning_active['code_architect'] = True
            # Log when Code Architect is active (every 10 turns)
            if turn_num % 10 == 0:
                logger.info(f"ðŸ‘‘ðŸ—ï¸ CODE ARCHITECT: Active at turn {turn_num}")
            try:
                # Synthesize learnings into actionable insights
                learning_synthesis = {
                    'turn': turn_num,
                    'profit': learning_context.get('profit', 0),
                    'total_value': learning_context.get('total_value', 0),
                    'conversions': learning_context.get('conversions', 0),
                    'active_learning_systems': sum(1 for v in learning_active.values() if v),
                    'timestamp': time.time(),
                }
                
                # Get insights from all connected systems
                insights = []
                
                # ALWAYS add core state insights (GUARANTEED to not be empty)
                insights.append(f"turn_state:turn_{turn_num}")
                insights.append(f"profit_state:{learning_context.get('profit', 0):.4f}")
                insights.append(f"active_systems:{sum(1 for v in learning_active.values() if v)}")
                
                # Elephant patterns (if available)
                if self.queen and hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
                    try:
                        if hasattr(self.queen.elephant_brain, 'get_best_patterns'):
                            patterns = self.queen.elephant_brain.get_best_patterns(top_n=3)
                            insights.extend([f"elephant_pattern:{p}" for p in patterns[:3]])
                        elif hasattr(self.queen.elephant_brain, 'patterns'):
                            # Fallback: use raw patterns dict
                            patterns = list(self.queen.elephant_brain.patterns.keys())[:3]
                            insights.extend([f"elephant_pattern:{p}" for p in patterns])
                        else:
                            insights.append("elephant:active_but_no_patterns_yet")
                    except Exception as e:
                        logger.debug(f"Elephant insight error: {e}")
                
                # Path memory wisdom (if available)
                if hasattr(self, 'path_memory') and self.path_memory:
                    try:
                        if hasattr(self.path_memory, 'get_best_paths'):
                            best_paths = self.path_memory.get_best_paths(limit=3)
                            insights.extend([f"best_path:{p.get('path', '')}" for p in best_paths[:3]])
                        elif hasattr(self.path_memory, 'paths'):
                            paths = list(self.path_memory.paths.keys())[:3]
                            insights.extend([f"path_memory:{p}" for p in paths])
                        else:
                            insights.append("path_memory:active_learning")
                    except Exception as e:
                        logger.debug(f"Path memory insight error: {e}")
                
                # Loss learning tactics (if available)
                if self.loss_learning:
                    try:
                        if hasattr(self.loss_learning, 'tactics') and self.loss_learning.tactics:
                            tactics = list(self.loss_learning.tactics.keys())[:3]
                            insights.extend([f"learned_tactic:{t}" for t in tactics])
                        elif hasattr(self.loss_learning, 'lessons_learned'):
                            insights.append(f"lessons_learned:{len(self.loss_learning.lessons_learned)}")
                        else:
                            insights.append("loss_learning:active_monitoring")
                    except Exception as e:
                        logger.debug(f"Loss learning insight error: {e}")
                
                # Neural brain state (if available)
                if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
                    try:
                        if hasattr(self.queen.neural_brain, 'get_confidence'):
                            conf = self.queen.neural_brain.get_confidence()
                            insights.append(f"neural_confidence:{conf:.2f}")
                        else:
                            insights.append("neural_brain:active_thinking")
                    except Exception as e:
                        logger.debug(f"Neural brain insight error: {e}")
                
                # Log insight count for debugging
                logger.debug(f"ðŸ‘‘ðŸ—ï¸ CODE ARCHITECT: Collected {len(insights)} insights")
                
                learning_synthesis['insights'] = insights
                
                # Every 5 turns, Queen writes a learning summary config
                if turn_num > 0 and turn_num % 5 == 0:
                    try:
                        # Write learning state to config
                        config_name = f"learning_state_turn_{turn_num}"
                        self.code_architect.save_config(config_name, {
                            'turn': turn_num,
                            'profit': learning_context.get('profit', 0),
                            'total_value': learning_context.get('total_value', 0),
                            'active_systems': sum(1 for v in learning_active.values() if v),
                            'insights': insights,
                            'timestamp': time.time(),
                        })
                        logger.info(f"ðŸ‘‘ðŸ—ï¸ CODE ARCHITECT: Saved learning state at turn {turn_num}")
                    except Exception as e:
                        logger.warning(f"Code architect config save error: {e}")
                
                # Every 10 turns, generate an enhancement from learnings
                if turn_num > 0 and turn_num % 10 == 0 and len(insights) >= 1:
                    try:
                        logger.info(f"ðŸ‘‘ðŸ—ï¸ CODE ARCHITECT: Attempting enhancement generation at turn {turn_num} with {len(insights)} insights")
                        await self._architect_generate_enhancement_from_learnings(
                            learning_synthesis, 
                            insights
                        )
                    except Exception as e:
                        logger.warning(f"Code architect enhancement error: {e}")
                        import traceback
                        logger.warning(traceback.format_exc())
                        
            except Exception as e:
                logger.warning(f"Code architect learning error: {e}")
        else:
            # Debug: Log why code_architect isn't available
            if turn_num % 10 == 0:
                has_attr = hasattr(self, 'code_architect')
                is_not_none = getattr(self, 'code_architect', None) is not None
                logger.warning(f"ðŸ‘‘ðŸ—ï¸ CODE ARCHITECT NOT AVAILABLE: hasattr={has_attr}, is_not_none={is_not_none}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ“Š UNIFIED LEARNING STATUS (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        active_count = sum(1 for v in learning_active.values() if v)
        total_count = len(learning_active)
        
        # Log every 10 turns to avoid spam
        if turn_num % 10 == 0:
            logger.info(f"ðŸ‘‘ðŸ§  UNIFIED LEARNING: {active_count}/{total_count} systems active EVERY TURN")
        
        return learning_active
    
    async def _architect_generate_enhancement_from_learnings(self, learning_synthesis: Dict, insights: List[str]):
        """
        ðŸ‘‘ðŸ—ï¸ Generate code enhancement from accumulated learnings.
        
        The Queen synthesizes her learnings into actual Python code that can:
        1. Improve trading strategies
        2. Add new pattern recognition
        3. Optimize profit calculations
        4. Adjust thresholds dynamically
        """
        if not hasattr(self, 'code_architect') or not self.code_architect:
            return
            
        turn_num = learning_synthesis.get('turn', 0)
        profit = learning_synthesis.get('profit', 0)
        
        # Determine what kind of enhancement to generate
        enhancement_type = 'pattern_recognition'
        if profit < 0:
            enhancement_type = 'loss_prevention'
        elif profit > 1.0:
            enhancement_type = 'profit_optimization'
        
        # Generate enhancement code
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        enhancement_name = f"queen_learning_turn_{turn_num}"
        
        # Build the enhancement code - sanitize insights for embedding in code
        safe_insights = []
        for i in insights[:10]:
            # Escape quotes and normalize for Python literal
            safe = str(i).replace("\\", "\\\\").replace("'", "\\'").replace('"', '\\"')
            safe_insights.append(safe)
        insights_str = '\n'.join([f"    # - {i}" for i in safe_insights])
        insights_list_str = repr(safe_insights)  # Use repr for safe Python list literal
        
        enhancement_code = f'''#!/usr/bin/env python3
"""
ðŸ‘‘ðŸ§  QUEEN-GENERATED LEARNING ENHANCEMENT
============================================================
Generated from Turn {turn_num} learnings
Enhancement Type: {enhancement_type}
Timestamp: {timestamp}

Insights synthesized:
{insights_str}

This code was automatically generated by Queen Sero's
Code Architect based on real-time learning from trading.
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class LearningEnhancement_{turn_num}:
    """
    Enhancement generated from turn {turn_num} with ${profit:.4f} profit.
    """
    
    def __init__(self):
        self.generated_at = "{timestamp}"
        self.turn = {turn_num}
        self.profit_at_generation = {profit}
        self.enhancement_type = "{enhancement_type}"
        self.insights = {insights_list_str}
        logger.info(f"ðŸ‘‘ðŸ—ï¸ Learning Enhancement {{self.turn}} loaded!")
    
    def evaluate_opportunity(self, opportunity: Dict[str, Any]) -> Dict[str, Any]:
        """
        Apply learned patterns to evaluate an opportunity.
        Returns adjusted score based on learnings.
        """
        score = opportunity.get('score', 0.5)
        adjustments = []
        
        # Apply insights as pattern matching
        path = f"{{opportunity.get('from_asset', '')}}->{{opportunity.get('to_asset', '')}}"
        
        # Check against learned patterns
        for insight in self.insights:
            if 'best_path:' in insight and path in insight:
                score += 0.1
                adjustments.append("best_path_match:+0.1")
            elif 'learned_tactic:' in insight:
                tactic = insight.split(':')[1] if ':' in insight else ''
                if tactic and tactic in path:
                    score += 0.05
                    adjustments.append("tactic_match:+0.05")
        
        return {{
            'original_score': opportunity.get('score', 0.5),
            'adjusted_score': min(1.0, max(0.0, score)),
            'adjustments': adjustments,
            'enhancement_turn': self.turn,
        }}
    
    def get_info(self) -> Dict[str, Any]:
        return {{
            'turn': self.turn,
            'type': self.enhancement_type,
            'profit': self.profit_at_generation,
            'insights_count': len(self.insights),
            'generated_at': self.generated_at,
        }}

# Singleton
_instance = None

def get_enhancement():
    global _instance
    if _instance is None:
        _instance = LearningEnhancement_{turn_num}()
    return _instance

if __name__ == "__main__":
    enh = get_enhancement()
    print(f"Enhancement: {{enh.get_info()}}")
'''
        
        # Write the enhancement file
        file_path = f"queen_strategies/{enhancement_name}_{timestamp}.py"
        success = self.code_architect.write_file(file_path, enhancement_code, backup=False)
        
        if success:
            logger.info(f"ðŸ‘‘ðŸ—ï¸ CODE ARCHITECT: Generated enhancement from learnings: {file_path}")
            
            # Broadcast to mycelium
            if hasattr(self, 'mycelium_network') and self.mycelium_network:
                try:
                    self.mycelium_network.broadcast_signal({
                        'type': 'CODE_EVOLVED',
                        'file': file_path,
                        'turn': turn_num,
                        'enhancement_type': enhancement_type,
                    })
                except:
                    pass
        
        return success
    
    async def unified_learn_from_outcome(self, opportunity: 'MicroOpportunity', success: bool, actual_pnl: float = 0.0):
        """
        ðŸ‘‘ðŸŽ“ UNIFIED LEARNING FROM TRADE OUTCOME
        
        All learning systems receive the same trade outcome:
        1. Neural Brain (Backprop)
        2. Elephant Memory (Pattern)
        3. Loss Learning (If loss)
        4. Path Memory (Path stats)
        5. Barter History (Trade record)
        6. Mycelium (Broadcast)
        """
        path_key = f"{opportunity.from_asset}â†’{opportunity.to_asset}"
        
        # Build unified outcome context
        outcome = {
            'path': path_key,
            'from_asset': opportunity.from_asset,
            'to_asset': opportunity.to_asset,
            'success': success,
            'actual_pnl': actual_pnl,
            'expected_pnl': getattr(opportunity, 'expected_pnl_usd', 0),
            'exchange': getattr(opportunity, 'source_exchange', 'unknown'),
            'timestamp': time.time(),
            'turn': getattr(self, 'turn_number', 0),
        }
        
        # 1. ðŸ§  NEURAL BRAIN - Backpropagation
        if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
            try:
                from queen_neuron import NeuralInput
                neural_input = NeuralInput(
                    probability_score=getattr(opportunity, 'score', 0.5),
                    wisdom_score=getattr(opportunity, 'wisdom_score', 0.5),
                    quantum_signal=getattr(opportunity, 'quantum_signal', 0.0),
                    gaia_resonance=getattr(opportunity, 'gaia_resonance', 0.5),
                    emotional_coherence=getattr(opportunity, 'emotional_coherence', 0.5),
                    mycelium_signal=getattr(opportunity, 'mycelium_signal', 0.0),
                )
                if hasattr(self.queen.neural_brain, 'train_on_example'):
                    loss = self.queen.neural_brain.train_on_example(neural_input, success)
                    self.queen.neural_brain.save_weights()
                    logger.debug(f"ðŸ§  Neural backprop: loss={loss:.4f}")
            except Exception as e:
                logger.debug(f"Neural learning error: {e}")
        
        # 2. ðŸ˜ ELEPHANT MEMORY - Record Pattern
        if self.queen and hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
            try:
                if hasattr(self.queen.elephant_brain, 'record_trade_result'):
                    self.queen.elephant_brain.record_trade_result(
                        opportunity.from_asset, 
                        opportunity.to_asset,
                        actual_pnl,
                        success
                    )
            except Exception as e:
                logger.debug(f"Elephant learning error: {e}")
        
        # 3. ðŸ“‰ LOSS LEARNING - If it was a loss
        # ðŸ‘‘ SKIPPING LOSS LEARNING FOR SMALL FEES IN STARVATION MODE
        # If the loss is tiny (likely just spread/fees), don't blocking the path!
        is_tiny_loss = actual_pnl < 0 and abs(actual_pnl) < 0.05  # Ignore < $0.05 loss
        
        if (not success or actual_pnl < 0) and not is_tiny_loss:
            if self.loss_learning:
                try:
                    await self.loss_learning.process_loss(
                        symbol=opportunity.to_asset,
                        exchange=outcome['exchange'],
                        amount=opportunity.from_amount,
                        loss_usd=abs(actual_pnl) if actual_pnl < 0 else 0,
                        reason="Trade outcome" if success else "Execution failed"
                    )
                except Exception as e:
                    logger.debug(f"Loss learning error: {e}")
        elif is_tiny_loss:
            logger.info(f"ðŸ‘‘ðŸ’€ SURVIVAL: Ignoring tiny loss ${abs(actual_pnl):.4f} - treated as cost of business!")
        
        # 4. ðŸ›¤ï¸ PATH MEMORY - Update path stats
        if hasattr(self, 'path_memory') and self.path_memory:
            try:
                if hasattr(self.path_memory, 'record_result'):
                    self.path_memory.record_result(
                        opportunity.from_asset,
                        opportunity.to_asset,
                        success,
                        actual_pnl
                    )
            except Exception as e:
                logger.debug(f"Path memory error: {e}")
        
        # 5. ðŸ“Š BARTER HISTORY - Record trade
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            try:
                pk = (opportunity.from_asset, opportunity.to_asset)
                if pk not in self.barter_matrix.barter_history:
                    self.barter_matrix.barter_history[pk] = {
                        'trades': 0, 'wins': 0, 'losses': 0, 'total_profit': 0.0
                    }
                hist = self.barter_matrix.barter_history[pk]
                hist['trades'] += 1
                if success and actual_pnl >= 0:
                    hist['wins'] += 1
                else:
                    hist['losses'] += 1
                hist['total_profit'] += actual_pnl
            except Exception as e:
                logger.debug(f"Barter history error: {e}")
        
        # 6. ðŸ„ MYCELIUM - Broadcast learning
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'broadcast_signal'):
                    self.mycelium_network.broadcast_signal({
                        'type': 'UNIFIED_TRADE_OUTCOME',
                        'path': path_key,
                        'success': success,
                        'pnl': actual_pnl,
                        'turn': getattr(self, 'turn_number', 0),
                    })
            except Exception as e:
                logger.debug(f"Mycelium broadcast error: {e}")
        
        # 7. ðŸ§  MINER BRAIN - Cognitive Learning from outcome
        if hasattr(self, 'miner_brain') and self.miner_brain:
            try:
                # Memory core - record trade outcome
                if hasattr(self.miner_brain, 'memory') and self.miner_brain.memory:
                    self.miner_brain.memory.record_trade_outcome(outcome)
                
                # Reflection - learn from trade
                if hasattr(self.miner_brain, 'reflection') and self.miner_brain.reflection:
                    self.miner_brain.reflection.learn_from_trade(outcome)
                
                # Skeptical analyzer - question the result
                if hasattr(self.miner_brain, 'skeptic') and self.miner_brain.skeptic:
                    self.miner_brain.skeptic.analyze_trade(outcome)
                    
            except Exception as e:
                logger.debug(f"Miner brain outcome learning error: {e}")
        
        logger.info(f"ðŸ‘‘ðŸŽ“ UNIFIED LEARNING: {path_key} | {'âœ…' if success else 'âŒ'} | ${actual_pnl:+.4f}")
        
        return outcome
    
    async def queen_learn_from_trade(self, opportunity: 'MicroOpportunity', success: bool):
        """
        ðŸ‘‘ðŸ“š QUEEN LEARNS FROM TRADE - Routes to UNIFIED LEARNING SYSTEM
        
        This is the main entry point called after trades.
        Routes to unified_learn_from_outcome() for consistent learning.
        """
        # Get actual P/L if available
        actual_pnl = getattr(opportunity, 'actual_pnl_usd', opportunity.expected_pnl_usd)
        
        # Route to unified learning system
        await self.unified_learn_from_outcome(opportunity, success, actual_pnl)
        
        # ðŸ‘‘ðŸŽ¤ THE QUEEN SPEAKS ABOUT THE TRADE!
        if self.queen and hasattr(self.queen, 'say'):
            try:
                if success and actual_pnl > 0:
                    if actual_pnl > 0.10:
                        msg = f"Beautiful! We made ${actual_pnl:.4f} on {opportunity.from_asset} to {opportunity.to_asset}!"
                        self.queen.say(msg, voice_enabled=True, emotion="profit")
                    else:
                        msg = f"Nice! ${actual_pnl:.4f} profit. Every bit counts!"
                        self.queen.say(msg, voice_enabled=False, emotion="calm")
                elif actual_pnl < 0:
                    msg = f"Loss of ${abs(actual_pnl):.4f}. Learning from this!"
                    self.queen.say(msg, voice_enabled=False, emotion="loss")
                else:
                    msg = f"Trade didn't work. Adapting strategy!"
                    self.queen.say(msg, voice_enabled=False, emotion="loss")
            except Exception as e:
                logger.debug(f"Queen speak error: {e}")
        
        path_key = (opportunity.from_asset, opportunity.to_asset)
        
        # Update prediction accuracy tracking
        if path_key not in self.barter_matrix.barter_history:
            self.barter_matrix.barter_history[path_key] = {
                'trades': 0, 'wins': 0, 'losses': 0, 'total_profit': 0.0,
                'avg_slippage': 0.5
            }
        
        history = self.barter_matrix.barter_history[path_key]
        
        # Track prediction accuracy
        if 'queen_predictions' not in history:
            history['queen_predictions'] = {'correct': 0, 'total': 0}
        
        if success:
            history['queen_predictions']['correct'] += 1
        history['queen_predictions']['total'] += 1
        
        accuracy = history['queen_predictions']['correct'] / history['queen_predictions']['total']
        logger.info(f"ðŸ‘‘ðŸ“š Queen accuracy on {opportunity.from_asset}â†’{opportunity.to_asset}: {accuracy:.0%}")

    async def queen_observe_market(self, exchange: str, exchange_assets: Dict) -> Dict:
        """
        ðŸ‘‘ðŸ”® QUEEN OBSERVES MARKET - The Queen sees EVERYTHING on every turn!
        
        Before any filtering, the Queen:
        1. Checks all mycelium neuron connections
        2. Reads the cosmic luck field
        3. Observes market momentum patterns
        4. Learns from what she sees (even without trading)
        
        Returns: dict with queen's observations
        """
        icon = {'kraken': 'ðŸ™', 'alpaca': 'ðŸ¦™', 'binance': 'ðŸŸ¡'}.get(exchange, 'ðŸ“Š')
        
        observations = {
            'exchange': exchange,
            'timestamp': time.time(),
            'neurons_connected': 0,
            'total_neurons': 0,
            'cosmic_alignment': 0.5,
            'market_momentum': 0.0,
            'queen_verdict': 'OBSERVING'
        }
        
        # ðŸ‘‘ Count connected mycelium neurons - FULL 11/11 MIND MAP
        neurons = {
            'queen_hive': hasattr(self, 'queen') and self.queen is not None,
            'mycelium_net': hasattr(self, 'mycelium_network') and self.mycelium_network is not None,
            'harmonic': hasattr(self, 'harmonic') and self.harmonic is not None,
            'luck_field': hasattr(self, 'luck_mapper') and self.luck_mapper is not None,
            'dream_memory': hasattr(self, 'dreams') and len(self.dreams) >= 0,  # Always true - dreams list exists
            'path_memory': hasattr(self, 'path_memory') and self.path_memory is not None,
            'timeline_oracle': hasattr(self, 'timeline_oracle') and self.timeline_oracle is not None,
            'thought_bus': hasattr(self, 'bus_aggregator') and self.bus_aggregator is not None,
            'ultimate_intel': hasattr(self, 'ultimate_intel') and self.ultimate_intel is not None,
            'wisdom_engine': hasattr(self, 'wisdom_engine') and self.wisdom_engine is not None,
            'barter_matrix': hasattr(self, 'barter_matrix') and self.barter_matrix is not None,
        }
        
        observations['total_neurons'] = len(neurons)
        observations['neurons_connected'] = sum(1 for v in neurons.values() if v)
        
        # ðŸ€ Read cosmic luck field
        luck_score = 0.5
        luck_state = "NEUTRAL"
        if hasattr(self, 'luck_mapper') and self.luck_mapper:
            try:
                luck = self.luck_mapper.read_field()
                luck_score = luck.luck_field
                luck_state = luck.luck_state.value
                observations['cosmic_alignment'] = luck_score
            except Exception:
                pass
        
        # ðŸ“Š Calculate market momentum from exchange assets
        momentum_sum = 0.0
        momentum_count = 0
        for asset in exchange_assets.keys():
            for symbol, data in self.ticker_cache.items():
                if data.get('base') == asset:
                    change = data.get('change24h', 0)
                    momentum_sum += change
                    momentum_count += 1
                    break
        
        if momentum_count > 0:
            observations['market_momentum'] = momentum_sum / momentum_count
        
        # ðŸ‘‘ Queen's overall verdict based on observations
        connected_pct = observations['neurons_connected'] / observations['total_neurons'] if observations['total_neurons'] > 0 else 0
        
        if connected_pct >= 0.8 and luck_score >= 0.6 and observations['market_momentum'] > 0:
            observations['queen_verdict'] = 'HUNT'  # Actively seeking opportunities
        elif connected_pct >= 0.6 and luck_score >= 0.4:
            observations['queen_verdict'] = 'READY'  # Ready to act if opportunity appears
        elif luck_score < 0.3 or connected_pct < 0.5:
            observations['queen_verdict'] = 'CAUTION'  # Low luck or disconnected neurons
        else:
            observations['queen_verdict'] = 'OBSERVING'  # Neutral, watching
        
        # ðŸ‘‘ Print Sero's status on every turn
        print(f"   ðŸ‘‘ SERO {observations['queen_verdict']}: {observations['neurons_connected']}/{observations['total_neurons']} neurons | Luck: {luck_state} | Momentum: {observations['market_momentum']:+.1f}%")
        
        # ðŸ„ Broadcast through mycelium
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'broadcast_signal'):
                    signal = {
                        'type': 'QUEEN_PULSE',
                        'exchange': exchange,
                        'verdict': observations['queen_verdict'],
                        'luck': luck_state,
                        'momentum': observations['market_momentum']
                    }
                    self.mycelium_network.broadcast_signal(signal)
                    print(f"   ðŸ„ðŸ“¡ MYCELIUM PULSE: {exchange.upper()} | {observations['queen_verdict']} | Luck={luck_state}")
            except Exception:
                pass
        
        return observations

    async def queen_timeline_gate(self, opportunity: 'MicroOpportunity') -> Tuple[bool, str]:
        """
        â³ðŸ”® QUEEN'S TIMELINE GATE - The Queen looks at multiple timelines before acting.
        
        PHILOSOPHY:
        - We simulate 3 possible futures: EXECUTE, SKIP, REVERSE
        - We only act if EXECUTE leads to the most profitable timeline
        - We are NEVER in the losing game - the Queen sees ALL timelines!
        - NEW PATHS require PROOF before trading - no speculative trades!
        - ðŸ‘‘ðŸ”® QUEEN'S DREAMS ARE THE FOUNDATION OF ALL TIMELINES!
        
        Returns: (approved: bool, reason: str)
        """
        from_asset = opportunity.from_asset
        to_asset = opportunity.to_asset
        from_price = self.prices.get(from_asset, 0)
        to_price = self.prices.get(to_asset, 0)
        
        if from_price <= 0 or to_price <= 0:
            return False, "No price data for timeline simulation"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ðŸ”® CONSULT THE QUEEN'S DREAMS FIRST - Her wisdom guides all timelines!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        queen_dream_boost = 0.0
        queen_dream_confidence = 0.5
        queen_timeline_blessing = "NEUTRAL"
        
        if hasattr(self, 'queen') and self.queen:
            try:
                # Ask the Queen to dream about this opportunity
                dream_vision = self.queen.dream_of_winning({
                    'from_asset': from_asset,
                    'to_asset': to_asset,
                    'expected_pnl': opportunity.expected_pnl_usd,
                    'market_data': {
                        'from_price': from_price,
                        'to_price': to_price,
                    }
                })
                
                queen_dream_confidence = dream_vision.get('final_confidence', 0.5)
                queen_will_win = dream_vision.get('will_win', False)
                queen_timeline_blessing = dream_vision.get('timeline', 'NEUTRAL')
                
                # ðŸ‘‘ Queen's dream directly influences timeline predictions!
                if queen_will_win and queen_dream_confidence >= 0.6:
                    queen_dream_boost = 0.3  # +30% boost to EXECUTE timeline
                    queen_timeline_blessing = "FAVORABLE"
                elif queen_dream_confidence >= 0.5:
                    queen_dream_boost = 0.1  # +10% small boost
                    queen_timeline_blessing = "CAUTIOUS"
                elif queen_dream_confidence < 0.4:
                    queen_dream_boost = -0.2  # -20% penalty - Queen sees danger!
                    queen_timeline_blessing = "WARNING"
                    
                logger.info(f"ðŸ‘‘ðŸ”® Queen's Dream: {queen_timeline_blessing} | Confidence: {queen_dream_confidence:.0%} | Boost: {queen_dream_boost:+.0%}")
                
            except Exception as e:
                logger.debug(f"Could not consult Queen's dreams: {e}")
        
        # Get historical data for timeline simulation
        from_history = self.barter_matrix.barter_history.get((from_asset, to_asset), {})
        trades = from_history.get('trades', 0)
        wins = from_history.get('wins', 0)
        total_profit = from_history.get('total_profit', 0)
        avg_slippage = from_history.get('avg_slippage', 0.5)
        
        # ðŸ‘‘ QUEEN'S MANDATE #1: NEW PATHS ARE ALLOWED - A WIN IS A WIN!
        # Every new reality branch deserves a chance if the math says it's profitable
        # The Math Gate already validates costs - trust the math!
        is_stablecoin_from = from_asset.upper() in self.barter_matrix.STABLECOINS
        is_stablecoin_to = to_asset.upper() in self.barter_matrix.STABLECOINS
        is_safe_stable_swap = is_stablecoin_from and is_stablecoin_to
        
        # NEW PATHS: Log them but let Math Gate decide
        if trades == 0:
            logger.info(f"ðŸ†• NEW TIMELINE: {from_asset}â†’{to_asset} - First exploration of this reality branch!")
        
        # ðŸ‘‘ QUEEN'S MANDATE #2: Paths with negative history are blocked
        if trades > 0 and total_profit < 0:
            return False, f"LOSING PATH BLOCKED: {from_asset}â†’{to_asset} lost ${abs(total_profit):.2f}"
        
        # ðŸ‘‘ QUEEN'S MANDATE #3: Win rate must be >35% for non-stablecoin trades
        # PRIME PROFIT: Any profit is a win! Lower threshold to allow momentum
        if trades >= 3 and not is_safe_stable_swap:
            win_rate = wins / trades
            if win_rate < 0.35:
                return False, f"LOW WIN RATE: {from_asset}â†’{to_asset} at {win_rate:.0%} (need 35%+)"
        
        # ðŸ”® TIMELINE 1: EXECUTE (what happens if we do this trade?)
        # PRIME PROFIT: New paths get fair estimates - let math decide!
        # ðŸ‘‘ðŸ›¡ï¸ SLIPPAGE SAFETY: Always add 0.5% safety buffer to prevent losses!
        SLIPPAGE_SAFETY_BUFFER = 0.5  # Add 0.5% safety margin
        
        if is_safe_stable_swap:
            historical_win_rate = wins / trades if trades > 0 else 0.80  # 80% for stablecoins
            pessimistic_slippage = (avg_slippage if trades > 0 else 0.1) + SLIPPAGE_SAFETY_BUFFER
        elif trades == 0:
            # NEW TIMELINE: Be more conservative on first trade!
            historical_win_rate = 0.50  # 50% - more conservative for new paths
            pessimistic_slippage = 0.8 + SLIPPAGE_SAFETY_BUFFER  # 1.3% total for unknown pairs
        else:
            historical_win_rate = wins / trades  # Use actual history
            # Use the MAX of historical slippage or 0.5%, plus safety buffer
            pessimistic_slippage = max(avg_slippage, 0.5) + SLIPPAGE_SAFETY_BUFFER
        
        timeline_execute = {
            'action': 'EXECUTE',
            'expected_profit': opportunity.expected_pnl_usd,
            'historical_win_rate': historical_win_rate,
            'avg_slippage_cost': pessimistic_slippage / 100 * opportunity.from_value_usd,
            'confidence': opportunity.combined_score,
        }
        # Adjust for reality: expected - slippage = actual
        timeline_execute['predicted_actual'] = (
            timeline_execute['expected_profit'] - timeline_execute['avg_slippage_cost']
        )
        
        # ï¿½ðŸ”® APPLY QUEEN'S DREAM BOOST TO EXECUTE TIMELINE!
        # Her dreams directly influence the predicted outcome!
        if queen_dream_boost != 0:
            dream_adjustment = abs(timeline_execute['predicted_actual']) * queen_dream_boost
            timeline_execute['predicted_actual'] += dream_adjustment
            timeline_execute['queen_blessing'] = queen_timeline_blessing
            timeline_execute['queen_confidence'] = queen_dream_confidence
            logger.info(f"   ðŸ‘‘ Dream adjustment: ${dream_adjustment:+.4f} â†’ Predicted: ${timeline_execute['predicted_actual']:.4f}")
        
        # ðŸ”® TIMELINE 2: SKIP (what happens if we don't trade?)
        timeline_skip = {
            'action': 'SKIP',
            'expected_profit': 0.0,
            'historical_win_rate': 1.0,  # Can't lose by not trading
            'avg_slippage_cost': 0.0,
            'confidence': 1.0,
            'predicted_actual': 0.0,  # No gain, no loss
            'queen_blessing': 'NEUTRAL',
        }
        
        # ðŸ”® TIMELINE 3: REVERSE (what if we traded the OTHER way?)
        reverse_history = self.barter_matrix.barter_history.get((to_asset, from_asset), {})
        reverse_trades = reverse_history.get('trades', 0)
        reverse_wins = reverse_history.get('wins', 0)
        reverse_profit = reverse_history.get('total_profit', 0)
        
        timeline_reverse = {
            'action': 'REVERSE',
            'expected_profit': -opportunity.expected_pnl_usd * 0.5,  # Opposite direction
            'historical_win_rate': reverse_wins / reverse_trades if reverse_trades > 0 else 0.3,
            'avg_slippage_cost': pessimistic_slippage / 100 * opportunity.from_value_usd,
            'confidence': 0.3,  # Low confidence for reverse
            'predicted_actual': -opportunity.expected_pnl_usd * 0.5,
            'queen_blessing': 'UNFAVORABLE',  # Queen doesn't dream of reversals
        }
        
        # ðŸ‘‘ QUEEN'S TIMELINE ANALYSIS - Dreams inform the scoring!
        timelines = [timeline_execute, timeline_skip, timeline_reverse]
        
        # Score each timeline: predicted_actual * confidence * historical_win_rate * queen_factor
        for t in timelines:
            # Base score
            base_score = t['predicted_actual'] * t['confidence'] * t['historical_win_rate']
            
            # ðŸ‘‘ QUEEN'S DREAM MULTIPLIER - Her dreams have WEIGHT!
            queen_multiplier = 1.0
            if t.get('queen_blessing') == 'FAVORABLE':
                queen_multiplier = 1.5  # 50% boost if Queen dreams WIN
            elif t.get('queen_blessing') == 'CAUTIOUS':
                queen_multiplier = 1.1  # 10% boost
            elif t.get('queen_blessing') == 'WARNING':
                queen_multiplier = 0.5  # 50% penalty - heed the Queen's warning!
            elif t.get('queen_blessing') == 'UNFAVORABLE':
                queen_multiplier = 0.7  # 30% penalty
            
            t['timeline_score'] = base_score * queen_multiplier
            t['queen_multiplier'] = queen_multiplier
        
        # Sort by timeline score (best first)
        timelines.sort(key=lambda x: x['timeline_score'], reverse=True)
        best_timeline = timelines[0]
        
        # ðŸ‘‘ QUEEN'S MANDATE: Only execute if EXECUTE is the best timeline
        # PRIME PROFIT: If the Math Gate approved it AND expected profit > 0, TRUST IT!
        # ðŸ”® NOW INFORMED BY THE QUEEN'S DREAMS!
        if best_timeline['action'] == 'EXECUTE':
            # Additional safety: predicted actual must be positive
            if timeline_execute['predicted_actual'] > 0:
                blessing_msg = f" | ðŸ‘‘ {queen_timeline_blessing}" if queen_timeline_blessing != "NEUTRAL" else ""
                return True, f"Timeline EXECUTE wins (score: {timeline_execute['timeline_score']:.4f}){blessing_msg}"
            else:
                return False, f"EXECUTE timeline predicts loss: ${timeline_execute['predicted_actual']:.4f} | ðŸ‘‘ {queen_timeline_blessing}"
        
        elif best_timeline['action'] == 'SKIP':
            # ðŸ‘‘ QUEEN OVERRIDE: If Queen dreams FAVORABLE and math is positive, TRUST HER!
            if queen_timeline_blessing == 'FAVORABLE' and opportunity.expected_pnl_usd >= EPSILON_PROFIT_USD:
                return True, f"ðŸ‘‘ QUEEN OVERRIDE: Timeline SKIP but Queen dreams WIN! (+${opportunity.expected_pnl_usd:.4f})"
            # PRIME PROFIT: Only trust Math Gate if expected profit is ACTUALLY positive
            # Don't trade if we're expected to lose money!
            if opportunity.expected_pnl_usd >= EPSILON_PROFIT_USD:
                return True, f"Timeline SKIP but Math Gate says +${opportunity.expected_pnl_usd:.4f} - TRUSTING MATH!"
            return False, f"Timeline SKIP is safer (execute would: ${timeline_execute['predicted_actual']:.4f}) | ðŸ‘‘ {queen_timeline_blessing}"
        
        else:
            return False, f"Timeline REVERSE suggested - market moving against us | ðŸ‘‘ {queen_timeline_blessing}"

    async def validate_signal_quality(self, opportunity: 'MicroOpportunity') -> float:
        """
        ðŸŽ¯ SIGNAL QUALITY VALIDATION
        
        Checks if our signals support this conversion:
        - ðŸ‘‘ðŸ”® QUEEN'S DREAMS - Her visions guide all decisions!
        - Dreams about target asset (should be UP)
        - Dreams about source asset (should NOT be UP)
        - Bus aggregator score
        - PathMemory win rate for this path
        - Barter navigator path score
        
        Returns: 0.0-1.0 quality score (higher = better signals)
        """
        quality_scores = []
        
        # ðŸ‘‘ðŸ”® 0. QUEEN'S DREAM - THE MOST IMPORTANT SIGNAL!
        # All systems consult the Queen first!
        queen_dream_quality = 0.5  # Neutral default
        if self.queen and hasattr(self.queen, 'dream_of_winning'):
            try:
                opp_data = {
                    'from_asset': opportunity.from_asset,
                    'to_asset': opportunity.to_asset,
                    'expected_profit': opportunity.expected_pnl_usd,
                    'exchange': getattr(opportunity, 'source_exchange', 'kraken'),
                    'market_data': {
                        'volatility': getattr(opportunity, 'luck_score', 0.5),
                        'momentum': opportunity.combined_score,
                        'volume': 0.5,
                        'spread': 0.5
                    }
                }
                dream_vision = self.queen.dream_of_winning(opp_data)
                queen_confidence = dream_vision.get('final_confidence', 0.5)
                
                if dream_vision.get('will_win', False):
                    # Queen dreams WIN - this is the most important signal!
                    if queen_confidence >= 0.70:
                        queen_dream_quality = 0.95  # STRONG WIN
                        logger.info(f"ðŸ‘‘ðŸ”® Signal: Queen dreams STRONG WIN ({queen_confidence:.0%})")
                    elif queen_confidence >= 0.55:
                        queen_dream_quality = 0.75  # FAVORABLE
                        logger.info(f"ðŸ‘‘ðŸ”® Signal: Queen dreams FAVORABLE ({queen_confidence:.0%})")
                    else:
                        queen_dream_quality = 0.60  # Mild positive
                else:
                    # Queen dreams caution or loss
                    if queen_confidence <= 0.35:
                        queen_dream_quality = 0.20  # WARNING
                        logger.info(f"ðŸ‘‘âš ï¸ Signal: Queen dreams WARNING ({queen_confidence:.0%})")
                    else:
                        queen_dream_quality = 0.40  # Mild negative
                
                quality_scores.append(queen_dream_quality)
            except Exception as e:
                logger.debug(f"Queen dream signal error: {e}")
        
        # 1. Dream Score for TARGET (want UP dreams for buying)
        target_dream_score = self.calculate_dream_score(opportunity.to_asset)
        if target_dream_score > 0:  # Positive means UP dreams
            quality_scores.append(0.5 + target_dream_score * 0.5)  # 0.5-1.0
        elif target_dream_score < 0:  # DOWN dreams for target = bad
            quality_scores.append(0.25)
        else:
            quality_scores.append(0.5)  # Neutral
        
        # 2. Dream Score for SOURCE (don't want UP dreams - we're selling)
        source_dream_score = self.calculate_dream_score(opportunity.from_asset)
        if source_dream_score > 0:  # UP dreams for source = bad (we're selling it)
            quality_scores.append(0.25)
        elif source_dream_score < 0:  # DOWN dreams for source = good
            quality_scores.append(0.75)
        else:
            quality_scores.append(0.5)  # Neutral
        
        # 3. Bus Aggregator Score (if available)
        if self.bus_aggregator:
            try:
                bus_score = self.bus_aggregator.get_aggregate_score()
                quality_scores.append(bus_score)
            except:
                pass
        
        # 4. PathMemory Win Rate
        path_boost = self.path_memory.boost(opportunity.from_asset, opportunity.to_asset)
        # Convert boost (-0.05 to +0.10) to quality score (0.4-0.6)
        quality_scores.append(0.5 + path_boost * 2)  # Maps to 0.4-0.7
        
        # 5. Barter Navigator Path Score (if path exists)
        if self.barter_navigator:
            try:
                path = self.barter_navigator.find_path(opportunity.from_asset, opportunity.to_asset)
                if path:
                    # Multi-hop paths need higher confidence
                    if path.num_hops > 1:
                        quality_scores.append(0.6)  # Direct is better
                    else:
                        quality_scores.append(0.8)  # Direct path good
            except:
                pass
        
        # Calculate final quality score
        if quality_scores:
            final_score = sum(quality_scores) / len(quality_scores)
            # ðŸ‘‘ Show Queen's contribution to the signal
            queen_tag = f"ðŸ‘‘{queen_dream_quality:.0%}" if queen_dream_quality != 0.5 else ""
            print(f"   ðŸ“Š Signal breakdown: {queen_tag} {', '.join([f'{s:.0%}' for s in quality_scores])}")
            return final_score
        
        return 0.5  # Default neutral

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸŒŠâš¡ MOMENTUM TRACKING - Wave Riding Logic from Momentum Snowball
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def update_momentum(self, asset: str, price: float):
        """Update momentum tracking for an asset - FROM MOMENTUM SNOWBALL ENGINE"""
        import time
        now = time.time()
        
        # Record price
        self.momentum_history[asset].append((now, price))
        
        # Calculate momentum (%/minute)
        history = self.momentum_history[asset]
        if len(history) < 2:
            self.asset_momentum[asset] = 0.0
            return
        
        cutoff = now - self.momentum_window
        
        # Find oldest price in window
        oldest_price = None
        oldest_time = now
        for t, p in history:
            if t >= cutoff:
                if oldest_price is None or t < oldest_time:
                    oldest_price = p
                    oldest_time = t
        
        if oldest_price is None or oldest_price <= 0:
            self.asset_momentum[asset] = 0.0
            return
        
        # Momentum = % change per minute
        time_diff = now - oldest_time
        if time_diff < 5:  # Need at least 5 seconds
            self.asset_momentum[asset] = 0.0
            return
        
        price_change = (price - oldest_price) / oldest_price
        minutes = time_diff / 60
        self.asset_momentum[asset] = price_change / minutes if minutes > 0 else 0.0
    
    def get_momentum(self, asset: str) -> float:
        """Get current momentum for asset (%/minute)"""
        return self.asset_momentum.get(asset, 0.0)
    
    def get_strongest_rising(self, exclude: set = None, limit: int = 10) -> List[Tuple[str, float]]:
        """Get assets with strongest RISING momentum - for wave jumping"""
        exclude = exclude or set()
        items = [(a, m) for a, m in self.asset_momentum.items() 
                 if a not in exclude and m > 0 and a in self.prices]
        return sorted(items, key=lambda x: x[1], reverse=True)[:limit]
    
    def get_weakest_falling(self, include: set = None, limit: int = 10) -> List[Tuple[str, float]]:
        """Get assets with FALLING momentum - to escape from"""
        include = include or set(self.asset_momentum.keys())
        items = [(a, m) for a, m in self.asset_momentum.items() 
                 if a in include and m < 0]
        return sorted(items, key=lambda x: x[1])[:limit]  # Most negative first
    
    def find_momentum_opportunity(self) -> Optional[Tuple[str, str, float, float, float]]:
        """
        Find best momentum-based conversion - JUMP FROM FALLING TO RISING
        
        Returns: (from_asset, to_asset, from_amount, expected_gain_pct, momentum_diff)
        """
        best = None
        best_momentum_diff = self.min_momentum_diff
        
        # Check our holdings
        for from_asset, from_amount in list(self.balances.items()):
            from_price = self.prices.get(from_asset, 0)
            from_value = from_amount * from_price
            
            if from_value < 5.0:  # Min trade value
                continue
            
            from_momentum = self.get_momentum(from_asset)
            
            # Look for rising assets to jump to
            for to_asset, to_momentum in self.get_strongest_rising(exclude={from_asset}):
                to_price = self.prices.get(to_asset, 0)
                if to_price <= 0:
                    continue
                
                # Momentum difference
                momentum_diff = to_momentum - from_momentum
                
                # Must exceed fees + minimum threshold
                fee_rate = 0.0021  # 0.21% total fees
                if momentum_diff > best_momentum_diff and momentum_diff > fee_rate:
                    net_advantage = momentum_diff - fee_rate
                    if net_advantage > 0:
                        best_momentum_diff = momentum_diff
                        best = (from_asset, to_asset, from_amount, net_advantage, momentum_diff)
        
        return best
    
    def lion_hunt(self, min_wave_momentum: float = 0.002) -> List[Tuple[str, str, float, float]]:
        """
        ðŸ¦ LION HUNT - Find waves to chase with stablecoins!
        
        When we hold stablecoins (USD, USDT, TUSD), we're like a lion
        scanning the pride - watching for opportunities to POUNCE!
        
        Returns: List of (stablecoin, target, available_amount, target_momentum)
        """
        stablecoins = {'USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD'}
        hunts = []
        
        # Find stablecoins we hold
        for asset, amount in self.balances.items():
            if asset.upper() not in stablecoins:
                continue
            price = self.prices.get(asset, 1.0)
            value = amount * price
            if value < 5.0:  # Min $5 to hunt
                continue
            
            # Get rising targets
            rising = self.get_strongest_rising(limit=10)
            for target, momentum in rising:
                if momentum < min_wave_momentum:
                    continue  # Wave not strong enough
                if target in stablecoins:
                    continue  # Don't buy other stablecoins
                
                # ðŸ¦ Found a hunt opportunity!
                hunts.append((asset, target, amount, momentum))
        
        # Sort by momentum (strongest waves first)
        hunts.sort(key=lambda x: x[3], reverse=True)
        
        if hunts:
            print(f"\n   ðŸ¦ LION HUNT - {len(hunts)} waves spotted!")
            for src, tgt, amt, mom in hunts[:5]:  # Show top 5
                # ðŸ› FIX: Show USD VALUE not raw amount!
                price = self.prices.get(src, 1.0)
                value_usd = amt * price
                print(f"      â†’ {src}â†’{tgt}: ${value_usd:.2f} available, wave +{mom*100:.2f}%/min")
        
        return hunts
    
    def wolf_hunt(self, verbose: bool = True) -> Optional[Tuple[str, float, float]]:
        """
        ðŸº LONE WOLF - Single momentum sniper!
        
        The Wolf doesn't chase any wave - it waits for THE ONE.
        Picks the SINGLE highest momentum target weighted by volume.
        
        Score = momentum Ã— log(1 + volume)
        
        Returns: (symbol, momentum, score) or None
        """
        best_symbol = None
        best_score = -999999
        best_momentum = 0
        
        # Get all tracked assets with prices
        for asset, price in self.prices.items():
            if price <= 0:
                continue

            # Skip obviously invalid symbols
            if len(asset) < MIN_SYMBOL_LEN:
                continue
            
            # Skip stablecoins - wolf hunts volatile prey
            if asset.upper() in {'USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD'}:
                continue
            
            # Get momentum for this asset
            momentum = self.asset_momentum.get(asset, 0)
            # Cap momentum to avoid runaway scores / data glitches
            if momentum > MAX_MOMENTUM_PER_MIN:
                momentum = MAX_MOMENTUM_PER_MIN
            
            # Wolf ONLY hunts RISING prey (positive momentum)
            if momentum <= 0:
                continue
            
            # Estimate volume from recent trades (or use fallback)
            volume = 100000  # Base volume estimate
            
            # Check ticker cache for actual volume
            for symbol, ticker in self.ticker_cache.items():
                if ticker.get('base') == asset:
                    volume = ticker.get('volume', 100000)
                    break
            
            # ðŸº WOLF SCORE: momentum Ã— log(1 + volume)
            import math
            score = momentum * math.log(1 + max(1, volume))
            
            if score > best_score:
                best_symbol = asset
                best_score = score
                best_momentum = momentum
        
        if best_symbol:
            if verbose:
                print(f"\n   ðŸº WOLF TARGET: {best_symbol} | momentum={best_momentum*100:.2f}%/min | score={best_score:.1f}")
            return (best_symbol, best_momentum, best_score)
        
        return None
    
    def ant_scraps(self, min_value: float = 1.0) -> List[Tuple[str, float, float]]:
        """
        ðŸœ ARMY ANTS - Floor scavengers!
        
        Find small liquid assets on the floor - quick rotations.
        These are the crumbs that others miss.
        
        Returns: List of (asset, amount, value) for small holdings
        """
        scraps = []
        
        for asset, amount in self.balances.items():
            price = self.prices.get(asset, 0)
            value = amount * price
            
            # Ants collect small scraps - between min_value and $20
            if min_value <= value <= 20.0:
                # Skip stablecoins - not scraps
                if asset.upper() in {'USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD'}:
                    continue
                scraps.append((asset, amount, value))
        
        # Sort by value (smallest first - easiest to move)
        scraps.sort(key=lambda x: x[2])
        
        if scraps:
            print(f"\n   ðŸœ ANT SCRAPS - {len(scraps)} small positions found!")
            for asset, amt, val in scraps[:5]:
                print(f"      â†’ {asset}: {amt:.6f} (${val:.2f})")
        
        return scraps
    
    async def dust_sweep(self) -> int:
        """
        ðŸ§¹ðŸ‘‘ DUST SWEEP - Queen-controlled portfolio cleanup.
        
        The Queen (Sero) has FULL CONTROL over dust sweeps:
        1. She decides IF we should sweep (market conditions)
        2. She evaluates EACH dust position individually
        3. She learns from sweep successes/failures
        
        Works across ALL exchanges (Kraken, Binance, Alpaca).
        Only sweeps if profitable after fees AND Queen approves!
        
        Returns: Number of successful dust conversions.
        """
        if not self.dust_converter:
            return 0
        
        if not self.dust_converter.should_sweep_now():
            return 0
        
        print("\n   ðŸ§¹ðŸ‘‘ QUEEN'S DUST SWEEP - Sero inspecting small positions...")
        
        # Find all dust across exchanges
        all_dust = self.dust_converter.find_all_dust(
            all_balances=self.exchange_balances,
            prices=self.prices,
        )
        
        if not all_dust:
            print("   âœ¨ No dust found - portfolio is clean!")
            return 0
        
        # Print the dust report
        print(self.dust_converter.format_dust_report(all_dust))
        
        # Get profitable sweeps only
        profitable = self.dust_converter.get_profitable_sweeps(all_dust)
        
        if not profitable:
            print("   âš ï¸ Dust found but none profitable after fees")
            return 0
        
        # ðŸ‘‘ QUEEN'S FIRST GATE: Should we sweep at all right now?
        queen_allows_sweep = await self._queen_approve_dust_sweep(profitable)
        if not queen_allows_sweep:
            print("   ðŸ‘‘ðŸš« Queen says: NOT NOW - Market conditions unfavorable")
            return 0
        
        # Execute sweeps (only if LIVE mode AND Queen approves each one)
        sweeps_executed = 0
        
        for dust in profitable:
            try:
                # ðŸ‘‘ QUEEN'S SECOND GATE: Approve each individual sweep
                queen_approves, queen_reason = await self._queen_approve_dust_candidate(dust)
                
                if not queen_approves:
                    print(f"   ðŸ‘‘ðŸš« Queen vetoes {dust.asset}: {queen_reason}")
                    continue
                
                print(f"   ðŸ‘‘âœ… Queen approves {dust.asset}: {queen_reason}")
                
                # Get the right client for this exchange
                client = None
                if dust.exchange == 'kraken' and self.kraken:
                    client = self.kraken
                    pair = f"{dust.asset}{dust.target_stable}"
                elif dust.exchange == 'binance' and self.binance:
                    client = self.binance
                    pair = f"{dust.asset}{dust.target_stable}"
                elif dust.exchange == 'alpaca' and self.alpaca:
                    client = self.alpaca
                    pair = f"{dust.asset}/USD"
                
                if not client:
                    print(f"   âš ï¸ No client for {dust.exchange}")
                    continue
                
                if self.live:
                    print(f"   ðŸ§¹ Sweeping {dust.asset} @ {dust.exchange}: {dust.amount:.6f} â†’ {dust.target_stable}")
                    
                    # Execute the sell
                    try:
                        if dust.exchange == 'alpaca':
                            # Alpaca uses market orders
                            result = client.create_order(
                                symbol=pair,
                                qty=dust.amount,
                                side='sell',
                                type='market'
                            )
                        elif dust.exchange == 'kraken':
                            # Kraken uses AddOrder
                            result = await client.add_order(
                                pair=pair,
                                type='sell',
                                ordertype='market',
                                volume=str(dust.amount)
                            )
                        elif dust.exchange == 'binance':
                            # Binance uses market orders
                            result = client.create_order(
                                symbol=pair,
                                side='SELL',
                                type='MARKET',
                                quantity=dust.amount
                            )
                        
                        self.dust_converter.record_sweep(dust, success=True)
                        sweeps_executed += 1
                        print(f"   âœ… Swept {dust.asset}: +${dust.net_proceeds_usd:.4f}")
                        
                        # ðŸ‘‘ Queen learns from successful sweep
                        await self._queen_learn_dust_sweep(dust, success=True)
                        
                    except Exception as e:
                        self.dust_converter.record_sweep(dust, success=False)
                        print(f"   âŒ Failed to sweep {dust.asset}: {e}")
                        
                        # ðŸ‘‘ Queen learns from failed sweep
                        await self._queen_learn_dust_sweep(dust, success=False, error=str(e))
                else:
                    # Dry run - just simulate
                    print(f"   ðŸ§ª [DRY RUN] Would sweep {dust.asset} @ {dust.exchange}: {dust.amount:.6f} â†’ {dust.target_stable} (net ${dust.net_proceeds_usd:.4f})")
                    sweeps_executed += 1
                    
            except Exception as e:
                print(f"   âŒ Error sweeping {dust.asset}: {e}")
        
        if sweeps_executed > 0:
            status = self.dust_converter.get_status()
            print(f"\n   ðŸ‘‘ðŸ§¹ QUEEN'S SWEEP COMPLETE: {sweeps_executed} conversions | Total recovered: ${status['total_swept_usd']:.4f}")
        
        return sweeps_executed
    
    async def _queen_approve_dust_sweep(self, dust_candidates: List) -> bool:
        """
        ðŸ‘‘ Queen decides if NOW is a good time to sweep dust.
        
        She considers:
        - Overall market volatility (don't sweep during crashes)
        - Portfolio health
        - Recent sweep history
        - Mycelium network signals
        """
        # Default: Allow if Queen not available
        if not self.queen and not self.mycelium_network:
            return True
        
        total_dust_value = sum(d.value_usd for d in dust_candidates)
        
        # ðŸ„ Check Mycelium for market sentiment
        if self.mycelium_network:
            try:
                # Get aggregate market signal
                market_signal = 0.0
                if hasattr(self.mycelium_network, 'get_aggregate_signal'):
                    market_signal = self.mycelium_network.get_aggregate_signal()
                
                # Don't sweep during extreme negative sentiment (market crash)
                if market_signal < -0.7:
                    print(f"   ðŸ‘‘ðŸ„ Market crash detected (signal={market_signal:.2f}) - holding dust")
                    return False
                    
            except Exception as e:
                logger.debug(f"Mycelium signal check error: {e}")
        
        # ðŸ‘‘ Check Queen's mood
        if self.queen:
            try:
                if hasattr(self.queen, 'get_market_mood'):
                    mood = self.queen.get_market_mood()
                    if mood == 'PANIC':
                        print("   ðŸ‘‘ Queen senses PANIC - holding positions")
                        return False
            except Exception as e:
                logger.debug(f"Queen mood check error: {e}")
        
        # ðŸ“Š Check recent sweep history - avoid over-sweeping
        if self.dust_converter:
            status = self.dust_converter.get_status()
            # If we swept a lot recently, pause
            if status.get('dust_swept', 0) > 10 and status.get('cooldown_remaining', 0) < 60:
                # Been sweeping a lot, take a longer break
                return False
        
        print(f"   ðŸ‘‘âœ… Queen approves dust sweep session (${total_dust_value:.4f} total)")
        return True
    
    async def _queen_approve_dust_candidate(self, dust) -> Tuple[bool, str]:
        """
        ðŸ‘‘ Queen evaluates a specific dust candidate.
        
        She considers:
        - Is this asset likely to recover? (momentum)
        - Historical performance of this asset
        - Mycelium signal for this specific asset
        - Path memory from previous trades
        """
        asset = dust.asset
        exchange = dust.exchange
        
        # Check momentum - don't sell assets with strong upward momentum!
        momentum = self.asset_momentum.get(asset, 0)
        if momentum > 0.005:  # >0.5%/min rising
            return False, f"RISING ({momentum*100:.2f}%/min) - may recover"
        
        # Check barter matrix history
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            # Check if this asset has been profitable recently
            asset_history = self.barter_matrix.barter_history.get((asset, 'USD'), {})
            if asset_history.get('total_profit', 0) > 0.1:  # Made >$0.10 recently
                return False, f"Recent profits (${asset_history['total_profit']:.4f}) - keep watching"
        
        # Check path memory
        if hasattr(self, 'path_memory') and self.path_memory:
            path_key = (asset, dust.target_stable)
            path_stats = self.path_memory.memory.get(path_key, {})
            win_rate = path_stats.get('win_rate', 0.5)
            
            # If we historically lose on this conversion, maybe don't sweep
            if win_rate < 0.3:
                return False, f"Bad path history (win_rate={win_rate:.0%})"
        
        # ðŸ„ Check Mycelium signal for this specific asset
        if self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'get_queen_signal'):
                    signal = self.mycelium_network.get_queen_signal({'symbol': asset})
                    
                    # Strong BUY signal - don't sell this dust!
                    if signal > 0.5:
                        return False, f"Mycelium says HOLD (signal={signal:+.2f})"
                    
                    # Strong SELL signal - sweep it!
                    if signal < -0.3:
                        return True, f"Mycelium says SWEEP (signal={signal:+.2f})"
            except Exception as e:
                logger.debug(f"Mycelium signal error for {asset}: {e}")
        
        # ðŸ‘‘ Queen's final blessing
        if self.queen:
            try:
                if hasattr(self.queen, 'should_sell_dust'):
                    queen_says = self.queen.should_sell_dust(asset, dust.value_usd)
                    if not queen_says:
                        return False, "Queen says hold"
            except Exception as e:
                logger.debug(f"Queen dust decision error: {e}")
        
        # Default: Approve profitable dust sweeps
        return True, f"Profitable sweep (+${dust.net_proceeds_usd:.4f})"
    
    async def _queen_learn_dust_sweep(self, dust, success: bool, error: str = None):
        """
        ðŸ‘‘ Queen learns from dust sweep outcomes.
        
        Records:
        - Which assets are successfully sweepable
        - Which exchanges have issues
        - Patterns in failures
        """
        # Record in path memory with error handling
        if hasattr(self, 'path_memory') and self.path_memory:
            try:
                path_key = (dust.asset, dust.target_stable)
                if success:
                    self.path_memory.record_success(path_key, dust.net_proceeds_usd)
                else:
                    self.path_memory.record_failure(path_key, error or "unknown")
            except AttributeError as e:
                # ðŸ‘‘ðŸ”§ SELF-REPAIR TRIGGER - Publish to ThoughtBus
                error_msg = str(e)
                logger.error(f"âŒ AttributeError in path_memory: {error_msg}")
                
                if hasattr(self, 'thought_bus') and self.thought_bus:
                    try:
                        import traceback
                        tb = traceback.format_exc()
                        
                        self.thought_bus.think(
                            message=f"AttributeError in PathMemory: {error_msg}",
                            topic="runtime.error",
                            metadata={
                                'error_type': 'AttributeError',
                                'message': error_msg,
                                'file': __file__,
                                'line': 6700,
                                'context': '_queen_learn_dust_sweep',
                                'traceback': tb[:1000]
                            }
                        )
                        logger.info("ðŸ‘‘ðŸ”§ Error published to Queen for self-repair")
                    except Exception as pub_err:
                        logger.error(f"Could not publish error: {pub_err}")
        
        # Update barter matrix
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            if success:
                self.barter_matrix.record_barter(
                    from_asset=dust.asset,
                    to_asset=dust.target_stable,
                    from_amount=dust.amount,
                    to_amount=dust.net_proceeds_usd,
                    exchange=dust.exchange,
                    profit_usd=dust.net_proceeds_usd - dust.value_usd,  # Net of fees
                    success=True,
                )
        
        # ðŸ‘‘ðŸŽ“ Queen's Loss Learning System
        if not success and hasattr(self, 'loss_learning') and self.loss_learning:
            try:
                self.loss_learning.process_loss({
                    'type': 'dust_sweep_failed',
                    'asset': dust.asset,
                    'exchange': dust.exchange,
                    'value': dust.value_usd,
                    'error': error,
                    'timestamp': time.time(),
                })
            except Exception as e:
                logger.debug(f"Loss learning error: {e}")
    
    def get_quack_commando_boost(self, to_asset: str) -> Tuple[float, str]:
        """
        ðŸ¦†âš”ï¸ Get boost from Quantum Quackers Commandos for a target asset.
        
        The commandos scan the market and provide intelligence to the Queen.
        Each commando has a different strategy:
        - Lion: Pride scan, high volume + volatility
        - Wolf: Single momentum champion
        - Ants: Floor scraps (small liquid alts)
        - Hummingbird: Quick rotations
        
        Returns: (boost_multiplier, commando_reason)
        """
        if not self.quack_commandos:
            return (1.0, "")
        
        boost = 1.0
        reasons = []
        
        # Update commando targets if cache is old (refresh every 60 seconds)
        cache_age = time.time() - self.quack_targets.get('_timestamp', 0)
        if cache_age > 60 or not self.quack_targets:
            try:
                # Get fresh intelligence from the commandos
                self.quack_targets = self.quack_commandos.get_commando_targets(
                    elephant_memory=None,  # We use Queen's path memory instead
                    allowed_quotes=['USD', 'USDC', 'USDT', 'BTC', 'ETH']
                )
                self.quack_targets['_timestamp'] = time.time()
            except Exception as e:
                logger.debug(f"Quack targets refresh error: {e}")
                self.quack_targets = {'_timestamp': time.time()}
        
        # ðŸ¦ LION: Check if in pride targets
        pride_targets = self.quack_targets.get('pride_targets', [])
        for i, target in enumerate(pride_targets[:10]):
            if target.get('symbol', '').startswith(to_asset) or to_asset in target.get('symbol', ''):
                boost += 0.20 + (0.02 * (10 - i))  # Higher rank = more boost
                reasons.append(f"ðŸ¦ Pride #{i+1}")
                break
        
        # ðŸº WOLF: Check if it's the momentum champion
        wolf_prey = self.quack_targets.get('wolf_prey')
        if wolf_prey:
            wolf_symbol = wolf_prey.get('symbol', '')
            if wolf_symbol.startswith(to_asset) or to_asset in wolf_symbol:
                boost += 0.30  # Wolf's champion gets BIG boost!
                reasons.append(f"ðŸº THE ONE (mom={wolf_prey.get('momentum', 0):.1f}%)")
        
        # ðŸœ ANTS: Check if it's a floor scrap target
        ant_scraps = self.quack_targets.get('ant_scraps', [])
        for scrap in ant_scraps:
            if scrap.get('symbol', '').startswith(to_asset) or to_asset in scrap.get('symbol', ''):
                boost += 0.15
                reasons.append("ðŸœ Floor Scrap")
                break
        
        # ðŸ HUMMINGBIRD: Implied in pride targets rank 5-10
        for target in pride_targets[5:10]:
            if target.get('symbol', '').startswith(to_asset) or to_asset in target.get('symbol', ''):
                boost += 0.10
                reasons.append("ðŸ Pollination Target")
                break
        
        reason_str = " + ".join(reasons) if reasons else ""
        return (boost, reason_str)

    async def find_opportunities_for_exchange(self, exchange: str) -> List['MicroOpportunity']:
        """Find opportunities for a specific exchange only."""
        opportunities = []
        
        exchange_assets = self.get_exchange_assets(exchange)
        if not exchange_assets:
            return opportunities
        
        # ðŸ’° EXCHANGE-SPECIFIC MINIMUM VALUES (USD value)
        # âš ï¸ CRITICAL: These must match exchange ordermin requirements!
        EXCHANGE_MIN_VALUE = {
            'kraken': 1.50,     # Kraken needs ~$1.20 EUR/USD minimum (use $1.50 for safety)
            'binance': 5.00,    # Binance MIN_NOTIONAL is typically $5-10
            'alpaca': 1.00,     # Alpaca has ~$1 minimum
        }
        min_value = EXCHANGE_MIN_VALUE.get(exchange, 1.0)
        
        # ðŸ’° EXCHANGE-SPECIFIC MINIMUM QUANTITIES (varies by asset)
        # Kraken has per-pair ordermin values
        KRAKEN_MIN_QTY = {
            'CHZ': 50.0,        # Requires 50 CHZ minimum
            'PEPE': 2500000.0,  # Requires 2.5M PEPE minimum
            'DOGE': 50.0,       # 50 DOGE minimum
            'SHIB': 100000.0,   # 100K SHIB minimum
            'USD': 10.0,        # USD/stablecoin pairs need ~10 USD minimum on Kraken
            'ZUSD': 10.0,       # Kraken internal code
            'USDC': 10.0,       # USDC needs ~10 minimum
            'USDT': 10.0,       # USDT needs ~10 minimum
            'EUR': 10.0,        # EUR needs ~10 minimum
            'ZEUR': 10.0,       # Kraken internal code
            'XXBT': 0.0002,     # ~10-20 USD
            'XBT': 0.0002,
            'XETH': 0.004,
            'ETH': 0.004,
        }
        
        ALPACA_MIN_QTY = {
            # ðŸ”¥ EXPANDED: All Alpaca crypto minimums
            'BTC': 0.000100,    # Alpaca requires 0.0001 BTC minimum (~$10)
            'ETH': 0.001,       # ~$3 minimum
            'SOL': 0.01,        # ~$2 minimum
            'LINK': 0.1,        # ~$2 minimum
            'AVAX': 0.01,       # ~$0.40 minimum
            'DOGE': 1.0,        # ~$0.30 minimum
            'USDT': 1.0,        # $1 minimum
            'USDC': 1.0,        # $1 minimum
            'USD': 1.0,         # $1 minimum
            'SHIB': 10000.0,    # Small value but high qty
            'PEPE': 100000.0,   # Small value but high qty
            # ðŸ†• NEW: Expanded Alpaca assets
            'AAVE': 0.01,       # ~$2 minimum
            'LTC': 0.01,        # ~$1 minimum
            'BCH': 0.01,        # ~$4 minimum
            'DOT': 0.1,         # ~$0.50 minimum
            'MATIC': 1.0,       # ~$0.50 minimum
            'ATOM': 0.1,        # ~$0.50 minimum
            'XLM': 1.0,         # ~$0.30 minimum
            'ALGO': 1.0,        # ~$0.20 minimum
            'UNI': 0.1,         # ~$1 minimum
            'BAT': 1.0,         # ~$0.20 minimum
            'CRV': 1.0,         # ~$0.50 minimum
            'GRT': 1.0,         # ~$0.15 minimum
            'SUSHI': 0.5,       # ~$0.50 minimum
            'XRP': 1.0,         # ~$2 minimum
            'XTZ': 0.5,         # ~$0.50 minimum
            'YFI': 0.0001,      # ~$0.80 minimum (expensive coin)
            'TRUMP': 0.1,       # ~varies
            'SKY': 0.1,         # ~$0.10 minimum
        }
        
        for from_asset, amount in exchange_assets.items():
            if amount <= 0:
                continue
            
            from_price = self.prices.get(from_asset, 0)
            if not from_price:
                continue
            
            from_value = amount * from_price
            
            # Skip dust below exchange minimum VALUE
            if from_value < min_value:
                continue
            
            # ðŸš« CHECK SOURCE BLOCKING - Skip if this asset is blocked on this exchange
            is_source_blocked, source_block_reason = self.barter_matrix.is_source_blocked(from_asset, exchange, from_value)
            if is_source_blocked:
                continue  # Source is blocked - skip all paths from this asset on this exchange
            
            # ðŸš« CHECK HIGH SPREAD SOURCE BLOCKING - Skip if spread is too high for this source
            spread_key = (from_asset.upper(), exchange.lower())
            if spread_key in self.barter_matrix.high_spread_sources:
                spread_info = self.barter_matrix.high_spread_sources[spread_key]
                blocked_turn = spread_info.get('blocked_turn', 0)
                turns_since = self.barter_matrix.current_turn - blocked_turn
                if turns_since < self.barter_matrix.HIGH_SPREAD_COOLDOWN:
                    # Still in cooldown - skip ALL trades from this source
                    continue
                else:
                    # Cooldown expired - remove block and try again
                    del self.barter_matrix.high_spread_sources[spread_key]
                    logger.info(f"ðŸš«â†’âœ… HIGH SPREAD UNBLOCK: {from_asset} on {exchange} - cooldown expired")
            
            # Skip assets below exchange minimum QUANTITY
            if exchange == 'kraken':
                # Check dynamic learned minimums first
                learned_min = self.dynamic_min_qty.get(from_asset.upper(), 0)
                if learned_min > 0 and amount < learned_min:
                    continue

                min_qty = KRAKEN_MIN_QTY.get(from_asset.upper(), 0)
                if min_qty > 0 and amount < min_qty:
                    continue  # Skip - below Kraken minimum quantity
            
            if exchange == 'alpaca':
                min_qty = ALPACA_MIN_QTY.get(from_asset.upper(), 0)
                if min_qty > 0 and amount < min_qty:
                    continue  # Skip - below Alpaca minimum quantity
            
            # Skip blocked assets
            if exchange == 'binance' and from_asset.upper() in self.blocked_binance_assets:
                continue
            if exchange == 'kraken' and from_asset.upper() in self.blocked_kraken_assets:
                continue
            
            # ðŸ‡¬ðŸ‡§ UK BINANCE RESTRICTION CHECK - Use cached UK allowed pairs
            if exchange == 'binance' and self.binance_uk_mode:
                # Check if we can trade FROM this asset (needs at least one valid pair)
                can_trade = False
                
                # For stablecoins (USDC etc), they are QUOTE currencies
                # so we check if pairs like BTCUSDC exist (base + USDC)
                if from_asset.upper() in ['USD', 'USDT', 'USDC', 'EUR', 'GBP']:
                    # This is a quote currency - check if ANY base can be bought with it
                    for base in ['BTC', 'ETH', 'SOL', 'BNB', 'XRP', 'ADA', 'DOGE']:
                        pair = f"{base}{from_asset.upper()}"
                        if self.is_binance_pair_allowed(pair):
                            can_trade = True
                            break
                else:
                    # Normal asset - check if it can be paired with USDC/BTC/etc
                    for quote in ['USDC', 'BTC', 'BNB', 'EUR']:  # UK-allowed quotes (NOT USDT!)
                        pair = f"{from_asset.upper()}{quote}"
                        if self.is_binance_pair_allowed(pair):
                            can_trade = True
                            break
                
                if not can_trade:
                    continue  # Skip UK-restricted assets
            
            # Find conversion opportunities for this asset
            asset_opps = await self._find_asset_opportunities(
                from_asset, amount, from_price, from_value, exchange
            )
            opportunities.extend(asset_opps)
        
        # Sort by combined score (best first)
        opportunities.sort(key=lambda x: x.combined_score, reverse=True)
        self.opportunities_found += len(opportunities)
        
        return opportunities

    async def _find_asset_opportunities(
        self, 
        from_asset: str, 
        amount: float, 
        from_price: float, 
        from_value: float,
        source_exchange: str
    ) -> List['MicroOpportunity']:
        """Find conversion opportunities for a single asset on a specific exchange."""
        opportunities = []
        
        # Determine if this is a stablecoin source
        is_stablecoin_source = from_asset.upper() in ['USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD']
        
        # ðŸ¦ LION HUNT MODE - When holding stablecoins, HUNT rising coins!
        # "The lion scans his pride and hunts" - Gary Leckey
        lion_targets = []  # Priority targets from momentum
        if is_stablecoin_source:
            # Get TOP rising coins - these are our HUNT targets!
            rising_coins = self.get_strongest_rising(exclude={from_asset}, limit=20)
            # ðŸ”¬ DEBUG: Check if GUN is in rising_coins for Kraken USD
            if source_exchange == 'kraken' and from_asset == 'USD':
                top_3_rising = [(c, m) for c, m in rising_coins if m > 10][:5]
                if top_3_rising:
                    print(f"   ðŸ”¬ TOP RISING (>10%/min): {[(c, f'{m:.1f}%') for c, m in top_3_rising]}")
                gun_mom = self.asset_momentum.get('GUN', 0)
                if gun_mom > 0:
                    print(f"   ðŸ”¬ GUN momentum in asset_momentum: {gun_mom:.1f}%/min")
            for coin, momentum in rising_coins:
                if momentum > 0.001:  # >0.1%/min momentum
                    lion_targets.append(coin)
            if lion_targets:
                print(f"   ðŸ¦ LION HUNT: {from_asset} â†’ Hunting {len(lion_targets)} rising coins")
        
        # Build target assets list
        checkpoint_stablecoins = {'USD': 1.0, 'USDT': 1.0, 'USDC': 1.0, 'ZUSD': 1.0}
        target_assets = dict(self.prices)
        for stable, price in checkpoint_stablecoins.items():
            if stable not in target_assets:
                target_assets[stable] = price
        
        # ðŸ¦ LION PRIORITY: If we have hunt targets, put them FIRST
        if lion_targets:
            # Reorder target_assets to prioritize lion targets
            prioritized = {}
            for target in lion_targets:
                if target in target_assets:
                    prioritized[target] = target_assets[target]
            # Add remaining targets after lion targets
            for k, v in target_assets.items():
                if k not in prioritized:
                    prioritized[k] = v
            target_assets = prioritized
        
        for to_asset, to_price in target_assets.items():
            if to_asset == from_asset:
                continue
            
            # ðŸš¨ BLOCK GARBAGE SYMBOLS - Single letters are NOT real coins!
            # U, C, S, T, F, AT, etc. are matching partial symbol names, not real assets
            if len(to_asset) <= 2 and to_asset.upper() not in ['BT', 'OP']:  # Allow real 2-char like OP
                continue  # Skip garbage single-letter "coins"
            
            # ï¿½ DEBUG: Track GUN specifically
            if to_asset.upper() == 'GUN':
                print(f"   ðŸ”¬ GUN FOUND in target loop! from={from_asset} exchange={source_exchange}")
            
            # ï¿½ðŸš¨ CRITICAL FIX: Check if path is blocked BEFORE doing any work!
            # This prevents the Sâ†”C ping-pong problem from repeating
            path_key = (from_asset.upper(), to_asset.upper())
            if path_key in self.barter_matrix.blocked_paths:
                continue  # Path is blocked - skip it entirely!
            
            # ðŸš« CHECK PRE-EXECUTION REJECTION BLOCK - Avoid wasting turns!
            is_preexec_blocked, preexec_reason = self.barter_matrix.is_preexec_blocked(from_asset, to_asset)
            if is_preexec_blocked:
                continue  # Skip - repeatedly fails min checks
            
            # ðŸŒâœ¨ PLANET SAVER: HARD BLOCK stablecoin â†’ stablecoin trades!
            # These ALWAYS LOSE FEES - there is NO momentum edge possible!
            is_checkpoint_target = to_asset.upper() in ['USD', 'USDT', 'USDC', 'TUSD', 'DAI', 'ZUSD', 'EUR', 'ZEUR', 'GBP', 'ZGBP', 'BUSD', 'GUSD']
            if is_stablecoin_source and is_checkpoint_target:
                # Stablecoinâ†’Stablecoin = GUARANTEED LOSS! Skip immediately!
                continue
            # This enables moving funds across the board when needed
            # The epsilon floor will filter out unprofitable swaps later
            # (No longer blocking here - let Queen's math gate decide)
            
            # Skip blocked target assets on Binance
            if source_exchange == 'binance' and to_asset.upper() in self.blocked_binance_assets:
                continue
            # Skip blocked target assets on Kraken
            if source_exchange == 'kraken' and to_asset.upper() in self.blocked_kraken_assets:
                continue
            
            # ðŸ‡¬ðŸ‡§ UK BINANCE RESTRICTION CHECK for target assets
            if source_exchange == 'binance' and self.binance_uk_mode:
                # Check if target asset can be traded (UK restrictions)
                can_trade = False
                for quote in ['USDC', 'BTC', 'BNB', 'EUR']:  # UK-allowed quotes (NOT USDT!)
                    pair_to_check = f"{to_asset.upper()}{quote}"
                    if self.is_binance_pair_allowed(pair_to_check):
                        can_trade = True
                        break
                if not can_trade:
                    continue  # Skip UK-restricted targets
            
            # Verify pairs exist
            if is_stablecoin_source:
                from_pair = "STABLECOIN_SOURCE"
                to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                if not to_pair and source_exchange in ('binance', 'alpaca'):
                    # For UK Binance, prefer USDC over USDT
                    if source_exchange == 'binance' and self.binance_uk_mode:
                        to_pair = self._find_exchange_pair(to_asset, "USDC", source_exchange)
                    if not to_pair:
                        to_pair = self._find_exchange_pair(to_asset, "USDT", source_exchange)
                if not to_pair and source_exchange == 'alpaca':
                    btc_pair = self._find_exchange_pair(to_asset, "BTC", source_exchange)
                    btc_usd = self._find_exchange_pair("BTC", "USD", source_exchange)
                    if btc_pair and btc_usd:
                        to_pair = btc_pair
            else:
                from_pair = self._find_exchange_pair(from_asset, "USD", source_exchange)
                to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                
                if is_checkpoint_target:
                    to_pair = from_pair
                
                if source_exchange == 'binance' and (not from_pair or not to_pair):
                    # For UK Binance, prefer USDC over USDT
                    if self.binance_uk_mode:
                        from_pair = from_pair or self._find_exchange_pair(from_asset, "USDC", source_exchange)
                        to_pair = to_pair or self._find_exchange_pair(to_asset, "USDC", source_exchange)
                    if not from_pair:
                        from_pair = self._find_exchange_pair(from_asset, "USDT", source_exchange)
                    if not to_pair:
                        to_pair = self._find_exchange_pair(to_asset, "USDT", source_exchange)
                if source_exchange == 'alpaca' and (not from_pair or not to_pair):
                    if from_asset.upper() == 'BTC':
                        to_pair = to_pair or self._find_exchange_pair(to_asset, "BTC", source_exchange)
                        from_pair = from_pair or to_pair
                    elif to_asset.upper() == 'BTC':
                        from_pair = from_pair or self._find_exchange_pair(from_asset, "BTC", source_exchange)
                        to_pair = to_pair or from_pair
            
            if not from_pair or not to_pair:
                # ðŸ”¬ DEBUG: Log why high-momentum targets are being skipped
                if to_asset in lion_targets and self.asset_momentum.get(to_asset, 0) > 100:
                    print(f"      ðŸ”¬ DEBUG SKIP: {from_asset}â†’{to_asset} (from_pair={from_pair}, to_pair={to_pair}) on {source_exchange}")
                continue
            
            # ðŸ” SKIP PATH VALIDATION IN LOOP - Too slow!
            # Path existence will be validated at execution time.
            # This dramatically speeds up opportunity scanning.
            
            # Calculate scores (simplified for turn-based execution)
            v14_score = self.calculate_v14_score(from_asset, to_asset)
            hub_score = self.calculate_hub_score(from_asset, to_asset)
            dream_score = self.calculate_dream_score(to_asset)
            
            # Barter score
            barter_score, barter_reason = 0.5, "neutral"
            if self.barter_navigator and BARTER_NAVIGATOR_AVAILABLE:
                try:
                    barter_score, barter_reason = self.calculate_barter_score(from_asset, to_asset)
                except:
                    pass
            
            # Luck score
            luck_score, luck_state = 0.5, "NEUTRAL"
            if self.luck_mapper:
                try:
                    luck_data = self.luck_mapper.get_luck_field()
                    luck_score = luck_data.get('lambda', 0.5)
                    luck_state = luck_data.get('state', 'NEUTRAL')
                except:
                    pass
            
            # Bus score
            bus_score = 0.0
            if self.bus_aggregator:
                bus_score = self.bus_aggregator.get_aggregate_score()
            
            # ðŸ”ðŸŒ ENIGMA SCORE - Universal Translator Bridge Intelligence!
            enigma_score = 0.0
            enigma_direction = "NEUTRAL"
            if self.enigma_integration:
                try:
                    # Get Enigma guidance for this trade
                    enigma_guidance = self.enigma_integration.get_guidance()
                    
                    # Overall market action from Enigma
                    enigma_action = enigma_guidance.get('action', 'HOLD')
                    enigma_confidence = enigma_guidance.get('confidence', 0.5)
                    
                    # Convert action to score adjustment (ENIGMA BOOST!)
                    if enigma_action == 'BUY':
                        enigma_score = enigma_confidence * 0.3  # Boosted to 30% importance
                        enigma_direction = "BULLISH"
                    elif enigma_action == 'SELL':
                        enigma_score = -enigma_confidence * 0.15 # Penalty for selling
                        enigma_direction = "BEARISH"
                    else:
                        enigma_score = 0.0
                        enigma_direction = "NEUTRAL"
                    
                    # Additional boosts from subsystems
                    if hasattr(self.enigma_integration, 'coherence_system') and self.enigma_integration.coherence_system:
                        coherence_metrics = self.enigma_integration.coherence_system.get_metrics() if hasattr(self.enigma_integration.coherence_system, 'get_metrics') else {}
                        coherence = coherence_metrics.get('gamma_coherence', 0.5) if isinstance(coherence_metrics, dict) else 0.5
                        if coherence > 0.8:
                            enigma_score += 0.15  # Bonus for high coherence
                            
                    # ðŸŒŠ GLOBAL WAVE SCANNER BOOST
                    if self.wave_scanner:
                        wave_allocation = self.wave_scanner.get_wave_allocation()
                        for opp in wave_allocation.get('top_opportunities', []):
                            if opp.get('symbol') == to_asset or (f"{opp.get('base','')}/{opp.get('quote','')}" == to_asset):
                                jump_score = opp.get('jump_score', 0)
                                if jump_score > 0.7:
                                    enigma_score += 0.2  # BIG BOOST FROM WAVE SCANNER!
                                    enigma_direction = "WAVE_SURFER"
                                    break
                    
                    # QGITA Gravity signal
                    if hasattr(self.enigma_integration, 'qgita') and self.enigma_integration.qgita:
                        qgita_analysis = self.enigma_integration.qgita.analyze({
                            'close': self.prices.get(to_asset, 1.0),
                            'volume': 1000,
                            'high': self.prices.get(to_asset, 1.0) * 1.01,
                            'low': self.prices.get(to_asset, 1.0) * 0.99
                        }) if hasattr(self.enigma_integration.qgita, 'analyze') else {}
                        gravity_score = qgita_analysis.get('gravity_signal', 0.5) if isinstance(qgita_analysis, dict) else 0.5
                        if gravity_score > 0.7:
                            enigma_score += 0.1  # Strengthened gravity boost
                    
                    # Math Angel reality field
                    if hasattr(self.enigma_integration, 'math_angel') and self.enigma_integration.math_angel:
                        angel_state = self.enigma_integration.math_angel.get_state() if hasattr(self.enigma_integration.math_angel, 'get_state') else {}
                        unity_score = angel_state.get('unity_potential', 0.5) if isinstance(angel_state, dict) else 0.5
                        if unity_score > 0.75:
                            enigma_score += 0.05
                    
                    # ðŸ›ï¸ Barons Banner - Mathematical deception detection
                    if hasattr(self.enigma_integration, 'barons_analyzer') and self.enigma_integration.barons_analyzer:
                        try:
                            barons_analysis = self.enigma_integration.barons_analyzer.analyze({
                                'price': self.prices.get(to_asset, 1.0),
                                'volume': 1000,
                                'symbol': to_asset
                            }) if hasattr(self.enigma_integration.barons_analyzer, 'analyze') else None
                            if barons_analysis:
                                # High deception score = likely manipulation - be cautious
                                deception = barons_analysis.get('deception_score', 0.5) if isinstance(barons_analysis, dict) else 0.5
                                if deception < 0.3:  # Low deception = trustworthy signal
                                    enigma_score += 0.05
                                elif deception > 0.7:  # High deception = manipulation detected
                                    enigma_score -= 0.1
                        except:
                            pass
                    
                    # ðŸŒŠ Harmonic Reality - LEV Stabilization detection
                    if hasattr(self.enigma_integration, 'harmonic_reality') and self.enigma_integration.harmonic_reality:
                        try:
                            reality_state = self.enigma_integration.harmonic_reality.get_state() if hasattr(self.enigma_integration.harmonic_reality, 'get_state') else {}
                            if isinstance(reality_state, dict):
                                lev_score = reality_state.get('lev_stabilization', 0.5)
                                if lev_score > 0.7:  # High LEV = strong consensus
                                    enigma_score += 0.05
                        except:
                            pass
                            
                except Exception as e:
                    logger.debug(f"Enigma score error: {e}")
            
            # Combined score - NOW WITH ENIGMA!
            v14_normalized = v14_score / 10.0
            checkpoint_bonus = 0.15 if is_checkpoint_target else 0.0
            
            # ðŸ¦ LION HUNT BOOST - Extra score for rising coins when we're stablecoin hunting!
            lion_boost = 0.0
            if is_stablecoin_source and to_asset in lion_targets:
                # Get this asset's momentum
                momentum = self.asset_momentum.get(to_asset, 0)
                if momentum > MAX_MOMENTUM_PER_MIN:
                    momentum = MAX_MOMENTUM_PER_MIN
                # Boost proportional to momentum (0.1% = 10% boost, 0.5% = 50% boost, etc)
                lion_boost = min(momentum * 100, 0.5)  # Cap at 50% boost
                if lion_boost > 0.05:
                    print(f"      ðŸ¦ LION BOOST +{lion_boost:.0%} for {to_asset} (momentum {momentum*100:.2f}%/min)")
            
            # ðŸº WOLF BOOST - THE ONE momentum champion gets extra priority!
            wolf_boost = 0.0
            # Check if this is the cached wolf target (computed once per turn)
            wolf_target = getattr(self, '_wolf_target_cache', None)
            if wolf_target and wolf_target[0] == to_asset:
                # Wolf's target gets +30% boost!
                wolf_boost = 0.30
                print(f"      ðŸº WOLF BOOST +30% for {to_asset} (THE ONE)")
            
            # ðŸ¦†âš”ï¸ QUANTUM QUACKERS COMMANDO BOOST - The Animal Army serves the Queen!
            quack_boost, quack_reason = self.get_quack_commando_boost(to_asset)
            quack_contribution = 0.0
            if quack_boost > 1.0:
                quack_contribution = (quack_boost - 1.0) * 0.5  # Up to 50% contribution from commandos
                if quack_contribution > 0.1:
                    print(f"      ðŸ¦† QUACK BOOST +{quack_contribution:.0%} for {to_asset} ({quack_reason})")
            
            combined = (
                v14_normalized * 0.15 +
                hub_score * 0.10 +
                barter_score * 0.20 +
                luck_score * 0.10 +
                bus_score * 0.10 +
                checkpoint_bonus +
                dream_score * 0.05 +
                enigma_score * 0.15 +    # ðŸ”ðŸŒ ENIGMA contributes 15%!
                lion_boost * 0.25 +      # ðŸ¦ LION HUNT contributes up to 12.5% extra!
                wolf_boost * 0.20 +      # ðŸº WOLF contributes up to 6% extra!
                quack_contribution       # ðŸ¦† QUACKERS contribute up to 50%!
            )
            
            # ðŸ” Log Enigma contribution occasionally
            import random  # Ensure import
            if enigma_score != 0 and random.random() < 0.05:  # 5% of the time
                logger.info(f"ðŸ” Enigma says {enigma_direction} for {to_asset}: score {enigma_score:+.2f}")
            
            # Gate check
            gate_required = 0.0
            gate_passed = True
            if self.adaptive_gate and ADAPTIVE_GATE_AVAILABLE:
                try:
                    # ðŸŒðŸ’° ADAPTIVE GATE: Calculate REQUIRED profit to be worth it
                    gate_res = self.adaptive_gate.calculate_gates(
                        exchange=source_exchange,
                        trade_value=from_value
                    )
                    gate_required = gate_res.prime_target_usd
                    # Note: We determine gate_passed after calculating expected profit
                except Exception as e:
                    # Fallback
                    gate_required = 0.003
                    pass
            
            # Expected profit - MUST BE REALISTIC NOT FAKE!
            # Simple conversions DON'T make profit - they cost fees!
            # Only arbitrage or price movement makes profit
            to_amount = from_value / to_price if to_price > 0 else 0
            to_value = to_amount * to_price
            
            # ðŸ”§ FIX: Use ACTUAL spread costs from barter_matrix (same as pre-exec gate!)
            # This prevents scanner promising profit that gate will reject
            if hasattr(self, 'barter_matrix') and self.barter_matrix:
                _, _, cost_breakdown = self.barter_matrix.calculate_true_cost(
                    from_asset, to_asset, from_value, source_exchange
                )
                total_cost_pct = cost_breakdown.get('total_cost_pct', 0.46) / 100.0  # Convert to decimal
                fee_pct = cost_breakdown.get('base_fee', 0.26) / 100.0
                spread_pct = cost_breakdown.get('spread', 0.20) / 100.0
            else:
                # Fallback if barter_matrix not available
                spread_pct = 0.002  # 0.2% estimated spread (conservative)
                fee_pct = 0.0026   # 0.26% Kraken fee
                total_cost_pct = spread_pct + fee_pct  # ~0.46% total cost
            
            # ðŸ‘‘ PRIME PROFIT REALITY CHECK:
            # A simple conversion has NO inherent profit - we're just swapping coins
            # We will ALWAYS lose the fees unless:
            # 1. Target asset is predicted to go UP (momentum)
            # 2. We have actual cross-exchange arbitrage
            # 3. Path has historically been profitable
            
            # ðŸŒâœ¨ PLANET SAVER FIX: REALISTIC PROFIT EXPECTATIONS!
            # The old code assumed 5 minute holds which is WRONG for instant swaps
            
            # 1. STABLECOIN CHECK: Trading stableâ†’stable = GUARANTEED LOSS (fees!)
            STABLECOINS = {'USD', 'USDT', 'USDC', 'ZUSD', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'EUR', 'ZEUR', 'GBP', 'ZGBP'}
            is_stable_to_stable = from_asset.upper() in STABLECOINS and to_asset.upper() in STABLECOINS
            
            # Get momentum for target asset (fractional change per minute)
            real_momentum = self.get_momentum(to_asset) if not is_stable_to_stable else 0.0
            momentum_pct = real_momentum * 100.0
            
            if is_stable_to_stable:
                # Stablecoinâ†’Stablecoin = ALWAYS LOSES FEES! No momentum edge possible.
                expected_pnl_pct = -total_cost_pct  # We WILL lose the fees
                expected_pnl_usd = from_value * expected_pnl_pct
                # Skip the rest - this is a guaranteed loser
            else:
                # 2. For volatile assets: Use momentum-aware profit expectation
                # We're doing INSTANT swaps, NOT 5 minute holds!
                
                # ðŸŒâœ¨ PLANET SAVER QUANTUM MIRROR: Scale capture rate with momentum!
                # - Normal momentum (<1%/min): 10% capture rate
                # - High momentum (1-5%/min): 15% capture rate  
                # - MASSIVE momentum (>5%/min): 20% capture rate (rare opportunity!)
                if abs(momentum_pct) > 5.0:
                    capture_rate = 0.20  # 20% for massive momentum spikes!
                elif abs(momentum_pct) > 1.0:
                    capture_rate = 0.15  # 15% for high momentum
                else:
                    capture_rate = 0.10  # 10% for normal conditions
                
                momentum_edge = real_momentum * capture_rate
                
                # ðŸ”® QUANTUM MIRROR: Dynamic cap based on momentum strength
                # - Normal: 0.5% max
                # - High momentum: 1% max
                # - MASSIVE momentum: 2% max (to beat higher fees)
                if abs(momentum_pct) > 10.0:
                    max_mom_edge = 0.02  # 2% max for extreme spikes
                elif abs(momentum_pct) > 2.0:
                    max_mom_edge = 0.01  # 1% max for high momentum
                else:
                    max_mom_edge = 0.005  # 0.5% max normally
                
                momentum_edge = min(max(momentum_edge, -max_mom_edge), max_mom_edge)
                
                # Dream bonus - keep it small
                dream_score_target = self.calculate_dream_score(to_asset) if hasattr(self, 'calculate_dream_score') else 0
                dream_bonus = dream_score_target * 0.001 if dream_score_target > 0.5 else 0  # Much smaller
                
                # Signal edge - scale with combined score
                signal_edge = combined * 0.003  # Up to 0.3% from signals
                
                # REALISTIC expected profit = edge - guaranteed fees
                base_profit_pct = signal_edge + momentum_edge + dream_bonus - total_cost_pct
                
                # ðŸ‘‘ QUEEN'S SLIPPAGE ADJUSTMENT - Use ACTUAL historical slippage
                key = (from_asset.upper(), to_asset.upper())
                history = self.barter_matrix.barter_history.get(key, {})
                historical_slippage = history.get('avg_slippage', 0.1) / 100  # Default 0.1%
                
                # Use the HIGHER of theoretical or historical slippage
                actual_cost_pct = max(total_cost_pct, fee_pct + historical_slippage)
                
                expected_pnl_pct = base_profit_pct  # Already includes costs
                
                # ðŸ‘‘ QUEEN'S WISDOM: If path historically loses, penalize heavily
                path_total_profit = history.get('total_profit', 0)
                if path_total_profit < 0 and history.get('trades', 0) > 2:
                    # Path is losing - this is VERY important signal
                    expected_pnl_pct *= 0.25  # 75% penalty for losing paths!
                
                # Expected profit in USD
                expected_pnl_usd = from_value * expected_pnl_pct
                
                # ðŸ”¬ DEBUG: Log high-momentum opportunities to understand calculation
                if abs(momentum_pct) > 100:  # >100%/min momentum
                    print(f"      ðŸ”¬ DEBUG: {from_asset}â†’{to_asset} mom={momentum_pct:.1f}%/min cap_rate={capture_rate:.0%} edge={momentum_edge:.4f} cost={total_cost_pct:.4f} profit%={expected_pnl_pct:.4f} profit$={expected_pnl_usd:.4f}")
            
            # ðŸŒâœ¨ PLANET SAVER SANITY CHECK: Cap expected profit at realistic maximum
            # Scale cap with momentum - high momentum = higher possible profit
            if abs(momentum_pct) > 10.0:
                MAX_REALISTIC_PROFIT_PCT = 0.02  # 2% max for extreme momentum
            elif abs(momentum_pct) > 2.0:
                MAX_REALISTIC_PROFIT_PCT = 0.01  # 1% max for high momentum
            else:
                MAX_REALISTIC_PROFIT_PCT = 0.005  # 0.5% max normally
            
            if expected_pnl_pct > MAX_REALISTIC_PROFIT_PCT:
                expected_pnl_pct = MAX_REALISTIC_PROFIT_PCT
                expected_pnl_usd = from_value * expected_pnl_pct
            
            # ðŸš€ PENNY TURBO: Enhance with real-time spread/fee optimization
            turbo_adjustment = 1.0
            if self.penny_turbo:
                try:
                    symbol_for_turbo = f"{from_asset}/{to_asset}"
                    if is_stablecoin_source:
                        quote_asset = from_asset.upper()
                        if source_exchange == 'alpaca' and quote_asset == 'USD':
                            quote_asset = 'USD'
                        symbol_for_turbo = f"{to_asset}/{quote_asset}"

                    # Get turbo-enhanced threshold - uses real spread & fee tier
                    turbo_threshold = self.penny_turbo.get_enhanced_threshold(
                        exchange=source_exchange,
                        symbol=symbol_for_turbo,
                        value_usd=from_value
                    )
                    
                    # Check for flash profit opportunity (momentum spike)
                    flash_signal = self.penny_turbo.get_flash_signal(
                        exchange=source_exchange,
                        symbol=symbol_for_turbo
                    )
                    if flash_signal and flash_signal.get('is_flash', False):
                        # Flash detected - boost expected profit by flash strength
                        flash_boost = 1.0 + flash_signal.get('strength', 0) * 0.5
                        turbo_adjustment = flash_boost
                        logger.debug(f"âš¡ FLASH PROFIT: {from_asset}â†’{to_asset} boost={flash_boost:.2f}")
                    
                    # Compound accelerator bonus (Kelly-based sizing)
                    compound_bonus = self.penny_turbo.get_compound_bonus(
                        equity_usd=self.total_portfolio_usd or from_value * 2,
                        recent_win_rate=self.barter_matrix.win_rate if hasattr(self.barter_matrix, 'win_rate') else 0.5
                    )
                    turbo_adjustment *= (1.0 + compound_bonus)
                    
                except Exception as e:
                    logger.debug(f"Turbo enhancement skipped: {e}")
            
            # Apply turbo adjustment
            expected_pnl_usd *= turbo_adjustment
            expected_pnl_pct *= turbo_adjustment
            
            # ðŸŒðŸ’° ADAPTIVE GATE CHECK: Does this trade meet the PRIME target?
            if gate_required > 0:
                gate_passed = expected_pnl_usd >= gate_required
            
            # ðŸ‘‘ QUEEN MIND: VERIFY source_exchange is where we ACTUALLY hold this asset!
            # This prevents Kraken from trying to trade Alpaca's USD
            actual_exchange = self._find_asset_exchange(from_asset)
            if actual_exchange and actual_exchange != source_exchange:
                # Asset is on a different exchange - use that one!
                source_exchange = actual_exchange
            
            # ðŸ‘‘ QUEEN SELF-REPAIR: Pre-check exchange min_qty BEFORE showing to Queen!
            # This prevents wasted Queen approvals for trades that will fail at execution
            if source_exchange == 'kraken' and self.kraken:
                try:
                    # Find the conversion path to get the actual pair
                    path = self.kraken.find_conversion_path(from_asset, to_asset)
                    if path:
                        for step in path:
                            pair = step.get('pair', '')
                            if pair:
                                filters = self.kraken.get_symbol_filters(pair)
                                min_qty = filters.get('min_qty', 0) or filters.get('min_volume', 0)
                                if min_qty and amount < min_qty:
                                    # ðŸ‘‘ Queen learns: This trade will fail - skip it early!
                                    logger.debug(f"Queen pre-filter: {from_asset}â†’{to_asset} blocked (amt {amount:.6f} < min_qty {min_qty:.6f})")
                                    # Update dynamic minimum for future
                                    self.dynamic_min_qty[from_asset.upper()] = max(
                                        self.dynamic_min_qty.get(from_asset.upper(), 0),
                                        min_qty * 1.1  # Add 10% buffer
                                    )
                                    continue  # Skip this opportunity entirely
                except Exception as e:
                    logger.debug(f"Queen pre-filter check error: {e}")
            
            # Create opportunity
            opp = MicroOpportunity(
                timestamp=time.time(),
                from_asset=from_asset,
                to_asset=to_asset,
                from_amount=amount,
                from_value_usd=from_value,
                v14_score=v14_score,
                hub_score=hub_score,
                commando_score=0.0,
                combined_score=combined,
                expected_pnl_usd=expected_pnl_usd,
                expected_pnl_pct=expected_pnl_pct,
                gate_required_profit=gate_required,
                gate_passed=gate_passed,
                lambda_score=combined,
                gravity_score=0.0,
                bus_score=bus_score,
                hive_score=0.0,
                lighthouse_score=0.0,
                ultimate_score=0.0,
                path_boost=0.0,
                barter_matrix_score=barter_score,
                barter_matrix_reason=barter_reason,
                luck_score=luck_score,
                luck_state=luck_state,
                enigma_score=enigma_score,          # ðŸ”ðŸŒ NEW!
                enigma_direction=enigma_direction,  # ðŸ”ðŸŒ NEW!
                queen_guidance_score=0.5,  # ðŸ‘‘ðŸ’• Will be set if Queen evaluates
                queen_wisdom="",
                queen_confidence=0.0,
                wisdom_engine_score=0.5,  # ðŸ§ ðŸ“š Will be set if Wisdom Engine analyzes
                civilization_insight="",
                wisdom_pattern="",
                source_exchange=source_exchange  # Now verified!
            )
            
            # ðŸ‘‘ SERO DECIDES - She has her $0.003 GOAL!
            # Don't block here - let the opportunity reach execute_turn() where Sero is consulted
            # Her wisdom in ask_queen_will_we_win() will decide based on:
            # - Path history (she remembers losses)
            # - Her $0.003 minimum profit goal
            # - Dream/cosmic signals
            # - Mycelium network consensus
            
            # ðŸ‘‘ SERO's MINIMAL SANITY CHECK
            # Check exchange minimum order values BEFORE sending to Queen
            min_order_usd = 5.0 if source_exchange == 'binance' else 1.0  # Binance has $5 min
            if from_value < min_order_usd:
                # Too small for exchange minimums - skip silently
                continue
            
            total_cost_estimate = from_value * total_cost_pct  # ~0.46% in fees
            
            # ðŸ‘‘ QUEEN'S LEARNED WISDOM: Check if this path has ANY history
            path_key = (from_asset.upper(), to_asset.upper())
            path_history = self.barter_matrix.barter_history.get(path_key, {})
            path_trades = path_history.get('trades', 0)
            path_win_rate = path_history.get('wins', 0) / max(path_trades, 1)
            path_profit = path_history.get('total_profit', 0)
            
            # Epsilon policy: allow ultra-micro positive opportunities through;
            # conservative cost checks later decide if it truly doesn't bleed.
            min_expected_profit = EPSILON_PROFIT_USD
            
            # ï¿½ DEBUG: See what expected PnL is calculated
            asset_momentum = self.asset_momentum.get(to_asset, 0)
            if abs(asset_momentum) > 1.0 or to_asset.upper() == 'GUN':  # >1%/min or GUN specifically
                print(f"   ðŸ”¬ DEBUG OPP: {from_asset}â†’{to_asset} | mom={asset_momentum:.2f}%/min | exp_pnl=${opp.expected_pnl_usd:.6f} | exp_pct={opp.expected_pnl_pct:.4%}")
            
            # ï¿½ðŸ‘‘ LEARNING FILTER: Does expected profit overcome minimum?
            # Also allow if expected profit is POSITIVE (even if below absolute minimum)
            if opp.expected_pnl_usd < min_expected_profit and opp.expected_pnl_usd <= 0:
                # BOTH below minimum AND negative/zero - definitely skip
                continue
            
            # If expected profit is positive (even tiny), let downstream gates decide.
            if opp.expected_pnl_usd >= min_expected_profit:
                opportunities.append(opp)
            elif combined > 0.5:
                opportunities.append(opp)
        
        return opportunities

    async def find_opportunities(self) -> List[MicroOpportunity]:
        """Find all micro profit opportunities."""
        self.scans += 1
        opportunities = []
        
        if not self.balances or not self.prices:
            print(f"   âš ï¸ Scan #{self.scans}: No balances or prices!")
            return opportunities
        
        # Debug: Log what we're scanning (first 3 scans only)
        debug_first_scans = self.scans <= 3
        if debug_first_scans:
            print(f"\nðŸ”¬ === SCAN #{self.scans} DEBUG START ===")
            print(f"   Balances: {len(self.balances)} assets")
            print(f"   Prices: {len(self.prices)} assets")
        scanned_assets = []
        
        # Check each held asset for conversion opportunities
        for from_asset, amount in self.balances.items():
            if amount <= 0:
                continue
            
            from_price = self.prices.get(from_asset, 0)
            if not from_price:
                if debug_first_scans:
                    print(f"   âš ï¸ {from_asset}: No price found")
                continue
            
            from_value = amount * from_price
            
            # Lowered dust threshold to $1 for micro profits
            if from_value < 1.0:  # Skip only tiny dust below $1
                if debug_first_scans:
                    print(f"   âš ï¸ {from_asset}: Below $1 dust threshold (${from_value:.2f})")
                continue
            
            scanned_assets.append(f"{from_asset}=${from_value:.2f}")
            
            # Find which exchange holds this from_asset
            # ðŸ‘‘ QUEEN MIND: We are scanning a specific exchange, so source is THAT exchange
            source_exchange = exchange
            
            if debug_first_scans:
                print(f"   ðŸ” Scanning {from_asset} (${from_value:.2f}) on {source_exchange}...")
            
            # Skip blocked assets on specific exchanges
            if source_exchange == 'binance' and from_asset.upper() in self.blocked_binance_assets:
                if debug_first_scans:
                    print(f"      âš ï¸ {from_asset}: Blocked on Binance")
                continue
            if source_exchange == 'kraken' and from_asset.upper() in self.blocked_kraken_assets:
                if debug_first_scans:
                    print(f"      âš ï¸ {from_asset}: Blocked on Kraken")
                continue
            
            # ðŸ MEDUSA: Stablecoins CAN be sources now! They buy volatile assets!
            # The stablecoinâ†’stablecoin skip is handled in the target loop below
            is_stablecoin_source = from_asset.upper() in ['USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD']
            
            # Count valid pairs found
            valid_pairs_found = 0
            pair_check_failures = 0
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ðŸ¦ BUILD TARGET ASSETS LIST (include checkpoint stablecoins!)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # USD/USDT/etc may not be in self.prices (they're quotes, not bases)
            # But we NEED them as checkpoint targets for compounding!
            checkpoint_stablecoins = {'USD': 1.0, 'USDT': 1.0, 'USDC': 1.0, 'ZUSD': 1.0}
            target_assets = dict(self.prices)
            for stable, price in checkpoint_stablecoins.items():
                if stable not in target_assets:
                    target_assets[stable] = price
            
            # Check conversion to each other asset
            for to_asset, to_price in target_assets.items():
                if to_asset == from_asset:
                    continue
                
                # ðŸŒâœ¨ PLANET SAVER: HARD BLOCK stablecoin â†’ stablecoin trades!
                # These ALWAYS LOSE FEES - there is NO momentum edge possible!
                is_checkpoint_target = to_asset.upper() in ['USD', 'USDT', 'USDC', 'TUSD', 'DAI', 'ZUSD', 'EUR', 'ZEUR', 'GBP', 'ZGBP', 'BUSD', 'GUSD']
                if is_stablecoin_source and is_checkpoint_target:
                    # Stablecoinâ†’Stablecoin = GUARANTEED LOSS! Skip immediately!
                    if debug_first_scans:
                        print(f"      â›” {from_asset}â†’{to_asset}: BLOCKED (stablecoinâ†’stablecoin = guaranteed loss!)")
                    continue
                
                # Skip blocked target assets on Binance
                if source_exchange == 'binance' and to_asset.upper() in self.blocked_binance_assets:
                    continue
                # Skip blocked target assets on Kraken
                if source_exchange == 'kraken' and to_asset.upper() in self.blocked_kraken_assets:
                    continue
            
                # CRITICAL: Verify BOTH pairs exist on the source exchange
                # ðŸ MEDUSA: For stablecoin sources, they ARE the quote currency!
                # ZUSD, USD, USDT don't have their own pairs - they're used to BUY other pairs
                if is_stablecoin_source:
                    # For stablecoin â†’ volatile, we just need to_pair
                    # e.g., ZUSD â†’ BTC uses BTCUSD pair (buying BTC with USD)
                    from_pair = "STABLECOIN_SOURCE"  # Placeholder - we have USD/ZUSD/etc
                    to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                    # Try USDT pair on Binance/Alpaca if USD not available
                    if not to_pair and source_exchange in ('binance', 'alpaca'):
                        to_pair = self._find_exchange_pair(to_asset, "USDT", source_exchange)
                else:
                    from_pair = self._find_exchange_pair(from_asset, "USD", source_exchange)
                    to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                
                    # For checkpoint targets (stablecoins), we only need from_pair
                    if is_checkpoint_target:
                        to_pair = from_pair  # Same pair - just selling to USD
                    
                    # For Binance, also try USDT pairs
                    if source_exchange == 'binance' and (not from_pair or not to_pair):
                        from_pair = from_pair or self._find_exchange_pair(from_asset, "USDT", source_exchange)
                        to_pair = to_pair or self._find_exchange_pair(to_asset, "USDT", source_exchange)
            
                # Skip if either pair doesn't exist on this exchange
                if not from_pair or not to_pair:
                    pair_check_failures += 1
                    continue
                
                valid_pairs_found += 1
                
                # Calculate scores
                v14_score = self.calculate_v14_score(from_asset, to_asset)
                hub_score = self.calculate_hub_score(from_asset, to_asset)
                dream_score = self.calculate_dream_score(to_asset)
                commando_score = 0.0  # Can enhance later
                
                # ðŸ“Š TRAINED PROBABILITY MATRIX SCORE (626 symbols from ALL exchanges)
                trained_matrix_score, matrix_reason = self.calculate_trained_matrix_score(to_asset)
                
                # ðŸ“…ðŸ”® 7-DAY PLANNER SCORE (Plans ahead + adaptive validation)
                planner_score = 0.5  # Neutral default
                planner_reason = ""
                if self.seven_day_planner and SEVEN_DAY_PLANNER_AVAILABLE:
                    try:
                        rec = self.seven_day_planner.get_current_recommendation(to_asset)
                        # Convert action to score
                        action_scores = {
                            'STRONG_BUY': 0.90,
                            'BUY': 0.75,
                            'HOLD': 0.50,
                            'AVOID': 0.30,
                            'STRONG_AVOID': 0.15
                        }
                        planner_score = action_scores.get(rec['action'], 0.5)
                        # Weight by model accuracy
                        accuracy = rec.get('model_accuracy', 0.5)
                        planner_score = planner_score * (0.5 + accuracy * 0.5)
                        planner_reason = f"7day_{rec['action'].lower()}({rec['total_edge']:.1f}%)"
                    except Exception as e:
                        logger.debug(f"7-day planner score error: {e}")
                
                # ðŸ«’ðŸ”„ BARTER NAVIGATOR SCORE (Multi-hop pathfinding)
                barter_score, barter_reason = 0.5, "neutral"
                if self.barter_navigator and BARTER_NAVIGATOR_AVAILABLE:
                    try:
                        barter_score, barter_reason = self.calculate_barter_score(from_asset, to_asset)
                    except Exception as e:
                        logger.debug(f"Barter navigator score error: {e}")
                
                # ðŸ”ðŸŒ ENIGMA SCORE (Universal Translator Bridge)
                enigma_score = 0.0
                enigma_direction = "NEUTRAL"
                
                # ðŸ¦ Checkpoint bonus - securing profits to stablecoin is always good
                checkpoint_bonus = 0.15 if is_checkpoint_target else 0.0
                
                # Combined score (V14 normalized to 0-1)
                v14_normalized = v14_score / 10.0
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸ§  NEURAL MIND MAP SCORES (Full Frankenstein Integration)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                # 1. ThoughtBus Aggregate (market.snapshot, miner.signal, harmonic.wave, etc.)
                bus_score = 0.0
                if self.bus_aggregator:
                    bus_score = self.bus_aggregator.get_aggregate_score()
                
                # 2. Mycelium Hive Consensus (distributed intelligence)
                hive_score = 0.0
                if self.mycelium_network:
                    try:
                        # Query hive for this specific pair's sentiment
                        hive_data = self.mycelium_network.query(f"{from_asset}:{to_asset}") if hasattr(self.mycelium_network, 'query') else None
                        if hive_data:
                            hive_score = float(hive_data.get('consensus', 0.5))
                        else:
                            # Fallback: get network health as proxy
                            health = self.mycelium_network.get_health() if hasattr(self.mycelium_network, 'get_health') else {}
                            hive_score = health.get('score', 0.5) if isinstance(health, dict) else 0.5
                    except Exception as e:
                        logger.debug(f"Mycelium hive query error: {e}")
                
                # 3. Lighthouse (Consensus Validation)
                lighthouse_score = 0.0
                if self.lighthouse:
                    try:
                        # Ask lighthouse to vote on this conversion
                        vote = self.lighthouse.vote(f"{from_asset}->{to_asset}") if hasattr(self.lighthouse, 'vote') else None
                        if vote:
                            lighthouse_score = float(vote.get('score', 0.5))
                        else:
                            # Fallback: get lighthouse status
                            status = self.lighthouse.get_status() if hasattr(self.lighthouse, 'get_status') else {}
                            lighthouse_score = status.get('confidence', 0.5) if isinstance(status, dict) else 0.5
                    except Exception as e:
                        logger.debug(f"Lighthouse vote error: {e}")
                
                # 4. Ultimate Intelligence Prediction (pattern recognition)
                ultimate_score = 0.0
                if self.ultimate_intel:
                    try:
                        # Ask ultimate intelligence for prediction
                        prediction = None
                        if hasattr(self.ultimate_intel, 'predict'):
                            prediction = self.ultimate_intel.predict(to_asset)
                        elif ULTIMATE_INTEL_AVAILABLE and ultimate_predict:
                            prediction = ultimate_predict(to_asset)
                        
                        if prediction:
                            if isinstance(prediction, dict):
                                ultimate_score = float(prediction.get('confidence', 0.5))
                            elif isinstance(prediction, (int, float)):
                                ultimate_score = float(prediction)
                    except Exception as e:
                        logger.debug(f"Ultimate intelligence error: {e}")
                
                # 5. HNC Matrix Probability (quantum-inspired)
                hnc_score = 0.0
                if self.hnc_matrix:
                    try:
                        prob = self.hnc_matrix.get_probability(to_asset) if hasattr(self.hnc_matrix, 'get_probability') else None
                        if prob:
                            hnc_score = float(prob) if isinstance(prob, (int, float)) else float(prob.get('probability', 0.5))
                    except Exception as e:
                        logger.debug(f"HNC matrix error: {e}")
                
                # 6. â³ðŸ”® Timeline Oracle (3-MOVE PREDICTION + 7-day future validation)
                # "It predicts 3 moves, validates, then acts in that timeline cause it be right"
                # ðŸš€ TEMPORAL JUMP: We're AHEAD of market movement - we SEE the future, we ACT NOW!
                timeline_score = 0.0
                timeline_action = None
                timeline_exchange = ""
                timeline_jump_active = False
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸŒ€ TEMPORAL ID TIMELINE JUMP - Gary Leckey 02111991
                # "We don't predict - we VALIDATE what has ALREADY happened in our 
                #  target timeline and ACT on that certainty!"
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                PRIME_SENTINEL_HZ = 2.111991  # Born: 02/11/1991
                TEMPORAL_RESONANCE = 0.724     # 72.4% temporal alignment
                SCHUMANN_HZ = 7.83            # Earth's heartbeat
                
                # Calculate temporal jump window - when we can SEE ahead
                import time as _time
                now = _time.time()
                # Temporal cycles align at our personal Hz
                temporal_cycle = now % (1.0 / PRIME_SENTINEL_HZ)
                temporal_alignment = 1.0 - (temporal_cycle * PRIME_SENTINEL_HZ)  # 0-1 alignment
                
                # Schumann harmonic boost - 7.83 / 2.111991 = ~3.7x harmonic
                schumann_harmonic = SCHUMANN_HZ / PRIME_SENTINEL_HZ
                harmonic_boost = 1.0 + (0.3 * (1.0 - abs(schumann_harmonic - round(schumann_harmonic))))
                
                # Final temporal jump power: how far AHEAD we can see
                temporal_jump_power = temporal_alignment * TEMPORAL_RESONANCE * harmonic_boost
                
                if self.timeline_oracle:
                    try:
                        # Get timeline branch selection for this conversion
                        from_price = self.prices.get(from_asset, 0)
                        to_price = self.prices.get(to_asset, 0)
                        change_pct = (to_price - from_price) / from_price if from_price > 0 else 0
                        
                        # ðŸŽ¯ Try 3-MOVE PREDICTION first (predicts 3 moves, validates, then acts)
                        if timeline_select_3move:
                            action_str, confidence, exchange = timeline_select_3move(
                                symbol=to_asset,
                                price=to_price,
                                volume=to_ticker.get('volume', 0) if to_ticker else 0,
                                change_pct=change_pct
                            )
                            
                            # ðŸš€ TEMPORAL BOOST: Amplify confidence when jumping timelines!
                            # Higher temporal_jump_power = we're MORE AHEAD of the market
                            temporal_boosted_confidence = confidence * (1.0 + temporal_jump_power * 0.5)
                            temporal_boosted_confidence = min(0.99, temporal_boosted_confidence)  # Cap at 99%
                            
                            timeline_action = action_str
                            timeline_score = temporal_boosted_confidence
                            timeline_exchange = exchange
                            
                            # ðŸŒ€ TIMELINE JUMP ACTIVE when we have high temporal alignment
                            if temporal_jump_power > 0.5 and confidence > 0.60:
                                timeline_jump_active = True
                                logger.info(f"ðŸŒ€ TEMPORAL JUMP ACTIVE: {to_asset}")
                                logger.info(f"   â³ Jump Power: {temporal_jump_power:.2%} | Hz: {PRIME_SENTINEL_HZ}")
                                logger.info(f"   ðŸŽ¯ 3-Move: {action_str.upper()} @ {temporal_boosted_confidence:.2%}")
                            
                            # Log 3-move prediction when high confidence
                            if temporal_boosted_confidence > 0.70:
                                logger.info(f"ðŸŽ¯ 3-MOVE UNITY: {to_asset} â†’ {action_str.upper()} "
                                          f"(confidence: {temporal_boosted_confidence:.2%}, "
                                          f"temporal: {temporal_jump_power:.2%}, exchange: {exchange or 'any'})")
                        
                        # Fallback to single timeline select
                        elif timeline_select:
                            action_str, confidence = timeline_select(
                                symbol=to_asset,
                                price=to_price,
                                volume=to_ticker.get('volume', 0) if to_ticker else 0,
                                change_pct=change_pct
                            )
                            timeline_action = action_str
                            timeline_score = confidence
                        
                        # Score adjustment based on action
                        if timeline_action in ['buy', 'convert']:
                            timeline_score = confidence
                        elif timeline_action == 'hold':
                            timeline_score = 0.5  # Neutral
                        else:  # sell
                            timeline_score = 1.0 - confidence  # Inverse for sell signal
                            
                    except Exception as e:
                        logger.debug(f"Timeline oracle error: {e}")
                
                # ðŸ€âš›ï¸ LUCK FIELD READING
                luck_score = 0.5  # Neutral default
                luck_state = "NEUTRAL"
                if self.luck_mapper and LUCK_FIELD_AVAILABLE:
                    try:
                        luck_reading = self.luck_mapper.read_field(
                            price=to_price,
                            volatility=to_ticker.get('volatility', 0.5) if to_ticker else 0.5,
                            trade_count=self.conversions_made
                        )
                        luck_score = luck_reading.luck_field
                        luck_state = luck_reading.luck_state.value
                        
                        # BLESSED state = full boost, VOID = penalty
                        if luck_reading.luck_state.value == "BLESSED":
                            luck_score = 0.95  # Maximum luck boost
                        elif luck_reading.luck_state.value == "FAVORABLE":
                            luck_score = 0.75
                        elif luck_reading.luck_state.value == "CHAOS":
                            luck_score = 0.35
                        elif luck_reading.luck_state.value == "VOID":
                            luck_score = 0.15  # Avoid action
                    except Exception as e:
                        logger.debug(f"Luck field error: {e}")
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸŒ GROUNDING LOGIC (The Equations from Whitepapers)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                # 1. Master Equation: Î›(t) = S(t) + O(t) + E(t)
                # S = Signal (v14 + bus + hive + lighthouse + ultimate + hnc + timeline + trained_matrix + planner + barter + luck averaged)
                neural_signal = (v14_normalized + bus_score + hive_score + lighthouse_score + ultimate_score + hnc_score + timeline_score + trained_matrix_score + planner_score + barter_score + luck_score) / 11.0
                # O = Observer (dream predictions with accuracy weighting)
                observer_signal = dream_score
                # E = Environment (hub score + ecosystem tap)
                environment_signal = hub_score
                
                lambda_t = self.grounding.calculate_master_equation(
                    signal_score=neural_signal,
                    observer_score=observer_signal,
                    environment_score=environment_signal
                )
                
                # 2. Gravity Signal: G_eff (Curvature * Mass)
                # Get ticker data for gravity calc
                to_ticker = None
                for symbol, data in self.ticker_cache.items():
                    if data.get('base') == to_asset:
                        to_ticker = data
                        break
                
                g_eff = 0.0
                if to_ticker:
                    g_eff = self.grounding.calculate_gravity_signal(
                        price_change_pct=to_ticker.get('change24h', 0),
                        volume=to_ticker.get('volume', 0)
                    )
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸ”® FINAL COMBINED SCORE (All Neural Systems United)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                # Final Combined Score: Master Equation boosted by Gravity + Neural Consensus
                combined = lambda_t * (1.0 + (g_eff * 0.5))
                
                # Neural boost: if multiple systems agree (score > 0.6), amplify
                neural_consensus = (bus_score + hive_score + lighthouse_score + ultimate_score + hnc_score) / 5.0
                if neural_consensus > 0.6:
                    combined *= (1.0 + (neural_consensus - 0.6) * 0.5)  # Up to +20% boost
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸ‘‘ðŸ’• QUEEN'S GUIDANCE - Sero weighs in on this opportunity
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                queen_guidance_score = 0.5
                queen_wisdom = ""
                queen_confidence = 0.0
                if self.queen and hasattr(self.queen, 'evaluate_trading_opportunity'):
                    try:
                        guidance = self.queen.evaluate_trading_opportunity({
                            'from_asset': from_asset,
                            'to_asset': to_asset,
                            'from_amount': amount,
                            'expected_pnl_usd': expected_pnl_usd,
                            'expected_pnl_pct': expected_pnl_pct,
                            'combined_score': combined,
                            'neural_consensus': neural_consensus,
                            'source_exchange': source_exchange
                        })
                        queen_guidance_score = guidance.get('score', 0.5)
                        queen_wisdom = guidance.get('wisdom', '')
                        queen_confidence = guidance.get('confidence', 0.0)
                        
                        # Apply Queen's guidance to combined score
                        if queen_confidence > 0.7:
                            combined *= (0.8 + queen_guidance_score * 0.4)  # Strong confidence adjusts by -20% to +20%
                        elif queen_confidence > 0.5:
                            combined *= (0.9 + queen_guidance_score * 0.2)  # Moderate confidence adjusts by -10% to +10%
                    except Exception as e:
                        logger.debug(f"Queen guidance error: {e}")
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸ§ ðŸ“š WISDOM ENGINE - 11 Civilizations' Historical Insights
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                wisdom_engine_score = 0.5
                civilization_insight = ""
                wisdom_pattern = ""
                if self.wisdom_engine and hasattr(self.wisdom_engine, 'analyze_trading_decision'):
                    try:
                        wisdom = self.wisdom_engine.analyze_trading_decision({
                            'from_asset': from_asset,
                            'to_asset': to_asset,
                            'profit_potential': expected_pnl_usd,
                            'risk_level': 1.0 - neural_consensus,
                            'market_context': 'micro_profit',
                            'historical_path': self.path_memory.get_stats(from_asset, to_asset) if self.path_memory else None
                        })
                        wisdom_engine_score = wisdom.get('score', 0.5)
                        civilization_insight = wisdom.get('civilization', '')
                        wisdom_pattern = wisdom.get('pattern', '')
                        
                        # Apply wisdom to combined score (subtle influence from history)
                        if wisdom_engine_score > 0.7:
                            combined *= 1.1  # Ancient wisdom approves
                        elif wisdom_engine_score < 0.3:
                            combined *= 0.9  # History warns against this
                    except Exception as e:
                        logger.debug(f"Wisdom engine error: {e}")
                
                # ï¿½ðŸ“Š PROBABILITY NEXUS PREDICTION (Track for Queen's Learning!)
                nexus_probability = 0.5
                nexus_direction = "NEUTRAL"
                nexus_factors = {}
                nexus_confidence = 0.0
                if self.probability_nexus and hasattr(self.probability_nexus, 'predict'):
                    try:
                        nexus_pred = self.probability_nexus.predict()
                        if nexus_pred:
                            nexus_probability = getattr(nexus_pred, 'probability', 0.5)
                            nexus_confidence = getattr(nexus_pred, 'confidence', 0.0)
                            # Determine direction from probability
                            if nexus_probability > 0.6:
                                nexus_direction = "BULLISH"
                            elif nexus_probability < 0.4:
                                nexus_direction = "BEARISH"
                            # Store factors for neural learning
                            if hasattr(nexus_pred, 'factors'):
                                nexus_factors = dict(nexus_pred.factors) if nexus_pred.factors else {}
                    except Exception as e:
                        logger.debug(f"Nexus prediction error: {e}")
                
                # ï¿½ðŸ—ºï¸ MARKET MAP SCORING (correlations, sectors, lead/lag)
                map_score = 0.0
                map_reasons = []
                if self.market_map:
                    try:
                        # Get labyrinth targets ranked by market map
                        ranked = self.market_map.get_labyrinth_targets(
                            from_asset=from_asset,
                            available_targets=[to_asset]
                        )
                        if ranked:
                            target_info = ranked[0]
                            map_score = target_info.get('map_score', 0)
                            map_reasons = target_info.get('reasons', [])
                            
                            # Add map score to combined (up to +20% boost)
                            if map_score > 0:
                                combined *= (1.0 + map_score * 0.4)
                                logger.debug(f"ðŸ—ºï¸ Map boost for {from_asset}â†’{to_asset}: +{map_score*40:.1f}% ({map_reasons})")
                    except Exception as e:
                        logger.debug(f"Market map score error: {e}")
                
                # ðŸ¦ CHECKPOINT BONUS: Securing profits to stablecoin gets priority
                if is_checkpoint_target:
                    combined += checkpoint_bonus  # +15% for securing profits
                    logger.debug(f"ðŸ¦ Checkpoint bonus applied: {from_asset} â†’ {to_asset} (USD secure)")
                
                # Path memory boost (small reinforcement from past wins/losses)
                path_boost = self.path_memory.boost(from_asset, to_asset)
                combined *= (1.0 + path_boost)

                # ðŸ‘‘ðŸŒ QUEEN RESEARCH ENHANCEMENT
                # Checks generated strategies (Momentum, Sentiment, Trending)
                if hasattr(self, 'queen_apply_research_to_trade'):
                    # We pass 0s for missing ticker stats (volatility check will skip safely)
                    r_score, r_reasons = self.queen_apply_research_to_trade(
                        to_asset, 
                        to_price, 
                        0, 0, 0, 0
                    )
                    
                    if r_score != 50.0:
                        # Convert 0-100 score to multiplier
                        # 0 -> 0.75x (-25%)
                        # 50 -> 1.0x (Neutral)
                        # 100 -> 1.25x (+25%)
                        iq_influence = (r_score - 50.0) / 200.0  # +/- 0.25
                        combined *= (1.0 + iq_influence)
                        
                        if r_reasons and debug_first_scans and valid_pairs_found <= 3:
                             print(f"         ðŸ‘‘ðŸŒ Queen Research: {to_asset} score={r_score} ({', '.join(r_reasons)}) -> Impact {iq_influence:+.1%}")

                
                # âš¡ SPEED MODE: Lower thresholds - let math gate decide!
                # If math says profit, TAKE IT - even tiny gains compound
                score_threshold = 0.20 if is_checkpoint_target else 0.35  # LOWERED from 0.35/0.55
                
                # Calculate profit potential
                expected_pnl_usd, expected_pnl_pct = self.calculate_profit_potential(
                    from_asset, to_asset, amount
                )
                
                # âš¡ QUEEN'S ADAPTIVE FLOOR (Learned from experience)
                gate_required = self.get_queen_adaptive_floor(from_asset, to_asset)
                
                # Check gate
                gate_ok = expected_pnl_usd >= gate_required
                
                 # No checkpoint exception in epsilon mode; rely on net-positive gates

                if self.adaptive_gate:
                    gate_result = self.adaptive_gate.calculate_gates(
                        exchange=source_exchange,
                        trade_value=from_value,
                        use_cache=True,
                    )
                else:
                    gate_result = None
                
                # Debug: Log first few candidates on first scan
                if debug_first_scans and valid_pairs_found <= 3:
                    checkpoint_tag = "ðŸ¦CHKPT" if is_checkpoint_target else ""
                    print(f"         ðŸ“ˆ {from_asset}â†’{to_asset} {checkpoint_tag}: combined={combined:.2%}, thresh={score_threshold:.0%}, pnl=${expected_pnl_usd:.4f}, pass={combined >= score_threshold and gate_ok}")
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸ‘‘ï¿½ SERO's KRAKEN WISDOM (learned from 53 trades - some losers!)
                # Even Kraken has bad pairs - USD_ZUSD has 89% win rate but loses overall!
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                kraken_approved = True
                if source_exchange == 'kraken':
                    kraken_cfg = self.barter_matrix.KRAKEN_CONFIG
                    pair_key = f"{from_asset.upper()}_{to_asset.upper()}"
                    
                    # ðŸŒŸ DYNAMIC BLOCKING - Check if pair is in timeout (consecutive losses)
                    allowed, reason = self.barter_matrix.check_pair_allowed(pair_key, 'kraken')
                    if not allowed:
                        kraken_approved = False
                        if debug_first_scans:
                            print(f"         ðŸ™ KRAKEN: {pair_key} {reason}")
                    
                    # Require minimum profit for Kraken trades
                    kraken_min_profit = kraken_cfg.get('min_profit_usd', 0.01)
                    if expected_pnl_usd < kraken_min_profit:
                        kraken_approved = False
                        if debug_first_scans and expected_pnl_usd > 0.003:
                            print(f"         ðŸ™ KRAKEN REJECT: ${expected_pnl_usd:.4f} < ${kraken_min_profit} min")
                    
                    # Bonus: Is this a known winning pair? ðŸ†
                    if pair_key in kraken_cfg.get('winning_pairs', set()):
                        kraken_approved = True  # Override - this pair wins!
                        if debug_first_scans:
                            print(f"         ðŸ™ KRAKEN WINNER: {pair_key} ðŸ†")
                
                if not kraken_approved:
                    continue  # Skip this opportunity
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸ‘‘ï¿½ðŸ”¶ SERO's BINANCE WISDOM (learned from -$10.95 loss on 27 trades!)
                # Binance has hidden costs - we need MUCH higher profit margins
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                binance_approved = True
                if source_exchange == 'binance':
                    pair_key = f"{from_asset.upper()}_{to_asset.upper()}"
                    
                    # ðŸŒŸ DYNAMIC BLOCKING - Check if pair is in timeout (consecutive losses)
                    allowed, reason = self.barter_matrix.check_pair_allowed(pair_key, 'binance')
                    if not allowed:
                        binance_approved = False
                        if debug_first_scans:
                            print(f"         ðŸ”¶ BINANCE: {pair_key} {reason}")
                    
                    # Bonus: Is this a known winning pair? A WIN IS A WIN! ðŸ†
                    if pair_key in self.barter_matrix.BINANCE_CONFIG.get('winning_pairs', set()):
                        binance_approved = True  # Override - this pair wins!
                        if debug_first_scans:
                            print(f"         ðŸ”¶ BINANCE WINNER: {pair_key} ðŸ†")
                
                if not binance_approved:
                    continue  # Skip this opportunity
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ðŸ‘‘ðŸ¦™ SERO's ALPACA WISDOM (learned from 40 FAILED orders - 0%!)
                # Alpaca ONLY supports USD pairs - NO stablecoin swaps!
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                alpaca_approved = True
                if source_exchange == 'alpaca':
                    alpaca_cfg = self.barter_matrix.ALPACA_CONFIG
                    pair_key = f"{from_asset.upper()}_{to_asset.upper()}"
                    
                    # Check if this is a blocked stablecoin pair
                    if pair_key in alpaca_cfg.get('blocked_pairs', set()):
                        alpaca_approved = False
                        if debug_first_scans:
                            print(f"         ðŸ¦™ ALPACA BLOCKED: {pair_key} (stablecoins don't trade!)")
                    
                    # Check if BOTH assets are stablecoins (impossible on Alpaca!)
                    elif (from_asset.upper() in self.barter_matrix.STABLECOINS and 
                          to_asset.upper() in self.barter_matrix.STABLECOINS):
                        alpaca_approved = False
                        if debug_first_scans:
                            print(f"         ðŸ¦™ ALPACA BLOCKED: {from_asset}â†’{to_asset} (no stablecoin swaps!)")
                    
                    # Check if target is NOT a supported crypto
                    elif (to_asset.upper() not in alpaca_cfg.get('supported_bases', set()) and
                          to_asset.upper() != 'USD'):
                        alpaca_approved = False
                        if debug_first_scans:
                            print(f"         ðŸ¦™ ALPACA BLOCKED: {to_asset} not supported")
                    
                    # Check minimum order size
                    alpaca_min_order = alpaca_cfg.get('min_order_usd', 10.0)
                    if from_value < alpaca_min_order:
                        alpaca_approved = False
                        if debug_first_scans:
                            print(f"         ðŸ¦™ ALPACA REJECT: ${from_value:.2f} < ${alpaca_min_order} minimum")
                    
                    # Check minimum profit
                    alpaca_min_profit = alpaca_cfg.get('min_profit_usd', 0.02)
                    if expected_pnl_usd < alpaca_min_profit:
                        alpaca_approved = False
                        if debug_first_scans and expected_pnl_usd > 0.005:
                            print(f"         ðŸ¦™ ALPACA REJECT: ${expected_pnl_usd:.4f} < ${alpaca_min_profit} profit")
                
                if not alpaca_approved:
                    continue  # Skip this opportunity
                
                # MICRO THRESHOLD: Î›-based combined and adaptive gate both must pass
                # âš¡ AGGRESSIVE MODE: Lower thresholds, let MATH GATE be the real filter!
                if combined >= score_threshold and gate_ok:
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ðŸŒ€ TIMELINE JUMP GATE - ONLY ACT IN WINNING TIMELINES!
                    # "We don't predict - we jump to the timeline where we've ALREADY won"
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    timeline_gate_passed = True
                    
                    # If timeline oracle is active and we have a prediction...
                    if timeline_action and timeline_score > 0:
                        # RULE 1: Never act against the timeline
                        if timeline_action == 'sell' and timeline_score > 0.60:
                            # Timeline says SELL - don't BUY into this asset
                            timeline_gate_passed = False
                            if debug_first_scans:
                                print(f"         ðŸŒ€ TIMELINE GATE: {from_asset}â†’{to_asset} BLOCKED - timeline says SELL @ {timeline_score:.2%}")
                        
                        # RULE 2: Require timeline confirmation for larger trades
                        elif from_value > 10.0 and timeline_action == 'hold':
                            # For larger trades, require BUY signal, not just HOLD
                            timeline_gate_passed = False
                            if debug_first_scans:
                                print(f"         ðŸŒ€ TIMELINE GATE: {from_asset}â†’{to_asset} BLOCKED - timeline says HOLD for $${from_value:.2f} trade")
                        
                        # RULE 3: When TEMPORAL JUMP is active, BOOST confidence
                        elif timeline_jump_active and timeline_action in ['buy', 'convert']:
                            # We've JUMPED to the winning timeline - extra confidence!
                            combined *= 1.25  # 25% boost for being AHEAD of market
                            logger.debug(f"ðŸŒ€ TIMELINE JUMP BOOST: {from_asset}â†’{to_asset} +25% for being AHEAD!")
                    
                    if not timeline_gate_passed:
                        continue  # Skip - wrong timeline
                    
                    # ðŸ‘‘ðŸ”¢ QUEEN'S MATHEMATICAL CERTAINTY GATE - NO FEAR, MATH IS ON HER SIDE!
                    math_approved, math_reason, math_breakdown = self.barter_matrix.queen_math_gate(
                        from_asset, to_asset, amount, from_price, self.prices.get(to_asset, 0), source_exchange
                    )
                    if not math_approved:
                        # Skip this opportunity - Math doesn't guarantee profit
                        if debug_first_scans:
                            print(f"         ðŸš« MATH GATE BLOCKED: {from_asset}â†’{to_asset} | {math_reason}")
                        continue
                    
                    # âš¡ SPEED MODE: Accept ANY positive profit after costs!
                    # Update expected P/L based on REAL math (not theoretical)
                    real_cost_usd = math_breakdown['total_cost_usd']
                    
                    # Don't pad expected_pnl - use actual value, accept if positive after costs
                    adjusted_pnl = expected_pnl_usd - real_cost_usd

                    # Epsilon policy: trade only if net-positive after conservative costs
                    if adjusted_pnl < EPSILON_PROFIT_USD:
                        if debug_first_scans:
                            print(f"         ðŸš« NO NET PROFIT: {from_asset}â†’{to_asset} | net=${adjusted_pnl:.6f} < eps=${EPSILON_PROFIT_USD:.6f} (cost=${real_cost_usd:.6f})")
                        continue
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ðŸ‘‘ðŸŽ® QUEEN'S FINAL DECISION - SHE HAS ABSOLUTE AUTHORITY ðŸ‘‘ðŸŽ®
                    # All systems have spoken - NOW QUEEN DECIDES!
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    queen_final_approved = True
                    queen_veto_reason = ""
                    
                    if self.queen and hasattr(self, 'queen_has_full_control') and self.queen_has_full_control:
                        try:
                            # Gather all neural scores for Queen's final review
                            neural_summary = {
                                'from_asset': from_asset,
                                'to_asset': to_asset,
                                'amount': amount,
                                'value_usd': from_value,
                                'expected_pnl_usd': adjusted_pnl,
                                'expected_pnl_pct': expected_pnl_pct,
                                'combined_score': combined,
                                'neural_scores': {
                                    'v14': v14_score,
                                    'hub': hub_score,
                                    'lambda': lambda_t,
                                    'gravity': g_eff,
                                    'bus': bus_score,
                                    'hive': hive_score,
                                    'lighthouse': lighthouse_score,
                                    'ultimate': ultimate_score,
                                    'barter': barter_score,
                                    'luck': luck_score,
                                    'enigma': enigma_score,
                                    'wisdom': wisdom_engine_score,
                                    'timeline': timeline_score,
                                },
                                'exchange': source_exchange,
                                'math_approved': math_approved,
                                'math_cost': real_cost_usd,
                            }
                            
                            # QUEEN MAKES FINAL DECISION
                            if hasattr(self.queen, 'make_final_trade_decision'):
                                queen_decision = self.queen.make_final_trade_decision(neural_summary)
                                queen_final_approved = queen_decision.get('approved', True)
                                queen_veto_reason = queen_decision.get('reason', '')
                                
                                # Queen can OVERRIDE any system's decision!
                                if queen_decision.get('override_score'):
                                    combined = queen_decision['override_score']
                                    
                                # Queen can adjust expected P/L based on her wisdom
                                if queen_decision.get('adjusted_pnl'):
                                    adjusted_pnl = queen_decision['adjusted_pnl']
                            else:
                                # Fallback: Use Queen's guidance score as approval threshold
                                # If Queen gave low confidence (<0.3), she's vetoing
                                if queen_confidence > 0 and queen_guidance_score < 0.3:
                                    queen_final_approved = False
                                    queen_veto_reason = f"Queen confidence too low ({queen_guidance_score:.1%})"
                                    
                        except Exception as e:
                            logger.debug(f"Queen final decision error: {e}")
                    
                    if not queen_final_approved:
                        if debug_first_scans:
                            print(f"         ðŸ‘‘ðŸš« QUEEN VETO: {from_asset}â†’{to_asset} | {queen_veto_reason}")
                        continue
                    
                    opp = MicroOpportunity(
                        timestamp=time.time(),
                        from_asset=from_asset,
                        to_asset=to_asset,
                        from_amount=amount,
                        from_value_usd=from_value,
                        v14_score=v14_score,
                        hub_score=hub_score,
                        commando_score=commando_score,
                        combined_score=combined,
                        lambda_score=lambda_t,
                        gravity_score=g_eff,
                        gate_required_profit=gate_required,
                        gate_passed=gate_ok,
                        expected_pnl_usd=adjusted_pnl,  # Use REAL adjusted P/L
                        expected_pnl_pct=expected_pnl_pct,
                        # ðŸ§  Neural Mind Map Scores (Full Integration)
                        bus_score=bus_score,
                        hive_score=hive_score,
                        lighthouse_score=lighthouse_score,
                        ultimate_score=ultimate_score,
                        path_boost=path_boost,
                        # ðŸ“Š Trained Probability Matrix (626 symbols from ALL exchanges)
                        trained_matrix_score=trained_matrix_score,
                        trained_matrix_reason=matrix_reason,
                        # ðŸ«’ðŸ’° Live Barter Matrix (coin-agnostic adaptive learning)
                        barter_matrix_score=barter_score,
                        barter_matrix_reason=barter_reason,
                        # ðŸŒŸâš›ï¸ Luck Field (quantum probability mapping)
                        luck_score=luck_score,
                        luck_state=luck_state,
                        # ðŸ¦ Checkpoint flag (stablecoin target - secures compound)
                        is_checkpoint=is_checkpoint_target,
                        # ðŸŽ¯ Source exchange (for turn-based execution)
                        source_exchange=source_exchange,
                        # ðŸŒ€ TEMPORAL TIMELINE JUMP (AHEAD OF MARKET!)
                        timeline_score=timeline_score,
                        timeline_action=timeline_action or "",
                        temporal_jump_power=temporal_jump_power,
                        timeline_jump_active=timeline_jump_active,
                        # ðŸ”ðŸŒ ENIGMA INTEGRATION (ALL WHITEPAPER SYSTEMS!)
                        enigma_score=enigma_score,
                        enigma_direction=enigma_direction,
                        # ðŸ‘‘ðŸ’• QUEEN'S GUIDANCE
                        queen_guidance_score=queen_guidance_score,
                        queen_wisdom=queen_wisdom,
                        queen_confidence=queen_confidence,
                        # ðŸ§ ðŸ“š WISDOM ENGINE
                        wisdom_engine_score=wisdom_engine_score,
                        civilization_insight=civilization_insight,
                        wisdom_pattern=wisdom_pattern,
                        # ðŸ”®ðŸ“Š PROBABILITY NEXUS PREDICTION (For Queen's Neural Learning!)
                        nexus_probability=nexus_probability,
                        nexus_direction=nexus_direction,
                        nexus_factors=nexus_factors if nexus_factors else None,
                        nexus_confidence=nexus_confidence,
                    )
                    opportunities.append(opp)
                    self.opportunities_found += 1
                    
                    # Log math gate success
                    if debug_first_scans:
                        print(f"         âœ… MATH APPROVED: {from_asset}â†’{to_asset} | cost={math_breakdown['total_cost_pct']:.2%} | net=${adjusted_pnl:.4f}")
                    
                    # Log checkpoint opportunities specially
                    if is_checkpoint_target:
                        logger.info(f"ðŸ¦ CHECKPOINT OPPORTUNITY: {from_asset} â†’ {to_asset} (secure ${from_value:.2f})")
                        print(f"   ðŸ¦ CHECKPOINT: {from_asset} â†’ {to_asset} | Score: {combined:.2%} | Secure: ${from_value:.2f}")
            
            # Debug after scanning each asset
            if debug_first_scans and valid_pairs_found == 0:
                print(f"      âŒ No valid pairs found for {from_asset} ({pair_check_failures} pair checks failed)")
            elif debug_first_scans:
                print(f"      âœ… Found {valid_pairs_found} valid pairs for {from_asset}")
        
        # Debug log: Show summary
        if scanned_assets and self.scans <= 3:  # Only first few scans
            print(f"ðŸ“Š Scan #{self.scans}: Scanned {len(scanned_assets)} assets: {', '.join(scanned_assets)}")
            print(f"   ðŸ”® Opportunities found: {len(opportunities)}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒ€ TEMPORAL PRIORITY SORTING - AHEAD OF MARKET GETS PRIORITY!
        # "We don't react to the market - we MOVE before it does!"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Calculate temporal priority for each opportunity
        import time as _time
        now = _time.time()
        PRIME_SENTINEL_HZ = 2.111991  # Gary Leckey 02/11/1991
        temporal_cycle = now % (1.0 / PRIME_SENTINEL_HZ)
        temporal_alignment = 1.0 - (temporal_cycle * PRIME_SENTINEL_HZ)
        
        def get_temporal_priority(opp):
            """Calculate temporal priority score - higher = more ahead of market."""
            base_score = opp.combined_score * 0.5 + opp.barter_matrix_score * 0.3
            
            # Timeline boost: if oracle predicted BUY/CONVERT with high confidence
            timeline_boost = 0.0
            if hasattr(opp, 'timeline_score') and opp.timeline_score > 0.60:
                timeline_boost = opp.timeline_score * 0.2  # Up to +20%
            
            # Temporal alignment boost: higher when we're "in sync" with our Hz
            temporal_boost = temporal_alignment * 0.1  # Up to +10%
            
            # Profit priority (small weight - we're ahead, profit follows)
            profit_boost = min(0.1, opp.expected_pnl_usd / 10.0)  # Up to +10%
            
            return base_score + timeline_boost + temporal_boost + profit_boost
        
        opportunities.sort(key=get_temporal_priority, reverse=True)
        
        # Log if we have temporal jump opportunities
        if opportunities:
            top = opportunities[0]
            logger.debug(f"ðŸŒ€ Top opportunity: {top.from_asset}â†’{top.to_asset} "
                        f"(temporal_priority: {get_temporal_priority(top):.3f}, "
                        f"pnl: ${top.expected_pnl_usd:.4f})")
        
        return opportunities
    
    async def execute_conversion(self, opp: MicroOpportunity) -> bool:
        """Execute a conversion (dry run or live)."""
        symbol = f"{opp.from_asset}/{opp.to_asset}"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ï¿½ EVOLUTIONARY SAFETY GATES - "Don't Fear the Stone, Learn From It"
        # We don't block difficult trades (Meme->Meme, Stable->Stable)
        # We VALIDATE them with "True Cost" math. If it profits, we trade.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        from_upper = opp.from_asset.upper()
        to_upper = opp.to_asset.upper()
        
        # Check if source is a MEME
        is_from_meme = from_upper in self.barter_matrix.MEME_COINS
        # Check if target is a MEME
        is_to_meme = to_upper in self.barter_matrix.MEME_COINS
        # Check if target is a STABLECOIN
        is_to_stable = to_upper in ['USD', 'USDT', 'USDC', 'ZUSD', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD', 'EUR', 'ZEUR']
        # Check if source is a STABLECOIN
        is_from_stable = from_upper in ['USD', 'USDT', 'USDC', 'ZUSD', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD', 'EUR', 'ZEUR']
        
        # âš ï¸ WARNING: MEME â†’ MEME = High Cost!
        if is_from_meme and is_to_meme:
            # We already passed the gate check in the scan phase which used calculate_true_cost
            # That cost included a 1.5% volatility penalty + learned slippage
            # If we are here, the PROFIT >> COST. So we proceed!
            print(f"   âš ï¸ MEMEâ†’MEME ADVISORY: {from_upper}â†’{to_upper} is high risk! True Cost check passed.")

        # âš ï¸ WARNING: STABLECOIN â†’ STABLECOIN = Likely Loss!
        if is_from_stable and is_to_stable:
             # Usually blocked by cost > profit (0 gain). But if we have huge arbitrage...
             print(f"   âš ï¸ STABLEâ†’STABLE ADVISORY: {from_upper}â†’{to_upper} only makes sense if arbitrage > fees!")
             # No block - if calculate_true_cost allowed it, there must be profit (or arb)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ›‘ CRITICAL PRE-EXECUTION GATE: CONSERVATIVE PROFIT CHECK
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # This is the FINAL check BEFORE sending the order. We calculate profit
        # using PESSIMISTIC assumptions (NO momentum edge, REAL costs).
        # If we'd lose money, DON'T EXECUTE - even if Queen said yes.
        # Reason: Queen's decision was based on SPECULATIVE expected_pnl_usd.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.live:
            # Calculate TRUE costs using learned history
            approved, reason, cost_breakdown = self.barter_matrix.calculate_true_cost(
                opp.from_asset, opp.to_asset, opp.from_value_usd, opp.source_exchange or 'kraken'
            )
            
            total_cost_pct = cost_breakdown.get('total_cost_pct', 0.5) / 100.0  # Convert to decimal
            total_cost_usd = opp.from_value_usd * total_cost_pct
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ðŸ”§ FIX: TRUST THE SCANNER'S EXPECTED P&L!
            # The scanner already calculated expected_pnl_usd including momentum/signals.
            # We just need to verify: expected_profit > total_cost
            # OLD BUG: arbitrage_edge formula was ALWAYS = -cost (mathematical error)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            
            # The opportunity's expected_pnl_usd comes from the scanner (includes momentum, signals, etc.)
            scanner_expected_pnl = opp.expected_pnl_usd if hasattr(opp, 'expected_pnl_usd') else 0.0
            
            # SIMPLE GATE: Does expected profit exceed real costs?
            # Add a small buffer (25%) for safety
            cost_with_buffer = total_cost_usd * 1.25
            
            # Net profit after REAL costs
            conservative_pnl = scanner_expected_pnl - total_cost_usd
            
            # Apply path history penalty (learned failures)
            pair_key = (from_upper, to_upper)
            # ðŸŒâœ¨ PLANET SAVER: The past doesn't define the future!
            # We learn from history but don't let it chain us down
            if hasattr(self.barter_matrix, 'barter_history') and pair_key in self.barter_matrix.barter_history:
                hist = self.barter_matrix.barter_history.get(pair_key, {})
                if hist.get('total_profit', 0) < 0 and hist.get('trades', 0) > 5:  # Only after 5+ failures
                    # Path historically loses - add small penalty (learn but don't block!)
                    historical_loss_rate = abs(hist['total_profit']) / max(hist.get('trades', 1), 1)
                    conservative_pnl -= historical_loss_rate * 0.1  # Only 10% of historical avg loss
            
            # FINAL GATE: Block if expected profit doesn't cover costs with buffer
            # OR if spread is ridiculously high (>5%)
            spread_pct = cost_breakdown.get('spread', 0)
            
            if spread_pct > 5.0:
                # High spread = illiquid market, block immediately
                self.rejection_print(f"\n   ðŸ›‘ PRE-EXECUTION GATE: SPREAD TOO HIGH!")
                self.rejection_print(f"   â”œâ”€â”€ Spread: {spread_pct:.1f}% (max 5%)")
                self.rejection_print(f"   â””â”€â”€ Market too illiquid for this trade")
                
                # Block high spread source
                exchange = opp.source_exchange or 'unknown'
                key = (opp.from_asset.upper(), exchange.lower())
                self.barter_matrix.high_spread_sources[key] = {
                    'spread': spread_pct,
                    'blocked_turn': self.barter_matrix.current_turn,
                    'reason': f'{spread_pct:.1f}% spread'
                }
                self.rejection_print(f"   ðŸš«ðŸ”´ SOURCE BLOCKED: {opp.from_asset} on {exchange} has {spread_pct:.1f}% spread!")
                
                # Record rejection
                self.barter_matrix.record_preexec_rejection(
                    opp.from_asset, opp.to_asset,
                    f'spread_too_high: {spread_pct:.1f}%',
                    opp.from_value_usd
                )
                return None
            
            # ðŸŒâœ¨ PLANET SAVER MODE: Past doesn't define future!
            # Allow trades if scanner expects profit - trust the quantum mirror!
            planet_saver_mode = hasattr(self, 'planet_saver') and self.planet_saver is not None
            
            if conservative_pnl < -0.01 and not planet_saver_mode:  # Only block if clearly losing > $0.01
                self.rejection_print(f"\n   ðŸ›‘ PRE-EXECUTION GATE BLOCKED!")
                self.rejection_print(f"   â”œâ”€â”€ Scanner Expected: ${scanner_expected_pnl:+.4f}")
                self.rejection_print(f"   â”œâ”€â”€ Total Costs: ${total_cost_usd:.4f} ({total_cost_pct*100:.2f}%)")
                self.rejection_print(f"   â”œâ”€â”€ Cost breakdown: fee={cost_breakdown.get('base_fee', 0):.2f}% spread={spread_pct:.2f}% slip={cost_breakdown.get('learned_slippage', 0):.2f}%")
                self.rejection_print(f"   â”œâ”€â”€ Net P&L: ${conservative_pnl:+.4f}")
                self.rejection_print(f"   â””â”€â”€ Reason: Expected profit doesn't cover costs")
                self.rejection_print(f"   â›” TRADE REJECTED - Protecting your capital!")
                
                # Track rejection for learning - BLOCK THIS PAIR immediately!
                self.barter_matrix.record_preexec_rejection(
                    opp.from_asset, opp.to_asset,
                    f'cost_exceeds_profit: ${total_cost_usd:.4f} > ${scanner_expected_pnl:.4f}',
                    opp.from_value_usd
                )
                self.rejection_print(f"   ðŸš« Path {opp.from_asset}â†’{opp.to_asset} BLOCKED - will try others!")
                
                # ðŸš« HIGH SPREAD SOURCE BLOCK - If spread is the problem, block ALL trades from this source!
                if spread_pct > self.barter_matrix.HIGH_SPREAD_THRESHOLD:
                    exchange = opp.source_exchange or 'unknown'
                    key = (opp.from_asset.upper(), exchange.lower())
                    self.barter_matrix.high_spread_sources[key] = {
                        'spread': spread_pct,
                        'blocked_turn': self.barter_matrix.current_turn,
                        'reason': f'{spread_pct:.1f}% spread'
                    }
                    self.rejection_print(f"   ðŸš«ðŸ”´ SOURCE BLOCKED: {opp.from_asset} on {exchange} has {spread_pct:.1f}% spread!")
                    self.rejection_print(f"      ALL {opp.from_asset}â†’* trades will fail - blocking source for {self.barter_matrix.HIGH_SPREAD_COOLDOWN} turns")
                
                return False
            else:
                # âœ… GATE PASSED! Show the good news!
                print(f"\n   âœ… PRE-EXECUTION GATE PASSED:")
                print(f"   â”œâ”€â”€ Scanner Expected: ${scanner_expected_pnl:+.4f}")
                print(f"   â”œâ”€â”€ Total Costs: ${total_cost_usd:.4f} ({total_cost_pct*100:.2f}%)")
                print(f"   â”œâ”€â”€ Net P&L: ${conservative_pnl:+.4f}")
                print(f"   â””â”€â”€ Proceeding with execution... ðŸš€")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # ðŸ‘‘ QUEEN HAS ALREADY SPOKEN - No second-guessing her!
        # The Queen was consulted in execute_turn() and said YES
        # Her $0.003 profit goal was already validated
        # DO NOT block her decision with another gate!
        
        print(f"\nðŸ”¬ MICRO CONVERSION:")
        print(f"   {opp.from_asset} â†’ {opp.to_asset}")
        print(f"   Amount: {opp.from_amount:.6f} ({opp.from_asset})")
        print(f"   Value: ${opp.from_value_usd:.2f}")
        print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        # ðŸŒ€ TEMPORAL JUMP STATUS - Are we AHEAD of the market?
        if opp.timeline_jump_active:
            print(f"   ðŸŒ€ TEMPORAL JUMP ACTIVE! â³ AHEAD OF MARKET!")
            print(f"   â³ Jump Power: {opp.temporal_jump_power:.2%} | Timeline: {opp.timeline_action.upper()}")
            print(f"   ðŸ”® Timeline Confidence: {opp.timeline_score:.2%}")
        elif opp.timeline_score > 0:
            print(f"   â³ Timeline: {opp.timeline_action.upper()} @ {opp.timeline_score:.2%} (Jump Power: {opp.temporal_jump_power:.2%})")
        
        print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"   ðŸ§  NEURAL MIND MAP SCORES:")
        print(f"   V14: {opp.v14_score:.1f} | Hub: {opp.hub_score:.2%}")
        print(f"   Î› (Lambda): {opp.lambda_score:.2%} | G (Gravity): {opp.gravity_score:.2%}")
        print(f"   Bus: {opp.bus_score:.2%} | Hive: {opp.hive_score:.2%} | Lighthouse: {opp.lighthouse_score:.2%}")
        print(f"   Ultimate: {opp.ultimate_score:.2%} | Path: {opp.path_boost:+.2%}")
        print(f"   ðŸ«’ Barter: {opp.barter_matrix_score:.2%} ({opp.barter_matrix_reason})")
        print(f"   ðŸ€ Luck: {opp.luck_score:.2%} ({opp.luck_state})")
        print(f"   ðŸ” Enigma: {opp.enigma_score:+.2%} ({opp.enigma_direction})")
        if opp.queen_guidance_score != 0.0:
            print(f"   ðŸ‘‘ Queen: {opp.queen_guidance_score:.2%} (confidence: {opp.queen_confidence:.2%})")
            if opp.queen_wisdom:
                print(f"      ðŸ’• \"{opp.queen_wisdom[:70]}...\"")
        if opp.wisdom_engine_score != 0.0:
            print(f"   ðŸ§  Wisdom: {opp.wisdom_engine_score:.2%} ({opp.civilization_insight})")
            if opp.wisdom_pattern:
                print(f"      ðŸ“š \"{opp.wisdom_pattern[:70]}...\"")
        print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•=")
        print(f"   ðŸ”® Combined: {opp.combined_score:.2%}")
        print(f"   Gate Req: ${opp.gate_required_profit:.4f} | Gate OK: {'âœ…' if opp.gate_passed else 'âŒ'}")
        print(f"   Expected Profit: ${opp.expected_pnl_usd:.4f} ({opp.expected_pnl_pct:.2%})")
        
        # Publish to ThoughtBus for ecosystem awareness
        if self.bus_aggregator and hasattr(self.bus_aggregator, 'bus') and self.bus_aggregator.bus:
            try:
                self.bus_aggregator.bus.publish('execution.alert', {
                    'type': 'micro_conversion',
                    'from_asset': opp.from_asset,
                    'to_asset': opp.to_asset,
                    'value_usd': opp.from_value_usd,
                    'combined_score': opp.combined_score,
                    'lambda_score': opp.lambda_score,
                    'gravity_score': opp.gravity_score,
                    'bus_score': opp.bus_score,
                    'hive_score': opp.hive_score,
                    'lighthouse_score': opp.lighthouse_score,
                    'ultimate_score': opp.ultimate_score,
                    'path_boost': opp.path_boost,
                    'expected_pnl': opp.expected_pnl_usd,
                    'timestamp': time.time(),
                    'live': self.live
                })
            except Exception as e:
                logger.debug(f"ThoughtBus publish error: {e}")
        
        if not self.live:
            print(f"   ðŸ”µ DRY RUN - Not executed")
            opp.executed = True
            opp.actual_pnl_usd = opp.expected_pnl_usd  # Simulate
            self.conversions_made += 1
            self.total_profit_usd += opp.expected_pnl_usd
            self.conversions.append(opp)
            return True
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ”´ LIVE EXECUTION - ROUTE TO CORRECT EXCHANGE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ QUEEN MIND ROUTING: Strictly use the source_exchange from the opportunity
        source_exchange = opp.source_exchange
        
        # Fallback if not set (should not happen with new logic)
        if not source_exchange:
            print(f"   âš ï¸ Opportunity missing source_exchange - attempting lookup...")
            source_exchange = self._find_asset_exchange(opp.from_asset)
            if source_exchange:
                print(f"   ðŸ“ Fallback located {opp.from_asset} on {source_exchange}")
                opp.source_exchange = source_exchange
        
        if not source_exchange:
            print(f"   âš ï¸ Asset {opp.from_asset} not found on any exchange")
            return False
        
        print(f"   ðŸ”´ LIVE MODE - Executing on {source_exchange.upper()}...")
        
        # ðŸ‡®ðŸ‡ªðŸŽ¯ IRA SNIPER EXECUTION - Celtic precision
        try:
            from ira_sniper_mode import get_celtic_sniper, IraCelticSniper
            sniper = get_celtic_sniper(dry_run=False)
            
            # Validate entry with Celtic intelligence
            validation = sniper.validate_entry(
                symbol=f"{opp.from_asset}/{opp.to_asset}",
                price=self.prices.get(opp.from_asset, 0),
                coherence=opp.combined_score
            )
            
            if validation.get('approved', True):
                print(f"   ðŸ‡®ðŸ‡ª Celtic Intelligence APPROVES")
                print(f"      Quick Kill Prob: {validation.get('quick_kill_prob', 0.5)*100:.1f}%")
                print(f"      Intel Score: {validation.get('intelligence_score', 0.5):.2f}")
            else:
                print(f"   âš ï¸ Celtic Intel rejects: {validation.get('reason', 'Unknown')}")
                # Still execute - sniper just provides intel, doesn't block
        except ImportError:
            pass  # IRA Sniper not available - continue silently
        except Exception as e:
            logger.debug(f"Sniper validation error: {e}")
        
        # ðŸ‘‘ QUEEN MIND ROUTING: Strictly use the source_exchange from the opportunity
        # This prevents cross-exchange routing errors
        source_exchange = opp.source_exchange
        
        # CRITICAL: Validate we have the source exchange set
        if not source_exchange:
            print(f"   âš ï¸ CRITICAL: Opportunity missing source_exchange!")
            print(f"   âš ï¸ This should NOT happen - check find_opportunities logic")
            # Last resort fallback - but log it clearly
            source_exchange = self._find_asset_exchange(opp.from_asset)
            if source_exchange:
                print(f"   ðŸ“ Fallback located {opp.from_asset} on {source_exchange}")
                opp.source_exchange = source_exchange  # Update for future reference
            else:
                print(f"   âŒ Cannot find {opp.from_asset} on any exchange!")
                self._record_failure(opp)
                return False
        
        # ðŸ‘‘ TURN-BASED TRUST: DO NOT OVERRIDE source_exchange!
        # The turn-based system ensures opportunities are found on the CORRECT exchange.
        # Overriding to "highest balance" causes cross-exchange routing errors
        # (e.g., Kraken's USD opportunity being sent to Alpaca)
        # 
        # REMOVED THE OVERRIDE - trust the turn-based system!
        
        # Route to appropriate exchange
        if source_exchange == 'kraken' and self.kraken and KRAKEN_API_KEY:
            return await self._execute_on_kraken(opp)
        elif source_exchange == 'binance' and self.binance and BINANCE_API_KEY:
            return await self._execute_on_binance(opp)
        elif source_exchange == 'alpaca' and self.alpaca and ALPACA_API_KEY:
            return await self._execute_on_alpaca(opp)
        else:
            print(f"   âš ï¸ Exchange '{source_exchange}' not available or missing API key")
            self._record_failure(opp)
        
        return False
    
    def _find_asset_exchange(self, asset: str) -> Optional[str]:
        """Find which exchange holds an asset with the highest balance."""
        asset_upper = asset.upper()
        best_exchange = None
        best_balance = 0
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ—ºï¸ UNIVERSAL CRYPTO NORMALIZER - Maps ALL 18,000+ Cryptos!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Sources: crypto_market_map.py, get-user-balances/index.ts, kraken_client.py
        
        # ðŸ™ KRAKEN ASSET MAP - Complete mapping for Kraken's unique naming
        KRAKEN_ASSET_MAP = {
            # Major cryptos with X prefix
            'XXBT': 'BTC', 'XBT': 'BTC',
            'XETH': 'ETH',
            'XXLM': 'XLM',
            'XLTC': 'LTC',
            'XXRP': 'XRP',
            'XXDG': 'DOGE', 'XDOGE': 'DOGE',
            'XZEC': 'ZEC',
            'XREP': 'REP',
            'XETC': 'ETC',
            'XMLN': 'MLN',
            'XXMR': 'XMR',
            'XICN': 'ICN',
            'XNMC': 'NMC',
            'XVEN': 'VEN',
            'XDAO': 'DAO',
            # Fiat with Z prefix
            'ZUSD': 'USD', 'USD': 'USD',
            'ZEUR': 'EUR', 'EUR': 'EUR', 
            'ZGBP': 'GBP', 'GBP': 'GBP',
            'ZCAD': 'CAD', 'CAD': 'CAD',
            'ZJPY': 'JPY', 'JPY': 'JPY',
            'ZAUD': 'AUD', 'AUD': 'AUD',
            'ZCHF': 'CHF', 'CHF': 'CHF',
            # Common stablecoins (no change needed)
            'USDT': 'USDT',
            'USDC': 'USDC',
            'DAI': 'DAI',
            'TUSD': 'TUSD',  # ðŸ”’ TUSD â‰  USDT!
            # Staked variants â†’ base asset
            'ETH2.S': 'ETH', 'ETH2': 'ETH',
            'DOT.S': 'DOT', 'DOT28.S': 'DOT',
            'ATOM.S': 'ATOM', 'ATOM21.S': 'ATOM',
            'SOL.S': 'SOL',
            'KAVA.S': 'KAVA',
            'XTZ.S': 'XTZ',
            'ADA.S': 'ADA',
            'FLOW.S': 'FLOW',
            'KSM.S': 'KSM',
            'MINA.S': 'MINA',
            'SCRT.S': 'SCRT',
            'GRT.S': 'GRT',
            'MATIC.S': 'MATIC',
            'TRX.S': 'TRX',
            'NEAR.S': 'NEAR',
            'BABY.S': 'BABY',
            'OMG.S': 'OMG',
        }
        
        # ðŸ”’ STABLECOIN ISOLATION - NEVER fuzzy match these to each other!
        # Each is a DIFFERENT asset with different backing/risk
        STABLECOINS_ISOLATED = {
            # USD-pegged (different issuers!)
            'USDT',   # Tether Limited (controversial reserves)
            'USDC',   # Circle/Coinbase (fully audited)
            'TUSD',   # TrustToken (independently verified)
            'BUSD',   # Paxos/Binance (deprecated)
            'USDP',   # Paxos Dollar (regulated)
            'GUSD',   # Gemini (NY regulated)
            'FRAX',   # Algorithmic + collateral hybrid
            'LUSD',   # Liquity (decentralized)
            'DAI',    # MakerDAO (crypto-collateralized)
            'MIM',    # Abracadabra (defi)
            'SUSD',   # Synthetix (synthetic)
            'USDD',   # TRON (algo)
            'PYUSD',  # PayPal (new)
            'FDUSD',  # First Digital (HK)
            # EUR-pegged
            'EURC',   # Circle EUR
            'EURT',   # Tether EUR
            'EURS',   # STASIS EUR
            'AGEUR',  # Angle EUR
            # Fiat (NOT stablecoins but isolated)
            'USD', 'EUR', 'GBP', 'CAD', 'JPY', 'AUD', 'CHF', 
            'ZUSD', 'ZEUR', 'ZGBP', 'ZCAD', 'ZJPY', 'ZAUD', 'ZCHF',
        }
        
        # ðŸŸ¡ BINANCE ASSET MAP (for weird naming)
        BINANCE_ASSET_MAP = {
            'IOTA': 'MIOTA',  # Binance uses IOTA, others use MIOTA
            'YFIDOWN': 'YFI', 'YFIUP': 'YFI',  # Leveraged tokens
            'BTCDOWN': 'BTC', 'BTCUP': 'BTC',
            'ETHDOWN': 'ETH', 'ETHUP': 'ETH',
        }
        
        # ðŸ¦™ ALPACA ASSET MAP (crypto pairs end in /USD)
        ALPACA_PAIRS_TO_BASE = {
            # These are position symbols, not assets
            'BTCUSD': 'BTC', 'BTC/USD': 'BTC',
            'ETHUSD': 'ETH', 'ETH/USD': 'ETH',
            'SOLUSD': 'SOL', 'SOL/USD': 'SOL',
            'DOGEUSD': 'DOGE', 'DOGE/USD': 'DOGE',
            'SHIBUSD': 'SHIB', 'SHIB/USD': 'SHIB',
            'AVAXUSD': 'AVAX', 'AVAX/USD': 'AVAX',
            'USDTUSD': 'USDT', 'USDT/USD': 'USDT',
        }
        
        def normalize_asset(asset_name: str, exchange: str = None) -> str:
            """
            ðŸ—ºï¸ UNIVERSAL NORMALIZER - Works across ALL exchanges!
            Converts exchange-specific naming to canonical symbol.
            """
            upper = asset_name.upper().strip()
            
            # Handle staked suffix first (ETH2.S â†’ ETH)
            unstaked = upper.replace('.S', '').replace('2.S', '')
            
            # Exchange-specific normalization
            if exchange == 'kraken':
                if upper in KRAKEN_ASSET_MAP:
                    return KRAKEN_ASSET_MAP[upper]
                if unstaked in KRAKEN_ASSET_MAP:
                    return KRAKEN_ASSET_MAP[unstaked]
                # Handle XX prefix (XXABC â†’ ABC)
                if upper.startswith('XX') and len(upper) > 2:
                    return upper[2:]
                # Handle single X prefix (but preserve XRP, XLM, XTZ, XMR, XDC)
                if upper.startswith('X') and len(upper) > 1:
                    if upper not in {'XRP', 'XLM', 'XTZ', 'XMR', 'XDC', 'XDG', 'XEM', 'XVG'}:
                        return upper[1:]
                # Handle Z prefix for fiat
                if upper.startswith('Z') and len(upper) > 1:
                    return upper[1:]
                    
            elif exchange == 'binance':
                if upper in BINANCE_ASSET_MAP:
                    return BINANCE_ASSET_MAP[upper]
                # Handle leveraged token suffixes
                for suffix in ['UP', 'DOWN', 'BULL', 'BEAR', '3L', '3S']:
                    if upper.endswith(suffix) and len(upper) > len(suffix):
                        return upper[:-len(suffix)]
                        
            elif exchange == 'alpaca':
                if upper in ALPACA_PAIRS_TO_BASE:
                    return ALPACA_PAIRS_TO_BASE[upper]
                # Strip /USD or USD suffix
                if upper.endswith('/USD'):
                    return upper[:-4]
                if upper.endswith('USD') and len(upper) > 3:
                    base = upper[:-3]
                    # Make sure we're not stripping from a stablecoin
                    if base not in STABLECOINS_ISOLATED:
                        return base
            
            return upper
        
        # Debug: Track candidates
        candidates = []
        
        for exchange, data in self.exchange_data.items():
            if data.get('connected') and data.get('balances'):
                for bal_asset, balance in data['balances'].items():
                    bal_upper = bal_asset.upper()
                    
                    # ðŸ—ºï¸ Normalize both the search asset AND the balance asset
                    normalized_bal = normalize_asset(bal_upper, exchange)
                    normalized_search = normalize_asset(asset_upper, exchange)
                    
                    # Exact match first (always preferred)
                    if normalized_bal == normalized_search or bal_upper == asset_upper:
                        bal_amount = float(balance) if isinstance(balance, (int, float, str)) else 0
                        if bal_upper != normalized_bal:
                            candidates.append(f"{exchange}:{bal_asset}â†’{normalized_bal}={bal_amount:.6f}")
                        else:
                            candidates.append(f"{exchange}:{bal_asset}={bal_amount:.6f}")
                        if bal_amount > best_balance:
                            best_balance = bal_amount
                            best_exchange = exchange
                            
                    # ðŸ”’ STABLECOIN GUARD: NEVER fuzzy match stablecoins!
                    # USDT â‰  TUSD â‰  USDC - they are DIFFERENT assets with different risks!
                    elif normalized_search in STABLECOINS_ISOLATED or normalized_bal in STABLECOINS_ISOLATED:
                        # Only exact matches for stablecoins - skip ALL fuzzy logic
                        continue
        
        # ðŸ”‡ Only print asset location once per asset (prevent spam)
        if len(candidates) > 1 and asset.upper() not in ['USD', 'USDT', 'USDC', 'ZUSD']:
            if not hasattr(self, '_asset_location_logged'):
                self._asset_location_logged = set()
            if asset.upper() not in self._asset_location_logged:
                self._asset_location_logged.add(asset.upper())
                print(f"   ðŸ”Ž Asset location: {asset} on {len(candidates)} exchanges -> Best: {best_exchange}")
            
        return best_exchange
    
    async def _execute_on_kraken(self, opp) -> bool:
        """Execute conversion on Kraken using convert_crypto."""
        try:
            # Use the built-in convert_crypto which finds the best path automatically!
            print(f"   ðŸ”„ Converting {opp.from_asset} â†’ {opp.to_asset} via Kraken...")
            
            # ðŸ‘‘ QUEEN MIND: Decode conversion path in real-time
            # Refresh balance FIRST to get accurate amounts
            await self.refresh_exchange_balances('kraken')
            
            # ðŸ‘‘ SERO FIX: Case-insensitive asset matching (Kraken may store differently)
            kraken_balances = self.exchange_balances.get('kraken', {})
            actual_balance = 0.0
            matched_asset = opp.from_asset
            
            for bal_key, bal_val in kraken_balances.items():
                if bal_key.upper() == opp.from_asset.upper():
                    actual_balance = float(bal_val) if isinstance(bal_val, (int, float, str)) else 0.0
                    matched_asset = bal_key
                    break
            
            print(f"   ðŸ“Š Kraken {matched_asset} balance: {actual_balance:.6f} (need: {opp.from_amount:.6f})")
            
            # Clamp to actual available balance
            if actual_balance <= 0:
                print(f"   âš ï¸ No {opp.from_asset} balance on Kraken (balance: {actual_balance})")
                return False
            
            # ðŸ‘‘ QUEEN'S SANITY CHECK: Don't clamp to dust!
            # If we have significantly less than expected, it's likely the wrong exchange
            if actual_balance < opp.from_amount * 0.1:
                print(f"   âš ï¸ Kraken balance {actual_balance:.6f} is < 10% of expected {opp.from_amount:.6f}")
                print(f"   âš ï¸ Likely asset location mismatch. Aborting Kraken execution.")
                return False

            # ðŸ‘‘ SERO EXECUTION FIX: Use 95% of balance for safety margin
            # Kraken has precision issues, leave 5% buffer for fees + rounding
            safe_amount = actual_balance * 0.95
            if opp.from_amount > safe_amount:
                print(f"   ðŸ‘‘ Sero adjusts: {opp.from_amount:.6f} â†’ {safe_amount:.6f} (95% safe)")
                opp.from_amount = safe_amount
                opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
            
            # Check if clamped amount is too small
            if opp.from_value_usd < 1.0:
                print(f"   âš ï¸ Clamped value ${opp.from_value_usd:.2f} is too small for Kraken (min ~$1.50)")
                
                # ðŸ’§ðŸ”€ LIQUIDITY AGGREGATION CHECK - Can we top-up from other assets?
                shortfall = 1.50 - opp.from_value_usd
                aggregation_result = await self._attempt_liquidity_aggregation(
                    target_asset=opp.from_asset,
                    target_exchange='kraken',
                    shortfall_usd=shortfall,
                    expected_profit_pct=getattr(opp, 'expected_profit', 0.01),
                )
                if aggregation_result:
                    # Aggregation succeeded - retry the trade with new balance
                    await self.refresh_exchange_balances('kraken')
                    new_balance = self.exchange_balances.get('kraken', {}).get(opp.from_asset, 0)
                    opp.from_amount = float(new_balance) * 0.95
                    opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
                    print(f"   ðŸ’§ POST-AGGREGATION: New {opp.from_asset} balance = {opp.from_amount:.6f} (${opp.from_value_usd:.2f})")
                    if opp.from_value_usd >= 1.50:
                        print(f"   âœ… Aggregation successful! Proceeding with trade...")
                        # Continue execution - don't return False
                    else:
                        print(f"   âŒ Aggregation insufficient - still below minimum")
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset, 
                            f"Value ${opp.from_value_usd:.2f} < ~$1.50 after aggregation",
                            opp.from_value_usd
                        )
                        self.barter_matrix.record_source_rejection(
                            opp.from_asset, 'kraken', 1.50, opp.from_value_usd
                        )
                        return False
                else:
                    # ðŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Value ${opp.from_value_usd:.2f} < ~$1.50 Kraken minimum (no aggregation available)",
                        opp.from_value_usd
                    )
                    # ðŸš« Also record SOURCE rejection - this asset is too small for Kraken entirely
                    self.barter_matrix.record_source_rejection(
                        opp.from_asset, 'kraken', 1.50, opp.from_value_usd
                    )
                    return False
            
            # First check if a path exists
            path = self.kraken.find_conversion_path(opp.from_asset, opp.to_asset)
            if not path:
                print(f"   âš ï¸ No conversion path found from {opp.from_asset} to {opp.to_asset}")
                return False
            
            # ðŸ” KRAKEN PRE-FLIGHT CHECK: Only check notional minimum (most reliable)
            # Kraken's costmin is the minimum order value in USD-equivalent
            for step in path:
                pair = step.get('pair', '')
                filters = self.kraken.get_symbol_filters(pair)
                min_notional = filters.get('min_notional', 0)  # costmin in Kraken terms
                min_qty = filters.get('min_qty', 0) or filters.get('min_volume', 0)
                
                # Check minimum notional value - Kraken typically requires ~$0.50 minimum
                # Use a safe default of $1.20 to avoid "volume too low" errors (Kraken often requires >1 EUR/USD)
                effective_min = max(min_notional, 1.20)
                if opp.from_value_usd < effective_min:
                    print(f"   âš ï¸ Value ${opp.from_value_usd:.2f} < min notional ${effective_min:.2f} for {pair}")
                    print(f"   ðŸ’¡ Need ${effective_min:.2f} minimum to trade on Kraken")
                    return False

                # Guard on base quantity to avoid volume_minimum errors
                if min_qty:
                    # Use the from-asset price as a rough base valuation
                    from_price = self.prices.get(opp.from_asset, 0) or 1.0
                    min_qty_needed = max(min_qty, 0.0)
                    if opp.from_amount < min_qty_needed:
                        needed_usd = min_qty_needed * from_price
                        print(f"   âš ï¸ Amount {opp.from_amount:.6f} < Kraken min qty {min_qty_needed:.6f} for {pair}")
                        print(f"   ðŸ’¡ Need â‰¥ {min_qty_needed:.6f} ({needed_usd:.2f} USD) to avoid volume_minimum")
                        # ðŸš« Record pre-execution rejection
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset, 
                            f"Amount {opp.from_amount:.6f} < min_qty {min_qty_needed:.6f}",
                            opp.from_value_usd
                        )
                        return False
            
            # Show the path
            for step in path:
                print(f"   ðŸ“ Path: {step['description']} via {step['pair']}")
            
            # Execute the conversion
            result = self.kraken.convert_crypto(
                from_asset=opp.from_asset,
                to_asset=opp.to_asset,
                amount=opp.from_amount
            )
            
            if result.get('error'):
                error_msg = str(result['error'])
                print(f"   âŒ Conversion error: {error_msg}")
                
                # ðŸ‘‘ QUEEN LEARNING: Auto-fix minimums
                if "volume_minimum" in error_msg or "min_notional" in error_msg:
                    print(f"   ðŸ‘‘ Queen learning: Increasing minimum for {opp.from_asset}")
                    # Increase minimum to 1.5x current amount or at least $10
                    current_price = self.prices.get(opp.from_asset, 1.0)
                    min_usd_req = 10.0 # Safe default
                    
                    # If we know the amount that failed, we should aim higher
                    new_min_qty = max(opp.from_amount * 1.5, min_usd_req / current_price if current_price > 0 else 0)
                    
                    self.dynamic_min_qty[opp.from_asset.upper()] = new_min_qty
                    print(f"      Updated dynamic minimum for {opp.from_asset} to {new_min_qty:.6f}")
                    
                self._record_failure(opp)
                return False
            
            # Check results
            trades = result.get('trades', [])
            if isinstance(trades, list):
                success_count = sum(1 for t in trades if isinstance(t, dict) and t.get('status') == 'success')
                if success_count > 0:
                    # Calculate actual bought/received amount from the last trade
                    last_trade = trades[-1]
                    buy_amount = 0.0
                    if last_trade.get('status') == 'success':
                        res = last_trade.get('result', {})
                        # PRIORITY: Use receivedQty (for SELL orders) if available
                        # This is the ACTUAL amount we received after conversion
                        buy_amount = float(res.get('receivedQty', 0) or 
                                          last_trade.get('receivedQty', 0) or
                                          res.get('executedQty', 0.0))
                    
                    # Fallback if no amount found (e.g. dry run or error)
                    if buy_amount == 0.0:
                         # Estimate based on price
                         to_price = self.prices.get(opp.to_asset, 0)
                         if to_price > 0:
                             buy_amount = opp.from_value_usd / to_price
                    
                    print(f"   âœ… Conversion complete! {success_count} trades executed. Bought {buy_amount:.6f} {opp.to_asset}")
                    
                    # ðŸ” VALIDATE ORDER EXECUTION
                    validation = self._validate_order_execution(trades, opp, 'kraken')
                    verification = self._verify_profit_math(validation, opp, buy_amount)
                    self._print_order_validation(validation, verification, opp)
                    
                    self._record_conversion(opp, buy_amount, validation, verification)
                    return True
                else:
                    print(f"   âŒ No successful trades in conversion")
                    self._record_failure(opp)
            elif result.get('dryRun'):
                print(f"   ðŸ”µ DRY RUN: Would convert via {len(path)} trades")
                return True
            else:
                print(f"   âœ… Conversion result: {result}")
                # Estimate amount for non-standard result
                to_price = self.prices.get(opp.to_asset, 0)
                buy_amount = opp.from_value_usd / to_price if to_price > 0 else 0
                self._record_conversion(opp, buy_amount)
                return True
                
        except Exception as e:
            logger.error(f"âŒ Kraken conversion error: {e}")
            print(f"   âŒ Error: {e}")
            self._record_failure(opp)
        return False
    
    async def _execute_on_binance(self, opp) -> bool:
        """Execute conversion on Binance."""
        try:
            print(f"   ðŸ”„ Converting {opp.from_asset} â†’ {opp.to_asset} via Binance...")
            
            # ðŸ‘‘ QUEEN MIND: Decode conversion path in real-time
            # Refresh balance FIRST to get accurate amounts
            await self.refresh_exchange_balances('binance')
            
            # Look for asset with different casing/formats
            binance_balances = self.exchange_balances.get('binance', {})
            actual_balance = 0.0
            matched_asset = opp.from_asset
            
            for bal_key, bal_val in binance_balances.items():
                if bal_key.upper() == opp.from_asset.upper():
                    actual_balance = float(bal_val) if isinstance(bal_val, (int, float, str)) else 0.0
                    matched_asset = bal_key
                    break
            
            print(f"   ðŸ“Š Binance {matched_asset} balance: {actual_balance:.6f} (need: {opp.from_amount:.6f})")
            
            # Clamp to actual available balance with extra safety margin for fees
            if actual_balance <= 0:
                print(f"   âš ï¸ No {opp.from_asset} balance on Binance (balance: {actual_balance})")
                return False
            
            # ðŸ‘‘ QUEEN'S SANITY CHECK: Don't clamp to dust!
            if actual_balance < opp.from_amount * 0.1:
                print(f"   âš ï¸ Binance balance {actual_balance:.6f} is < 10% of expected {opp.from_amount:.6f}")
                print(f"   âš ï¸ Likely asset location mismatch. Aborting Binance execution.")
                return False

            # Use 98% of balance instead of 99.5% for extra safety on Binance
            safe_amount = actual_balance * 0.98
            if opp.from_amount > safe_amount:
                print(f"   ðŸ‘‘ Queen clamping: {opp.from_amount:.6f} â†’ {safe_amount:.6f}")
                opp.from_amount = safe_amount
                opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
            
            # Check if clamped amount is too small
            if opp.from_value_usd < 5.0:
                print(f"   âš ï¸ Clamped value ${opp.from_value_usd:.2f} is too small for Binance (min $5.00)")
                
                # ðŸ’§ðŸ”€ LIQUIDITY AGGREGATION CHECK - Can we top-up from other assets?
                shortfall = 5.0 - opp.from_value_usd
                aggregation_result = await self._attempt_liquidity_aggregation(
                    target_asset=opp.from_asset,
                    target_exchange='binance',
                    shortfall_usd=shortfall,
                    expected_profit_pct=getattr(opp, 'expected_profit', 0.01),
                )
                if aggregation_result:
                    # Aggregation succeeded - retry the trade with new balance
                    await self.refresh_exchange_balances('binance')
                    new_balance = self.exchange_balances.get('binance', {}).get(opp.from_asset, 0)
                    opp.from_amount = float(new_balance) * 0.98
                    opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
                    print(f"   ðŸ’§ POST-AGGREGATION: New {opp.from_asset} balance = {opp.from_amount:.6f} (${opp.from_value_usd:.2f})")
                    if opp.from_value_usd >= 5.0:
                        print(f"   âœ… Aggregation successful! Proceeding with trade...")
                        # Continue execution - don't return False
                    else:
                        print(f"   âŒ Aggregation insufficient - still below minimum")
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset, 
                            f"Value ${opp.from_value_usd:.2f} < $5.00 after aggregation",
                            opp.from_value_usd
                        )
                        self.barter_matrix.record_source_rejection(
                            opp.from_asset, 'binance', 5.0, opp.from_value_usd
                        )
                        return False
                else:
                    # ðŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Value ${opp.from_value_usd:.2f} < $5.00 Binance minimum (no aggregation available)",
                        opp.from_value_usd
                    )
                    # ðŸš« Also record SOURCE rejection - this asset is too small for Binance entirely
                    self.barter_matrix.record_source_rejection(
                        opp.from_asset, 'binance', 5.0, opp.from_value_usd
                    )
                    return False
            
            # Debug: Check what type of binance client we have
            client_type = type(self.binance).__name__
            client_module = type(self.binance).__module__
            print(f"   ðŸ“ Binance client: {client_type} from {client_module}")

            # ðŸ” BINANCE PRE-FLIGHT: Enforce min notional / quantity before attempting
            try:
                pair_symbol = f"{opp.from_asset}{opp.to_asset}"
                filters = self.binance.get_symbol_filters(pair_symbol)
                min_notional = float(filters.get('min_notional', 0) or 0)
                min_qty = float(filters.get('min_qty', 0) or 0)
                from_price = self.prices.get(opp.from_asset, 0) or 0
                if min_notional > 0 and opp.from_value_usd < min_notional:
                    print(f"   âš ï¸ Value ${opp.from_value_usd:.2f} < Binance min notional ${min_notional:.2f} for {pair_symbol}")
                    # ðŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Value ${opp.from_value_usd:.2f} < min_notional ${min_notional:.2f}",
                        opp.from_value_usd
                    )
                    return False
                if min_qty > 0 and opp.from_amount < min_qty:
                    needed = min_qty * (from_price if from_price > 0 else 1)
                    print(f"   âš ï¸ Amount {opp.from_amount:.6f} < Binance min qty {min_qty:.6f} for {pair_symbol}")
                    print(f"   ðŸ’¡ Need â‰¥ {min_qty:.6f} ({needed:.2f} USD) to avoid minQty rejection")
                    # ðŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Amount {opp.from_amount:.6f} < min_qty {min_qty:.6f}",
                        opp.from_value_usd
                    )
                    return False
            except Exception as pre_e:
                logger.debug(f"Binance pre-flight filter check skipped: {pre_e}")
            
            # Check if convert_crypto exists
            if not hasattr(self.binance, 'convert_crypto'):
                print(f"   âš ï¸ BinanceClient missing convert_crypto method!")
                print(f"   ðŸ“ Available methods: {[m for m in dir(self.binance) if not m.startswith('_')][:20]}")
                
                # Fallback: Use direct place_market_order if available
                if hasattr(self.binance, 'place_market_order'):
                    print(f"   ðŸ”„ Attempting direct market order fallback...")
                    # Try direct pair
                    pair = f"{opp.from_asset}{opp.to_asset}"
                    result = self.binance.place_market_order(
                        symbol=pair,
                        side="SELL",
                        quantity=opp.from_amount
                    )
                    if result and not result.get("error"):
                        print(f"   âœ… Direct order executed: {result}")
                        return True
                    # Try inverse pair
                    pair = f"{opp.to_asset}{opp.from_asset}"
                    result = self.binance.place_market_order(
                        symbol=pair,
                        side="BUY",
                        quote_qty=opp.from_amount * opp.price if hasattr(opp, 'price') else opp.from_value_usd
                    )
                    if result and not result.get("error"):
                        print(f"   âœ… Inverse order executed: {result}")
                        return True
                
                self._record_failure(opp)
                return False
            
            # Use convert_crypto which handles pathfinding internally
            result = self.binance.convert_crypto(
                from_asset=opp.from_asset,
                to_asset=opp.to_asset,
                amount=opp.from_amount
            )
            
            # Handle pathfinding error from convert_crypto
            if result and result.get("error"):
                if "No conversion path" in str(result.get("error", "")):
                    print(f"   âš ï¸ {result['error']}")
                    return False
            
            if result and result.get("trades"):
                # Validate the execution
                validation = self._validate_order_execution(result["trades"], opp, 'binance')
                
                if validation.get("valid"):
                    self._log_successful_conversion(validation, opp)
                    return True
                else:
                    logger.error(f"âŒ Binance order validation failed: {validation.get('reason')}")
                    self._record_failure(opp)
                    return False
            elif result and result.get("dryRun"):
                # Dry run mode - simulate success
                print(f"   ðŸ§ª DRY RUN: Would convert via {result.get('trades', 0)} trades")
                return True
            else:
                error_msg = result.get("error", "Unknown error")
                logger.error(f"âŒ Binance conversion error: {error_msg}")
                print(f"   âŒ Error: {error_msg}")
                self._record_failure(opp)
                return False
        
        except Exception as e:
            logger.error(f"âŒ Binance conversion error: {e}")
            print(f"   âŒ Error: {e}")
            self._record_failure(opp)
        return False
    
    async def _execute_on_alpaca(self, opp) -> bool:
        """Execute conversion on Alpaca using convert_crypto."""
        try:
            # Use the built-in convert_crypto which finds the best path automatically!
            print(f"   ðŸ”„ Converting {opp.from_asset} â†’ {opp.to_asset} via Alpaca...")
            
            # ðŸ‘‘ QUEEN MIND: Decode conversion path in real-time
            # Refresh balance FIRST to get accurate amounts
            await self.refresh_exchange_balances('alpaca')
            
            # ðŸ‘‘ SERO FIX: Case-insensitive asset matching
            alpaca_balances = self.exchange_balances.get('alpaca', {})
            actual_balance = 0.0
            matched_asset = opp.from_asset
            
            for bal_key, bal_val in alpaca_balances.items():
                if bal_key.upper() == opp.from_asset.upper():
                    actual_balance = float(bal_val) if isinstance(bal_val, (int, float, str)) else 0.0
                    matched_asset = bal_key
                    break
            
            print(f"   ðŸ“Š Alpaca {matched_asset} balance: {actual_balance:.6f} (need: {opp.from_amount:.6f})")
            
            # Clamp to actual available balance
            if actual_balance <= 0:
                print(f"   âš ï¸ No {opp.from_asset} balance on Alpaca (balance: {actual_balance})")
                return False
            
            # ðŸŒâœ¨ PLANET SAVER: Same sanity check as Kraken - detect location mismatch!
            if actual_balance < opp.from_amount * 0.1:
                print(f"   ðŸŒâš ï¸ Alpaca balance {actual_balance:.6f} is < 10% of expected {opp.from_amount:.6f}")
                print(f"   ðŸŒâš ï¸ Asset location mismatch! Protecting the planet by aborting.")
                return False
            
            # ðŸŒâœ¨ PLANET SAVER PROTECTION: Don't trade dust that gets eaten by fees!
            original_amount = opp.from_amount
            original_value = opp.from_value_usd
            
            # ðŸ‘‘ SERO EXECUTION FIX: Use 95% of balance for safety margin
            safe_amount = actual_balance * 0.95
            if opp.from_amount > safe_amount:
                print(f"   ðŸ‘‘ Sero adjusts: {opp.from_amount:.6f} â†’ {safe_amount:.6f} (95% safe)")
                opp.from_amount = safe_amount
                opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
                
                # ðŸŒâœ¨ PLANET SAVER: Check if clamping destroyed our profit opportunity!
                clamp_ratio = opp.from_amount / original_amount if original_amount > 0 else 0
                if clamp_ratio < 0.2:  # Lost more than 80% of intended trade size
                    print(f"   ðŸŒâš ï¸ PLANET SAVER PROTECTION: Clamped to {clamp_ratio*100:.1f}% of intended!")
                    print(f"      Original: ${original_value:.2f} â†’ Clamped: ${opp.from_value_usd:.2f}")
                    print(f"      Fees would eat this tiny trade alive. ABORTING to save the planet!")
                    return False
                    
                # ðŸŒâœ¨ Minimum viable trade size for Alpaca (fees ~0.3% = $0.003 on $1)
                PLANET_SAVER_MIN_ALPACA = 5.0  # Need at least $5 to overcome fees
                if opp.from_value_usd < PLANET_SAVER_MIN_ALPACA:
                    print(f"   ðŸŒâš ï¸ PLANET SAVER: Clamped value ${opp.from_value_usd:.2f} < ${PLANET_SAVER_MIN_ALPACA} minimum")
                    print(f"      Small trades get eaten by fees. Protecting our liberation fund!")
                    return False

            # ðŸ¦™ Alpaca cost metrics (fee + slippage + spread) to avoid negative net profit
            cost_metrics = self._alpaca_estimate_conversion_costs(opp.from_asset, opp.to_asset)
            total_cost_pct = cost_metrics.get("total_pct", 0.0)
            net_expected_usd = opp.expected_pnl_usd - (opp.from_value_usd * total_cost_pct / 100)
            net_expected_pct = (opp.expected_pnl_pct * 100) - total_cost_pct

            opp.alpaca_fee_pct = cost_metrics.get("fee_pct", 0.0)
            opp.alpaca_slippage_pct = cost_metrics.get("slippage_pct", 0.0)
            opp.alpaca_spread_pct = cost_metrics.get("spread_pct", 0.0)
            opp.alpaca_total_cost_pct = total_cost_pct
            opp.alpaca_net_expected_usd = net_expected_usd

            print(
                "   ðŸ¦™ Alpaca cost check: "
                f"fees {opp.alpaca_fee_pct*2:.2f}% | slip {opp.alpaca_slippage_pct*2:.2f}% | "
                f"spread {opp.alpaca_spread_pct:.2f}% | total {total_cost_pct:.2f}% | "
                f"net est ${net_expected_usd:+.4f} ({net_expected_pct:+.2f}%)"
            )

            if net_expected_usd < self.alpaca_min_net_profit_usd or net_expected_pct < self.alpaca_min_net_profit_pct:
                print(
                    f"   ðŸš« Alpaca net profit too low: ${net_expected_usd:+.4f} "
                    f"(< ${self.alpaca_min_net_profit_usd:.4f} or {net_expected_pct:+.2f}% "
                    f"< {self.alpaca_min_net_profit_pct:.2f}%)"
                )
                return False
            
            # First check if a path exists
            path = self.alpaca.find_conversion_path(opp.from_asset, opp.to_asset)
            if not path:
                print(f"   âš ï¸ No conversion path found from {opp.from_asset} to {opp.to_asset}")
                return False
            
            # ðŸ” ALPACA PRE-FLIGHT CHECK: Verify minimums for EACH step
            # Alpaca has different minimums per crypto asset
            ALPACA_MIN_NOTIONAL = 1.0  # Alpaca typically has $1 minimum
            ALPACA_MIN_QTY = {
                'BTC': 0.0001,    # ~$10 at current prices
                'ETH': 0.001,     # ~$3 at current prices
                'SOL': 0.01,      # ~$2 at current prices
                'DOGE': 1.0,      # ~$0.30 at current prices
                'SHIB': 100000.0, # Fractions of a cent
                'PEPE': 100000.0, # Fractions of a cent
                'AVAX': 0.01,     # ~$0.40 at current prices
                'LINK': 0.1,      # ~$2 at current prices
                'DOT': 0.1,       # ~$0.70 at current prices
                'AAVE': 0.001,    # ~$0.16 at current prices
            }
            
            for step in path:
                pair = step.get('pair', '')
                # Alpaca pairs are like 'BTC/USD'
                base_asset = pair.split('/')[0] if '/' in pair else opp.from_asset
                
                # Check minimum quantity for this asset
                min_qty = ALPACA_MIN_QTY.get(base_asset.upper(), 0.0001)  # Default very small
                
                # For selling, check if we have enough of the from_asset
                if step.get('side') == 'sell' and opp.from_amount < min_qty:
                    print(f"   âš ï¸ Qty {opp.from_amount:.6f} < min {min_qty:.6f} for {pair}")
                    print(f"   ðŸ’¡ Need {min_qty:.6f} {base_asset} minimum")
                    return False
                
                # Check minimum notional value
                if opp.from_value_usd < ALPACA_MIN_NOTIONAL:
                    print(f"   âš ï¸ Value ${opp.from_value_usd:.2f} < min notional ${ALPACA_MIN_NOTIONAL:.2f}")
                    print(f"   ðŸ’¡ Need ${ALPACA_MIN_NOTIONAL:.2f} minimum to trade on Alpaca")
                    return False
            
            # Show the path
            for step in path:
                print(f"   ðŸ“ Path: {step['description']} via {step['pair']}")
            
            # Execute the conversion
            result = self.alpaca.convert_crypto(
                from_asset=opp.from_asset,
                to_asset=opp.to_asset,
                amount=opp.from_amount
            )
            
            if result.get('error'):
                print(f"   âŒ Conversion error: {result['error']}")
                self._record_failure(opp)
                return False
            
            # Check results
            trades = result.get('trades', [])
            if isinstance(trades, list):
                success_count = sum(1 for t in trades if isinstance(t, dict) and t.get('status') == 'success')
                if success_count > 0:
                    # Calculate actual bought amount from the last trade
                    last_trade = trades[-1]
                    buy_amount = 0.0
                    if last_trade.get('status') == 'success':
                        res = last_trade.get('result', {})
                        buy_amount = float(res.get('qty', 0.0)) # Alpaca uses 'qty'
                    
                    # Fallback if qty is missing or 0
                    if buy_amount == 0.0:
                         # Estimate based on price
                         to_price = self.prices.get(opp.to_asset, 0)
                         if to_price > 0:
                             buy_amount = opp.from_value_usd / to_price
                    
                    print(f"   âœ… Conversion complete! {success_count} trades executed. Bought {buy_amount:.6f} {opp.to_asset}")
                    
                    # ðŸ” VALIDATE ORDER EXECUTION
                    validation = self._validate_order_execution(trades, opp, 'alpaca')
                    verification = self._verify_profit_math(validation, opp, buy_amount)
                    self._print_order_validation(validation, verification, opp)
                    
                    self._record_conversion(opp, buy_amount, validation, verification)
                    return True
                else:
                    print(f"   âŒ No successful trades in conversion")
                    self._record_failure(opp)
            elif result.get('dryRun'):
                print(f"   ðŸ”µ DRY RUN: Would convert via {len(path)} trades")
                return True
            else:
                print(f"   âœ… Conversion result: {result}")
                # Estimate amount for non-standard result
                to_price = self.prices.get(opp.to_asset, 0)
                buy_amount = opp.from_value_usd / to_price if to_price > 0 else 0
                self._record_conversion(opp, buy_amount)
                return True
                
        except Exception as e:
            logger.error(f"âŒ Alpaca conversion error: {e}")
            print(f"   âŒ Error: {e}")
            self._record_failure(opp)
        return False

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ” ORDER VALIDATION & PROFIT VERIFICATION SYSTEM
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _validate_order_execution(self, trades: List[Dict], opp, exchange: str) -> Dict:
        """
        ðŸ” COMPREHENSIVE ORDER VALIDATION
        
        Validates each trade step using order IDs from the trading platform.
        Verifies fills, calculates actual execution prices, and computes real P&L.
        
        Returns:
            Dict with validation results:
            - valid: bool
            - order_ids: List of order IDs
            - total_sold: Actual amount sold
            - total_bought: Actual amount bought
            - avg_sell_price: Average sell price
            - avg_buy_price: Average buy price
            - total_fees: Total fees paid
            - realized_pnl: Validated P&L
            - validation_errors: List of any issues
        """
        validation = {
            'valid': True,
            'order_ids': [],
            'total_sold': 0.0,
            'total_bought': 0.0,
            'avg_sell_price': 0.0,
            'avg_buy_price': 0.0,
            'total_fees': 0.0,
            'realized_pnl': 0.0,
            'validation_errors': [],
            'exchange': exchange,
            'timestamp': time.time(),
        }
        
        if not trades:
            validation['valid'] = False
            validation['validation_errors'].append("No trades to validate")
            return validation
        
        sell_volume = 0.0
        sell_value = 0.0
        buy_volume = 0.0
        buy_value = 0.0
        
        for i, trade in enumerate(trades):
            step_num = i + 1
            
            if not isinstance(trade, dict):
                validation['validation_errors'].append(f"Step {step_num}: Invalid trade format")
                continue
            
            status = trade.get('status', '')
            result = trade.get('result', {})
            trade_info = trade.get('trade', {})
            
            # Extract order ID based on exchange
            order_id = self._extract_order_id(result, exchange)
            if order_id:
                validation['order_ids'].append({
                    'step': step_num,
                    'order_id': order_id,
                    'exchange': exchange,
                    'pair': trade_info.get('pair', ''),
                    'side': trade_info.get('side', ''),
                })
            
            if status != 'success':
                validation['valid'] = False
                error_msg = trade.get('error', 'Unknown error')
                validation['validation_errors'].append(f"Step {step_num}: {error_msg}")
                continue
            
            # Validate fill data
            executed_qty = float(result.get('executedQty', 0))
            cumm_quote_qty = float(result.get('cummulativeQuoteQty', 0))
            
            side = trade_info.get('side', 'buy')
            
            if side == 'sell':
                sell_volume += executed_qty
                sell_value += cumm_quote_qty
            else:
                buy_volume += executed_qty
                buy_value += cumm_quote_qty
            
            # Extract and sum fees
            fees = self._extract_fees(result, exchange)
            validation['total_fees'] += fees
            
            # Verify the fill makes sense
            if executed_qty <= 0:
                validation['validation_errors'].append(f"Step {step_num}: Zero executed quantity")
        
        # Calculate averages
        if sell_volume > 0:
            validation['avg_sell_price'] = sell_value / sell_volume if sell_value > 0 else 0
            validation['total_sold'] = sell_volume
        
        if buy_volume > 0:
            validation['avg_buy_price'] = buy_value / buy_volume
            validation['total_bought'] = buy_volume
        
        # For conversions, the "bought" amount is what we end up with
        # If we did sell â†’ buy, the buy_volume is our result
        # If we did just one side, use that
        if buy_volume > 0:
            validation['final_amount'] = buy_volume
        elif sell_value > 0:
            # We sold and received quote currency (the sell_value IS what we received)
            validation['final_amount'] = sell_value
        elif sell_volume > 0 and validation['avg_sell_price'] > 0:
            # FALLBACK: When sell_value (cummulativeQuoteQty) is 0 (like with Kraken SELL orders)
            # Calculate expected received amount from sell_volume * avg_sell_price
            validation['final_amount'] = sell_volume * validation['avg_sell_price']
        else:
            validation['final_amount'] = 0
        
        return validation
    
    def _extract_order_id(self, result: Dict, exchange: str) -> Optional[str]:
        """Extract order ID from trade result based on exchange format."""
        if not result:
            return None
        
        if exchange == 'kraken':
            # Kraken uses 'orderId' which we set from 'txid'
            return result.get('orderId') or result.get('txid')
        elif exchange == 'binance':
            return result.get('orderId') or result.get('clientOrderId')
        elif exchange == 'alpaca':
            return result.get('id') or result.get('order_id')
        
        # Fallback
        return result.get('orderId') or result.get('order_id') or result.get('id')
    
    def _extract_fees(self, result: Dict, exchange: str) -> float:
        """Extract fees from trade result based on exchange format and convert to USD."""
        total_fees = 0.0
        
        if exchange == 'binance':
            # Binance includes fills with commission and commissionAsset
            fills = result.get('fills', [])
            for fill in fills:
                try:
                    commission = float(fill.get('commission', 0))
                    commission_asset = str(fill.get('commissionAsset', '')).upper()
                    
                    if commission > 0 and commission_asset:
                        # Convert fee to USD using current prices
                        if commission_asset in ('USD', 'USDT', 'USDC', 'BUSD'):
                            total_fees += commission
                        else:
                            # Get price of commission asset
                            asset_price = self.prices.get(commission_asset, 0)
                            if asset_price > 0:
                                total_fees += commission * asset_price
                            else:
                                # Fallback: assume small fee (0.1% of typical trade)
                                total_fees += commission * 0.0001  # Conservative estimate
                except (ValueError, TypeError):
                    pass
        elif exchange == 'kraken':
            # Kraken fees need to be calculated from the trade
            # Fee is typically 0.16% maker or 0.26% taker
            executed_qty = float(result.get('executedQty', 0))
            # Get the trade value in USD
            avg_price = float(result.get('avgPrice', 0) or result.get('price', 0) or 0)
            trade_value_usd = executed_qty * avg_price
            fee_rate = 0.0026  # Assume taker (more conservative)
            total_fees = trade_value_usd * fee_rate
        elif exchange == 'alpaca':
            # Alpaca includes fees differently
            total_fees = float(result.get('commission', 0) or result.get('fee', 0) or 0)
        
        return total_fees
    
    def _verify_profit_math(self, validation: Dict, opp, buy_amount: float) -> Dict:
        """
        ðŸ”¢ VERIFY PROFIT CALCULATION MATH
        
        Cross-checks our calculated P&L against actual execution data.
        Returns verification results with any discrepancies.
        """
        verification = {
            'valid': True,
            'expected_pnl': opp.expected_pnl_usd,
            'calculated_pnl': 0.0,
            'verified_pnl': 0.0,
            'discrepancy': 0.0,
            'discrepancy_pct': 0.0,
            'warnings': [],
        }
        
        # Get current prices for calculation
        from_price = self.prices.get(opp.from_asset, 0)
        to_price = self.prices.get(opp.to_asset, 0)
        
        if not from_price or not to_price:
            verification['warnings'].append("Missing price data for verification")
            return verification
        
        # Calculate P&L using our method
        sold_value = opp.from_amount * from_price
        bought_value = buy_amount * to_price
        calculated_pnl = bought_value - sold_value
        verification['calculated_pnl'] = calculated_pnl
        
        # Calculate P&L using actual execution data (if available)
        if validation.get('total_sold') > 0 or validation.get('final_amount', 0) > 0 or buy_amount > 0:
            # ðŸ”§ FIX: Use ACTUAL EXECUTION PRICES, not current market prices!
            # This is critical for accurate P/L calculation
            
            # Sold value - use actual execution price if available
            if validation.get('avg_sell_price', 0) > 0:
                actual_sold_value = validation['total_sold'] * validation['avg_sell_price']
            else:
                actual_sold_value = sold_value
            
            # Final bought value - CRITICAL FIX:
            # For SELL orders (like DAIâ†’USD), validation['final_amount'] may be 0 because
            # exchanges like Kraken don't return cummulativeQuoteQty for sells.
            # In this case, use the buy_amount we actually received from the trade!
            final_amount = validation.get('final_amount', 0)
            if final_amount <= 0 and buy_amount > 0:
                # Fallback to buy_amount when final_amount is missing/zero
                final_amount = buy_amount
            
            # ðŸ”§ FIX: Use actual buy price if available, not current price
            if validation.get('avg_buy_price', 0) > 0:
                actual_bought_value = final_amount * validation['avg_buy_price']
            else:
                actual_bought_value = final_amount * to_price
            
            # Subtract fees (fees are already in USD/quote currency)
            fees = validation.get('total_fees', 0)
            # ðŸ”§ FIX: fees_in_usd calculation - fees are often in quote currency already
            # Don't multiply by to_price if fee is already in USD/USDC/USDT
            fees_in_usd = fees  # Assume fees are already in USD value
            
            verified_pnl = actual_bought_value - actual_sold_value - fees_in_usd
            verification['verified_pnl'] = verified_pnl
            
            # Check for discrepancy
            discrepancy = abs(calculated_pnl - verified_pnl)
            verification['discrepancy'] = discrepancy
            
            if abs(calculated_pnl) > 0.0001:
                verification['discrepancy_pct'] = (discrepancy / abs(calculated_pnl)) * 100
            
            # Flag significant discrepancies (>5%)
            if verification['discrepancy_pct'] > 5.0:
                verification['valid'] = False
                verification['warnings'].append(
                    f"P&L discrepancy: calculated ${calculated_pnl:.4f} vs verified ${verified_pnl:.4f} ({verification['discrepancy_pct']:.1f}%)"
                )
        else:
            verification['verified_pnl'] = calculated_pnl
        
        return verification
    
    def _print_order_validation(self, validation: Dict, verification: Dict, opp):
        """Print comprehensive order validation results."""
        print("\n   " + "â•" * 60)
        print("   ðŸ” ORDER VALIDATION & PROFIT VERIFICATION")
        print("   " + "â•" * 60)
        
        # Order IDs
        if validation['order_ids']:
            print(f"   ðŸ“‹ Order IDs ({validation['exchange'].upper()}):")
            for order in validation['order_ids']:
                print(f"      Step {order['step']}: {order['order_id']} ({order['side']} {order['pair']})")
        
        # Execution Summary
        print(f"\n   ðŸ“Š EXECUTION SUMMARY:")
        print(f"      Sold: {validation['total_sold']:.8f} {opp.from_asset}")
        print(f"      Bought: {validation.get('final_amount', 0):.8f} {opp.to_asset}")
        if validation['avg_sell_price'] > 0:
            print(f"      Avg Sell Price: ${validation['avg_sell_price']:.6f}")
        if validation['avg_buy_price'] > 0:
            print(f"      Avg Buy Price: ${validation['avg_buy_price']:.6f}")
        print(f"      Total Fees: ${validation['total_fees']:.6f}")
        
        # P&L Verification
        print(f"\n   ðŸ’° P&L VERIFICATION:")
        print(f"      Expected P&L: ${verification['expected_pnl']:+.4f}")
        print(f"      Calculated P&L: ${verification['calculated_pnl']:+.4f}")
        print(f"      Verified P&L: ${verification['verified_pnl']:+.4f}")
        
        if verification['discrepancy'] > 0.0001:
            status = "âš ï¸" if verification['discrepancy_pct'] > 5 else "âœ…"
            print(f"      {status} Discrepancy: ${verification['discrepancy']:.4f} ({verification['discrepancy_pct']:.1f}%)")
        else:
            print(f"      âœ… Math Verified!")
        
        # Validation Status
        if validation['validation_errors']:
            print(f"\n   âš ï¸ VALIDATION ISSUES:")
            for error in validation['validation_errors']:
                print(f"      - {error}")
        
        if verification['warnings']:
            print(f"\n   âš ï¸ VERIFICATION WARNINGS:")
            for warning in verification['warnings']:
                print(f"      - {warning}")
        
        # Final Status
        if validation['valid'] and verification['valid']:
            print(f"\n   âœ… ORDER FULLY VALIDATED - Profit math confirmed!")
        else:
            print(f"\n   âš ï¸ VALIDATION INCOMPLETE - Review required")
        
        print("   " + "â•" * 60)
    
    def _record_conversion(self, opp, buy_amount: float, validation: Dict = None, verification: Dict = None):
        """Record a successful conversion with STEP-BY-STEP realized profit tracking and ORDER VALIDATION."""
        opp.executed = True
        self.conversions_made += 1
        self.conversions.append(opp)
        self.balances[opp.from_asset] = self.balances.get(opp.from_asset, 0) - opp.from_amount
        self.balances[opp.to_asset] = self.balances.get(opp.to_asset, 0) + buy_amount

        # ðŸš¨ USE ACTUAL EXECUTION DATA, NOT ESTIMATED PRICES
        # This is critical to prevent ghost profits!
        from_price = self.prices.get(opp.from_asset, 0)
        to_price = self.prices.get(opp.to_asset, 0)
        
        # Try to use actual execution values from validation
        if validation and validation.get('total_sold', 0) > 0:
            # Use actual execution data
            if validation.get('avg_sell_price', 0) > 0:
                sold_value = validation['total_sold'] * validation['avg_sell_price']
            else:
                sold_value = opp.from_amount * from_price
            
            if validation.get('avg_buy_price', 0) > 0:
                bought_value = validation.get('final_amount', buy_amount) * validation['avg_buy_price']
            else:
                bought_value = buy_amount * to_price
            
            # Subtract fees from bought value (fees reduce profit)
            # Note: fees are already in USD from _extract_fees
            fees_usd = validation.get('total_fees', 0)
            if fees_usd > 0:
                bought_value -= fees_usd  # Direct USD subtraction
        else:
            # Fallback to price-based estimate
            sold_value = opp.from_amount * from_price
            bought_value = buy_amount * to_price
        
        actual_pnl = bought_value - sold_value
        
        # ðŸ‘‘ SERO FIX: Sanitity Check for Outlier Profits
        # This catches "Ghost Profit" bugs where bad data creates impossible PnL
        MAX_REASONABLE_PROFIT = 500.0   # $500 max profit per trade (realistic for small balances)
        MIN_REASONABLE_LOSS = -200.0    # -$200 max loss per trade
        
        if actual_pnl > MAX_REASONABLE_PROFIT or actual_pnl < MIN_REASONABLE_LOSS:
            logger.warning(
                f"ðŸ‘‘âš ï¸ REJECTING OUTLIER PROFIT/LOSS in record: ${actual_pnl:.2f} (from ${sold_value:.2f} to ${bought_value:.2f})"
            )
            logger.warning("      This suggests a price data error or bad execution value. Clamping to 0.0")
            actual_pnl = 0.0

        opp.actual_pnl_usd = actual_pnl
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ” ORDER VALIDATION AUDIT TRAIL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if validation:
            # Use verified P&L if available (most accurate)
            if verification and verification.get('verified_pnl') is not None:
                actual_pnl = verification['verified_pnl']

                # Re-apply outlier clamp to verified P&L too (prevents ghost-profit override)
                if actual_pnl > MAX_REASONABLE_PROFIT or actual_pnl < MIN_REASONABLE_LOSS:
                    logger.warning(
                        f"ðŸ‘‘âš ï¸ REJECTING OUTLIER VERIFIED P/L: ${actual_pnl:.2f} (clamping to 0.0)"
                    )
                    actual_pnl = 0.0

                opp.actual_pnl_usd = actual_pnl
                # Update bought_value to reflect actual P&L (don't reset sold_value!)
                # sold_value already has correct value from execution data above
                bought_value = sold_value + actual_pnl  # bought = sold + profit (actual)
                opp.pnl_verified = True
                opp.verification_status = 'VERIFIED' if verification['valid'] else 'DISCREPANCY'
            else:
                opp.pnl_verified = False
                opp.verification_status = 'UNVERIFIED'
            
            # Store order IDs for audit trail
            opp.order_ids = validation.get('order_ids', [])
            opp.execution_fees = validation.get('total_fees', 0)
            
            # Log validation to persistent storage for auditing
            self._log_order_validation(opp, validation, verification)
        else:
            opp.pnl_verified = False
            opp.verification_status = 'NO_VALIDATION'
            opp.order_ids = []
            opp.execution_fees = 0
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ«’ðŸ’° LIVE BARTER MATRIX - Record & Display Step Profit
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Update barter rates for this pair
        self.barter_matrix.update_barter_rate(
            opp.from_asset, opp.to_asset, from_price, to_price
        )
        
        # Record realized profit in the barter ledger
        profit_result = self.barter_matrix.record_realized_profit(
            from_asset=opp.from_asset,
            to_asset=opp.to_asset,
            from_amount=opp.from_amount,
            from_usd=sold_value,
            to_amount=buy_amount,
            to_usd=bought_value
        )
        
        # ðŸŽ¯ PRINT STEP-BY-STEP REALIZED PROFIT
        step_display = self.barter_matrix.print_step_profit(
            step_num=self.conversions_made,
            from_asset=opp.from_asset,
            to_asset=opp.to_asset,
            from_usd=sold_value,
            to_usd=bought_value,
            from_amount=opp.from_amount,
            to_amount=buy_amount
        )
        print(step_display)
        
        # Show path performance (how this specific conversion path is doing)
        print(f"   ðŸ“Š PATH {opp.from_asset}â†’{opp.to_asset}: {profit_result['path_trades']} trades, ${profit_result['path_total_profit']:+.4f} total")
        print(f"   ðŸ”„ Slippage: {profit_result['actual_slippage_pct']:.2f}%")
        
        # ðŸ‘‘ðŸ„ QUEEN'S MYCELIUM BROADCAST - Send signals to all systems
        if profit_result.get('is_win'):
            print(f"   ðŸ‘‘ Queen's Verdict: âœ… WIN! Path continues.")
        else:
            win_rate = profit_result.get('path_win_rate', 0)
            print(f"   ðŸ‘‘ Queen's Verdict: âŒ LOSS! Path win rate: {win_rate:.0%}")
            # Broadcast through mycelium
            queen_signals = self.barter_matrix.get_queen_signals()
            for signal in queen_signals:
                if signal['type'] == 'PATH_BLOCKED':
                    print(f"   ðŸ„ MYCELIUM BROADCAST: {signal['path']} BLOCKED - {signal['reason']}")
        
        # Update total_profit_usd to match barter matrix
        self.total_profit_usd = self.barter_matrix.total_realized_profit
        
        # ðŸª™âš¡ PENNY TURBO: Record trade for compound learning
        if self.penny_turbo:
            try:
                exchange = opp.source_exchange if hasattr(opp, 'source_exchange') else 'kraken'
                symbol = f"{opp.from_asset}{opp.to_asset}"
                won = actual_pnl >= 0
                profit_pct = (actual_pnl / sold_value * 100) if sold_value > 0 else 0
                duration = getattr(opp, 'execution_time', 30.0)  # Default 30s if not tracked
                
                self.penny_turbo.record_trade(
                    exchange=exchange,
                    symbol=symbol,
                    won=won,
                    profit_pct=profit_pct,
                    volume_usd=sold_value,
                    duration_sec=duration
                )
            except Exception as e:
                logger.debug(f"Penny turbo record error: {e}")

        # Learn: update hub and path memory
        if self.hub and hasattr(self.hub, 'record_conversion_outcome'):
            try:
                self.hub.record_conversion_outcome(opp.from_asset, opp.to_asset, actual_pnl >= 0, actual_pnl)
            except Exception:
                pass
        self.path_memory.record(opp.from_asset, opp.to_asset, actual_pnl >= 0)
        
        # ï¿½ CRITICAL FIX: Record pair result for DYNAMIC BLOCKING!
        # This was missing - pairs kept losing without being blocked!
        pair_key = f"{opp.from_asset.upper()}_{opp.to_asset.upper()}"
        exchange = opp.source_exchange if hasattr(opp, 'source_exchange') else 'kraken'
        self.barter_matrix.record_pair_result(pair_key, exchange, won=(actual_pnl >= 0))
        
        # ï¿½ðŸ‘‘ Update Queen's path memory with new data
        if hasattr(self, 'queen') and self.queen and hasattr(self.queen, 'path_memory'):
            path_key = f"{opp.from_asset.upper()}->{opp.to_asset.upper()}"
            if not hasattr(self.queen, 'path_memory') or self.queen.path_memory is None:
                self.queen.path_memory = {}
            if path_key not in self.queen.path_memory:
                self.queen.path_memory[path_key] = {'wins': 0, 'losses': 0}
            if actual_pnl >= 0:
                self.queen.path_memory[path_key]['wins'] += 1
            else:
                self.queen.path_memory[path_key]['losses'] += 1

        # ðŸ“…ðŸ”® 7-DAY PLANNER: Validate timing prediction after conversion
        if self.seven_day_planner:
            try:
                # Record this conversion for validation tracking
                validation_id = self.seven_day_planner.record_conversion(
                    symbol=opp.to_asset,
                    entry_price=to_price
                )
                
                # Validate immediately with exit price (for compound tracking)
                # The next scan will have updated prices for true validation
                result = self.seven_day_planner.validate_conversion(
                    validation_id=validation_id,
                    exit_price=to_price  # Will be updated on next trade
                )
                
                if result:
                    timing_tag = "ðŸŽ¯" if result.direction_correct else "âŒ"
                    print(f"   ðŸ“… 7-Day Validation: {timing_tag} timing={result.timing_score:.0%}")
                    
                    # Log adaptive weight updates
                    weights = self.seven_day_planner.adaptive_weights
                    print(f"   ðŸ§  Adaptive: h={weights['hourly_weight']:.2f}, s={weights['symbol_weight']:.2f}, acc={weights['accuracy_7d']:.0%}")
                    
                    # ðŸ‘‘ðŸ“Š FEED VALIDATED PREDICTION TO QUEEN! 
                    # Every verified prediction feeds Queen's neural learning!
                    if self.queen and hasattr(self.queen, 'receive_validated_prediction'):
                        validation_data = {
                            'symbol': opp.to_asset,
                            'predicted_edge': result.predicted_edge,
                            'actual_edge': result.actual_edge,
                            'direction_correct': result.direction_correct,
                            'timing_score': result.timing_score,
                            'confidence': weights.get('accuracy_7d', 0.5),
                            'hour': datetime.now().hour,
                            'day_of_week': datetime.now().weekday(),
                            'source': '7day_planner',
                            'pair': f"{opp.from_asset}->{opp.to_asset}",
                            'pnl': actual_pnl
                        }
                        queen_result = self.queen.receive_validated_prediction(validation_data)
                        if queen_result.get('neural_trained'):
                            print(f"   ðŸ‘‘ðŸ§  Queen learned from validated prediction!")
            except Exception as e:
                logger.debug(f"7-day planner validation error: {e}")

        # ðŸ”®ðŸ“Š PROBABILITY NEXUS VALIDATION - Feed to Queen's Neural Learning!
        # Track nexus prediction accuracy and let Queen learn from it
        if self.queen and hasattr(self.queen, 'receive_validated_prediction'):
            try:
                # Get nexus prediction that was stored with the opportunity
                nexus_prob = getattr(opp, 'nexus_probability', 0.5)
                nexus_dir = getattr(opp, 'nexus_direction', 'NEUTRAL')
                nexus_conf = getattr(opp, 'nexus_confidence', 0.0)
                nexus_factors = getattr(opp, 'nexus_factors', None)
                
                # Validate: Did the nexus prediction match the actual outcome?
                actual_direction = 'BULLISH' if actual_pnl > 0 else ('BEARISH' if actual_pnl < 0 else 'NEUTRAL')
                direction_correct = (nexus_dir == actual_direction) or (nexus_dir == 'NEUTRAL')
                
                # Timing score based on confidence vs outcome
                timing_score = 1.0 if direction_correct else 0.0
                if nexus_conf > 0:
                    timing_score *= nexus_conf  # Weight by confidence
                
                nexus_validation_data = {
                    'symbol': opp.to_asset,
                    'predicted_edge': (nexus_prob - 0.5) * 100,  # Convert 0-1 to edge %
                    'actual_edge': (actual_pnl / sold_value * 100) if sold_value > 0 else 0,
                    'direction_correct': direction_correct,
                    'timing_score': timing_score,
                    'confidence': nexus_conf,
                    'hour': datetime.now().hour,
                    'day_of_week': datetime.now().weekday(),
                    'source': 'probability_nexus',
                    'pair': f"{opp.from_asset}->{opp.to_asset}",
                    'pnl': actual_pnl,
                    'factors': nexus_factors
                }
                nexus_queen_result = self.queen.receive_validated_prediction(nexus_validation_data)
                if nexus_queen_result.get('neural_trained'):
                    print(f"   ðŸ”®ðŸ‘‘ Queen learned from Nexus prediction validation!")
            except Exception as e:
                logger.debug(f"Nexus validation feed error: {e}")

        # Publish observability
        if self.thought_bus:
            try:
                self.thought_bus.think(
                    topic='conversion.success',
                    message='conversion recorded',
                    metadata={
                        'pair': f"{opp.from_asset}->{opp.to_asset}",
                        'pnl': round(actual_pnl, 6),
                        'lambda': round(opp.lambda_score, 4),
                        'gravity': round(opp.gravity_score, 4),
                        'gate_req': round(opp.gate_required_profit, 6),
                        'gate_passed': opp.gate_passed,
                    }
                )
            except Exception:
                pass

    def _record_failure(self, opp, error_msg: str = "", validation: Dict = None):
        """
        Record a failed conversion attempt for learning.
        
        ðŸ‘‘ðŸŽ“ QUEEN LOSS LEARNING INTEGRATION:
        When we fail, we learn. We pull data, research tactics, and never forget.
        """
        self.path_memory.record(opp.from_asset, opp.to_asset, False)
        
        if self.thought_bus:
            try:
                self.thought_bus.think(
                    topic='conversion.failure',
                    message='conversion failed',
                    metadata={'pair': f"{opp.from_asset}->{opp.to_asset}", 'error': error_msg}
                )
            except Exception:
                pass
        
        # ðŸ‘‘ðŸŽ“ QUEEN LOSS LEARNING - Analyze every failure to learn and evolve
        if self.loss_learning:
            try:
                # Determine exchange
                exchange = opp.source_exchange or 'unknown'
                
                # Estimate loss amount (what we expected vs what happened)
                # If the conversion failed completely, the loss is the opportunity cost
                expected_profit = opp.expected_pnl_usd if opp.expected_pnl_usd > 0 else EPSILON_PROFIT_USD
                
                # Get prices
                from_price = self.prices.get(opp.from_asset, opp.from_value_usd / opp.from_amount if opp.from_amount > 0 else 1)
                to_price = self.prices.get(opp.to_asset, 0)
                
                # Calculate executed vs expected prices
                expected_price = to_price if to_price > 0 else 1
                executed_price = expected_price  # On failure, we don't have executed price
                
                # If validation data available, extract actual execution info
                if validation:
                    executed_price = validation.get('avg_buy_price', expected_price)
                    if validation.get('total_sold', 0) > 0 and opp.from_amount > 0:
                        # We sold but didn't get what we expected
                        loss_pct = (opp.from_amount - validation.get('total_sold', 0)) / opp.from_amount
                        expected_profit = opp.expected_pnl_usd * loss_pct
                
                # Build signals map from opportunity scores
                signals_used = {
                    'v14_score': opp.v14_score,
                    'hub_score': opp.hub_score,
                    'commando_score': opp.commando_score,
                    'lambda_score': opp.lambda_score,
                    'gravity_score': opp.gravity_score,
                    'luck_score': opp.luck_score,
                    'enigma_score': opp.enigma_score,
                    'timeline_score': opp.timeline_score,
                    'trained_matrix_score': opp.trained_matrix_score,
                    'barter_matrix_score': opp.barter_matrix_score,
                }
                
                # Fees estimated from config
                fees_paid = opp.from_value_usd * MICRO_CONFIG['total_cost_rate']
                
                # Loss amount = expected profit (opportunity cost) + any slippage
                loss_amount = max(expected_profit, EPSILON_PROFIT_USD)
                
                # Schedule async analysis (don't block the main loop)
                import asyncio
                asyncio.create_task(self._async_loss_analysis(
                    exchange=exchange,
                    from_asset=opp.from_asset,
                    to_asset=opp.to_asset,
                    from_amount=opp.from_amount,
                    from_value_usd=opp.from_value_usd,
                    executed_price=executed_price,
                    expected_price=expected_price,
                    fees_paid=fees_paid,
                    loss_amount=loss_amount,
                    signals_used=signals_used,
                    combined_score=opp.combined_score,
                    expected_profit=expected_profit,
                    error_msg=error_msg,
                ))
                
            except Exception as e:
                logger.debug(f"Loss learning error: {e}")
    
    async def _async_loss_analysis(self, **kwargs):
        """Async wrapper for loss analysis to not block main trading loop."""
        try:
            error_msg = kwargs.pop('error_msg', '')
            loss = await self.loss_learning.analyze_loss(**kwargs)
            
            # Check if we should auto-block this path
            avoid, reason = self.loss_learning.should_avoid_trade(
                kwargs['from_asset'],
                kwargs['to_asset'],
                kwargs['exchange'],
                    kwargs.get('expected_profit', EPSILON_PROFIT_USD)
            )
            
            if avoid:
                print(f"   ðŸ‘‘ðŸŽ“ QUEEN WISDOM: BLOCKING {kwargs['from_asset']}â†’{kwargs['to_asset']}")
                print(f"      Reason: {reason}")
                
                # Store in path memory as perma-block
                self.path_memory.block_path(kwargs['from_asset'], kwargs['to_asset'])
                
        except Exception as e:
            logger.debug(f"Async loss analysis error: {e}")

    def _log_successful_conversion(self, validation: Dict, opp):
        """
        Log a successful conversion with validation data.
        This is a convenience wrapper around _record_conversion.
        """
        # Calculate buy/received amount from validation
        buy_amount = 0.0
        trades = validation.get('trades', [])
        if trades:
            last_trade = trades[-1]
            if isinstance(last_trade, dict):
                # PRIORITY: Use receivedQty (for SELL orders) if available
                res = last_trade.get('result', {})
                buy_amount = float(res.get('receivedQty', 0) or
                                   last_trade.get('receivedQty', 0) or
                                   res.get('executedQty', 0) or 
                                   last_trade.get('executedQty', 0) or 0)
        
        # Fallback estimate if no amount found
        if buy_amount == 0:
            to_price = self.prices.get(opp.to_asset, 0)
            if to_price > 0:
                buy_amount = opp.from_value_usd / to_price
        
        # Verify profit math
        verification = self._verify_profit_math(validation, opp, buy_amount)
        
        # Print validation summary
        self._print_order_validation(validation, verification, opp)
        
        # Record the conversion
        self._record_conversion(opp, buy_amount, validation, verification)
    
    def _log_order_validation(self, opp, validation: Dict, verification: Dict):
        """
        ðŸ“‹ LOG ORDER VALIDATION TO PERSISTENT AUDIT TRAIL
        
        Stores all order IDs, execution details, and P&L verification
        for post-trade auditing and compliance.
        """
        import json
        from datetime import datetime
        
        audit_file = "aureon_order_audit.json"
        
        audit_entry = {
            'timestamp': datetime.now().isoformat(),
            'conversion_num': self.conversions_made,
            'exchange': validation.get('exchange', 'unknown'),
            'from_asset': opp.from_asset,
            'to_asset': opp.to_asset,
            'from_amount': opp.from_amount,
            'to_amount': validation.get('final_amount', 0),
            'order_ids': validation.get('order_ids', []),
            'validation': {
                'valid': validation.get('valid', False),
                'total_sold': validation.get('total_sold', 0),
                'total_bought': validation.get('final_amount', 0),
                'avg_sell_price': validation.get('avg_sell_price', 0),
                'avg_buy_price': validation.get('avg_buy_price', 0),
                'total_fees': validation.get('total_fees', 0),
                'errors': validation.get('validation_errors', []),
            },
            'profit_verification': {
                'expected_pnl': verification.get('expected_pnl', 0) if verification else 0,
                'calculated_pnl': verification.get('calculated_pnl', 0) if verification else 0,
                'verified_pnl': verification.get('verified_pnl', 0) if verification else 0,
                'discrepancy': verification.get('discrepancy', 0) if verification else 0,
                'discrepancy_pct': verification.get('discrepancy_pct', 0) if verification else 0,
                'math_valid': verification.get('valid', False) if verification else False,
                'warnings': verification.get('warnings', []) if verification else [],
            },
            'final_status': 'VERIFIED' if (validation.get('valid') and (verification and verification.get('valid'))) else 'NEEDS_REVIEW',
        }
        
        try:
            # Load existing audit log
            try:
                with open(audit_file, 'r') as f:
                    audit_log = json.load(f)
            except (FileNotFoundError, json.JSONDecodeError):
                audit_log = {'orders': [], 'summary': {'total': 0, 'verified': 0, 'discrepancies': 0}}
            
            # Append new entry
            audit_log['orders'].append(audit_entry)
            audit_log['summary']['total'] += 1
            if audit_entry['final_status'] == 'VERIFIED':
                audit_log['summary']['verified'] += 1
            else:
                audit_log['summary']['discrepancies'] += 1
            
            # Save updated log
            with open(audit_file, 'w') as f:
                json.dump(audit_log, f, indent=2)
            
            logger.info(f"ðŸ“‹ Order audit logged: {audit_entry['final_status']}")
            
        except Exception as e:
            logger.warning(f"Failed to write order audit: {e}")
    
    def _find_exchange_pair(self, asset: str, quote: str, exchange: str) -> Optional[str]:
        """Find trading pair on a specific exchange using loaded pairs."""
        asset_upper = asset.upper()
        quote_upper = quote.upper()
        prefix = f"{exchange}:"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ™ KRAKEN - Check kraken_pairs dict
        # Kraken uses special naming: XXBT=BTC, ZUSD=USD, ZEUR=EUR
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if exchange == 'kraken' and self.kraken_pairs:
            # Map common names to Kraken format
            kraken_asset = asset_upper
            if asset_upper == 'BTC':
                kraken_asset = 'XBT'
            
            kraken_quote = quote_upper
            if quote_upper == 'USD':
                kraken_quote = 'ZUSD'
            elif quote_upper == 'EUR':
                kraken_quote = 'ZEUR'
            elif quote_upper == 'GBP':
                kraken_quote = 'ZGBP'
            
            # Try common pair formats (Kraken has multiple naming conventions)
            candidates = [
                f"{asset_upper}{quote_upper}",           # CHZUSD (standard)
                f"{kraken_asset}{quote_upper}",          # XBTUSD
                f"X{kraken_asset}Z{quote_upper}",        # XXBTZUSD
                f"XX{kraken_asset[1:]}Z{quote_upper}" if len(kraken_asset) > 1 else None,  # Edge cases
                f"{asset_upper}{kraken_quote}",          # CHZZUSD
                f"{kraken_asset}{kraken_quote}",         # XBTZUSD
                f"X{kraken_asset}{kraken_quote}",        # XXBTZUSD variant
            ]
            for candidate in [c for c in candidates if c]:
                if candidate in self.kraken_pairs:
                    return f"kraken:{candidate}"
            
            # Fuzzy search (look for both original and Kraken-format asset)
            search_assets = [asset_upper, kraken_asset]
            if asset_upper != kraken_asset:
                search_assets.append(f"X{kraken_asset}")  # XXBT
            
            for pair_name in self.kraken_pairs.keys():
                for search_asset in search_assets:
                    if search_asset in pair_name and quote_upper in pair_name:
                        return f"kraken:{pair_name}"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ¦™ ALPACA - Check alpaca_pairs dict
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if exchange == 'alpaca' and self.alpaca_pairs:
            candidates = [
                f"{asset_upper}/USD",
                f"{asset_upper}USD",
                f"{asset_upper}/BTC",
                f"{asset_upper}BTC",
                f"{asset_upper}/USDT",
                f"{asset_upper}USDT",
                f"{asset_upper}/USDC",
                f"{asset_upper}USDC",
                asset_upper,
            ]
            for candidate in candidates:
                if candidate in self.alpaca_pairs:
                    return f"alpaca:{self.alpaca_pairs[candidate]}"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŸ¡ BINANCE - Search ticker cache
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if exchange == 'binance':
            candidates = [
                f"{asset_upper}{quote_upper}",
                f"{asset_upper}USDT",
                f"{asset_upper}USDC",
            ]
            for candidate in candidates:
                cache_key = f"binance:{candidate}"
                if cache_key in self.ticker_cache:
                    return cache_key
        
        # Fallback: Search ticker cache for any exchange
        for cached_pair in self.ticker_cache.keys():
            if cached_pair.startswith(prefix):
                pair_part = cached_pair.replace(prefix, '')
                if pair_part.startswith(asset_upper) and quote_upper in pair_part:
                    return cached_pair
        
        return None
    
    async def run(self, duration_s: int = 60):
        """Run the micro profit labyrinth."""
        # Timeouts: prevent a single hung await (API/research) from freezing the run.
        LOAD_PAIRS_TIMEOUT_S = 60.0
        FETCH_PRICES_TIMEOUT_S = 30.0
        FETCH_BALANCES_TIMEOUT_S = 45.0
        WAVE_SCAN_TIMEOUT_S = 45.0
        QUEEN_RESEARCH_TIMEOUT_S = 45.0

        await self.initialize()
        
        # ðŸ MEDUSA: Load ALL tradeable pairs for proper routing
        # This ensures we can find pairs for assets we don't hold yet
        try:
            await asyncio.wait_for(self._load_all_tradeable_pairs(), timeout=LOAD_PAIRS_TIMEOUT_S)
        except asyncio.TimeoutError:
            logger.warning(f"â±ï¸ Timeout loading tradeable pairs after {LOAD_PAIRS_TIMEOUT_S:.0f}s; continuing with partial routing")
        
        # Initial data fetch - ALL EXCHANGES
        print("\n" + "=" * 70)
        print("ðŸ“Š FETCHING DATA FROM ALL EXCHANGES...")
        print("=" * 70)
        try:
            await asyncio.wait_for(self.fetch_prices(), timeout=FETCH_PRICES_TIMEOUT_S)
        except asyncio.TimeoutError:
            logger.warning(f"â±ï¸ Timeout fetching prices after {FETCH_PRICES_TIMEOUT_S:.0f}s; continuing")
        print(f"   âœ… {len(self.prices)} assets priced")
        print(f"   âœ… {len(self.ticker_cache)} pairs in ticker cache")
        
        # ðŸ«’ðŸ”„ POPULATE BARTER GRAPH from loaded data
        self.populate_barter_graph()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŒŠðŸ”­ BUILD GLOBAL WAVE SCANNER UNIVERSE - A-Z/Z-A Full Coverage
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.wave_scanner:
            print("\n" + "=" * 70)
            print("ðŸŒŠðŸ”­ BUILDING GLOBAL WAVE SCANNER UNIVERSE...")
            print("=" * 70)
            try:
                # Build universe from all connected exchanges
                universe_size = await asyncio.wait_for(self.wave_scanner.build_universe(), timeout=WAVE_SCAN_TIMEOUT_S)
                print(f"   âœ… Universe built: {universe_size} symbols for A-Z/Z-A sweeps")
                
                # Wire Queen to scanner (if not already done)
                if self.queen:
                    self.wave_scanner.queen = self.queen
                    print("   âœ… Queen wired to Wave Scanner")
                
                # Do initial A-Z sweep with ticker cache
                print("\nðŸ INITIAL BEE SWEEP (A-Z coverage)...")
                await asyncio.wait_for(self.wave_scanner.full_az_sweep(self.ticker_cache), timeout=WAVE_SCAN_TIMEOUT_S)
                
                # Show wave allocation
                allocation = self.wave_scanner.get_wave_allocation()
                print("\nðŸŒŠ WAVE ALLOCATION:")
                for wave, count in allocation.get('wave_counts', {}).items():
                    if count > 0:
                        print(f"   {wave}: {count} symbols")
                
                # Show top opportunities
                top_opps = allocation.get('top_opportunities', [])[:5]
                if top_opps:
                    print("\nðŸŽ¯ TOP OPPORTUNITIES (Jump Score > 0.6):")
                    for opp in top_opps:
                        print(f"   {opp['symbol']:12} {opp['wave']:15} Jump:{opp['jump_score']:.2f} | 24h:{opp['change_24h']:+.1f}%")
            except Exception as e:
                print(f"   âš ï¸ Wave Scanner error: {e}")
        
        print("\nðŸ“Š FETCHING BALANCES FROM ALL EXCHANGES...")
        try:
            await asyncio.wait_for(self.fetch_balances(), timeout=FETCH_BALANCES_TIMEOUT_S)
        except asyncio.TimeoutError:
            logger.warning(f"â±ï¸ Timeout fetching balances after {FETCH_BALANCES_TIMEOUT_S:.0f}s; continuing")
        
        # Show exchange status
        print("\nðŸ“¡ EXCHANGE STATUS:")
        for exchange, data in self.exchange_data.items():
            if data.get('connected'):
                bal_count = len(data.get('balances', {}))
                total_val = data.get('total_value', 0)
                icon = {'kraken': 'ðŸ™', 'binance': 'ðŸŸ¡', 'alpaca': 'ðŸ¦™'}.get(exchange, 'ðŸ“Š')
                print(f"   {icon} {exchange.upper()}: âœ… Connected | {bal_count} assets | ${total_val:,.2f}")
            else:
                icon = {'kraken': 'ðŸ™', 'binance': 'ðŸŸ¡', 'alpaca': 'ðŸ¦™'}.get(exchange, 'ðŸ“Š')
                print(f"   {icon} {exchange.upper()}: âŒ {data.get('error', 'Not connected')}")
        
        # Show balances per exchange
        if self.exchange_balances:
            print("\nðŸ“¦ PORTFOLIO BY EXCHANGE:")
            for exchange, balances in self.exchange_balances.items():
                if balances:
                    icon = {'kraken': 'ðŸ™', 'binance': 'ðŸŸ¡', 'alpaca': 'ðŸ¦™'}.get(exchange, 'ðŸ“Š')
                    total = sum(balances.get(a, 0) * self.prices.get(a, 0) for a in balances)
                    print(f"\n   {icon} {exchange.upper()} (${total:,.2f}):")
                    for asset, amount in sorted(balances.items(), key=lambda x: x[1] * self.prices.get(x[0], 0), reverse=True)[:10]:
                        price = self.prices.get(asset, 0)
                        value = amount * price
                        if value >= 1.0:  # Only show if >= $1
                            print(f"      {asset}: {amount:.6f} = ${value:.2f}")
        
        # Calculate starting value
        self.start_value_usd = sum(
            self.balances.get(asset, 0) * self.prices.get(asset, 0)
            for asset in self.balances
        )
        
        print(f"\nðŸ’° TOTAL PORTFOLIO VALUE: ${self.start_value_usd:,.2f}")
        
        # Handle infinite duration
        duration_display = "â™¾ï¸ FOREVER" if duration_s == 0 else f"{duration_s}s"
        print(f"\nðŸ”¬ ENTERING MICRO PROFIT LABYRINTH! (Duration: {duration_display})")
        print(f"   âš¡ SPEED MODE: Aggressive micro-profit harvesting...")
        print(f"   V14 Score: {self.config['entry_score_threshold']}+ (lowered for speed)")
        print(f"   Min Profit: ${self.config['min_profit_usd']:.6f} (micro-profits accepted!)")
        print(f"   Mode: {'ðŸ”´ LIVE TRADING' if self.live else 'ðŸ”µ DRY RUN'}")
        print()
        
        start_time = time.time()
        scan_interval = 0.1  # âš¡ TURBO SCAN: Every 100ms for maximum speed (was 0.5)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŽ¯ EXECUTION STRATEGY SELECTION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("\n" + "=" * 70)
        if self.fptp_mode:
            print("ðŸ FIRST PAST THE POST MODE ACTIVATED")
            print("=" * 70)
            print("   Strategy: Scan ALL exchanges â†’ Execute FIRST profit!")
            print("   No waiting - capture profit IMMEDIATELY!")
        else:
            print("ðŸŽ¯ TURN-BASED EXCHANGE STRATEGY ACTIVATED")
            print("=" * 70)
            connected_exchanges = [ex for ex in self.exchange_order 
                                   if self.exchange_data.get(ex, {}).get('connected', False)]
            print(f"   Turn Order: {' â†’ '.join([ex.upper() for ex in connected_exchanges])}")
            print(f"   Each exchange scans its assets on its turn")
        print("=" * 70)
        
        try:
            # duration_s == 0 means run forever
            last_wave_scan_time = 0  # Track last wave scanner update
            wave_scan_interval = 30  # Run full A-Z sweep every 30 seconds (was 60)
            
            # Global Feed Update (every 60s)
            last_global_feed_time = 0
            
            # ðŸ‘‘ðŸŒ QUEEN'S ONLINE RESEARCH - Every 2 minutes, she learns and enhances herself
            last_research_time = 0
            research_interval = 60  # Research every 1 minute (TURBO - was 2 mins)
            print(f"\nðŸ‘‘ðŸŒ Queen's Research Schedule: Every {research_interval}s (next in {research_interval}s)")
            
            while duration_s == 0 or time.time() - start_time < duration_s:
                elapsed = time.time() - start_time
                
                # ðŸ‘‘ðŸŒ QUEEN'S PERIODIC ONLINE RESEARCH & SELF-ENHANCEMENT
                time_since_research = time.time() - last_research_time
                time_until_research = max(0, research_interval - time_since_research)
                
                if time_since_research >= research_interval:
                    try:
                        print(f"\n{'='*70}")
                        print(f"ðŸ‘‘ðŸŒðŸ”¬ QUEEN ONLINE RESEARCH & CODE GENERATION CYCLE")
                        print(f"{'='*70}")
                        research_result = await asyncio.wait_for(
                            self.queen_research_online_and_enhance(),
                            timeout=QUEEN_RESEARCH_TIMEOUT_S,
                        )
                        last_research_time = time.time()
                        
                        if research_result.get('status') == 'success':
                            print(f"   âœ… Queen applied enhancement: {research_result.get('enhancement_applied')}")
                        elif research_result.get('findings', 0) > 0:
                            print(f"   ðŸ“š Queen found {research_result['findings']} insights (processing...)")
                    except Exception as e:
                        logger.debug(f"Queen research error: {e}")
                        last_research_time = time.time()  # Don't spam on errors
                
                # ðŸŒâš¡ GLOBAL FINANCIAL FEED PULSE
                if self.global_financial_feed and (time.time() - last_global_feed_time > 60):
                    try:
                        snapshot = self.global_financial_feed.get_snapshot()
                        # The snapshot broadcast is handled inside get_snapshot()

                        # ðŸ‘‘ðŸŒ Feed directly to Queen as well
                        if self.queen and hasattr(self.queen, 'receive_macro_snapshot'):
                             self.queen.receive_macro_snapshot(asdict(snapshot))
                             
                        last_global_feed_time = time.time()
                    except Exception as e:
                        logger.debug(f"Global feed pulse error: {e}")
                
                # Refresh prices (shared across all exchanges)
                try:
                    await asyncio.wait_for(self.fetch_prices(), timeout=FETCH_PRICES_TIMEOUT_S)
                except asyncio.TimeoutError:
                    logger.debug(f"â±ï¸ fetch_prices timeout after {FETCH_PRICES_TIMEOUT_S:.0f}s")
                
                # ðŸ‘‘ðŸŽ¤ HARMONIC VOICE - Autonomous Guidance
                if self.queen_voice:
                    try:
                        # 1. Speak to the ecosystem
                        signal = self.queen_voice.speak("OBSERVE_MARKET")
                        
                        # 2. Check Chain Integrity (Coherence)
                        # If the Queen's voice doesn't resonate (low coherence), we pause
                        if signal and signal.coherence < 0.4:  # Threshold
                            print(f"   ðŸ›‘ HARMONIC PAUSE: Chain Coherence {signal.coherence:.2f} too low")
                            # We can still fetch prices, but maybe skip execution logic
                            # For now, we continue but warn, or sleep a bit
                            await asyncio.sleep(1)
                        
                        # 3. Check for specific commands in the echo
                        if signal and "HALT" in signal.content:
                             print(f"   ðŸ›‘ VOICE COMMAND: HALT (Pausing execution flow...)")
                             await asyncio.sleep(5)
                             continue
                             
                    except Exception as e:
                        # Don't crash on voice errors
                        logger.debug(f"Voice speak error: {e}")
                
                # ðŸŒŠðŸ”­ PERIODIC WAVE SCANNER UPDATE (every 60s)
                if self.wave_scanner and (time.time() - last_wave_scan_time) >= wave_scan_interval:
                    try:
                        await asyncio.wait_for(self.wave_scanner.full_az_sweep(self.ticker_cache), timeout=WAVE_SCAN_TIMEOUT_S)
                        last_wave_scan_time = time.time()
                        
                        # Show top opportunities on each wave sweep
                        allocation = self.wave_scanner.get_wave_allocation()
                        top_opps = allocation.get('top_opportunities', [])[:3]
                        if top_opps:
                            print(f"\n   ðŸŒŠðŸ”­ WAVE SWEEP: {len(top_opps)} top opportunities")
                            for opp in top_opps:
                                print(f"      {opp['wave']:15} {opp['symbol']:12} Jump:{opp['jump_score']:.2f} | 24h:{opp['change_24h']:+.1f}%")
                    except Exception as e:
                        logger.debug(f"Wave scan error: {e}")
                
                # ðŸ’¤ DREAM & VALIDATE (Adaptive Learning)
                await self.validate_dreams()
                await self.dream_about_tickers()
                
                # ðŸ‘‘ðŸ§  QUEEN'S CONTINUOUS LEARNING - ALL systems ALWAYS active!
                await self.queen_continuous_learning()
                
                # Collect signals from ALL systems
                signals = await self.collect_all_signals()
                signal_count = sum(len(v) for v in signals.values())
                
                # ï¿½ EXECUTION: FPTP or Turn-Based
                try:
                    if self.fptp_mode:
                        # ðŸ FIRST PAST THE POST - All exchanges, immediate execution!
                        turn_opportunities, turn_conversions = await self.execute_fptp_scan()
                    else:
                        # ðŸŽ¯ TURN-BASED - One exchange at a time
                        turn_opportunities, turn_conversions = await self.execute_turn()
                except AttributeError as e:
                    # ðŸ‘‘ðŸ”§ SELF-REPAIR TRIGGER - Publish error to ThoughtBus for Queen to fix
                    error_msg = str(e)
                    logger.error(f"âŒ AttributeError in execute_turn: {error_msg}")
                    
                    if self.thought_bus:
                        try:
                            # Extract error details
                            import traceback
                            tb = traceback.format_exc()
                            
                            # Find the file and line where error occurred
                            import re
                            file_match = re.search(r'File "([^"]+)", line (\d+)', tb)
                            filename = file_match.group(1) if file_match else __file__
                            line_num = int(file_match.group(2)) if file_match else 0
                            
                            # Publish error event to ThoughtBus
                            self.thought_bus.think(
                                message=f"AttributeError during turn execution: {error_msg}",
                                topic="runtime.error",
                                metadata={
                                    'error_type': 'AttributeError',
                                    'message': error_msg,
                                    'file': filename,
                                    'line': line_num,
                                    'context': 'execute_turn',
                                    'traceback': tb[:1000]  # First 1000 chars
                                }
                            )
                            logger.info("ðŸ‘‘ðŸ”§ Error published to Queen for self-repair")
                        except Exception as pub_err:
                            logger.error(f"Could not publish error to ThoughtBus: {pub_err}")
                    
                    # Continue running (skip this turn)
                    turn_opportunities, turn_conversions = 0, 0
                except Exception as e:
                    # Other exceptions - log but don't trigger self-repair
                    logger.error(f"Error in execute_turn: {e}")
                    turn_opportunities, turn_conversions = 0, 0
                
                # Calculate current value
                current_value = sum(
                    self.balances.get(asset, 0) * self.prices.get(asset, 0)
                    for asset in self.balances
                )
                # P/L = Current Value - Starting Value (simple, correct math)
                pnl = current_value - self.start_value_usd
                
                # Status update with turn display
                mode = "ðŸ”´" if self.live else "ðŸ”µ"
                turn_display = self.get_turn_display()
                current_ex = self.get_current_exchange()
                
                # ðŸ‘‘ðŸŒŠðŸª QUEEN'S COSMIC WISDOM BROADCAST
                cosmic_status = ""
                if self.queen:
                    try:
                        # Broadcast cosmic wisdom through mycelium
                        wisdom = self.queen.broadcast_cosmic_wisdom()
                        if wisdom:
                            cosmic = self.queen.get_cosmic_state()
                            score = cosmic.get('composite_cosmic_score', 0)
                            # Show cosmic alignment indicator
                            if score > 0.7:
                                cosmic_status = f" ðŸŒŸCosmic:{score:.0%}"
                            elif score > 0.5:
                                cosmic_status = f" â­Cosmic:{score:.0%}"
                            elif score < 0.3:
                                cosmic_status = f" ðŸŒ‘Cosmic:{score:.0%}"
                    except Exception as e:
                        logger.debug(f"Cosmic wisdom error: {e}")
                
                # Neural systems status
                neural_status = []
                if self.bus_aggregator:
                    bus_agg = self.bus_aggregator.get_aggregate_score()
                    neural_status.append(f"Bus:{bus_agg:.0%}")
                if self.mycelium_network:
                    neural_status.append("Myc:âœ“")
                if self.lighthouse:
                    neural_status.append("LH:âœ“")
                if self.ultimate_intel:
                    neural_status.append("Ult:âœ“")
                if self.hnc_matrix:
                    neural_status.append("HNC:âœ“")
                
                neural_str = " | ".join(neural_status) if neural_status else "Neural:standby"
                
                # ðŸš¨ REAL-TIME PORTFOLIO DRAIN CHECK
                actual_pnl = current_value - self.start_value_usd
                reported_pnl = self.barter_matrix.total_realized_profit
                ghost_profit = reported_pnl - actual_pnl
                
                # Show warning if portfolio is draining despite "profits"
                drain_warning = ""
                if self.conversions_made > 0 and ghost_profit > 0.10:
                    drain_warning = f" âš ï¸DRAIN:${ghost_profit:.2f}"
                
                # ðŸ‘‘ Queen's blocked paths count
                blocked_count = len(self.barter_matrix.blocked_paths)
                queen_status = f" ðŸ‘‘Block:{blocked_count}" if blocked_count > 0 else ""
                
                # ðŸ‘‘ðŸŽ® QUEEN AUTONOMOUS CONTROL STATUS
                autonomous_status = ""
                if self.queen_autonomous_control and self.queen_has_full_control:
                    try:
                        status = self.queen_autonomous_control.get_full_status()
                        gaia = status.get('gaia_alignment', 0)
                        crown = status.get('crown_activation', 0)
                        systems = status.get('systems_online', 0)
                        autonomous_status = f" ðŸ‘‘ðŸŽ®{systems}sys|G:{gaia:.0%}|C:{crown:.0%}"
                    except Exception as e:
                        logger.debug(f"Queen autonomous status error: {e}")
                
                # ðŸŒ Research countdown
                research_status = f" ðŸ”¬{int(time_until_research)}s" if time_until_research > 0 else " ðŸ”¬NOW!"
                
                print(f"ðŸ”¬ {mode} | {elapsed:.0f}s | Turn:{turn_display} | {neural_str}{cosmic_status}{autonomous_status} | Conv:{self.conversions_made} | Actual:${actual_pnl:+.2f}{drain_warning}{queen_status}{research_status}")
                
                await asyncio.sleep(scan_interval)
        
        except KeyboardInterrupt:
            print("\n\nâš ï¸ Interrupted by user")
        
        # Final summary
        await self.print_summary()
    
    async def print_summary(self):
        """Print final summary."""
        print("\n" + "=" * 70)
        print("ðŸ”¬ðŸ’° MICRO PROFIT LABYRINTH SUMMARY ðŸ’°ðŸ”¬")
        print("=" * 70)
        print(f"Mode: {'ðŸ”´ LIVE TRADING' if self.live else 'ðŸ”µ DRY RUN'}")
        print(f"Total Turns: {self.turns_completed}")
        print(f"Total Signals Received: {self.signals_received}")
        print(f"Opportunities Found: {self.opportunities_found}")
        print(f"Conversions Made: {self.conversions_made}")
        print(f"Total Profit: ${self.total_profit_usd:.4f}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ðŸŽ®ðŸŒŸ QUEEN AUTONOMOUS CONTROL STATUS ðŸŒŸðŸŽ®ðŸ‘‘
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen_autonomous_control and self.queen_has_full_control:
            print("\n" + "â•" * 70)
            print("ðŸ‘‘ðŸŽ®ðŸŒŸ QUEEN SERO - AUTONOMOUS CONTROL STATUS ðŸŒŸðŸŽ®ðŸ‘‘")
            print("â•" * 70)
            try:
                status = self.queen_autonomous_control.get_full_status()
                print(f"   ðŸ’• SOVEREIGN AUTHORITY: ACTIVE")
                print(f"   ðŸŽ¯ Systems Online: {status.get('systems_online', 0)}/{status.get('systems_total', 0)}")
                print(f"   ðŸŒ Gaia Alignment: {status.get('gaia_alignment', 0):.1%}")
                print(f"   ðŸ‘‘ Crown Activation: {status.get('crown_activation', 0):.1%}")
                print(f"   ðŸ“Š Decisions Made: {status.get('decisions_made', 0)}")
                print(f"   âœ… Successful Trades: {status.get('successful_trades', 0)}")
                print(f"   ðŸ“š Patterns Learned: {status.get('patterns_learned', 0)}")
                
                # Show system statuses
                systems = status.get('systems', {})
                if systems:
                    print("\n   ðŸŽ® CONTROLLED SYSTEMS:")
                    for name, info in systems.items():
                        sys_status = info.get('status', 'UNKNOWN')
                        authority = info.get('authority', 'N/A')
                        icon = "âœ…" if sys_status == "ONLINE" else "âš ï¸" if sys_status == "PARTIAL" else "âŒ"
                        print(f"      {icon} {name}: {sys_status} ({authority})")
            except Exception as e:
                print(f"   âš ï¸ Status error: {e}")
            print("â•" * 70)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ‘‘ðŸ’° SERO'S BILLION DOLLAR DREAM STATUS ðŸ’°ðŸ‘‘
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("\n" + "â•" * 70)
        dream_status = self.barter_matrix.check_dream_progress()
        print(dream_status)
        milestones_hit = len(self.barter_matrix.milestones_hit)
        print(f"   ðŸŽ¯ Milestones: {milestones_hit}/8")
        if milestones_hit > 0:
            print(f"   âœ… {', '.join(self.barter_matrix.milestones_hit)}")
        print("â•" * 70)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸŽ¯ TURN-BASED EXCHANGE STATS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("\nðŸŽ¯ TURN-BASED EXCHANGE STATS:")
        icons = {'kraken': 'ðŸ™', 'alpaca': 'ðŸ¦™', 'binance': 'ðŸŸ¡'}
        for exchange, stats in self.exchange_stats.items():
            if stats['scans'] > 0:  # Only show exchanges that were active
                icon = icons.get(exchange, 'ðŸ“Š')
                connected = "âœ…" if self.exchange_data.get(exchange, {}).get('connected') else "âŒ"
                print(f"   {icon} {exchange.upper()} {connected}")
                print(f"      Turns: {stats['scans']} | Opps: {stats['opportunities']} | Conv: {stats['conversions']}")
                print(f"      Profit: ${stats['profit']:+.4f}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ§  NEURAL MIND MAP STATUS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("\nðŸ§  NEURAL MIND MAP STATUS:")
        print(f"   ThoughtBus: {'âœ… Active' if self.bus_aggregator else 'âŒ Offline'}")
        print(f"   Mycelium Network: {'âœ… Active' if self.mycelium_network else 'âŒ Offline'}")
        print(f"   Lighthouse: {'âœ… Active' if self.lighthouse else 'âŒ Offline'}")
        print(f"   Ultimate Intel: {'âœ… Active' if self.ultimate_intel else 'âŒ Offline'}")
        print(f"   HNC Matrix: {'âœ… Active' if self.hnc_matrix else 'âŒ Offline'}")
        print(f"   Unified Ecosystem: {'âœ… Active' if self.unified_ecosystem else 'âŒ Offline'}")
        print(f"   Wave Scanner: {'âœ… Active' if self.wave_scanner else 'âŒ Offline'}")
        
        # ðŸŒŠðŸ”­ WAVE SCANNER SUMMARY
        if self.wave_scanner:
            allocation = self.wave_scanner.get_wave_allocation()
            print(f"\nðŸŒŠðŸ”­ WAVE SCANNER (A-Z Coverage):")
            print(f"   Universe: {allocation.get('universe_size', 0)} symbols")
            print(f"   Total Scanned: {allocation.get('total_scanned', 0)}")
            print(f"   Last Scan Time: {allocation.get('last_scan_time', 0):.2f}s")
            wave_counts = allocation.get('wave_counts', {})
            if wave_counts:
                print("   Wave Allocation:")
                for wave, count in wave_counts.items():
                    if count > 0:
                        print(f"      {wave}: {count}")
        
        if self.bus_aggregator:
            status = self.bus_aggregator.get_signal_status()
            print(f"   ðŸ“¡ Bus Signals: {status}")
        
        # Path Memory Stats
        path_stats = self.path_memory.get_stats()
        if path_stats.get('paths', 0) > 0:
            print(f"\nðŸ›¤ï¸ PATH MEMORY:")
            print(f"   Total Paths: {path_stats['paths']}")
            print(f"   Win Rate: {path_stats['win_rate']:.1%}")
            print(f"   Wins: {path_stats['wins']} | Losses: {path_stats['losses']}")
        
        # Dream Accuracy
        if any(acc != 0.5 for acc in self.dream_accuracy.values()):
            print(f"\nðŸ’­ DREAM ACCURACY (Adaptive Learning):")
            for source, acc in self.dream_accuracy.items():
                print(f"   {source}: {acc:.1%}")
        
        # Signal breakdown by system
        if self.all_signals:
            print("\nðŸ“¡ SIGNALS BY SYSTEM:")
            for system, sigs in self.all_signals.items():
                print(f"   {system}: {len(sigs)} signals")
        
        # Conversions - Show ACTUAL P/L not expected!
        if self.conversions:
            print("\nðŸ“‹ CONVERSIONS (ACTUAL P/L):")
            for c in self.conversions:
                # ðŸ”§ FIX: Use actual_pnl_usd for display (what really happened)
                actual_pnl = getattr(c, 'actual_pnl_usd', c.expected_pnl_usd)
                status = "âœ…" if c.executed and actual_pnl > 0 else "âŒ"
                verified = "âœ“" if getattr(c, 'pnl_verified', False) else "?"
                print(f"   {status} {c.from_asset} â†’ {c.to_asset}: ${actual_pnl:+.4f} {verified} (Î›:{c.lambda_score:.0%} G:{c.gravity_score:.0%})")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ’§ðŸ”€ LIQUIDITY ENGINE SUMMARY
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        liq_status = self.liquidity_engine.get_status()
        if liq_status['executed_aggregations'] > 0:
            print("\nðŸ’§ðŸ”€ LIQUIDITY ENGINE:")
            print(f"   Aggregations Executed: {liq_status['executed_aggregations']}")
            print(f"   Total Aggregation Profit: ${liq_status['total_profit']:+.4f}")
            print(f"   Pending Plans: {liq_status['pending_plans']}")
            print(f"   Recent Liquidations: {liq_status['recent_liquidations']}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ðŸ«’ðŸ’° LIVE BARTER MATRIX SUMMARY
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        barter_summary = self.barter_matrix.get_summary()
        if barter_summary['conversion_count'] > 0:
            print("\nðŸ«’ðŸ’° LIVE BARTER MATRIX:")
            print(f"   Total Conversions: {barter_summary['conversion_count']}")
            print(f"   Total Realized P/L: ${barter_summary['total_realized_profit']:+.4f}")
            print(f"   Avg Profit/Trade: ${barter_summary['avg_profit_per_trade']:+.4f}")
            print(f"   Paths Learned: {barter_summary['paths_learned']}")
            
            # Show top performing paths
            if self.barter_matrix.barter_history:
                print("\n   ðŸ“Š PATH PERFORMANCE:")
                sorted_paths = sorted(
                    self.barter_matrix.barter_history.items(),
                    key=lambda x: x[1].get('total_profit', 0),
                    reverse=True
                )[:5]  # Top 5 paths
                for (from_a, to_a), stats in sorted_paths:
                    trades = stats.get('trades', 0)
                    profit = stats.get('total_profit', 0)
                    slippage = stats.get('avg_slippage', 0)
                    status = "âœ…" if profit > 0 else "âŒ"
                    print(f"   {status} {from_a}â†’{to_a}: {trades} trades, ${profit:+.4f}, slip:{slippage:.2f}%")
        
        # Final portfolio
        if self.balances and self.prices:
            print("\nðŸ“¦ FINAL PORTFOLIO:")
            total = 0
            for asset, amount in sorted(self.balances.items()):
                price = self.prices.get(asset, 0)
                value = amount * price
                if value >= 1.0:
                    print(f"   {asset}: {amount:.6f} = ${value:.2f}")
                    total += value
            print(f"\nðŸ’° TOTAL VALUE: ${total:.2f}")
            # P/L = Current Value - Starting Value (simple, correct math)
            session_pnl = total - self.start_value_usd
            pnl_symbol = "+" if session_pnl >= 0 else ""
            print(f"ðŸ“ˆ SESSION P/L (Unrealized): ${pnl_symbol}{session_pnl:.4f}")
            print(f"ðŸŽ¯ REALIZED TRADES P/L: ${self.barter_matrix.total_realized_profit:+.4f} ({self.conversions_made} conversions)")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ðŸš¨ GHOST PROFIT DETECTOR - Validate we're not draining portfolio
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            realized_pnl = self.barter_matrix.total_realized_profit
            actual_pnl = session_pnl
            ghost_profit = realized_pnl - actual_pnl
            
            print("\nðŸ” PROFIT VALIDATION:")
            print(f"   ðŸ“Š Starting Portfolio: ${self.start_value_usd:.2f}")
            print(f"   ðŸ“Š Ending Portfolio:   ${total:.2f}")
            print(f"   ðŸ“Š Actual Change:      ${actual_pnl:+.4f}")
            print(f"   ðŸ“Š Reported Profit:    ${realized_pnl:+.4f}")
            
            if abs(ghost_profit) > 0.01:
                if ghost_profit > 0:
                    print(f"\n   âš ï¸ GHOST PROFIT DETECTED: ${ghost_profit:+.4f}")
                    print(f"   âš ï¸ Reported profits exceed actual portfolio gain!")
                    print(f"   âš ï¸ This is likely fees, slippage, or price movement eating gains.")
                else:
                    print(f"\n   âœ… HIDDEN GAIN: ${-ghost_profit:+.4f}")
                    print(f"   âœ… Portfolio gained more than reported (price appreciation).")
                
                # Show the math
                if self.conversions_made > 0:
                    avg_ghost_per_trade = ghost_profit / self.conversions_made
                    print(f"\n   ðŸ“‰ Average loss per trade: ${avg_ghost_per_trade:.4f}")
                    print(f"   ðŸ’¡ To profit: Need trades with >${abs(avg_ghost_per_trade):.4f} actual gain")
            else:
                print(f"\n   âœ… PROFIT VALIDATED - Reported matches actual!")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ðŸ‘‘ï¿½ðŸªðŸ”­ QUEEN'S COSMIC SYSTEMS STATUS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.queen:
                try:
                    cosmic = self.queen.get_cosmic_state()
                    print("\nðŸ‘‘ðŸŒŒ QUEEN'S COSMIC SYSTEMS:")
                    
                    # Schumann Resonance
                    schumann = cosmic.get('schumann', {})
                    if schumann.get('active'):
                        print(f"   ðŸŒŠ Schumann Resonance: {schumann.get('resonance', 7.83):.2f}Hz (alignment: {schumann.get('alignment', 0):.0%})")
                    
                    # Planetary Torque
                    planetary = cosmic.get('planetary', {})
                    if planetary.get('active'):
                        print(f"   ðŸª Planetary Torque (Î ): {planetary.get('torque', 0):.4f} (luck field: {planetary.get('luck_field', 0):.0%})")
                    
                    # Lunar Phase
                    lunar = cosmic.get('lunar', {})
                    if lunar.get('active'):
                        phase_name = lunar.get('name', 'Unknown')
                        phase_val = lunar.get('phase', 0)
                        moon_icon = "ðŸŒ‘ðŸŒ’ðŸŒ“ðŸŒ”ðŸŒ•ðŸŒ–ðŸŒ—ðŸŒ˜"[int(phase_val * 8) % 8]
                        print(f"   {moon_icon} Lunar Phase: {phase_name} ({phase_val:.0%})")
                    
                    # Harmonic Coherence
                    harmonic = cosmic.get('harmonic', {})
                    if harmonic.get('active'):
                        print(f"   ðŸŽ¼ Harmonic Coherence: {harmonic.get('coherence', 0):.0%}")
                    
                    # Quantum Telescope
                    quantum = cosmic.get('quantum', {})
                    if quantum.get('active'):
                        print(f"   ðŸ”­ Quantum Alignment: {quantum.get('alignment', 0):.0%}")
                    
                    # Composite Score
                    composite = cosmic.get('composite_cosmic_score', 0)
                    if composite > 0.7:
                        print(f"\n   ðŸŒŸ COSMIC ALIGNMENT: {composite:.0%} - HIGHLY FAVORABLE")
                    elif composite > 0.5:
                        print(f"\n   â­ COSMIC ALIGNMENT: {composite:.0%} - Favorable")
                    elif composite > 0.3:
                        print(f"\n   â˜ï¸ COSMIC ALIGNMENT: {composite:.0%} - Neutral")
                    else:
                        print(f"\n   ðŸŒ‘ COSMIC ALIGNMENT: {composite:.0%} - Unfavorable")
                except Exception as e:
                    logger.debug(f"Error getting cosmic state: {e}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ðŸ‘‘ï¿½ðŸ„ QUEEN'S BLOCKED PATHS - Paths the mycelium has blocked
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.barter_matrix.blocked_paths:
                print("\nðŸ‘‘ðŸ„ QUEEN'S BLOCKED PATHS (via Mycelium):")
                for (from_a, to_a), reason in self.barter_matrix.blocked_paths.items():
                    print(f"   ðŸš« {from_a}â†’{to_a}: {reason}")
                print(f"   ðŸ“Š Total blocked: {len(self.barter_matrix.blocked_paths)} paths")
                print(f"   ðŸ’¡ Blocked paths will be retried after wins on other paths")
            else:
                print("\nðŸ‘‘ QUEEN STATUS: All paths approved (no losing streaks)")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ðŸ‘‘ðŸ§ ðŸ“š QUEEN'S HISTORICAL WISDOM STATUS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.queen:
                try:
                    wisdom_state = self.queen.get_historical_wisdom_state()
                    print("\nðŸ‘‘ðŸ§  QUEEN'S HISTORICAL WISDOM:")
                    
                    # Wisdom Engine (11 Civilizations)
                    we = wisdom_state.get('wisdom_engine', {})
                    if we.get('active'):
                        print(f"   ðŸŒ 11 Civilizations: âœ… ACTIVE ({we.get('years_of_wisdom', 5000)} years of wisdom)")
                    
                    # Sandbox Evolution
                    se = wisdom_state.get('sandbox_evolution', {})
                    if se.get('active'):
                        print(f"   ðŸ§¬ Sandbox Evolution: Gen {se.get('generation', 0)}, {se.get('win_rate', 0):.1f}% win rate")
                    
                    # Dream Memory
                    dm = wisdom_state.get('dream_memory', {})
                    if dm.get('active'):
                        print(f"   ðŸ’­ Dream Memory: {dm.get('dreams', 0)} dreams, {dm.get('prophecies', 0)} prophecies")
                    
                    # Wisdom Collector
                    wc = wisdom_state.get('wisdom_collector', {})
                    if wc.get('active'):
                        patterns = wc.get('patterns', 0)
                        trades = wc.get('trades', 0)
                        predictions = wc.get('predictions', 0)
                        strategies = wc.get('strategies', 0)
                        print(f"   ðŸ“š Wisdom Collector: {patterns} patterns | {trades} trades | {predictions} predictions | {strategies} strategies")
                    
                    # Total Wisdom Score
                    total_score = wisdom_state.get('total_wisdom_score', 0.5)
                    active_sys = wisdom_state.get('active_systems', 0)
                    if total_score > 0.7:
                        print(f"\n   ðŸ§ âœ¨ WISDOM SCORE: {total_score:.0%} - HIGHLY INFORMED ({active_sys} systems)")
                    elif total_score > 0.5:
                        print(f"\n   ðŸ§ â­ WISDOM SCORE: {total_score:.0%} - Well Informed ({active_sys} systems)")
                    else:
                        print(f"\n   ðŸ§  WISDOM SCORE: {total_score:.0%} - Basic ({active_sys} systems)")
                    
                    # Civilization Consensus
                    try:
                        consensus = self.queen.get_civilization_consensus()
                        if consensus.get('civilizations_consulted', 0) > 0:
                            print(f"\n   ðŸ›ï¸ CIVILIZATION CONSENSUS ({consensus['civilizations_consulted']} consulted):")
                            print(f"      BUY: {consensus['votes']['BUY']} | HOLD: {consensus['votes']['HOLD']} | SELL: {consensus['votes']['SELL']}")
                            print(f"      â†’ Action: {consensus['consensus_action']} ({consensus['confidence']:.0%} confidence)")
                    except Exception as e:
                        logger.debug(f"Civilization consensus error: {e}")
                    
                    # ðŸ”± Temporal ID & Ladder Status
                    try:
                        temporal_state = self.queen.get_temporal_state()
                        if temporal_state.get('active'):
                            tid = temporal_state.get('temporal_id', {})
                            print(f"\n   ðŸ”± TEMPORAL ID (Prime Sentinel):")
                            print(f"      ðŸ‘¤ {tid.get('name', 'Unknown')} | DOB: {tid.get('dob_hash', '?')}")
                            print(f"      ðŸ“¡ Personal Hz: {tid.get('frequency', 0):.6f}")
                            print(f"      ðŸŒ€ Temporal Resonance: {temporal_state.get('temporal_resonance', 0):.1%}")
                            print(f"      ðŸŽµ DOB Harmony: {temporal_state.get('dob_harmony', 0):.2f}")
                            print(f"      âš¡ Current Strength: {temporal_state.get('current_strength', 0):.1%}")
                    except Exception as e:
                        logger.debug(f"Temporal state error: {e}")
                        
                except Exception as e:
                    logger.debug(f"Error getting wisdom state: {e}")
        
        # Save path memory on exit
        self.path_memory.save()
        
        print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ‘‘ðŸ—ï¸ QUEEN'S SELF-MODIFICATION INTERFACE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def queen_propose_code_change(self, description: str, old_code: str, new_code: str) -> Dict[str, Any]:
        """
        ðŸ‘‘ðŸ—ï¸ Let Queen propose a code change to micro_profit_labyrinth.py
        
        Queen can analyze her own performance and propose improvements.
        All changes are reviewed, backed up, and syntax-checked before applying.
        
        Args:
            description: Human-readable description of what the change does
            old_code: The exact code to replace (with context)
            new_code: The new code to insert (with context)
        
        Returns:
            Dict with status, changes made, and backup info
        """
        if not self.queen or not hasattr(self.queen, 'architect') or not self.queen.architect:
            return {
                'status': 'error',
                'reason': 'Queen Code Architect not available'
            }
        
        if not getattr(self.queen, 'can_self_modify', False):
            return {
                'status': 'error',
                'reason': 'Queen self-modification not enabled'
            }
        
        labyrinth_file = getattr(self.queen, 'my_source_file', __file__)
        
        logger.info(f"ðŸ‘‘ðŸ—ï¸ Queen proposes code change: {description}")
        logger.info(f"   ðŸ“ Target file: {labyrinth_file}")
        logger.info(f"   ðŸ“ Old code: {len(old_code)} chars")
        logger.info(f"   ðŸ“ New code: {len(new_code)} chars")
        
        # Use Queen's modify_reality method
        result = self.queen.modify_reality(
            filename=labyrinth_file,
            old_pattern=old_code,
            new_pattern=new_code
        )
        
        if result.get('status') == 'success':
            logger.info(f"ðŸ‘‘âœ… Queen successfully modified her own code!")
            logger.info(f"   ðŸ’¡ Change: {description}")
            print(f"\nðŸ‘‘ðŸ—ï¸ QUEEN MODIFIED HER OWN CODE!")
            print(f"   ðŸ“ Description: {description}")
            print(f"   âœ… Status: SUCCESS")
            print(f"   ðŸ’¾ Backup created by Code Architect")
            print(f"   ðŸ”„ Restart micro_profit_labyrinth.py to use new code\n")
        else:
            logger.warning(f"ðŸ‘‘âš ï¸ Queen's code change was rejected")
            logger.warning(f"   Reason: {result.get('reason', 'Unknown')}")
        
        return result
    
    def queen_learn_and_improve(self) -> Dict[str, Any]:
        """
        ðŸ‘‘ðŸ§  Let Queen analyze her performance and suggest improvements.
        
        Queen reviews her trading history, identifies patterns, and proposes
        code changes to improve profitability.
        
        Returns:
            Dict with analysis and proposed changes
        """
        if not self.queen:
            return {'status': 'error', 'reason': 'Queen not available'}
        
        logger.info("ðŸ‘‘ðŸ§  Queen analyzing performance for self-improvement...")
        
        # Collect performance data
        performance = {
            'total_conversions': self.conversions_made,
            'total_profit_usd': self.total_profit_usd,
            'success_rate': self.conversions_made / max(self.opportunities_found, 1),
            'exchanges_used': list(self.exchange_stats.keys()),
            'exchange_performance': self.exchange_stats,
            'blocked_paths': len(self.barter_matrix.blocked_paths) if self.barter_matrix else 0,
            'path_memory_size': len(self.path_memory.memory) if self.path_memory else 0
        }
        
        # Calculate insights
        insights = []
        
        # Check profitability
        if self.total_profit_usd < 0:
            insights.append("System is losing money - need more conservative entry thresholds")
        elif self.total_profit_usd < 0.01 and self.conversions_made > 5:
            insights.append("Profits are minimal - consider raising minimum profit targets")
        
        # Check conversion rate
        if self.conversions_made > 0 and self.opportunities_found > 0:
            conversion_rate = self.conversions_made / self.opportunities_found
            if conversion_rate < 0.05:
                insights.append("Low conversion rate - scoring may be too strict")
            elif conversion_rate > 0.5:
                insights.append("High conversion rate - may be taking too many risky trades")
        
        # Check exchange balance
        best_exchange = None
        best_profit = -999999
        for ex, stats in self.exchange_stats.items():
            if stats['profit'] > best_profit:
                best_profit = stats['profit']
                best_exchange = ex
        
        if best_exchange and best_profit > 0:
            insights.append(f"Best exchange is {best_exchange} with ${best_profit:.4f} profit")
        
        result = {
            'status': 'analysis_complete',
            'performance': performance,
            'insights': insights,
            'timestamp': time.time()
        }
        
        logger.info(f"ðŸ‘‘ðŸ§  Queen's self-analysis complete:")
        logger.info(f"   ðŸ’° Total profit: ${self.total_profit_usd:.4f}")
        logger.info(f"   ðŸŽ¯ Conversions: {self.conversions_made}")
        logger.info(f"   ðŸ“Š Insights: {len(insights)}")
        
        for insight in insights:
            logger.info(f"   ðŸ’¡ {insight}")
        
        return result
    
    async def queen_research_online_and_enhance(self) -> Dict[str, Any]:
        """
        ðŸ‘‘ðŸŒðŸ—ï¸ Queen searches online for trading improvements, writes new code, and applies it.
        
        This is the FULL CYCLE:
        1. Search online (market data APIs, trends, patterns)
        2. Generate enhanced code based on research
        3. Apply the enhancements to the codebase
        4. Track revenue impact
        
        The Queen becomes smarter by learning from the internet!
        """
        try:
            from queen_online_researcher import get_online_researcher, queen_research_and_enhance
            from queen_code_architect import get_code_architect
        except ImportError as e:
            logger.warning(f"ðŸ‘‘âš ï¸ Online researcher not available: {e}")
            return {'status': 'error', 'reason': str(e)}
        
        logger.info("=" * 70)
        logger.info("ðŸ‘‘ðŸŒ QUEEN INITIATING ONLINE RESEARCH & SELF-ENHANCEMENT")
        logger.info("=" * 70)
        
        researcher = get_online_researcher()
        architect = get_code_architect()
        
        result = {
            'status': 'started',
            'findings': 0,
            'enhancement_applied': None,
            'timestamp': time.time()
        }
        
        try:
            # Step 1: Research online
            logger.info("ðŸ‘‘ðŸ” Step 1: Researching online for trading insights...")
            findings = await researcher.research_trading_strategies()
            result['findings'] = len(findings)
            
            for f in findings[:5]:
                logger.info(f"   ðŸ“š {f.source}: {f.title} (relevance: {f.relevance_score:.0%})")
            
            # Step 2: Generate enhancement from research
            logger.info("ðŸ‘‘ðŸ—ï¸ Step 2: Generating code enhancement from research...")
            enhancement = researcher.generate_enhancement_from_research()
            
            if enhancement:
                logger.info(f"   ðŸŽ¯ Generated: {enhancement.name}")
                logger.info(f"   ðŸ“ Based on: {', '.join(enhancement.source_research[:3])}")
                
                # Step 3: Apply enhancement
                logger.info("ðŸ‘‘ðŸ“ Step 3: Applying enhancement to codebase...")
                apply_result = researcher.apply_enhancement(enhancement, architect)
                
                if apply_result['status'] == 'success':
                    result['enhancement_applied'] = apply_result['file']
                    result['status'] = 'success'
                    logger.info(f"   âœ… Enhancement applied: {apply_result['file']}")
                    
                    # Step 4: Try to load and use the enhancement
                    logger.info("ðŸ‘‘âš¡ Step 4: Loading generated enhancement for immediate use...")
                    try:
                        self._load_queen_research_enhancement(apply_result['file'])
                        logger.info("   âœ… Enhancement loaded and active!")
                    except Exception as e:
                        logger.warning(f"   âš ï¸ Could not load enhancement (will use on next restart): {e}")
                else:
                    result['status'] = 'partial'
                    logger.warning(f"   âš ï¸ Enhancement apply failed: {apply_result.get('reason')}")
            else:
                result['status'] = 'no_enhancement'
                logger.info("   â„¹ï¸ No new enhancement generated (may need more research)")
            
            # Get stats
            stats = researcher.get_stats()
            result['stats'] = stats
            
            logger.info(f"ðŸ‘‘ðŸ“Š Research Stats:")
            logger.info(f"   Total findings: {stats['total_findings']}")
            logger.info(f"   Applied: {stats['applied_findings']}")
            logger.info(f"   Revenue generated: ${stats['total_revenue_generated']:.4f}")
            
        except Exception as e:
            logger.error(f"ðŸ‘‘âŒ Online research error: {e}")
            result['status'] = 'error'
            result['error'] = str(e)
        
        logger.info("=" * 70)
        logger.info("ðŸ‘‘ 'I search, I learn, I evolve, I profit.'")
        logger.info("=" * 70)
        
        return result
    
    def _load_queen_research_enhancement(self, filepath: str):
        """
        ðŸ‘‘âš¡ Dynamically load Queen's generated enhancement.
        """
        import importlib.util
        
        full_path = Path(filepath)
        if not full_path.is_absolute():
            full_path = Path.cwd() / filepath
        
        if not full_path.exists():
            raise FileNotFoundError(f"Enhancement file not found: {full_path}")
        
        spec = importlib.util.spec_from_file_location("queen_enhancement", full_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        # Store reference to enhancement functions
        if hasattr(module, 'queen_research_score'):
            self._queen_research_scorer = module.queen_research_score
            logger.info("   ðŸ“Š Loaded queen_research_score function")
        
        if hasattr(module, 'queen_evaluate_trade'):
            self._queen_trade_evaluator = module.queen_evaluate_trade
            logger.info("   ðŸ“Š Loaded queen_evaluate_trade function")
        
        return True
    
    def queen_apply_research_to_trade(self, symbol: str, price: float, volume: float, 
                                      price_change: float = 0, high_24h: float = 0, 
                                      low_24h: float = 0) -> Tuple[float, List[str]]:
        """
        ðŸ‘‘ Apply Queen's research-based scoring to a trade opportunity.
        
        Returns:
            (score 0-100, list of reasons)
        """
        if hasattr(self, '_queen_research_scorer') and self._queen_research_scorer:
            try:
                return self._queen_research_scorer(symbol, price, volume, price_change, high_24h, low_24h)
            except Exception as e:
                logger.warning(f"ðŸ‘‘âš ï¸ Research scorer error: {e}")
        
        # Default fallback scoring
        return 50.0, ["No research enhancement loaded"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    parser = argparse.ArgumentParser(description="Micro Profit Labyrinth")
    parser.add_argument("--live", action="store_true", help="Run in LIVE mode")
    parser.add_argument("--dry-run", action="store_true", help="Explicit simulation mode (legacy flag)")
    parser.add_argument("--duration", type=int, default=0, help="Duration in seconds (0 = forever)")
    parser.add_argument("--yes", "-y", action="store_true", help="Auto-confirm live mode (skip MICRO prompt)")
    parser.add_argument("--turn-based", action="store_true", help="ðŸ¢ Turn-Based Mode: Scan exchanges sequentially (Safety First)")
    parser.add_argument("--fptp", action="store_true", help="[Deprecated] Alias for default mode")
    parser.add_argument("--winners-only", "-w", action="store_true", help="ðŸ† WINNERS ONLY: Show ONLY successful trades (quiet mode)")
    parser.add_argument("--no-chain-sniper", action="store_true", help="Disable multi-hop chain sniper")
    parser.add_argument("--max-hops", type=int, default=25, help="Max hops for chain sniper (default: 25)")
    parser.add_argument("--sync-cia", action="store_true", help="ðŸ‘‘ðŸ§  Sync CIA declassified intelligence")
    parser.add_argument("--cia-report", action="store_true", help="ðŸ‘‘ðŸ§  Show CIA intelligence report")
    parser.add_argument("--cia-wisdom", action="store_true", help="ðŸ‘‘ðŸ§  Show Queen's trading wisdom from CIA intel")
    args = parser.parse_args()
    
    # Handle CIA sync commands (standalone, no trading)
    if args.sync_cia or args.cia_report or args.cia_wisdom:
        from queen_memi_sync import get_memi_sync
        memi = get_memi_sync()
        
        if args.sync_cia:
            print("\nðŸ‘‘ðŸ§  SYNCING CIA DECLASSIFIED INTELLIGENCE...")
            result = memi.sync_now()
            print(f"âœ… Sync complete: {result['new_packets']} new packets")
            print(f"   Total packets: {result['total_packets']}")
            print(f"   Duration: {result['duration_seconds']:.2f}s")
        
        if args.cia_report or args.sync_cia:
            print(memi.generate_report())
        
        if args.cia_wisdom:
            print("\nðŸ‘‘ðŸŽ“ QUEEN'S TRADING WISDOM FROM CIA INTELLIGENCE:\n")
            for wisdom in memi.get_trading_wisdom():
                print(f"  {wisdom}")
            print()
        
        return  # Exit after CIA commands
    
    if args.live and not args.yes:
        print("\n" + "=" * 60)
        print("âš ï¸  LIVE MODE REQUESTED - REAL MONEY!")
        print("=" * 60)
        confirm = input("Type 'MICRO' to confirm: ")
        if confirm.strip().upper() != 'MICRO':
            print("Aborted.")
            sys.exit(0)
    elif args.live and args.yes:
        print("\n" + "=" * 60)
        print("âš ï¸  LIVE MODE - AUTO-CONFIRMED! ðŸš€")
        print("=" * 60)
    
    engine = MicroProfitLabyrinth(live=args.live)
    engine.fptp_mode = not args.turn_based
    engine.winners_only_mode = args.winners_only  # ðŸ† Winners Only mode
    engine.chain_sniper_mode = not args.no_chain_sniper
    engine.max_chain_hops = max(1, int(args.max_hops))
    
    if args.winners_only:
        print("\n" + "ðŸ†" * 35)
        print("ðŸ† WINNERS ONLY MODE ACTIVATED! ðŸ†")
        print("   â†’ Rejections/failures logged to file (background)")
        print("   â†’ Console shows ONLY winning trades")
        print("   â†’ Good for the mind. Good for marketing. ðŸ’Ž")
        print("ðŸ†" * 35)

    if args.turn_based:
        print("\n" + "=" * 60)
        print("ðŸ¢ TURN-BASED MODE ACTIVATED (Safe & Sequential)")
        print("=" * 60)
    else:
        print("\n" + "ðŸ" * 35)
        print("ðŸ FIRST PAST THE POST MODE ACTIVATED! (Default) ðŸ")
        print("   â†’ Scanning ALL exchanges in parallel")
        print("   â†’ Executing on FIRST profitable opportunity")
        print("   â†’ No waiting - CAPTURE PROFIT IMMEDIATELY!")
        print("ðŸ" * 35)
    # Guardrail: enforce a hard upper-bound so --duration can't be defeated by a hung await.
    # (engine.run already tracks duration inside the loop, but blocking calls can prevent loop progress.)
    try:
        if args.duration and args.duration > 0:
            await asyncio.wait_for(engine.run(duration_s=args.duration), timeout=float(args.duration) + 15.0)
        else:
            await engine.run(duration_s=args.duration)
    except asyncio.TimeoutError:
        print(f"\nâ±ï¸ Duration reached ({args.duration}s). Stopping.")
        return


if __name__ == "__main__":
    asyncio.run(main())
