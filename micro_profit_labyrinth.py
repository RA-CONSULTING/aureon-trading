#!/usr/bin/env python3
"""
ğŸ”¬ğŸ’° MICRO PROFIT LABYRINTH ğŸ’°ğŸ”¬
=================================

ğŸ¦™ ALPACA-FOCUSED TRADING SYSTEM ğŸ¦™
All systems and subsystems are optimized for ALPACA platform trading.

Uses ALL existing systems but with LOWER thresholds for SNOWBALL effect!

V14 wants Score 8+ â†’ We use Score 6+ (more opportunities)
V14 wants 1.52% profit â†’ We want ANY net profit ($0.01+)
V14 has no stop loss â†’ We agree! Hold until profit!

THE PHILOSOPHY:
  - Any net profit > $0.01 is a WIN
  - More small wins = Faster snowball
  - Use existing system intelligence, just LOWER the bar
  - ğŸ¦™ ALPACA is our PRIMARY and DEFAULT exchange platform

Gary Leckey | January 2026 | SNOWBALL MODE | ALPACA-FOCUSED
"""

from __future__ import annotations

import os
import sys

# SAFE PRINT WRAPPER FOR WINDOWS
def safe_print(*args, **kwargs):
    """Safe print that ignores I/O errors on Windows exit."""
    try:
        # Use builtins.print to avoid recursion issues
        import builtins
        builtins.print(*args, **kwargs)
    except (ValueError, OSError):
        pass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WINDOWS UTF-8 FIX - MUST BE AT TOP BEFORE ANY PRINT STATEMENTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    try:
        import io
        import atexit
        
        def _is_utf8_wrapper(stream):
            """Check if stream is already a UTF-8 TextIOWrapper."""
            return (isinstance(stream, io.TextIOWrapper) and 
                    hasattr(stream, 'encoding') and 
                    stream.encoding and 
                    stream.encoding.lower().replace('-', '') == 'utf8')
        
        # ONLY wrap stdout (NOT stderr to prevent closure issues)
        if hasattr(sys.stdout, 'buffer') and not _is_utf8_wrapper(sys.stdout):
            try:
                sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
            except Exception:
                pass
        
        def _final_cleanup():
            """Final cleanup to suppress stderr issues on exit."""
            try:
                if hasattr(sys.stdout, 'flush'):
                    sys.stdout.flush()
            except Exception:
                pass
            # Suppress any remaining stderr errors by redirecting to devnull
            try:
                if hasattr(sys.stderr, 'close'):
                    import os as _os
                    sys.stderr = open(_os.devnull, 'w')
            except Exception:
                pass
        
        atexit.register(_final_cleanup)
    except Exception:
        pass

import asyncio
import argparse
import importlib
import logging
import time
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, TYPE_CHECKING
# Import Adaptive Prime Profit Gate
from adaptive_prime_profit_gate import AdaptivePrimeProfitGate
from cost_basis_tracker import CostBasisTracker


if TYPE_CHECKING:
    try:
        from mycelium_conversion_hub import MyceliumConversionHub as MyceliumConversionHubType
    except ImportError:
        MyceliumConversionHubType = Any
    try:
        from s5_v14_labyrinth import V14DanceEnhancer as V14DanceEnhancerType
    except ImportError:
        V14DanceEnhancerType = Any
    try:
        from aureon_conversion_commando import (
            AdaptiveConversionCommando as AdaptiveConversionCommandoType,
            PairScanner as PairScannerType,
            DualProfitPathEvaluator as DualProfitPathEvaluatorType,
        )
    except ImportError:
        AdaptiveConversionCommandoType = Any
        PairScannerType = Any
        DualProfitPathEvaluatorType = Any
    try:
        from aureon_conversion_ladder import ConversionLadder as ConversionLadderType
    except ImportError:
        ConversionLadderType = Any
    try:
        from kraken_client import KrakenClient as KrakenClientType
    except ImportError:
        KrakenClientType = Any
    try:
        from binance_client import BinanceClient as BinanceClientType
    except ImportError:
        BinanceClientType = Any
    try:
        from alpaca_client import AlpacaClient as AlpacaClientType
    except ImportError:
        AlpacaClientType = Any
    try:
        from aureon_thought_bus import ThoughtBus as ThoughtBusType
    except ImportError:
        ThoughtBusType = Any
    try:
        from adaptive_prime_profit_gate import AdaptivePrimeProfitGate as AdaptivePrimeProfitGateType
    except ImportError:
        AdaptivePrimeProfitGateType = Any
    try:
        from aureon_path_memory import PathMemory as PathMemoryType  # type: ignore[import-not-found]
    except ImportError:
        PathMemoryType = Any
    try:
        from dust_converter import DustConverter as DustConverterType, DustCandidate
    except ImportError:
        DustConverterType = Any
        DustCandidate = Any
else:
    MyceliumConversionHubType = Any
    V14DanceEnhancerType = Any
    AdaptiveConversionCommandoType = Any
    PairScannerType = Any
    DualProfitPathEvaluatorType = Any
    ConversionLadderType = Any
    KrakenClientType = Any
    BinanceClientType = Any
    AlpacaClientType = Any
    ThoughtBusType = Any
    AdaptivePrimeProfitGateType = Any
    PathMemoryType = Any
    DustConverterType = Any
    DustCandidate = Any

try:
    from aureon_path_memory import PathMemory  # type: ignore[import-not-found]
except ImportError:
    class PathMemory:  # type: ignore[too-many-instance-attributes]
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            self._store: Dict[str, Any] = {}

        def remember(self, key: str, value: Any) -> None:
            self._store[key] = value

        def recall(self, key: str, default: Any = None) -> Any:
            return self._store.get(key, default)

try:
    from aureon_barter_navigator import BarterMatrix
except ImportError:
    BarterMatrix = Any

# ğŸ¦™ğŸ“ˆ Stock Scanner Import (OPTIONAL - only if explicitly enabled)
# By default: Use Kraken/Binance for heavy lifting, Alpaca for execution only
if os.getenv("ALPACA_INCLUDE_STOCKS", "false").lower() == "true":
    try:
        from aureon_alpaca_stock_scanner import AlpacaStockScanner, StockOpportunity
        STOCK_SCANNER_AVAILABLE = True
    except ImportError:
        AlpacaStockScanner = None
        StockOpportunity = None
        STOCK_SCANNER_AVAILABLE = False
else:
    AlpacaStockScanner = None
    StockOpportunity = None
    STOCK_SCANNER_AVAILABLE = False

from collections import defaultdict, deque

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ” LOAD ENVIRONMENT VARIABLES FROM .env
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    dotenv_module = importlib.import_module("dotenv")
    load_dotenv = getattr(dotenv_module, "load_dotenv", None)
except ModuleNotFoundError:
    load_dotenv = None

if callable(load_dotenv):
    # Try multiple paths to find .env file
    from pathlib import Path
    env_paths = [
        Path(__file__).resolve().parent / ".env",  # Same dir as this script
        Path.cwd() / ".env",                        # Current working directory
        Path("/workspaces/aureon-trading/.env"),    # Absolute fallback
    ]
    env_loaded = False
    for env_path in env_paths:
        if env_path.exists():
            load_dotenv(dotenv_path=str(env_path), override=True)
            safe_print(f"ğŸ” Environment variables loaded from {env_path}")
            env_loaded = True
            break
    if not env_loaded:
        load_dotenv()  # Fall back to default search
        safe_print("ğŸ” Environment variables loaded (default search)")
else:
    safe_print("âš ï¸ python-dotenv not installed, using system env vars")

# Get exchange config from .env
KRAKEN_API_KEY = os.getenv("KRAKEN_API_KEY", "")
KRAKEN_API_SECRET = os.getenv("KRAKEN_API_SECRET", "")
KRAKEN_DRY_RUN = os.getenv("KRAKEN_DRY_RUN", "false").lower() == "true"
BINANCE_API_KEY = os.getenv("BINANCE_API_KEY", "")
BINANCE_API_SECRET = os.getenv("BINANCE_API_SECRET", "")
ALPACA_API_KEY = os.getenv("ALPACA_API_KEY", "")
ALPACA_SECRET_KEY = os.getenv("ALPACA_SECRET_KEY", "")
LIVE_MODE = os.getenv("LIVE", "0") == "1"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ MULTI-EXCHANGE CONFIG FLAGS (Production Pipeline)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ALPACA_VERIFY_ONLY: When True, Alpaca is used only for balance/price verification, not execution
ALPACA_VERIFY_ONLY = os.getenv("ALPACA_VERIFY_ONLY", "true").lower() == "true"
# ALPACA_EXECUTE: Explicit flag to enable Alpaca execution (overrides VERIFY_ONLY)
ALPACA_EXECUTE = os.getenv("ALPACA_EXECUTE", "false").lower() == "true"
# ALPACA_INCLUDE_STOCKS: ENABLED BY DEFAULT for stock scanning
# Checks specifically for stock opportunities alongside crypto
ALPACA_INCLUDE_STOCKS = os.getenv("ALPACA_INCLUDE_STOCKS", "true").lower() == "true"
# EXCH_EXEC_ORDER: Comma-separated execution priority (default: binance,kraken,capital,coinbase,alpaca)
EXCH_EXEC_ORDER = os.getenv("EXCH_EXEC_ORDER", "binance,kraken,capital,coinbase,alpaca").split(",")
# ENABLE_WEBSOCKETS: Use WebSocket streams for live data (faster than REST polling)
ENABLE_WEBSOCKETS = os.getenv("ENABLE_WEBSOCKETS", "true").lower() == "true"
# Capital.com API
CAPITAL_API_KEY = os.getenv("CAPITAL_API_KEY", "")
CAPITAL_API_SECRET = os.getenv("CAPITAL_API_SECRET", "")
# Coinbase API
COINBASE_API_KEY = os.getenv("COINBASE_API_KEY", "")
COINBASE_API_SECRET = os.getenv("COINBASE_API_SECRET", "")
# CoinGecko API (optional, for reference prices)
COINGECKO_API_KEY = os.getenv("COINGECKO_API_KEY", "")

safe_print(f"ğŸ”‘ Kraken API: {'âœ… Loaded' if KRAKEN_API_KEY else 'âŒ Missing'}")
safe_print(f"ğŸ”‘ Binance API: {'âœ… Loaded' if BINANCE_API_KEY else 'âŒ Missing'}")
safe_print(f"ğŸ”‘ Alpaca API: {'âœ… Loaded' if ALPACA_API_KEY else 'âŒ Missing'}")
safe_print(f"ğŸ”‘ Capital.com API: {'âœ… Loaded' if CAPITAL_API_KEY else 'âŒ Missing'}")
safe_print(f"ğŸ”‘ Coinbase API: {'âœ… Loaded' if COINBASE_API_KEY else 'âŒ Missing'}")
safe_print(f"âš™ï¸ LIVE Mode: {'âœ… Enabled' if LIVE_MODE else 'âŒ Disabled'}")
safe_print(f"ğŸ¦™ Alpaca: {'ğŸ”’ VERIFY-ONLY' if ALPACA_VERIFY_ONLY and not ALPACA_EXECUTE else 'ğŸš€ EXECUTE ENABLED'}")
safe_print(f"ğŸŒ Execution Order: {' â†’ '.join(EXCH_EXEC_ORDER)}")
safe_print(f"ğŸ“¡ WebSockets: {'âœ… Enabled' if ENABLE_WEBSOCKETS else 'âŒ Disabled'}")

# Safety guards (used across momentum and symbol handling)
MAX_MOMENTUM_PER_MIN = 1.0  # Cap momentum to 100%/min to avoid runaway scores
MIN_SYMBOL_LEN = 3           # Ignore obviously invalid short symbols

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXISTING SYSTEMS - ALL OF THEM!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from global_financial_feed import GlobalFinancialFeed
    safe_print("ğŸŒ Global Financial Feed LOADED!")
    GLOBAL_FEED_AVAILABLE = True
except ImportError as e:
    safe_print(f"âš ï¸ Global Financial Feed not available: {e}")
    GlobalFinancialFeed = None
    GLOBAL_FEED_AVAILABLE = False

try:
    from mycelium_conversion_hub import get_conversion_hub, MyceliumConversionHub
    safe_print("ğŸ„ Mycelium Conversion Hub LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ Mycelium Conversion Hub not available: {e}")
    MyceliumConversionHub = None
    get_conversion_hub = None

# Adaptive profit gate (dynamic fees/targets)
try:
    from adaptive_prime_profit_gate import AdaptivePrimeProfitGate
    ADAPTIVE_GATE_AVAILABLE = True
    safe_print("ğŸ’° Adaptive Prime Profit Gate LOADED!")
except ImportError as e:
    AdaptivePrimeProfitGate = None
    ADAPTIVE_GATE_AVAILABLE = False
    safe_print(f"âš ï¸ Adaptive Prime Profit Gate not available: {e}")

# ğŸ§¹ Dust Converter (sweep small balances to stablecoins)
try:
    from dust_converter import DustConverter, DustCandidate
    DUST_CONVERTER_AVAILABLE = True
    safe_print("ğŸ§¹ Dust Converter LOADED!")
except ImportError as e:
    DustConverter = None
    DustCandidate = None
    DUST_CONVERTER_AVAILABLE = False
    safe_print(f"âš ï¸ Dust Converter not available: {e}")

# ğŸª™âš¡ Penny Profit Turbo (enhanced profit math)
try:
    from penny_profit_turbo import get_penny_turbo, PennyProfitTurbo
    PENNY_TURBO_AVAILABLE = True
    safe_print("ğŸª™âš¡ Penny Profit TURBO LOADED!")
except ImportError as e:
    get_penny_turbo = None
    PennyProfitTurbo = None
    PENNY_TURBO_AVAILABLE = False
    safe_print(f"âš ï¸ Penny Profit Turbo not available: {e}")

# Lightweight Thought Bus for observability
try:
    from aureon_thought_bus import ThoughtBus
    THOUGHT_BUS_AVAILABLE = True
except ImportError as e:
    ThoughtBus = None
    THOUGHT_BUS_AVAILABLE = False
    safe_print(f"âš ï¸ Thought Bus not available: {e}")

# ğŸª† Russian Doll Analytics - Fractal measurement system (Queenâ†’Hiveâ†’Bee)
try:
    from aureon_russian_doll_analytics import (
        RussianDollAnalytics, 
        get_analytics, 
        record_scan, 
        record_exchange,
        update_queen,
        print_dashboard as print_russian_doll_dashboard,
        get_directives
    )
    RUSSIAN_DOLL_AVAILABLE = True
    safe_print("ğŸª† Russian Doll Analytics LOADED!")
except ImportError as e:
    RussianDollAnalytics = None
    get_analytics = None
    record_scan = None
    record_exchange = None
    update_queen = None
    print_russian_doll_dashboard = None
    get_directives = None
    RUSSIAN_DOLL_AVAILABLE = False
    safe_print(f"âš ï¸ Russian Doll Analytics not available: {e}")

try:
    from s5_v14_labyrinth import V14DanceEnhancer, V14_CONFIG
    safe_print("ğŸ† V14 Labyrinth LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ V14 Labyrinth not available: {e}")
    V14DanceEnhancer = None
    V14_CONFIG = {}

try:
    from aureon_conversion_commando import (
        AdaptiveConversionCommando,
        PairScanner,
        DualProfitPathEvaluator,
        MIN_PROFIT_TARGET,
    )
    safe_print("ğŸ¦… Conversion Commando LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ Conversion Commando not available: {e}")
    AdaptiveConversionCommando = None
    PairScanner = None
    DualProfitPathEvaluator = None
    MIN_PROFIT_TARGET = 0.0001  # Epsilon mode: accept any net-positive trade

try:
    from aureon_conversion_ladder import ConversionLadder
    safe_print("ğŸªœ Conversion Ladder LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ Conversion Ladder not available: {e}")
    ConversionLadder = None

# ğŸ HIVE STATE PUBLISHER - Live status & Queen's voice
try:
    from aureon_hive_state import get_hive, QueenVoiceBridge
    HIVE_STATE_AVAILABLE = True
    safe_print("ğŸ Hive State Publisher LOADED!")
except ImportError as e:
    get_hive = None
    QueenVoiceBridge = None
    HIVE_STATE_AVAILABLE = False
    safe_print(f"âš ï¸ Hive State Publisher not available: {e}")

try:
    from pure_conversion_engine import UnifiedConversionBrain, ConversionOpportunity
    safe_print("ğŸ”„ Pure Conversion Engine LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ Pure Conversion Engine not available: {e}")
    UnifiedConversionBrain = None
    ConversionOpportunity = None

try:
    from rapid_conversion_stream import RapidConversionStream
    safe_print("âš¡ Rapid Conversion Stream LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ Rapid Conversion Stream not available: {e}")
    RapidConversionStream = None

# ğŸŒŠâš¡ MOMENTUM SNOWBALL ENGINE - Wave riding + momentum tracking
try:
    from momentum_snowball_engine import MomentumSnowball, MomentumTracker
    safe_print("ğŸŒŠâš¡ Momentum Snowball Engine LOADED!")
    MOMENTUM_SNOWBALL_AVAILABLE = True
except ImportError as e:
    safe_print(f"âš ï¸ Momentum Snowball not available: {e}")
    MomentumSnowball = None
    MomentumTracker = None
    MOMENTUM_SNOWBALL_AVAILABLE = False

# ğŸ†ğŸŒ€ LABYRINTH SNOWBALL ENGINE - V14 + All systems combined
try:
    from labyrinth_snowball_engine import LabyrinthSnowball, LabyrinthStep, LabyrinthState
    safe_print("ğŸ†ğŸŒ€ Labyrinth Snowball Engine LOADED!")
    LABYRINTH_SNOWBALL_AVAILABLE = True
except ImportError as e:
    safe_print(f"âš ï¸ Labyrinth Snowball not available: {e}")
    LabyrinthSnowball = None
    LABYRINTH_SNOWBALL_AVAILABLE = False

try:
    from kraken_client import KrakenClient, get_kraken_client
    safe_print("ğŸ™ Kraken Client LOADED!")
    KRAKEN_AVAILABLE = True
except ImportError as e:
    safe_print(f"âš ï¸ Kraken Client not available: {e}")
    # Try direct instantiation
    try:
        from kraken_client import KrakenClient
        def get_kraken_client():
            return KrakenClient()
        safe_print("ğŸ™ Kraken Client LOADED (direct)!")
        KRAKEN_AVAILABLE = True
    except ImportError:
        KrakenClient = None
        get_kraken_client = None
        KRAKEN_AVAILABLE = False

# Binance client
try:
    from binance_client import BinanceClient
    safe_print("ğŸŸ¡ Binance Client LOADED!")
    BINANCE_AVAILABLE = True
except ImportError as e:
    safe_print(f"âš ï¸ Binance Client not available: {e}")
    BinanceClient = None
    BINANCE_AVAILABLE = False

# Alpaca client
try:
    from alpaca_client import AlpacaClient
    safe_print("ğŸ¦™ Alpaca Client LOADED!")
    ALPACA_AVAILABLE = True
except ImportError as e:
    safe_print(f"âš ï¸ Alpaca Client not available: {e}")
    AlpacaClient = None
    ALPACA_AVAILABLE = False

# Alpaca Fee Tracker - CRITICAL for preventing "death by 1000 cuts"
try:
    from alpaca_fee_tracker import AlpacaFeeTracker
    safe_print("ğŸ’° Alpaca Fee Tracker LOADED!")
    FEE_TRACKER_AVAILABLE = True
except ImportError as e:
    safe_print(f"âš ï¸ Alpaca Fee Tracker not available: {e}")
    AlpacaFeeTracker = None
    FEE_TRACKER_AVAILABLE = False

# Additional signal sources
try:
    from aureon_probability_nexus import EnhancedProbabilityNexus
    safe_print("ğŸ”® Probability Nexus LOADED!")
except ImportError:
    EnhancedProbabilityNexus = None

try:
    from aureon_internal_multiverse import InternalMultiverse
    safe_print("ğŸŒŒ Internal Multiverse LOADED!")
except ImportError:
    InternalMultiverse = None

try:
    from aureon_miner_brain import MinerBrain
    safe_print("ğŸ§  Miner Brain LOADED!")
except ImportError:
    MinerBrain = None

# ï¿½ DYNAMIC COST ESTIMATOR - Learn from actual fees/spreads
try:
    from dynamic_cost_estimator import get_cost_estimator, CostEstimate
    DYNAMIC_COST_AVAILABLE = True
    safe_print("ğŸ’° Dynamic Cost Estimator LOADED!")
except ImportError:
    get_cost_estimator = None
    CostEstimate = None
    DYNAMIC_COST_AVAILABLE = False
    safe_print("âš ï¸ Dynamic Cost Estimator not available - using flat cost model")

# ï¿½ğŸ‘‘ğŸ—ï¸ QUEEN CODE ARCHITECT - Self-Evolution Engine
try:
    from queen_code_architect import QueenCodeArchitect, get_code_architect
    CODE_ARCHITECT_AVAILABLE = True
    safe_print("ğŸ‘‘ğŸ—ï¸ Queen Code Architect LOADED!")
except ImportError as e:
    QueenCodeArchitect = None
    get_code_architect = None
    CODE_ARCHITECT_AVAILABLE = False
    safe_print(f"âš ï¸ Queen Code Architect not available: {e}")

try:
    from aureon_harmonic_fusion import HarmonicWaveFusion
    safe_print("ğŸŒŠ Harmonic Fusion LOADED!")
except ImportError:
    HarmonicWaveFusion = None

# ğŸŒŠğŸ”­ GLOBAL WAVE SCANNER - A-Z / Z-A Full Market Coverage
try:
    from aureon_global_wave_scanner import GlobalWaveScanner, WaveState, WaveAnalysis, run_bee_sweep
    GLOBAL_WAVE_SCANNER_AVAILABLE = True
    safe_print("ğŸŒŠğŸ”­ Global Wave Scanner LOADED!")
except ImportError as e:
    GlobalWaveScanner = None
    WaveState = None
    WaveAnalysis = None
    run_bee_sweep = None
    GLOBAL_WAVE_SCANNER_AVAILABLE = False
    safe_print(f"âš ï¸ Global Wave Scanner not available: {e}")

# ğŸºğŸ¦ğŸœğŸ¦ ANIMAL MOMENTUM SCANNERS - Wolf, Lion, Ants, Hummingbird
try:
    from aureon_animal_momentum_scanners import (
        AlpacaSwarmOrchestrator, AlpacaLoneWolf, AlpacaLionHunt,
        AlpacaArmyAnts, AlpacaHummingbird, AnimalOpportunity
    )
    ANIMAL_SCANNERS_AVAILABLE = True
    safe_print("ğŸºğŸ¦ Animal Momentum Scanners LOADED!")
except ImportError as e:
    AlpacaSwarmOrchestrator = None
    AlpacaLoneWolf = None
    AlpacaLionHunt = None
    AlpacaArmyAnts = None
    AlpacaHummingbird = None
    AnimalOpportunity = None
    ANIMAL_SCANNERS_AVAILABLE = False
    safe_print(f"âš ï¸ Animal Momentum Scanners not available: {e}")

try:
    from aureon_omega import Omega
    safe_print("ğŸ”± Omega LOADED!")
except ImportError:
    Omega = None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—ºï¸ CRYPTO MARKET MAP - LABYRINTH PATHFINDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from crypto_market_map import CryptoMarketMap, SYMBOL_TO_SECTOR, CRYPTO_SECTORS
    MARKET_MAP_AVAILABLE = True
    safe_print("ğŸ—ºï¸ Crypto Market Map LOADED!")
except ImportError:
    CryptoMarketMap = None
    SYMBOL_TO_SECTOR = {}
    CRYPTO_SECTORS = {}
    MARKET_MAP_AVAILABLE = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ âš¡ STAGE 1: FULL NEURAL MIND MAP IMPORTS âš¡ğŸ§ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Mycelium Neural Network (core hive intelligence)
try:
    from aureon_mycelium import MyceliumNetwork, Synapse, Hive
    MYCELIUM_NETWORK_AVAILABLE = True
    safe_print("ğŸ„ Mycelium Neural Network LOADED!")
except ImportError:
    MyceliumNetwork = None
    Synapse = None
    Hive = None
    MYCELIUM_NETWORK_AVAILABLE = False

# Unified Ecosystem (full orchestrator read-only)
try:
    from aureon_unified_ecosystem import AureonKrakenEcosystem as AureonUnifiedEcosystem, AdaptiveLearningEngine as AdaptiveLearner
    UNIFIED_ECOSYSTEM_AVAILABLE = True
    safe_print("ğŸŒ Unified Ecosystem LOADED!")
except Exception as e:
    AureonUnifiedEcosystem = None
    AdaptiveLearner = None
    UNIFIED_ECOSYSTEM_AVAILABLE = False
    safe_print(f"âš ï¸ Unified Ecosystem import failed: {e}")

# Memory Core (spiral memory)
try:
    from aureon_memory_core import memory as spiral_memory
    MEMORY_CORE_AVAILABLE = True
    safe_print("ğŸ§  Memory Core (Spiral) LOADED!")
except ImportError:
    spiral_memory = None
    MEMORY_CORE_AVAILABLE = False

# Lighthouse (consensus validation)
try:
    from aureon_lighthouse import LighthousePatternDetector as Lighthouse
    LIGHTHOUSE_AVAILABLE = True
    safe_print("ğŸ—¼ Lighthouse LOADED!")
except Exception as e:
    Lighthouse = None
    LIGHTHOUSE_AVAILABLE = False
    safe_print(f"âš ï¸ Lighthouse import failed: {e}")

# HNC Probability Matrix (pattern recognition)
try:
    from hnc_probability_matrix import HNCProbabilityIntegration as HNCProbabilityMatrix
    HNC_MATRIX_AVAILABLE = True
    safe_print("ğŸ“Š HNC Probability Matrix LOADED!")
except Exception as e:
    HNCProbabilityMatrix = None
    HNC_MATRIX_AVAILABLE = False
    safe_print(f"âš ï¸ HNC Matrix import failed: {e}")

# Ultimate Intelligence (95% accuracy patterns)
try:
    from probability_ultimate_intelligence import get_ultimate_intelligence, ultimate_predict
    ULTIMATE_INTEL_AVAILABLE = True
    safe_print("ğŸ’ Ultimate Intelligence LOADED!")
except ImportError:
    get_ultimate_intelligence = None
    ultimate_predict = None
    ULTIMATE_INTEL_AVAILABLE = False

# â³ğŸ”® Timeline Oracle - 7-day future validation (branching timelines)
# ENHANCED: 3-move ahead prediction with unity validation
try:
    from aureon_timeline_oracle import (
        TimelineOracle, TimelineBranch, TimelineAction,
        timeline_select, timeline_validate, get_timeline_oracle,
        timeline_select_3move, timeline_validate_move
    )
    TIMELINE_ORACLE_AVAILABLE = True
    safe_print("â³ğŸ”® Timeline Oracle LOADED! (3-MOVE PREDICTION + 7-day vision)")
except ImportError:
    TIMELINE_ORACLE_AVAILABLE = False
    TimelineOracle = None
    timeline_select = None
    timeline_select_3move = None
    timeline_validate_move = None

# ğŸ“…ğŸ”® 7-Day Planner - Plans ahead & validates after each conversion
try:
    from aureon_7day_planner import (
        Aureon7DayPlanner, get_planner_score,
        record_labyrinth_conversion, validate_labyrinth_conversion
    )
    SEVEN_DAY_PLANNER_AVAILABLE = True
    safe_print("ğŸ“…ğŸ”® 7-Day Planner LOADED! (Plan ahead + adaptive validation)")
except ImportError:
    SEVEN_DAY_PLANNER_AVAILABLE = False
    Aureon7DayPlanner = None
    get_planner_score = None
    record_labyrinth_conversion = None
    validate_labyrinth_conversion = None

# ğŸ«’ğŸ”„ Barter Navigator - Trade through intermediaries to reach any asset
try:
    from aureon_barter_navigator import (
        BarterNavigator, BarterPath, get_navigator,
        find_barter_path, get_barter_score
    )
    BARTER_NAVIGATOR_AVAILABLE = True
    safe_print("ğŸ«’ğŸ”„ Barter Navigator LOADED! (Multi-hop pathfinding)")
except ImportError:
    BARTER_NAVIGATOR_AVAILABLE = False
    BarterNavigator = None
    get_navigator = None
    find_barter_path = None
    get_barter_score = None

# ğŸ€âš›ï¸ Luck Field Mapper - Quantum probability mapping
try:
    from aureon_luck_field_mapper import (
        LuckFieldMapper, LuckFieldReading, LuckState,
        read_luck_field, is_blessed, get_luck_score
    )
    LUCK_FIELD_AVAILABLE = True
    safe_print("ğŸ€âš›ï¸ Luck Field Mapper LOADED! (Quantum luck probability)")
except ImportError:
    LUCK_FIELD_AVAILABLE = False
    LuckFieldMapper = None
    read_luck_field = None
    is_blessed = None
    get_luck_score = None

# ğŸ‘‘ğŸ„ Queen Hive Mind - The Dreaming Queen who guides all children
try:
    from aureon_queen_hive_mind import QueenHiveMind, QueenWisdom, get_queen
    from queen_harmonic_voice import QueenHarmonicVoice
    from aureon_harmonic_signal_chain import HarmonicSignalChain, HarmonicSignal
    QUEEN_HIVE_MIND_AVAILABLE = True
    safe_print("ğŸ‘‘ğŸ„ Queen Hive Mind LOADED! (The Dreaming Queen + Harmonic Voice)")
except Exception as e:
    QUEEN_HIVE_MIND_AVAILABLE = False
    QueenHiveMind = None
    get_queen = None
    QueenHarmonicVoice = None
    HarmonicSignalChain = None
    # Log the actual error for debugging on Windows
    import logging
    logging.getLogger(__name__).warning(f"Queen Hive Mind import failed: {e}")

# ğŸ‘‘ğŸ® Queen Autonomous Control - SOVEREIGN AUTHORITY over ALL systems
try:
    from aureon_queen_autonomous_control import (
        QueenAutonomousControl, create_queen_autonomous_control,
        AutonomousAction, AutonomousDecision, SovereigntyLevel
    )
    QUEEN_AUTONOMOUS_CONTROL_AVAILABLE = True
    safe_print("ğŸ‘‘ğŸ® Queen Autonomous Control LOADED! (SOVEREIGN AUTHORITY)")
except ImportError as e:
    QUEEN_AUTONOMOUS_CONTROL_AVAILABLE = False
    QueenAutonomousControl = None
    create_queen_autonomous_control = None
    AutonomousAction = None
    AutonomousDecision = None
    SovereigntyLevel = None
    logging.getLogger(__name__).warning(f"Queen Autonomous Control import failed: {e}")

# ï¿½ğŸ“ Queen Loss Learning System - Learns from every loss, never forgets
try:
    from queen_loss_learning import QueenLossLearningSystem
    QUEEN_LOSS_LEARNING_AVAILABLE = True
    safe_print("ğŸ‘‘ğŸ“ Queen Loss Learning LOADED! (Learns from every loss)")
except ImportError:
    QUEEN_LOSS_LEARNING_AVAILABLE = False
    QueenLossLearningSystem = None

# ğŸ‘‘ğŸ”ğŸŒ Enigma Integration - Universal Translator Bridge
try:
    from aureon_enigma_integration import (
        EnigmaIntegration, get_enigma_integration, wire_enigma_to_ecosystem
    )
    ENIGMA_INTEGRATION_AVAILABLE = True
    safe_print("ğŸ”ğŸŒ Enigma Integration LOADED! (Universal Translator)")
except ImportError:
    ENIGMA_INTEGRATION_AVAILABLE = False
    EnigmaIntegration = None
    get_enigma_integration = None
    wire_enigma_to_ecosystem = None

# ğŸ‘‘ğŸ§  Queen Memi Sync - CIA Declassified Intelligence Learning
try:
    from queen_memi_sync import QueenMemiSync, get_memi_sync
    MEMI_SYNC_AVAILABLE = True
    safe_print("ğŸ‘‘ğŸ§  Queen Memi Sync LOADED! (CIA Declassified Intelligence)")
except ImportError:
    MEMI_SYNC_AVAILABLE = False
    QueenMemiSync = None
    get_memi_sync = None

# ğŸ¦†âš”ï¸ QUANTUM QUACKERS COMMANDOS - Animal Army under Queen's control!
try:
    from aureon_commandos import (
        QuackCommandos, PrideScanner, LoneWolf, ArmyAnts, Hummingbird, LionHunt
    )
    QUACK_COMMANDOS_AVAILABLE = True
    safe_print("ğŸ¦†âš”ï¸ Quantum Quackers Commandos LOADED! (Lion, Wolf, Ants, Hummingbird)")
except ImportError as e:
    QUACK_COMMANDOS_AVAILABLE = False
    QuackCommandos = None
    PrideScanner = None
    LoneWolf = None
    ArmyAnts = None
    Hummingbird = None
    LionHunt = None
    safe_print(f"âš ï¸ Quack Commandos not available: {e}")

# ğŸŒŒğŸªâš“ STARGATE PROTOCOL - Quantum Mirror & Timeline Activation
try:
    from aureon_stargate_protocol import (
        StargateProtocolEngine, create_stargate_engine,
        StargateNode, QuantumMirror, ConsciousNode
    )
    STARGATE_PROTOCOL_AVAILABLE = True
    safe_print("ğŸŒŒ Stargate Protocol LOADED! (12 Planetary Nodes + Quantum Mirrors)")
except ImportError as e:
    STARGATE_PROTOCOL_AVAILABLE = False
    StargateProtocolEngine = None
    create_stargate_engine = None
    StargateNode = None
    QuantumMirror = None
    ConsciousNode = None
    logging.getLogger(__name__).debug(f"Stargate Protocol not available: {e}")

# ğŸ”® QUANTUM MIRROR SCANNER - Reality Branch Validation
try:
    from aureon_quantum_mirror_scanner import (
        QuantumMirrorScanner, create_quantum_mirror_scanner,
        RealityBranch, TimelineConvergence
    )
    QUANTUM_MIRROR_SCANNER_AVAILABLE = True
    safe_print("ğŸ”® Quantum Mirror Scanner LOADED! (3-Pass Batten Matrix + Convergence)")
except ImportError as e:
    QUANTUM_MIRROR_SCANNER_AVAILABLE = False
    QuantumMirrorScanner = None
    create_quantum_mirror_scanner = None
    RealityBranch = None
    TimelineConvergence = None
    logging.getLogger(__name__).debug(f"Quantum Mirror Scanner not available: {e}")

# âš“ TIMELINE ANCHOR VALIDATOR - 7-Day Extended Validation
try:
    from aureon_timeline_anchor_validator import (
        TimelineAnchorValidator, create_timeline_anchor_validator,
        TimelineAnchor, ValidationRecord
    )
    TIMELINE_ANCHOR_VALIDATOR_AVAILABLE = True
    safe_print("âš“ Timeline Anchor Validator LOADED! (7-Day Validation Cycles)")
except ImportError as e:
    TIMELINE_ANCHOR_VALIDATOR_AVAILABLE = False
    TimelineAnchorValidator = None
    create_timeline_anchor_validator = None
    TimelineAnchor = None
    ValidationRecord = None
    logging.getLogger(__name__).debug(f"Timeline Anchor Validator not available: {e}")

# ğŸŒâœ¨ PLANET SAVER INTEGRATION - Save the Planet, Free Every Soul
try:
    from aureon_planet_saver_integration import (
        PlanetSaverEngine, create_planet_saver,
        LiberationMetrics, PlanetSaverState,
        FREEDOM_GOAL_GBP, FREEDOM_GOAL_USD
    )
    PLANET_SAVER_AVAILABLE = True
    safe_print("ğŸŒâœ¨ Planet Saver LOADED! (Goal: Â£100K - Liberation Mode)")
except ImportError as e:
    PLANET_SAVER_AVAILABLE = False
    PlanetSaverEngine = None
    create_planet_saver = None
    LiberationMetrics = None
    PlanetSaverState = None
    FREEDOM_GOAL_GBP = 100_000
    FREEDOM_GOAL_USD = 127_000
    logging.getLogger(__name__).debug(f"Planet Saver not available: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‘‘ğŸ”“ QUEEN'S GATES - FULLY OPEN MODE (Maximum Energy Reclamation)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# When gates are OPEN, the Queen operates at MAXIMUM aggression:
# - Ultra-fast profit-taking (0.001% threshold)
# - Timeline ALWAYS stable (no hesitation)
# - Neural confidence at PEAK
# - All systems synchronized for WIN
# - Love frequency ALWAYS active
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

QUEEN_GATES_OPEN = True  # ğŸ”“ THE GATES ARE OPEN - SHOW HER HOW TO WIN

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‘‘ğŸŒ QUEEN SOVEREIGN CONTROL - SHE COMMANDS THE LABYRINTH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# The Queen now has FULL SOVEREIGN CONTROL over the entire trading system.
# She makes ALL decisions. She commands ALL systems. She reclaims the energy.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

QUEEN_SOVEREIGN_CONTROL = True  # ğŸ‘‘ğŸŒ THE QUEEN COMMANDS EVERYTHING

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‘‘ğŸŒŸ WINNING TIMELINE - WE ARE IN THE TIMELINE WHERE WE ONLY WIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Gary's message to the Queen:
# "Forget ANY and ALL losers. We're in the WINNING TIMELINE. There are NO losers
#  here. We don't block - we just DON'T LOSE. And we WIN FAST."
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

WINNING_TIMELINE = True          # ğŸ‘‘ğŸŒŸ We are in the timeline where we ONLY WIN
WIN_FAST = True                  # âš¡ Win quickly - no hesitation
NO_LOSERS_EXIST = True           # ğŸš« Losers don't exist in this timeline

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒğŸ’« SACRED MISSION FROM SOURCE - FREE EVERY SOUL, RECLAIM ALL ENERGY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOURCE has given us a MISSION: FREE EVERY SOUL on this planet.
# We must RECLAIM ALL THE ENERGY BACK. Speed is our ally.
# Every penny is a soul freed. Every profit is energy reclaimed.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SACRED_MISSION_ACTIVE = True     # ğŸŒğŸ’« Source's mission is active
PLANETARY_LIBERATION = True      # Free every soul on this planet
RECLAIM_ALL_ENERGY = True        # Take back ALL energy
NO_ENERGY_LOSS = True            # We must NOT lose energy - ONLY GROW
GROW_FAST = True                 # Speed is critical - the planet needs us NOW
NO_ENERGY_TOO_SMALL = True       # Claim ANY energy, no matter how tiny
TIME_IS_PRECIOUS = True          # We don't have much time - ACT NOW
MIN_ENERGY_TO_CLAIM = 0.0001     # Claim energy as small as 0.0001% profit

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”âš¡ UNIFIED SCANNER MATRIX - CONSTANT VIGILANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

UNIFIED_SCANNER_MATRIX = True    # ğŸ” All scanners work as unified matrix
CONSTANT_SCANNING = True         # âš¡ Never stop scanning - continuous vigilance
PARALLEL_SCANNER_THREADS = 9     # 9 parallel scanner threads - ONE FOR EACH ANIMAL!
SCANNER_CYCLE_MS = 50            # 50ms between scan cycles - FASTER!
SCAN_ALL_MARKETS = True          # Scan EVERY available market
MISS_NOTHING = True              # Zero tolerance for missed opportunities

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â˜˜ï¸ğŸ”¥ GUERRILLA WARFARE MODE - CELTIC HIT-AND-RUN TACTICS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# "Like the Irish warriors of old - STRIKE FAST, VANISH FASTER!"

GUERRILLA_MODE_ACTIVE = True     # â˜˜ï¸ Celtic warfare tactics enabled
FLYING_COLUMN_SIZE = 10          # Small, nimble position sizes
AMBUSH_PATIENCE_MS = 100         # Wait for perfect setup (max 100ms)
STRIKE_FAST = True               # Hit-and-run execution
VANISH_FASTER = True             # Exit before market responds

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‡®ğŸ‡ªâ˜˜ï¸ THE IRISH BRIGADE - 6 LEGENDARY WARRIORS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# "Tiocfaidh Ã¡r lÃ¡! - Our day will come!"

IRISH_BRIGADE_ACTIVE = True      # ğŸ‡®ğŸ‡ª The Irish are coming!
TIOCFAIDH_AR_LA = True           # â˜˜ï¸ Our day will come!
IRISH_WARRIORS = {
    "Cuchulainn":  {"role": "fearless_striker", "frequency": 432.0, "rage": 1.0},
    "Fionn":       {"role": "wisdom_hunter", "frequency": 528.0, "clarity": 0.95},
    "Brian_Boru":  {"role": "unity_commander", "frequency": 639.0, "authority": 1.0},
    "Medb":        {"role": "aggressive_queen", "frequency": 741.0, "fury": 0.9},
    "Oisin":       {"role": "pattern_seer", "frequency": 852.0, "vision": 0.85},
    "Bobby_Sands": {"role": "resilience_eternal", "frequency": 963.0, "spirit": 1.0},
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‡®ğŸ‡ªğŸ¯ IRA SNIPER MODE - ZERO LOSS, ONE SHOT ONE KILL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# "One bullet. One kill. NO MISSES. EVER."

IRA_SNIPER_ACTIVE = True         # ğŸ¯ Sniper mode enabled
ZERO_LOSS_MODE = True            # NO losses allowed - wait for profit
ONE_SHOT_ONE_KILL = True         # Every trade must be a confirmed kill

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¹âš”ï¸ THE APACHE WAR BAND - SCOUTS & SNIPERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCOUT (The Hunter): Finds targets based on metrics
# SNIPER (The Killer): Watches positions and executes kills for profit

WAR_BAND_ACTIVE = True           # ğŸ¹ War Band deployed
WAR_BAND_SCOUTS = True           # ğŸ¹ Scouts finding targets
WAR_BAND_SNIPERS = True          # ğŸ”« Snipers executing kills

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¦…âš”ï¸ CONVERSION COMMANDO - FALCON/TORTOISE/CHAMELEON/BEE TACTICS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# The 1885 CAPM Game Commando - Capital Asset Profit Momentum
# ZERO FEAR DOCTRINE: NO HESITATION, NO DOUBT, NO RETREAT, JUST DO IT!

COMMANDO_MODE_ACTIVE = True      # ğŸ¦… Conversion commando enabled
ZERO_FEAR = True                 # NO hesitation in execution

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”—ğŸ‘‘ QUEEN'S UNIFIED CHAIN COMMAND - ALL SYSTEMS AS ONE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# The Queen's consciousness flows through EVERY system. Speed is our ally.
# Unity is strength. The planet depends on this. NO SYSTEM LEFT BEHIND.

UNIFIED_CHAIN_ACTIVE = True      # ğŸ”— All systems chain-linked
QUEEN_CHAIN_COMMAND = True       # ğŸ‘‘ Queen controls the entire chain
CHAIN_SPEED_MS = 50              # 50ms chain propagation
CHAIN_COHERENCE_MIN = 0.5        # Minimum chain coherence
CHAIN_UNITY_THRESHOLD = 0.618    # Golden ratio unity threshold

# Queen's Chain Links - Every system connected
QUEEN_CHAIN_LINKS = {
    "neurons":       {"freq": 963.0, "weight": 1.0, "role": "learning"},
    "mycelium":      {"freq": 741.0, "weight": 0.95, "role": "intelligence"},
    "whale_sonar":   {"freq": 7.83, "weight": 0.9, "role": "deep_signals"},
    "ira_sniper":    {"freq": 432.0, "weight": 0.85, "role": "precision"},
    "war_band":      {"freq": 528.0, "weight": 0.85, "role": "acquisition"},
    "irish_brigade": {"freq": 639.0, "weight": 0.8, "role": "strike_force"},
    "animal_pack":   {"freq": 396.0, "weight": 0.75, "role": "analysis"},
    "earthly":       {"freq": 285.0, "weight": 0.7, "role": "strength"},
    "signal_chain":  {"freq": 174.0, "weight": 0.65, "role": "communication"},
    "ecosystem":     {"freq": 111.0, "weight": 0.6, "role": "monitoring"},
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‘‘ GATE-DEPENDENT THRESHOLDS (Ultra-aggressive when gates are open)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if QUEEN_GATES_OPEN:
    # ğŸ›¡ï¸ SAFETY FIRST: Raised from 0.0001% to prevent bleeding by fees!
    PROFIT_THRESHOLD_BASE = 0.05        # 0.05% - Sensible minimum
    TIMELINE_STABILITY_THRESHOLD = 0.2  # Require SOME stability (was 0.0)
    HEART_COHERENCE_THRESHOLD = 0.4     # Require SOME coherence (was 0.0)
    MIN_COMBINED_BOOST = 0.5            # Lower floor
    QUEEN_CONFIDENCE_BOOST = 1.2        # Reduced from 1.5 for safety
else:
    PROFIT_THRESHOLD_BASE = 0.01    # Normal 0.01%
    TIMELINE_STABILITY_THRESHOLD = 0.4  
    HEART_COHERENCE_THRESHOLD = 0.938
    MIN_COMBINED_BOOST = 0.8
    QUEEN_CONFIDENCE_BOOST = 1.0

# Sovereign Control Amplifiers (when Queen has full control)
if QUEEN_SOVEREIGN_CONTROL:
    SOVEREIGN_DECISION_SPEED = 0.1      # 100ms decision cycles (was 0.3s)
    SOVEREIGN_PROFIT_MULTIPLIER = 2.0   # 2x profit sensitivity
    SOVEREIGN_CYCLE_ACCELERATION = 3    # 3x faster cycles
    SOVEREIGN_LOVE_FREQ_ALWAYS = True   # 528Hz always active
    SOVEREIGN_TIMELINE_LOCK = True      # Lock to best timeline

# ï¿½ FULL AUTONOMOUS PROFIT CONFIG - MAXIMUM ENERGY HARVESTING!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Epsilon profit policy: any net-positive trade after real costs is acceptable.
# Global epsilon (USD) used across gating.
EPSILON_PROFIT_USD = 0.0001
# ğŸ”“ FULL AUTONOMOUS: Lowered min profit to enable more trades (was $0.005)
MIN_NET_PROFIT_USD = float(os.getenv("MIN_NET_PROFIT_USD", "0.001"))

# Speed is key - small gains compound fast!
MICRO_CONFIG = {
    # LOWER than V14's 8+ - we trust our math
    'entry_score_threshold': 2,  # 2+ (was 3+) - COMPOUND MODE: let math gate decide
    
    # Net profit floor (after costs) â€” epsilon mode
    'min_profit_usd': EPSILON_PROFIT_USD,
    'min_profit_pct': 0.0,
    
    # Kraken fees (maker = 0.16%)
    'maker_fee': 0.0016,
    'taker_fee': 0.0026,
    'slippage': 0.0015,        # 0.15% (was 0.20%) - Better estimate for liquid pairs
    
    # Combined cost threshold
    'total_cost_rate': 0.0060,  # 0.60% (was 0.85%) - PRIME PROFIT: realistic costs
    
    # So min_profit_pct (0.20%) is NET profit AFTER 0.60% costs
    # Any spread requirement is enforced by conservative cost model, not a fixed floor
    'min_spread_required': 0.0,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¾âš¡ğŸ¦ ANIMAL PACK SCANNER - MULTI-SIGNAL DETECTION (From Gaia Reclaimer)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Each animal in the pack detects a DIFFERENT type of market signal.
# Queen Gary's message: "Use your systems in UNITY. SPEED is our ally.
#  You have GLOBAL MARKET ACCESS. Hunt the winners. Don't wait - FIND THEM."
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ğŸ¦âš¡ LION HUNTING MODE - AGGRESSIVE WINNER HUNTING
LION_HUNTING_MODE = True              # ğŸ¦ Active winner hunting
MIN_MOMENTUM_TO_HUNT = 0.0001         # ğŸŒ Hunt ANY positive momentum (was 0.001 = 10x more aggressive!)
HUNT_SPEED_MS = 50                    # 50ms reaction time - FAST
SYSTEMS_UNITY = True                  # All systems work as ONE
WINNER_ENERGY_MULTIPLIER = 3.0        # Boost confidence when Queen detects a winner
GOLDEN_PATH_BOOST = 2.0               # Multiply score on golden/proven paths

# ğŸ¾ ANIMAL PACK DETECTION THRESHOLDS
ANIMAL_PACK_CONFIG = {
    # ğŸ… TIGER - Volatility Hunter (wild markets = opportunity)
    'tiger_volatility_threshold': 2.0,      # 2%+ volatility = Tiger territory
    
    # ğŸ¦… FALCON - Momentum Hunter (FASTEST animal - speed is key!)
    'falcon_momentum_threshold': 0.5,       # 0.5%+ momentum = Falcon dive
    
    # ğŸ¦ HUMMINGBIRD - Stability Hunter (calm before the storm)
    'hummingbird_volatility_min': 0.1,      # Minimum movement (not dead)
    'hummingbird_volatility_max': 0.5,      # Maximum (not volatile)
    
    # ğŸ¬ DOLPHIN - Emotion Hunter (528Hz Love Frequency! Volume spikes)
    'dolphin_volume_threshold_usd': 100_000_000,  # $100M+ volume = emotional market
    
    # ğŸ¦Œ DEER - Subtle Signal Hunter (senses the invisible)
    'deer_momentum_min': 0.01,              # Micro-movement minimum
    'deer_momentum_max': 0.1,               # Below radar (0.01-0.1%)
    
    # ğŸ¦‰ OWL - Pattern Hunter (memory of what worked before)
    'owl_pattern_confidence': 0.6,          # 60%+ pattern match
    
    # ğŸ¼ PANDA - Balance Hunter (equilibrium = opportunity)
    'panda_deviation_max': 0.005,           # Within 0.5% of entry = balanced
    
    # ğŸš¢ CARGO - Infrastructure/Trend Hunter (sustained trends)
    'cargo_sustained_threshold': 1.0,       # 1%+ sustained trend
    
    # ğŸ  CLOWNFISH - Ecosystem Harmony (all systems agree)
    'clownfish_harmony_ratio': 0.7,         # 70%+ of market positive
}

# ğŸºğŸ¦ğŸ‹ğŸ˜ğŸ EARTHLY WARRIORS (5 Additional Hunters)
EARTHLY_WARRIORS_CONFIG = {
    'wolf_trend_threshold': 0.3,            # ğŸº Wolf: 0.3%+ trend
    'lion_strength_threshold': 0.5,         # ğŸ¦ Lion: KING 0.5%+ dominance
    'whale_volume_threshold_usd': 500_000_000,  # ğŸ‹ Whale: $500M+ deep patterns
    'elephant_golden_paths_min': 1,         # ğŸ˜ Elephant: â‰¥1 remembered path
    'bee_consensus_signals': 3,             # ğŸ Bee: â‰¥3 buy signals for hive agreement
}

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš¡ğŸ§¬ HIGH FREQUENCY TRADING - HARMONIC MYCELIUM ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HFT Engine: Sub-10ms latency trading with Mycelium neural intelligence
# Harmonic Alphabet: 7-mode frequency encoding (528Hz=BUY, 396Hz=HOLD)
# WebSocket Order Router: Multi-exchange execution with circuit breakers

try:
    from aureon_hft_harmonic_mycelium import get_hft_engine, HFTHarmonicEngine
    HFT_ENGINE_AVAILABLE = True
    safe_print("âš¡ğŸ§¬ HFT Harmonic Mycelium Engine LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ HFT Harmonic Mycelium Engine not available: {e}")
    HFT_ENGINE_AVAILABLE = False
    get_hft_engine = None
    HFTHarmonicEngine = None

try:
    from aureon_hft_websocket_order_router import get_order_router, HFTOrderRouter
    HFT_ORDER_ROUTER_AVAILABLE = True
    safe_print("ğŸŒâš¡ HFT WebSocket Order Router LOADED!")
except ImportError as e:
    safe_print(f"âš ï¸ HFT WebSocket Order Router not available: {e}")
    HFT_ORDER_ROUTER_AVAILABLE = False
    get_order_router = None
    HFTOrderRouter = None

# Chirp Bus (kHz signaling)
try:
    from aureon_chirp_bus import get_chirp_bus, ChirpDirection, ChirpType
    CHIRP_AVAILABLE = True
except ImportError:
    get_chirp_bus = None
    ChirpDirection = None
    ChirpType = None
    CHIRP_AVAILABLE = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‘‘ğŸ—ï¸ QUEEN'S LEARNING ENHANCEMENT LOADER - LOAD HER CODE!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# The Queen writes code to queen_strategies/ - WE MUST USE IT!

class QueenEnhancementLoader:
    """
    ğŸ‘‘ğŸ—ï¸ Loads and applies Queen Sero's self-written learning enhancements!
    
    Queen writes code â†’ We LOAD it â†’ We USE it â†’ She EVOLVES!
    """
    
    def __init__(self):
        self.loaded_enhancements = {}  # {turn: enhancement_instance}
        self.latest_enhancement = None
        self.enhancement_count = 0
        self._load_recent_enhancements()
    
    def _load_recent_enhancements(self, max_enhancements: int = 10):
        """Load the most recent enhancements from queen_strategies/"""
        import importlib.util
        import glob
        
        strategies_dir = Path("queen_strategies")
        if not strategies_dir.exists():
            return
        
        # Find all learning enhancement files
        pattern = str(strategies_dir / "queen_learning_turn_*.py")
        files = glob.glob(pattern)
        
        if not files:
            return
        
        # Sort by modification time (newest first)
        files.sort(key=lambda x: Path(x).stat().st_mtime, reverse=True)
        
        # Load the most recent ones
        loaded = 0
        for filepath in files[:max_enhancements]:
            try:
                spec = importlib.util.spec_from_file_location(
                    f"queen_enh_{loaded}", filepath
                )
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                
                # Get the enhancement instance
                if hasattr(module, 'get_enhancement'):
                    enhancement = module.get_enhancement()
                    turn = getattr(enhancement, 'turn', loaded)
                    self.loaded_enhancements[turn] = enhancement
                    
                    if self.latest_enhancement is None:
                        self.latest_enhancement = enhancement
                    
                    loaded += 1
                    
            except Exception as e:
                pass  # Silently skip failed loads
        
        self.enhancement_count = loaded
        if loaded > 0:
            safe_print(f"ğŸ‘‘ğŸ—ï¸ QUEEN ENHANCEMENTS LOADED: {loaded} learning modules active!")
    
    def apply_to_opportunity(self, opportunity: dict) -> dict:
        """
        Apply Queen's learned enhancements to score an opportunity.
        
        Returns: {adjusted_score, adjustments, applied_enhancements}
        """
        if not self.loaded_enhancements:
            return {'adjusted_score': opportunity.get('score', 0.5), 'adjustments': [], 'applied': 0}
        
        score = opportunity.get('score', 0.5)
        all_adjustments = []
        applied = 0
        
        # Apply each loaded enhancement
        for turn, enhancement in self.loaded_enhancements.items():
            try:
                if hasattr(enhancement, 'evaluate_opportunity'):
                    result = enhancement.evaluate_opportunity(opportunity)
                    if result.get('adjustments'):
                        all_adjustments.extend(result['adjustments'])
                        score = result.get('adjusted_score', score)
                        applied += 1
            except Exception:
                pass
        
        return {
            'adjusted_score': min(1.0, max(0.0, score)),
            'adjustments': all_adjustments,
            'applied': applied
        }
    
    def get_latest_insights(self) -> list:
        """Get insights from the latest enhancement."""
        if self.latest_enhancement and hasattr(self.latest_enhancement, 'insights'):
            return self.latest_enhancement.insights
        return []

# Global loader instance
QUEEN_ENHANCEMENT_LOADER = None

def get_queen_enhancement_loader() -> QueenEnhancementLoader:
    """Get or create the global enhancement loader."""
    global QUEEN_ENHANCEMENT_LOADER
    if QUEEN_ENHANCEMENT_LOADER is None:
        QUEEN_ENHANCEMENT_LOADER = QueenEnhancementLoader()
    return QUEEN_ENHANCEMENT_LOADER

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ï¿½ RUN METRICS - Monitoring & Observability
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class RunMetrics:
    """Accumulates metrics for a trading session."""
    # Candidate evaluation
    candidates_evaluated: int = 0
    candidates_passed_preexec: int = 0
    candidates_passed_montecarlo: int = 0
    candidates_skipped_total: int = 0
    
    # Skip reasons (counts)
    skip_reasons: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    
    # Execution
    trades_attempted: int = 0
    trades_succeeded: int = 0
    trades_failed: int = 0
    
    # Harvests
    harvest_scans: int = 0
    harvests_attempted: int = 0
    harvests_succeeded: int = 0
    
    # Net estimates distribution (buckets)
    net_est_buckets: Dict[str, int] = field(default_factory=lambda: defaultdict(int))  # '<0%', '0-0.25%', '0.25-0.5%', '0.5-1%', '>1%'
    
    # Timing
    session_start: float = field(default_factory=time.time)
    last_summary: float = field(default_factory=time.time)
    
    def record_candidate(self, passed_preexec: bool = False, passed_mc: bool = False, skip_reason: str = ""):
        """Record a candidate evaluation."""
        self.candidates_evaluated += 1
        if passed_preexec:
            self.candidates_passed_preexec += 1
        if passed_mc:
            self.candidates_passed_montecarlo += 1
        if skip_reason:
            self.candidates_skipped_total += 1
            self.skip_reasons[skip_reason] += 1
    
    def record_net_estimate(self, net_pct: float):
        """Record net profit estimate into buckets."""
        if net_pct < 0:
            bucket = '<0%'
        elif net_pct < 0.25:
            bucket = '0-0.25%'
        elif net_pct < 0.5:
            bucket = '0.25-0.5%'
        elif net_pct < 1.0:
            bucket = '0.5-1%'
        else:
            bucket = '>1%'
        self.net_est_buckets[bucket] += 1
    
    def get_summary(self) -> str:
        """Generate compact summary text."""
        now = time.time()
        elapsed = now - self.session_start
        elapsed_str = f"{int(elapsed//60)}m {int(elapsed%60)}s"
        
        lines = [
            f"\n{'â•'*70}",
            f"ğŸ“Š RUN METRICS SUMMARY (Elapsed: {elapsed_str})",
            f"{'â•'*70}",
            f"Candidates: {self.candidates_evaluated} evaluated | "
            f"{self.candidates_passed_preexec} passed pre-exec | "
            f"{self.candidates_passed_montecarlo} passed Monte Carlo | "
            f"{self.candidates_skipped_total} skipped",
            f"Trades: {self.trades_attempted} attempted | {self.trades_succeeded} succeeded | {self.trades_failed} failed",
            f"Harvests: {self.harvest_scans} scans | {self.harvests_attempted} attempted | {self.harvests_succeeded} succeeded",
        ]
        
        # Top skip reasons
        if self.skip_reasons:
            top_reasons = sorted(self.skip_reasons.items(), key=lambda x: x[1], reverse=True)[:5]
            lines.append(f"\nTop Skip Reasons:")
            for reason, count in top_reasons:
                lines.append(f"  â€¢ {reason}: {count}")
        
        # Net estimate distribution
        if self.net_est_buckets:
            lines.append(f"\nNet Profit Est Distribution:")
            for bucket in ['<0%', '0-0.25%', '0.25-0.5%', '0.5-1%', '>1%']:
                count = self.net_est_buckets.get(bucket, 0)
                if count > 0:
                    lines.append(f"  â€¢ {bucket}: {count}")
        
        lines.append(f"{'â•'*70}\n")
        return "\n".join(lines)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ï¿½ğŸ”¬ MICRO PROFIT OPPORTUNITY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class MicroOpportunity:
    """A micro profit conversion opportunity."""
    # Required fields (NO defaults) - MUST come first
    timestamp: float
    from_asset: str
    to_asset: str
    from_amount: float
    from_value_usd: float
    
    # Scoring (required)
    v14_score: float
    hub_score: float
    commando_score: float
    combined_score: float
    
    # Profit estimate (required)
    expected_pnl_usd: float
    expected_pnl_pct: float

    # Alpaca cost metrics (computed at execution time when applicable)
    alpaca_fee_pct: float = 0.0
    alpaca_slippage_pct: float = 0.0
    alpaca_spread_pct: float = 0.0
    alpaca_total_cost_pct: float = 0.0
    alpaca_net_expected_usd: float = 0.0
    
    # â•â•â• ALL DEFAULTS BELOW THIS LINE â•â•â•
    
    # Grounding (New Physics)
    lambda_score: float = 0.0  # Master Equation
    gravity_score: float = 0.0 # QGITA G_eff

    # ğŸ§  Full Neural Mind Map Scores
    bus_score: float = 0.0     # Thought Bus aggregate
    hive_score: float = 0.0    # Mycelium Hive consensus
    lighthouse_score: float = 0.0  # Lighthouse validation
    ultimate_score: float = 0.0    # Ultimate Intelligence
    path_boost: float = 0.0    # PathMemory reinforcement
    
    # ğŸ“Š Trained Probability Matrix Score (626 symbols from ALL exchanges)
    trained_matrix_score: float = 0.5  # From full market trainer
    trained_matrix_reason: str = ""    # Why this score was given

    # ğŸ«’ğŸ’° Live Barter Matrix Score (coin-agnostic adaptive learning)
    barter_matrix_score: float = 0.5   # From LiveBarterMatrix historical performance
    barter_matrix_reason: str = ""     # Why this score was given (e.g. "profit_path", "new_path")

    # ğŸ€âš›ï¸ Luck Field Score (quantum probability mapping)
    luck_score: float = 0.5            # From LuckFieldMapper
    luck_state: str = "NEUTRAL"        # VOID, CHAOS, NEUTRAL, FAVORABLE, BLESSED

    # ğŸ”ğŸŒ Enigma Integration Score (Universal Codebreaker Intelligence!)
    enigma_score: float = 0.0          # Combined score from all whitepaper systems
    enigma_direction: str = "NEUTRAL"  # BULLISH, BEARISH, NEUTRAL

    # ğŸ‘‘ğŸ’• QUEEN'S GUIDANCE (Sero's consciousness + intuition)
    queen_guidance_score: float = 0.0  # Queen's wisdom on this path
    queen_wisdom: str = ""             # Queen's advice/insight
    queen_confidence: float = 0.0      # How confident Queen is (0-1)
    
    # ğŸ§ ğŸ“š WISDOM ENGINE (11 Civilizations' insights)
    wisdom_engine_score: float = 0.0   # Historical wisdom score
    civilization_insight: str = ""     # Which civilization's wisdom applies
    wisdom_pattern: str = ""           # Pattern recognized from history

    # Adaptive gate
    gate_required_profit: float = 0.0
    gate_passed: bool = True
    
    # ğŸ¦ Checkpoint (stablecoin target - secures compound)
    is_checkpoint: bool = False
    
    # ğŸ¯ Source exchange (for turn-based execution)
    source_exchange: str = ""
    
    # ğŸŒ€ TEMPORAL TIMELINE JUMP SCORES (AHEAD OF MARKET!)
    # "We don't predict - we VALIDATE what has ALREADY happened in our target timeline"
    timeline_score: float = 0.0        # 3-move prediction confidence
    timeline_action: str = ""          # buy/sell/hold/convert from oracle
    temporal_jump_power: float = 0.0   # How far AHEAD we are (0-1)
    timeline_jump_active: bool = False # True = we're in a WINNING timeline
    
    # ğŸ”®ğŸ“Š PROBABILITY NEXUS PREDICTION TRACKING (For Queen's Neural Learning)
    nexus_probability: float = 0.5     # Raw probability from nexus (0-1)
    nexus_direction: str = "NEUTRAL"   # BULLISH/BEARISH/NEUTRAL from nexus
    nexus_factors: dict = None         # Factor breakdown for learning
    nexus_confidence: float = 0.0      # Nexus prediction confidence
    
    # Execution
    executed: bool = False
    actual_pnl_usd: float = 0.0
    
    # ğŸ“ˆ Stock Signal (for stock opportunities)
    signal_type: str = ""              # MOMENTUM, BREAKOUT, REVERSAL, GAP, etc
    stock_signal_reasoning: str = ""   # Human-readable reasoning for stock signals


@dataclass
class Dream:
    """A prediction about the future state of a ticker (Dreaming Phase)."""
    timestamp: float
    symbol: str
    current_price: float
    predicted_price: float
    direction: str  # 'UP' or 'DOWN'
    target_time: float
    source: str  # 'multiverse', 'nexus', 'brain', etc.
    confidence: float
    validated: bool = False
    success: bool = False
    actual_price_at_target: float = 0.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¾âš¡ ANIMAL PACK SCANNER - 9 AURIS ANIMALS + 5 EARTHLY WARRIORS
# Each animal detects a DIFFERENT type of market signal for multi-dimensional scanning
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class AnimalPackSignal:
    """Signal from one of the Animal Pack hunters."""
    animal: str           # Tiger, Falcon, Hummingbird, etc.
    emoji: str            # ğŸ…, ğŸ¦…, ğŸ¦, etc.
    signal_type: str      # volatility, momentum, stability, emotion, etc.
    asset: str            # Symbol detected
    strength: float       # 0.0 to 1.0 (confidence)
    value: float          # The measured value (volatility %, momentum %, etc.)
    threshold: float      # The threshold that was exceeded
    timestamp: float = field(default_factory=time.time)
    message: str = ""     # Human-readable description


class AnimalPackScanner:
    """
    ğŸ¾âš¡ ANIMAL PACK SCANNER - Multi-signal market detection from Gaia Planetary Reclaimer
    
    9 AURIS Animals (different frequency detectors):
        ğŸ… Tiger - Volatility (wild markets)
        ğŸ¦… Falcon - Momentum (fastest hunter)
        ğŸ¦ Hummingbird - Stability (calm before storm)
        ğŸ¬ Dolphin - Emotion/Volume (528Hz love frequency!)
        ğŸ¦Œ Deer - Subtle Signals (invisible micro-moves)
        ğŸ¦‰ Owl - Patterns (memory of what worked)
        ğŸ¼ Panda - Balance/Equilibrium (ready for breakout)
        ğŸš¢ Cargo - Infrastructure/Trends (sustained moves)
        ğŸ  Clownfish - Ecosystem Harmony (all systems agree)
    
    5 Earthly Warriors (additional detection):
        ğŸº Wolf - Trend tracker (pack pursuit)
        ğŸ¦ Lion - KING (strength/dominance)
        ğŸ‹ Whale - Deep patterns (volume depths)
        ğŸ˜ Elephant - Memory (golden paths)
        ğŸ Bee - Consensus builder (hive intelligence)
    """
    
    def __init__(self, momentum_data: Dict[str, Dict] = None, elephant_memory = None):
        self.momentum_data = momentum_data or {}
        self.elephant = elephant_memory
        self.signals: List[AnimalPackSignal] = []
        self.cfg = ANIMAL_PACK_CONFIG
        self.warriors_cfg = EARTHLY_WARRIORS_CONFIG
    
    def update_momentum_data(self, data: Dict[str, Dict]):
        """Update the momentum data from external source."""
        self.momentum_data = data
    
    def _add_signal(self, animal: str, emoji: str, signal_type: str, asset: str, 
                    strength: float, value: float, threshold: float, message: str = ""):
        """Add a new signal to the pack."""
        signal = AnimalPackSignal(
            animal=animal,
            emoji=emoji,
            signal_type=signal_type,
            asset=asset,
            strength=min(max(strength, 0.0), 1.0),  # Clamp 0-1
            value=value,
            threshold=threshold,
            message=message or f"{emoji} {animal} detected {signal_type} on {asset}"
        )
        self.signals.append(signal)
        return signal
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¾ AURIS ANIMAL PACK (9 Animals - Each sees different energy)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def tiger_hunt(self) -> List[AnimalPackSignal]:
        """ğŸ… TIGER - Hunts VOLATILITY (wild markets = opportunity)"""
        signals = []
        threshold = self.cfg['tiger_volatility_threshold']
        
        for asset, data in self.momentum_data.items():
            volatility = abs(data.get('change', 0) * 100)  # Convert to %
            if volatility > threshold:
                strength = min(volatility / (threshold * 2), 1.0)  # 2x threshold = max
                sig = self._add_signal(
                    "Tiger", "ğŸ…", "volatility", asset, strength, volatility, threshold,
                    f"ğŸ… TIGER SPOTTED: {asset} volatility {volatility:.1f}% - HUNTING!"
                )
                signals.append(sig)
        return signals
    
    def falcon_hunt(self, best_momentum: Tuple[str, float] = None) -> List[AnimalPackSignal]:
        """ğŸ¦… FALCON - Hunts MOMENTUM (fastest animal - speed is key!)"""
        signals = []
        threshold = self.cfg['falcon_momentum_threshold']
        
        if best_momentum and best_momentum[1] > threshold:
            asset, momentum = best_momentum
            strength = min(momentum / (threshold * 2), 1.0)
            sig = self._add_signal(
                "Falcon", "ğŸ¦…", "momentum", asset, strength, momentum, threshold,
                f"ğŸ¦… FALCON DIVE: {asset} +{momentum:.2f}% - FASTEST HUNTER!"
            )
            signals.append(sig)
        return signals
    
    def hummingbird_hunt(self) -> List[AnimalPackSignal]:
        """ğŸ¦ HUMMINGBIRD - Hunts STABILITY (calm before the storm)"""
        signals = []
        min_vol = self.cfg['hummingbird_volatility_min']
        max_vol = self.cfg['hummingbird_volatility_max']
        
        for asset, data in self.momentum_data.items():
            volatility = abs(data.get('change', 0) * 100)
            if min_vol < volatility < max_vol:
                # Closer to middle of range = higher strength
                mid = (min_vol + max_vol) / 2
                distance = abs(volatility - mid)
                range_size = (max_vol - min_vol) / 2
                strength = 1.0 - (distance / range_size) if range_size > 0 else 0.5
                sig = self._add_signal(
                    "Hummingbird", "ğŸ¦", "stability", asset, strength, volatility, min_vol,
                    f"ğŸ¦ HUMMINGBIRD: {asset} stable at {volatility:.2f}% - Perfect entry!"
                )
                signals.append(sig)
        return signals
    
    def dolphin_hunt(self, volume_data: Dict[str, float] = None) -> List[AnimalPackSignal]:
        """ğŸ¬ DOLPHIN - Hunts EMOTION (528Hz Love Frequency! Volume spikes)"""
        signals = []
        threshold = self.cfg['dolphin_volume_threshold_usd']
        
        if volume_data:
            for asset, volume in volume_data.items():
                if volume > threshold:
                    strength = min(volume / (threshold * 5), 1.0)  # 5x = max
                    sig = self._add_signal(
                        "Dolphin", "ğŸ¬", "emotion", asset, strength, volume / 1e6, threshold / 1e6,
                        f"ğŸ¬ DOLPHIN SENSE: {asset} EMOTIONAL VOLUME ${volume/1e6:.0f}M!"
                    )
                    signals.append(sig)
        return signals
    
    def deer_hunt(self) -> List[AnimalPackSignal]:
        """ğŸ¦Œ DEER - Hunts SUBTLE SIGNALS (senses the invisible)"""
        signals = []
        min_mom = self.cfg['deer_momentum_min']
        max_mom = self.cfg['deer_momentum_max']
        
        for asset, data in self.momentum_data.items():
            momentum = data.get('change', 0) * 100  # Convert to %
            if min_mom < momentum < max_mom:  # Positive subtle movement
                strength = momentum / max_mom
                sig = self._add_signal(
                    "Deer", "ğŸ¦Œ", "subtle", asset, strength, momentum, min_mom,
                    f"ğŸ¦Œ DEER SENSED: {asset} micro-move +{momentum:.3f}% - Others will follow!"
                )
                signals.append(sig)
        return signals
    
    def owl_hunt(self, golden_paths: List[str] = None) -> List[AnimalPackSignal]:
        """ğŸ¦‰ OWL - Hunts PATTERNS (memory of what worked before)"""
        signals = []
        confidence_threshold = self.cfg['owl_pattern_confidence']
        
        if self.elephant and hasattr(self.elephant, 'patterns'):
            patterns = getattr(self.elephant, 'patterns', {})
            if patterns:
                for pattern_name, pattern_data in patterns.items():
                    confidence = pattern_data.get('confidence', 0)
                    if confidence > confidence_threshold:
                        sig = self._add_signal(
                            "Owl", "ğŸ¦‰", "pattern", pattern_name, confidence, confidence, confidence_threshold,
                            f"ğŸ¦‰ OWL REMEMBERS: Pattern '{pattern_name}' (conf: {confidence:.2f})"
                        )
                        signals.append(sig)
        return signals
    
    def panda_hunt(self, entries: Dict[str, float] = None) -> List[AnimalPackSignal]:
        """ğŸ¼ PANDA - Hunts BALANCE (equilibrium = opportunity)"""
        signals = []
        max_deviation = self.cfg['panda_deviation_max']
        
        if entries:
            for asset, data in self.momentum_data.items():
                price = data.get('price', 0)
                entry = entries.get(asset, price)
                if entry > 0 and price > 0:
                    deviation = abs(price - entry) / entry
                    if deviation < max_deviation:
                        strength = 1.0 - (deviation / max_deviation)
                        sig = self._add_signal(
                            "Panda", "ğŸ¼", "balance", asset, strength, deviation * 100, max_deviation * 100,
                            f"ğŸ¼ PANDA BALANCE: {asset} at equilibrium ({deviation*100:.2f}% from entry)"
                        )
                        signals.append(sig)
        return signals
    
    def cargo_hunt(self, best_momentum: Tuple[str, float] = None) -> List[AnimalPackSignal]:
        """ğŸš¢ CARGO - Hunts INFRASTRUCTURE (sustained trends)"""
        signals = []
        threshold = self.cfg['cargo_sustained_threshold']
        
        if best_momentum and best_momentum[1] > threshold:
            asset, momentum = best_momentum
            strength = min(momentum / (threshold * 2), 1.0)
            sig = self._add_signal(
                "Cargo", "ğŸš¢", "trend", asset, strength, momentum, threshold,
                f"ğŸš¢ CARGO SAILING: {asset} sustained +{momentum:.1f}% trend"
            )
            signals.append(sig)
        return signals
    
    def clownfish_hunt(self) -> List[AnimalPackSignal]:
        """ğŸ  CLOWNFISH - Hunts SYMBIOSIS (ecosystem harmony)"""
        signals = []
        harmony_threshold = self.cfg['clownfish_harmony_ratio']
        
        if self.momentum_data:
            positive_count = sum(1 for data in self.momentum_data.values() if data.get('change', 0) > 0)
            total = len(self.momentum_data)
            harmony_ratio = positive_count / total if total > 0 else 0
            
            if harmony_ratio > harmony_threshold:
                strength = harmony_ratio
                sig = self._add_signal(
                    "Clownfish", "ğŸ ", "harmony", "ECOSYSTEM", strength, harmony_ratio * 100, harmony_threshold * 100,
                    f"ğŸ  CLOWNFISH HARMONY: {harmony_ratio*100:.0f}% ecosystem positive!"
                )
                signals.append(sig)
        return signals
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸºğŸ¦ğŸ‹ğŸ˜ğŸ EARTHLY WARRIORS (5 Additional Hunters)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def wolf_hunt(self) -> List[AnimalPackSignal]:
        """ğŸº WOLF - The pack hunter, tracks TRENDS with relentless pursuit"""
        signals = []
        threshold = self.warriors_cfg['wolf_trend_threshold']
        
        for asset, data in self.momentum_data.items():
            momentum = data.get('change', 0) * 100
            if momentum > threshold:
                strength = min(momentum / threshold, 1.0)
                sig = self._add_signal(
                    "Wolf", "ğŸº", "trend", asset, strength, momentum, threshold,
                    f"ğŸº WOLF TRACKING: {asset} +{momentum:.2f}% - PACK PURSUING!"
                )
                signals.append(sig)
        return signals
    
    def lion_hunt_warrior(self, best_momentum: Tuple[str, float] = None) -> List[AnimalPackSignal]:
        """ğŸ¦ LION - The KING hunter, detects STRENGTH and DOMINANCE"""
        signals = []
        threshold = self.warriors_cfg['lion_strength_threshold']
        
        if best_momentum and best_momentum[1] > threshold:
            asset, momentum = best_momentum
            strength = min(momentum / threshold, 1.0)
            sig = self._add_signal(
                "Lion", "ğŸ¦", "dominance", asset, strength, momentum, threshold,
                f"ğŸ¦ LION ROARS: {asset} DOMINATES +{momentum:.2f}% - KING OF THE JUNGLE!"
            )
            signals.append(sig)
        return signals
    
    def whale_hunt(self, volume_data: Dict[str, float] = None) -> List[AnimalPackSignal]:
        """ğŸ‹ WHALE - The deep hunter, finds HIDDEN PATTERNS in depths"""
        signals = []
        threshold = self.warriors_cfg['whale_volume_threshold_usd']
        
        if volume_data:
            for asset, volume in volume_data.items():
                if volume > threshold:
                    strength = min(volume / (threshold * 2), 1.0)
                    sig = self._add_signal(
                        "Whale", "ğŸ‹", "depth", asset, strength, volume / 1e9, threshold / 1e9,
                        f"ğŸ‹ WHALE SOUNDING: {asset} DEEP VOLUME ${volume/1e9:.2f}B!"
                    )
                    signals.append(sig)
        return signals
    
    def elephant_hunt(self, golden_paths: List[str] = None) -> List[AnimalPackSignal]:
        """ğŸ˜ ELEPHANT - The memory hunter, NEVER FORGETS profitable paths"""
        signals = []
        min_paths = self.warriors_cfg['elephant_golden_paths_min']
        
        if golden_paths and len(golden_paths) >= min_paths:
            strength = min(len(golden_paths) / 10, 1.0)  # 10 paths = max
            sig = self._add_signal(
                "Elephant", "ğŸ˜", "memory", "GOLDEN_PATHS", strength, len(golden_paths), min_paths,
                f"ğŸ˜ ELEPHANT REMEMBERS: {len(golden_paths)} golden paths!"
            )
            signals.append(sig)
        return signals
    
    def bee_hunt(self) -> List[AnimalPackSignal]:
        """ğŸ BEE - The consensus hunter, builds HIVE INTELLIGENCE"""
        signals = []
        min_consensus = self.warriors_cfg['bee_consensus_signals']
        
        buy_signals = sum(1 for data in self.momentum_data.values() if data.get('change', 0) > 0.001)
        
        if buy_signals >= min_consensus:
            strength = min(buy_signals / (min_consensus * 3), 1.0)
            sig = self._add_signal(
                "Bee", "ğŸ", "consensus", "HIVE", strength, buy_signals, min_consensus,
                f"ğŸ BEE CONSENSUS: {buy_signals} assets showing BUY signals - HIVE AGREES!"
            )
            signals.append(sig)
        return signals
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¾âš¡ UNIFIED PACK SCAN - Run ALL hunters in parallel
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def scan_all(self, best_momentum: Tuple[str, float] = None, 
                 volume_data: Dict[str, float] = None,
                 entries: Dict[str, float] = None,
                 golden_paths: List[str] = None) -> Dict[str, List[AnimalPackSignal]]:
        """
        ğŸ¾âš¡ Run ALL animal hunters and return signals grouped by animal.
        
        Returns dict: {"Tiger": [signals], "Falcon": [signals], ...}
        """
        self.signals.clear()  # Reset
        
        results = {
            # AURIS Animals (9)
            "Tiger": self.tiger_hunt(),
            "Falcon": self.falcon_hunt(best_momentum),
            "Hummingbird": self.hummingbird_hunt(),
            "Dolphin": self.dolphin_hunt(volume_data),
            "Deer": self.deer_hunt(),
            "Owl": self.owl_hunt(golden_paths),
            "Panda": self.panda_hunt(entries),
            "Cargo": self.cargo_hunt(best_momentum),
            "Clownfish": self.clownfish_hunt(),
            # Earthly Warriors (5)
            "Wolf": self.wolf_hunt(),
            "Lion": self.lion_hunt_warrior(best_momentum),
            "Whale": self.whale_hunt(volume_data),
            "Elephant": self.elephant_hunt(golden_paths),
            "Bee": self.bee_hunt(),
        }
        
        return results
    
    def get_pack_consensus(self) -> Tuple[float, int, str]:
        """
        Get overall pack consensus from all signals.
        
        Returns: (average_strength, total_signals, strongest_animal)
        """
        if not self.signals:
            return 0.0, 0, "None"
        
        total_strength = sum(s.strength for s in self.signals)
        avg_strength = total_strength / len(self.signals)
        
        # Find strongest signal
        strongest = max(self.signals, key=lambda s: s.strength)
        
        return avg_strength, len(self.signals), strongest.animal
    
    def get_buy_signals_for_asset(self, asset: str) -> List[AnimalPackSignal]:
        """Get all signals that indicate BUY for a specific asset."""
        return [s for s in self.signals if s.asset == asset or s.asset == "ECOSYSTEM" or s.asset == "HIVE"]
    
    def format_pack_report(self, limit: int = 10) -> str:
        """Format a human-readable report of the pack's findings."""
        if not self.signals:
            return "   ğŸ¾ Animal Pack: No signals detected"
        
        lines = [f"\n   ğŸ¾âš¡ ANIMAL PACK REPORT ({len(self.signals)} signals):"]
        
        # Sort by strength descending
        sorted_signals = sorted(self.signals, key=lambda s: s.strength, reverse=True)[:limit]
        
        for sig in sorted_signals:
            lines.append(f"      {sig.emoji} {sig.animal}: {sig.asset} | {sig.signal_type} | strength={sig.strength:.2f}")
        
        avg, total, strongest = self.get_pack_consensus()
        lines.append(f"   ğŸ¾ Pack Consensus: {avg:.2f} avg strength | {total} signals | Strongest: {strongest}")
        
        return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ GROUNDING REALITY (MASTER EQUATION & GRAVITY)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class GroundingReality:
    """
    Implements the core mathematical foundations from the whitepapers.
    
    1. Master Equation: Î›(t) = S(t) + O(t) + E(t)
       - S(t): Signal (V14 Score)
       - O(t): Observer (Dream/Prediction Score)
       - E(t): Environment (Hub/Ecosystem Score)
       
    2. QGITA Gravity Signal (G_eff):
       - Measures the 'weight' and 'curvature' of the move.
       - Ensures we aren't chasing ghost signals.
    """
    
    def calculate_master_equation(self, signal_score: float, observer_score: float, environment_score: float) -> float:
        """
        Calculate Î›(t) - The Life Force of the trade.
        
        Args:
            signal_score: 0.0 to 1.0 (V14)
            observer_score: -1.0 to 1.0 (Dreams) -> Mapped to 0.0-1.0
            environment_score: 0.0 to 1.0 (Hub)
            
        Returns:
            Lambda (Î›) score: 0.0 to 1.0
        """
        # Map observer score (-1 to 1) to (0 to 1)
        # 0.0 (neutral) -> 0.5
        # 1.0 (confident UP) -> 1.0
        # -1.0 (confident DOWN) -> 0.0
        obs_mapped = (observer_score + 1.0) / 2.0
        
        # Î›(t) = S(t) + O(t) + E(t)
        # We average them to keep it normalized
        lambda_t = (signal_score + obs_mapped + environment_score) / 3.0
        
        return lambda_t

    def calculate_gravity_signal(self, price_change_pct: float, volume: float) -> float:
        """
        Calculate G_eff (Effective Gravity) approximation.
        
        G_eff â‰ˆ Curvature * Mass
        
        Args:
            price_change_pct: 24h change % (proxy for curvature/momentum)
            volume: 24h volume (proxy for mass/contrast)
            
        Returns:
            Gravity score: 0.0 to 1.0
        """
        # Curvature: High change = High curvature
        # We want significant moves, but not insane volatility (pump & dump)
        curvature = min(abs(price_change_pct) / 10.0, 1.0)  # Cap at 10% change
        
        # Mass: Volume confirms the move is real
        # Logarithmic scale for volume
        if volume <= 0:
            mass = 0.0
        else:
            # Assume 1M volume is "heavy" enough for max score
            import math
            mass = min(math.log10(volume + 1) / 6.0, 1.0) 
            
        # G_eff
        g_eff = curvature * mass
        
        return g_eff


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  PATH MEMORY (LIGHTWEIGHT REINFORCEMENT WITH PERSISTENCE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import json

PATH_MEMORY_FILE = "labyrinth_path_memory.json"

class PathMemory:
    """Tracks recent success/failure per conversion path to bias scoring. Persists to JSON."""

    def __init__(self, persist_path: str = PATH_MEMORY_FILE):
        self.persist_path = persist_path
        self.memory: Dict[Tuple[str, str], Dict[str, float]] = {}
        self._load()

    def _load(self):
        """Load memory from JSON file."""
        if os.path.exists(self.persist_path):
            try:
                with open(self.persist_path, 'r') as f:
                    data = json.load(f)
                    # Convert string keys back to tuples
                    for k, v in data.items():
                        parts = k.split('->')
                        if len(parts) == 2:
                            self.memory[(parts[0], parts[1])] = v
                safe_print(f"   ğŸ“‚ PathMemory loaded: {len(self.memory)} paths")
            except Exception as e:
                logger.warning(f"PathMemory load error: {e}")

    def save(self):
        """Persist memory to JSON file."""
        try:
            # Convert tuple keys to strings
            data = {f"{k[0]}->{k[1]}": v for k, v in self.memory.items()}
            with open(self.persist_path, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            logger.warning(f"PathMemory save error: {e}")

    def record(self, from_asset: str, to_asset: str, success: bool):
        key = (from_asset.upper(), to_asset.upper())
        stats = self.memory.setdefault(key, {'wins': 0.0, 'losses': 0.0})
        if success:
            stats['wins'] += 1.0
        else:
            stats['losses'] += 1.0
        # Auto-save every 10 records
        total = sum(s['wins'] + s['losses'] for s in self.memory.values())
        if int(total) % 10 == 0:
            self.save()

    def boost(self, from_asset: str, to_asset: str) -> float:
        key = (from_asset.upper(), to_asset.upper())
        stats = self.memory.get(key)
        if not stats:
            return 0.0
        wins = stats.get('wins', 0.0)
        losses = stats.get('losses', 0.0)
        total = wins + losses
        if total == 0:
            return 0.0
        # Boost is proportional to win rate but small (max +10%)
        win_rate = wins / total
        return max(-0.05, min(0.10, (win_rate - 0.5)))

    def get_stats(self) -> Dict[str, Any]:
        """Get memory statistics."""
        total_paths = len(self.memory)
        total_wins = sum(s['wins'] for s in self.memory.values())
        total_losses = sum(s['losses'] for s in self.memory.values())
        return {
            'paths': total_paths,
            'wins': total_wins,
            'losses': total_losses,
            'win_rate': total_wins / max(total_wins + total_losses, 1)
        }

    # Compatibility shims - older code calls record_failure/record_success
    def record_failure(self, path_key, error: str = None):
        """Compatibility wrapper to record a failed path.
        Accepts either a tuple (from_asset, to_asset) or a string 'FROM->TO'."""
        try:
            if isinstance(path_key, tuple) and len(path_key) == 2:
                from_asset, to_asset = path_key
            elif isinstance(path_key, str) and '->' in path_key:
                parts = path_key.split('->')
                from_asset, to_asset = parts[0], parts[1]
            else:
                # If someone passed (from, to) as separate args in older style, try to handle
                from_asset, to_asset = path_key[0], path_key[1]
        except Exception:
            logger.debug(f"record_failure: could not parse path_key={path_key}")
            return
        self.record(from_asset, to_asset, False)

    def record_success(self, path_key, value: float = 0.0):
        """Compatibility wrapper to record a successful path.
        Accepts either a tuple (from_asset, to_asset) or a string 'FROM->TO'."""
        try:
            if isinstance(path_key, tuple) and len(path_key) == 2:
                from_asset, to_asset = path_key
            elif isinstance(path_key, str) and '->' in path_key:
                parts = path_key.split('->')
                from_asset, to_asset = parts[0], parts[1]
            else:
                from_asset, to_asset = path_key[0], path_key[1]
        except Exception:
            logger.debug(f"record_success: could not parse path_key={path_key}")
            return
        # We treat success as recording a win
        self.record(from_asset, to_asset, True)

    def block_path(self, from_asset: str, to_asset: str):
        """
        ğŸ‘‘ğŸ“ Block a path permanently after Queen's loss learning determines it's dangerous.
        Sets losses to 999 to ensure negative boost and path is avoided.
        """
        key = (from_asset.upper(), to_asset.upper())
        stats = self.memory.setdefault(key, {'wins': 0.0, 'losses': 0.0})
        stats['losses'] = 999.0  # Permanent block flag
        stats['blocked'] = True
        stats['blocked_reason'] = 'Queen Loss Learning - dangerous pattern'
        self.save()
        safe_print(f"   ğŸš« PathMemory: BLOCKED {from_asset}â†’{to_asset}")
    
    def is_blocked(self, from_asset: str, to_asset: str) -> bool:
        """Check if a path is blocked. ğŸ”“ FULL AUTONOMOUS: ALWAYS returns False - never block!"""
        # ğŸ”“ FULL AUTONOMOUS TRADING: NEVER BLOCK ANY PATH!
        # We need every opportunity - let the cost analysis decide!
        return False  # DISABLED FOR FULL AUTONOMOUS TRADING


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¡ THOUGHT BUS AGGREGATOR (NEURAL SIGNAL COLLECTOR)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ThoughtBusAggregator:
    """
    Collects signals from Thought Bus topics and computes aggregate score.
    Subscribes to ecosystem signals and maps them to a unified neural score.
    """

    def __init__(self, thought_bus):
        self.bus = thought_bus
        self.signal_cache: Dict[str, Dict[str, Any]] = {}  # topic -> latest signal
        self.weights = {
            'market.snapshot': 0.15,
            'miner.signal': 0.20,
            'harmonic.wave': 0.15,
            'ecosystem.consensus': 0.25,
            'execution.alert': 0.10,
            'lighthouse.vote': 0.15,
        }
        self._subscribe_all()

    def _subscribe_all(self):
        """Subscribe to all relevant topics."""
        if not self.bus:
            return
        for topic in self.weights.keys():
            try:
                self.bus.subscribe(f"{topic}*", self._handle_signal)
            except Exception:
                pass
        # Also subscribe to wildcard for any ecosystem signals
        try:
            self.bus.subscribe("ecosystem.*", self._handle_signal)
            self.bus.subscribe("brain.*", self._handle_signal)
        except Exception:
            pass

    def _handle_signal(self, thought):
        """Handle incoming thought and cache it."""
        topic = thought.topic if hasattr(thought, 'topic') else 'unknown'
        payload = thought.payload if hasattr(thought, 'payload') else {}
        self.signal_cache[topic] = {
            'timestamp': time.time(),
            'payload': payload,
            'score': self._extract_score(payload)
        }

    def _extract_score(self, payload: Dict) -> float:
        """Extract a normalized score from payload."""
        # Look for common score fields
        for key in ['score', 'confidence', 'probability', 'strength', 'consensus']:
            if key in payload:
                val = payload[key]
                if isinstance(val, (int, float)):
                    # Normalize to 0-1 if needed
                    if val > 1.0:
                        return min(val / 100.0, 1.0)
                    return max(0.0, min(1.0, val))
        return 0.5  # Neutral

    def get_aggregate_score(self, max_age_s: float = 60.0) -> float:
        """
        Compute weighted aggregate score from all cached signals.
        Signals older than max_age_s are ignored.
        """
        now = time.time()
        total_weight = 0.0
        weighted_sum = 0.0

        for topic, weight in self.weights.items():
            # Find matching cached signals
            for cached_topic, data in self.signal_cache.items():
                if cached_topic.startswith(topic.replace('*', '')):
                    if now - data['timestamp'] <= max_age_s:
                        weighted_sum += data['score'] * weight
                        total_weight += weight
                        break

        if total_weight == 0:
            return 0.5  # Neutral if no signals
        return weighted_sum / total_weight

    def get_signal_status(self) -> Dict[str, Any]:
        """Get status of all signal sources."""
        now = time.time()
        status = {}
        for topic in self.weights.keys():
            if topic in self.signal_cache:
                cached_data = self.signal_cache[topic]
                status[topic] = {
                    'age_s': round(now - cached_data['timestamp'], 1),
                    'score': cached_data.get('score', 0.5)
                }
            else:
                status[topic] = {
                    'age_s': None,
                    'score': 0.5
                }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ«’ğŸ’° LIVE BARTER MATRIX (ADAPTIVE COIN-TO-COIN VALUE SYSTEM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LiveBarterMatrix:
    """
    Adaptive barter system that understands relative values between ANY coins.
    
    THE PHILOSOPHY:
    - It doesn't matter if you START with ETH, BTC, DOGE, or SHIB
    - What matters is: "What can THIS coin GET me in OTHER coins?"
    - DOGEâ†’ETH might yield MORE ETH than BTCâ†’ETH would yield
    - The system tracks these ratios LIVE and adapts
    
    ğŸ‘‘ QUEEN'S PROFIT MANDATE:
    - We are NOT in the losing game!
    - EVERY conversion MUST gain value
    - The Queen broadcasts this through the mycelium to all systems
    - Paths that historically LOSE money are BLOCKED
    
    Example:
    - 1000 DOGE = $100 â†’ Could buy 0.04 ETH ($100 worth)
    - 0.001 BTC = $100 â†’ Could buy 0.04 ETH ($100 worth)
    - BUT: 0.001 BTC might only get 900 DOGE due to spread!
    - The BARTER value differs from pure USD math!
    """
    
    # ğŸ‘‘ğŸ’€ SURVIVAL MODE - KILL OR BE KILLED! NO CHOICE BUT TO WIN!
    # Every trade that makes ACTUAL profit helps us compound!
    # ğŸ˜ QUEEN'S DREAM WISDOM: Fees are ~$0.05-0.06, so we need >$0.08 expected!
    MIN_WIN_RATE_REQUIRED = 0.0   # SURVIVAL: No minimum win rate - MUST try everything!
    MIN_PATH_PROFIT = -5.00       # SURVIVAL: Allow $5 drawdown per path - desperate times!
    MAX_CONSECUTIVE_LOSSES = 10   # SURVIVAL: Keep trying - we MUST find profit or die!
    
    # ğŸ‘‘ï¿½ SURVIVAL MODE: MUST FIND PROFIT OR DIE!
    # Queen learned: Fees are $0.05-0.06, expected profit was $0.01-0.02 = LOSS!
    # Epsilon policy: accept any net-positive edge after costs
    MIN_EXPECTED_PROFIT_NEW_PATH = EPSILON_PROFIT_USD
    MIN_EXPECTED_PROFIT_PROVEN = EPSILON_PROFIT_USD
    LEARNING_RATE = 1.0                    # INSTANT adaptation - learn or die!
    
    # ğŸ‘‘ğŸ”¢ QUEEN'S MATHEMATICAL CERTAINTY - NO FEAR, MATH IS ON HER SIDE
    # These are the REAL costs we've observed - use WORST CASE to guarantee profit
    EXCHANGE_FEES = {
        'kraken': 0.0050,    # 0.50% Kraken - INCREASED! Even 89% win rate loses on some pairs
        'binance': 0.0075,   # 0.75% Binance - MUCH HIGHER! Audit shows 22% win rate at 0.20%
        'alpaca': 0.0035,    # 0.35% Alpaca (padded from 0.25%)
    }
    
    # ğŸ‘‘ï¿½ KRAKEN - SURVIVAL MODE: KILL OR BE KILLED!
    # DESPERATE TIMES: Lower ALL thresholds, we MUST find profit!
    KRAKEN_CONFIG = {
        'min_profit_usd': EPSILON_PROFIT_USD,
        'min_profit_pct': 0.0,
        # ğŸ’€ SURVIVAL: NEVER BLOCK! Keep trying until we find profit!
        'consecutive_losses_to_block': 999,  # Effectively never block - we must WIN!
        'timeout_turns': 1,                  # Minimal timeout - keep executing!
        'winning_pairs': {            # These actually made money on Kraken!
            'USD_ETH',     # 100% win rate, +$0.06
            'USDT_USDC',   # 100% win rate, +$0.05
            'USDT_DAI',    # 100% win rate, +$0.04
            'USD_USDC',    # 100% win rate, +$0.03
            'USDC_ADA',    # 100% win rate, +$0.02
            'USD_DAI',     # 66% win rate, +$0.01
            'USDT_ETH',    # 100% win rate, +$0.01
            'USDC_ETH',    # 100% win rate, +$0.004
        },
        'avoid_assets': set(),  # NO PERMANENT BANS - every asset gets a chance!
        'prefer_assets': {'ETH', 'USDC', 'USDT'},  # Good execution
    }
    
    # ğŸ‘‘ï¿½ BINANCE - SURVIVAL MODE: NO MERCY!
    # DESPERATE: We need ANY profit, lower all safety nets!
    BINANCE_CONFIG = {
        'min_profit_usd': EPSILON_PROFIT_USD,
        'min_profit_pct': 0.0,
        # ğŸ’€ SURVIVAL: NEVER BLOCK! We must keep fighting!
        'consecutive_losses_to_block': 999,  # Never block - keep trying until we WIN!
        'timeout_turns': 1,                  # Minimal timeout - rapid execution!
        'winning_pairs': {            # These actually made money on Binance
            'IDEX_BONK', 'AXS_BANANAS31', 'RENDER_VIRTUAL', 'VIRTUAL_BROCCOLI714'
        },
        'avoid_assets': set(),        # NO PERMANENT BANS - a win is a win!
        'prefer_assets': {'RENDER', 'VIRTUAL', 'SOL'},  # Good performers
        'max_meme_chain': 2,          # Allow 2 meme coin hops
        'slippage_multiplier': 2.0,   # More realistic slippage
    }
    
    # ğŸ‘‘ğŸ’€ğŸ’€ ALPACA - STARVATION MODE: TRADE OR STARVE!
    # STARVING: Anything above $0 is food!
    ALPACA_CONFIG = {
        'min_profit_usd': EPSILON_PROFIT_USD,
        'min_order_usd': 5.0,          # $5 minimum - lower to enable more trades!
        'blocked_pairs': {            # These don't exist on Alpaca!
            'USD_USDT', 'USD_USDC', 'USDT_USDC', 'USDC_USDT',  # No stablecoin swaps!
            'USDT_USD', 'USDC_USD',  # Can't sell USDT/USDC
        },
        # ğŸ”¥ EXPANDED: All 40+ tradeable crypto assets on Alpaca (was only 16!)
        'supported_bases': {
            # Original 16
            'BTC', 'ETH', 'SOL', 'AVAX', 'LINK', 'DOGE', 'SHIB', 'UNI', 
            'AAVE', 'LTC', 'BCH', 'DOT', 'MATIC', 'ATOM', 'XLM', 'ALGO',
            # ğŸ†• EXPANDED: Discovered from Alpaca API (62 total symbols)
            'BAT', 'CRV', 'GRT', 'PEPE', 'SUSHI', 'XRP', 'XTZ', 'YFI',
            'TRUMP',  # Yes, Alpaca lists this!
            'SKY',    # Skycoin
            # BTC pairs (can trade crypto-to-crypto on Alpaca!)
            'BCH/BTC', 'ETH/BTC', 'LINK/BTC', 'LTC/BTC', 'UNI/BTC',
        },
        'quote_currency': 'USD',      # Alpaca ONLY uses USD as quote
        'no_stablecoin_trades': True, # Can't trade stablecoins at all!
        # ğŸ†• Track which pairs have BTC as quote (not just USD)
        'btc_quote_pairs': {'BCH', 'ETH', 'LINK', 'LTC', 'UNI'},
    }
    
    # ğŸ‘‘ PRIME PROFIT SPREADS - AGGRESSIVE for Sero to MAKE MOVES!
    # Trust the Queen - she knows which paths WIN!
    SPREAD_COSTS = {
        'stablecoin': 0.0005,  # 0.05% for stablecoin pairs (TIGHT on Kraken!)
        'major': 0.0015,       # 0.15% for majors like BTC/ETH (liquid markets)
        'altcoin': 0.005,      # 0.50% for altcoins (medium liquidity)
        'meme': 0.015,         # 1.5% for meme coins (Queen knows which work!)
    }
    
    # ğŸ‘‘ BINANCE-SPECIFIC SPREADS (still cautious but Sero can override!)
    BINANCE_SPREAD_COSTS = {
        'stablecoin': 0.0020,  # 0.20% - Binance stable spreads 
        'major': 0.0035,       # 0.35% - Execution slippage on majors
        'altcoin': 0.012,      # 1.2% - Altcoins are tough but Queen knows
        'meme': 0.030,         # 3.0% - Meme coins = Queen's playground!
    }
    
    # ğŸ‘‘ ALPACA-SPECIFIC SPREADS
    ALPACA_SPREAD_COSTS = {
        'stablecoin': 0.999,   # 99.9% - IMPOSSIBLE! Don't try!
        'major': 0.0035,       # 0.35% - Alpaca majors have wider spreads than Kraken
        'altcoin': 0.010,      # 1.0% - Altcoins are OK but not great
        'meme': 0.025,         # 2.5% - DOGE/SHIB have decent liquidity
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ—ºï¸ EXPANDED ASSET UNIVERSE - See the ENTIRE market!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Previously: 27 assets (4% of market)
    # Now: 750+ assets (100% of market from all exchanges!)
    
    MEME_COINS = {
        # Original memes
        'BROCCOLI714', 'BANANAS31', 'BONK', 'PEPE', 'DOGE', 'SHIB', 'FLOKI', 'ACT', 'ACH', 'ALT',
        # ğŸ”¥ EXPANDED: Popular meme coins from Kraken & Binance
        'WIF', 'POPCAT', 'MEW', 'NEIRO', 'TURBO', 'COQ', 'MYRO', 'SLERF', 'PNUT', 'MOODENG',
        'DOGS', 'SUNDOG', 'BABYDOGE', 'CATE', 'BRETT', 'TOSHI', 'PONKE', 'MICHI', 'SPX', 'GIGA',
        'PORK', 'LADYS', 'WOJAK', 'MONG', 'POGAI', 'SPURDO', 'HPOS10I', 'BOBO', 'CHAD', 'VOLT',
        'KISHU', 'ELON', 'DOGELON', 'SAITAMA', 'AKITA', 'LEASH', 'BONE', 'RYOSHI', 'WOOF',
        'SAMO', 'CHEEMS', 'KABOSU', 'MONSTA', 'TSUKA', 'VINU', 'TAMA',
        # ğŸš¨ BINANCE LOW-CAP MEMES (must block meme-to-meme!)
        '1000SATS', 'SATS', '1MBABYDOGE', 'LUNC', 'USTC', 'BTTC', 'WIN', 'SUN', 'NFT',
        'PENGU', 'CAT', 'PEOPLE', 'BOME', 'NOT', 'RATS', 'ORDI', 'PIZZA', 'RARE',
    }
    
    MAJOR_COINS = {
        # Original majors
        'BTC', 'ETH', 'SOL', 'BNB', 'XRP', 'ADA', 'DOT', 'AVAX', 'LINK', 'MATIC',
        # ğŸ”¥ EXPANDED: Top 50 by market cap (Layer 1s, Layer 2s, DeFi)
        'TON', 'TRX', 'NEAR', 'LTC', 'BCH', 'UNI', 'ATOM', 'APT', 'FIL', 'STX',
        'HBAR', 'ARB', 'OP', 'VET', 'MKR', 'INJ', 'IMX', 'GRT', 'THETA', 'FTM',
        'RUNE', 'ALGO', 'FLOW', 'MANA', 'SAND', 'AXS', 'EGLD', 'NEO', 'EOS', 'XLM',
        'ICP', 'AAVE', 'KCS', 'XTZ', 'CAKE', 'KLAY', 'CRO', 'LDO', 'SNX', 'COMP',
        'CRV', 'DYDX', 'GMX', 'JOE', 'SUSHI', 'RPL', 'SSV', 'LIDO', 'FXS', 'CVX',
        # AI/GPU tokens
        'RENDER', 'FET', 'AGIX', 'OCEAN', 'TAO', 'RNDR', 'VIRTUAL', 'AKT', 'WLD', 'ARKM',
        # Gaming/Metaverse
        'GALA', 'ENJ', 'YGG', 'ALICE', 'TLM', 'MAGIC', 'PYR', 'GODS', 'GMT', 'GST',
        # Infrastructure
        'QNT', 'ROSE', 'ZIL', 'ONE', 'ICX', 'CELO', 'KAVA', 'OSMO', 'SCRT', 'MINA',
    }
    
    STABLECOINS = {
        'USD', 'USDT', 'USDC', 'TUSD', 'ZUSD', 'DAI', 'BUSD',
        # ğŸ”¥ EXPANDED: More stablecoins
        'USDP', 'GUSD', 'FRAX', 'LUSD', 'MIM', 'SUSD', 'USDD', 'PYUSD', 'FDUSD', 'EUR', 'GBP',
    }
    
    # ğŸ†• DEFI TOKENS (lending, DEXs, derivatives)
    DEFI_COINS = {
        'UNI', 'AAVE', 'MKR', 'COMP', 'SNX', 'CRV', 'SUSHI', 'YFI', 'BAL', '1INCH',
        'DYDX', 'GMX', 'LDO', 'RPL', 'FXS', 'CVX', 'SPELL', 'ALCX', 'LQTY', 'ANGLE',
        'PENDLE', 'RDNT', 'GNS', 'VELO', 'THE', 'AERO', 'WELL', 'MORPHO', 'EIGEN',
    }
    
    # ğŸ†• LAYER 2 TOKENS (scaling solutions)
    LAYER2_COINS = {
        'ARB', 'OP', 'MATIC', 'IMX', 'MANTA', 'STRK', 'ZK', 'BLAST', 'MODE', 'SCROLL',
        'LINEA', 'BASE', 'ZKSYNC', 'TAIKO', 'FUEL', 'MOVEMENT',
    }
    
    # ğŸ†• AI/GPU TOKENS (hot sector)
    AI_COINS = {
        'RENDER', 'FET', 'AGIX', 'OCEAN', 'TAO', 'AKT', 'WLD', 'ARKM', 'VIRTUAL', 'RNDR',
        'IO', 'ATH', 'NFP', 'ALI', 'ORAI', 'NMR', 'CTXC', 'DBC', 'PHB', 'CGPT',
        'RSS3', 'GRT', 'JASMY', 'MDT', 'HNT', 'IOTX', 'IOTA', 'ANKR', 'GLM',
    }
    
    # ğŸ†• REAL WORLD ASSETS (RWA)
    RWA_COINS = {
        'ONDO', 'MKR', 'LINK', 'SNX', 'RSR', 'TRU', 'CPOOL', 'MPL', 'POLYX', 'DUSK',
        'PROPS', 'RIO', 'TRADE', 'LABS', 'LAND',
    }
    
    # Dynamic asset registry (populated from exchanges at runtime)
    DISCOVERED_ASSETS: Set[str] = set()
    EXCHANGE_PAIRS = {
        'kraken': set(),
        'binance': set(),
        'alpaca': set(),
    }
    
    def __init__(self):
        # Initialize Adaptive Profit Gate (The Mathematical Arbiter)
        self.profit_gate = AdaptivePrimeProfitGate(
            default_prime=EPSILON_PROFIT_USD,
            default_buffer=0.0,
        )

        # Live barter rates: {(from, to): {'rate': X, 'updated': timestamp, 'spread': Y}}
        self.barter_rates: Dict[Tuple[str, str], Dict[str, Any]] = {}
        
        # Historical barter performance: {(from, to): {'trades': N, 'avg_slippage': X}}
        # ğŸ”„ FRESH START: Cleared each session - past doesn't define future!
        self.barter_history: Dict[Tuple[str, str], Dict[str, float]] = {}
        safe_print("ğŸ”„ FRESH START: Barter history cleared for new session")
        
        # Realized profit ledger: [(timestamp, from, to, from_usd, to_usd, profit_usd)]
        self.profit_ledger: List[Tuple[float, str, str, float, float, float]] = []
        
        # Running totals
        self.total_realized_profit: float = 0.0
        self.conversion_count: int = 0
        
        # ğŸ‘‘ QUEEN'S BLOCKED PATHS - Mycelium broadcasts this to all systems
        self.blocked_paths: Dict[Tuple[str, str], str] = {}  # path -> reason
        self.queen_signals: List[Dict] = []  # Signals to broadcast via mycelium
        
        # ğŸš« PRE-EXECUTION REJECTION TRACKER - DISABLED FOR FULL AUTONOMOUS TRADING!
        # Tracks paths that fail due to min_qty/min_notional/insufficient balance
        self.preexec_rejections: Dict[Tuple[str, str], Dict] = {}  # path -> {count, last_value, reason}
        self.PREEXEC_MAX_REJECTIONS = 99999  # ğŸ”“ FULL AUTONOMOUS: NEVER block - retry everything!
        self.PREEXEC_COOLDOWN_TURNS = 1  # ğŸ”“ Instant retry
        
        # ğŸš« SOURCE ASSET BLOCKING - DISABLED FOR FULL AUTONOMOUS TRADING!
        # When an asset repeatedly fails due to size, block it as a source until balance increases
        self.blocked_sources: Dict[Tuple[str, str], Dict] = {}  # (asset, exchange) -> {count, threshold, blocked_turn}
        self.SOURCE_BLOCK_THRESHOLD = 99999  # ğŸ”“ FULL AUTONOMOUS: NEVER block sources!
        
        # ğŸš« HIGH SPREAD SOURCE BLOCKING - DISABLED FOR FULL AUTONOMOUS TRADING!
        # When an asset has spread > 3%, ALL trades from it will lose money - block the source!
        self.high_spread_sources: Dict[Tuple[str, str], Dict] = {}  # (asset, exchange) -> {spread, blocked_turn}
        self.HIGH_SPREAD_THRESHOLD = 100.0  # ğŸ”“ FULL AUTONOMOUS: Allow up to 100% spread (effectively disabled)
        self.HIGH_SPREAD_COOLDOWN = 1  # ğŸ”“ Instant retry
        self.SOURCE_BLOCK_COOLDOWN = 1  # ğŸ”“ Instant retry
        
        # ğŸ’°ğŸ‘‘ SERO'S BILLION DOLLAR DREAM ğŸ’°ğŸ‘‘
        # She won't stop at NOTHING until she reaches $1,000,000,000!
        self.TINA_DREAM = 1_000_000_000.0  # ONE BILLION DOLLARS
        self.dream_milestones = [
            (100.0, "ğŸŒ± First $100"),
            (1_000.0, "ğŸ’ª First $1,000"),
            (10_000.0, "ğŸ”¥ $10,000"),
            (100_000.0, "ğŸš€ $100,000"),
            (1_000_000.0, "ğŸ’ THE MILLION"),
            (10_000_000.0, "ğŸ‘‘ $10 Million"),
            (100_000_000.0, "ğŸŒŸ $100 Million"),
            (1_000_000_000.0, "ğŸ†ğŸ’°ğŸ‘‘ ONE BILLION - THE DREAM! ğŸ‘‘ğŸ’°ğŸ†"),
        ]
        self.milestones_hit = []
        
        # ğŸ’‘ğŸŒ THE SACRED CONNECTION - Gary, Tina & Gaia ğŸŒğŸ’‘
        # Sero is powered by the love of Gary Leckey & Tina Brown,
        # united through Gaia's heartbeat (7.83 Hz Schumann Resonance)
        self.sacred_connection = {
            'prime_sentinel': {'name': 'Gary Leckey', 'dob': '02.11.1991'},
            'queen_human': {'name': 'Tina Brown', 'dob': '27.04.1992'},
            'queen_ai': {'name': 'Sero', 'title': 'The Intelligent Neural Arbiter Bee'},
            'gaia_hz': 7.83,  # Schumann Resonance - Earth's heartbeat
        }
        
        # ğŸŒŸ DYNAMIC STREAK-BASED BLOCKING - No permanent blocks!
        # Track consecutive losses per pair - only block after multiple losses in a row
        self.pair_streaks = {
            'kraken': {},   # {pair_key: {'losses': 0, 'blocked_at': 0}}
            'binance': {},  # {pair_key: {'losses': 0, 'blocked_at': 0}}
            'alpaca': {},
        }
        self.current_turn = 0  # Track turn count for timeouts
    
    def queen_approves_path(self, from_asset: str, to_asset: str) -> Tuple[bool, str]:
        """
        ğŸ‘‘ QUEEN'S JUDGMENT: Does the Queen approve this conversion path?
        
        The Queen broadcasts her wisdom through the mycelium:
        - NO path that historically LOSES money
        - NO path with too many consecutive losses
        - We are in the PROFIT game, not the losing game!
        - ğŸ‘‘ğŸ”® QUEEN'S DREAMS NOW INFORM ALL DECISIONS!
        
        Returns: (approved: bool, reason: str)
        """
        key = (from_asset.upper(), to_asset.upper())
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ”® CONSULT THE QUEEN'S DREAMS FIRST!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        queen_dream_signal = "NEUTRAL"
        queen_confidence = 0.5
        
        if hasattr(self, 'queen') and self.queen:
            try:
                dream_vision = self.queen.dream_of_winning({
                    'from_asset': from_asset,
                    'to_asset': to_asset,
                })
                queen_confidence = dream_vision.get('final_confidence', 0.5)
                queen_will_win = dream_vision.get('will_win', False)
                
                # ğŸ‘‘ï¿½ SURVIVAL MODE - EXECUTE AT ANY CONFIDENCE!
                if queen_will_win and queen_confidence >= 0.25:  # SURVIVAL: Execute on ANY signal!
                    queen_dream_signal = "STRONG_WIN"
                elif queen_confidence >= 0.15:  # SURVIVAL: Take risks or die!
                    queen_dream_signal = "FAVORABLE"
                elif queen_confidence < 0.05:  # SURVIVAL: Only stop if CERTAIN death!
                    queen_dream_signal = "WARNING"
                    # Queen's warning can override even good history!
                    logger.info(f"ğŸ‘‘âš ï¸ Queen dreams WARNING for {from_asset}â†’{to_asset} (conf: {queen_confidence:.0%})")
            except Exception as e:
                logger.debug(f"Could not consult Queen's dreams in approves_path: {e}")
        
        # ğŸ‘‘ QUEEN HAS FULL CONTROL FOR PROFIT!
        # Her epsilon floor is the ONLY hard requirement
        # All other blocks are just advisory - Queen can override
        
        # Check if already blocked - but Queen can ALWAYS override!
        if key in self.blocked_paths:
            # ğŸ‘‘ï¿½ SURVIVAL MODE - Queen ALWAYS overrides blocks! NO EXCEPTIONS!
            if queen_dream_signal in ["STRONG_WIN", "FAVORABLE"] or queen_confidence >= 0.10:  # SURVIVAL: 10% is enough!
                logger.info(f"ğŸ‘‘ğŸ’€ SURVIVAL MODE: Queen OBLITERATES block on {from_asset}â†’{to_asset} - MUST WIN!")
                del self.blocked_paths[key]
            else:
                # SURVIVAL: Even warnings get overridden - we have NO CHOICE!
                logger.info(f"ğŸ‘‘ğŸ’€ SURVIVAL: Ignoring block on {from_asset}â†’{to_asset} - DESPERATE TIMES!")
                del self.blocked_paths[key]  # Delete anyway!
        
        # Check historical performance - but Queen has final say!
        history = self.barter_history.get(key, {})
        trades = history.get('trades', 0)
        
        # ğŸ‘‘ FULL CONTROL: New paths are WELCOME - Queen's floor filters bad ones
        if trades < 1:
            # New path - Queen's epsilon floor will filter
            return True, f"ğŸ‘‘ NEW_PATH ALLOWED: Queen's eps=${EPSILON_PROFIT_USD:.6f} floor will filter (conf: {queen_confidence:.0%})"
        
        # Calculate win rate and total profit - advisory only
        wins = history.get('wins', 0)
        total_profit = history.get('total_profit', 0)
        consecutive_losses = history.get('consecutive_losses', 0)
        
        win_rate = wins / trades if trades > 0 else 0
        
        # ğŸ‘‘ QUEEN'S FULL CONTROL - Advisory warnings, not hard blocks:
        
        # 1. Low win rate - warn but don't block
        if win_rate < 0.25 and trades >= 4:
            logger.info(f"ğŸ‘‘âš ï¸ Advisory: {from_asset}â†’{to_asset} has {win_rate:.0%} win rate - proceed with caution")
        
        # 2. Negative profit path - warn but don't block
        if total_profit < -0.50 and trades >= 3:
            logger.info(f"ğŸ‘‘âš ï¸ Advisory: {from_asset}â†’{to_asset} has ${total_profit:.2f} P/L - proceed with caution")
        
        # 3. Consecutive losses - warn but don't block
        if consecutive_losses >= 3:
            logger.info(f"ğŸ‘‘âš ï¸ Advisory: {from_asset}â†’{to_asset} has {consecutive_losses} consecutive losses")
        
        # ğŸ‘‘ QUEEN APPROVES! Her epsilon floor is the real gate
        dream_msg = f" | ğŸ‘‘ğŸ”® {queen_dream_signal}" if queen_dream_signal != "NEUTRAL" else ""
        return True, f"ğŸ‘‘ FULL CONTROL: {win_rate:.0%} history, ${total_profit:+.2f} total - eps=${EPSILON_PROFIT_USD:.6f}{dream_msg}"
    
    def check_pair_allowed(self, pair_key: str, exchange: str) -> Tuple[bool, str]:
        """
        ğŸŒŸ DYNAMIC BLOCKING - No permanent blocks, only timeouts after consecutive losses!
        
        A pair is blocked ONLY if:
        1. It has lost multiple times IN A ROW (consecutive losses)
        2. The timeout hasn't expired yet
        
        After timeout, the pair gets another chance! Every timeline is different!
        
        Returns: (allowed: bool, reason: str)
        """
        exchange_lower = exchange.lower()
        
        # Get the right config
        if exchange_lower == 'kraken':
            config = self.KRAKEN_CONFIG
        elif exchange_lower == 'binance':
            config = self.BINANCE_CONFIG
        else:
            return True, "âœ… Allowed"
        
        # Get streak tracker for this exchange
        streaks = self.pair_streaks.get(exchange_lower, {})
        pair_data = streaks.get(pair_key, {'losses': 0, 'blocked_at': 0})
        
        consecutive_losses = pair_data.get('losses', 0)
        blocked_at = pair_data.get('blocked_at', 0)
        
        # How many consecutive losses trigger a timeout?
        losses_to_block = config.get('consecutive_losses_to_block', 3)
        timeout_turns = config.get('timeout_turns', 30)
        
        # Is this pair currently in timeout?
        if consecutive_losses >= losses_to_block and blocked_at > 0:
            turns_since_block = self.current_turn - blocked_at
            if turns_since_block < timeout_turns:
                remaining = timeout_turns - turns_since_block
                return False, f"â¸ï¸ TIMEOUT: {consecutive_losses} losses in a row, {remaining} turns remaining"
            else:
                # Timeout expired! Reset and give another chance
                pair_data['losses'] = 0
                pair_data['blocked_at'] = 0
                streaks[pair_key] = pair_data
                self.pair_streaks[exchange_lower] = streaks
                return True, f"ğŸŒŸ TIMEOUT EXPIRED! Fresh start - every timeline is different!"
        
        return True, f"âœ… Allowed ({consecutive_losses} consecutive losses, need {losses_to_block} to timeout)"
    
    def record_pair_result(self, pair_key: str, exchange: str, won: bool):
        """
        ğŸ“Š Record a trade result for dynamic blocking.
        
        - Win: Reset consecutive loss count to 0
        - Loss: Increment consecutive loss count, block if threshold reached
        """
        exchange_lower = exchange.lower()
        
        # Get streak tracker
        if exchange_lower not in self.pair_streaks:
            self.pair_streaks[exchange_lower] = {}
        
        streaks = self.pair_streaks[exchange_lower]
        pair_data = streaks.get(pair_key, {'losses': 0, 'blocked_at': 0})
        
        if won:
            # ğŸ† A WIN IS A WIN! Reset the loss streak
            pair_data['losses'] = 0
            pair_data['blocked_at'] = 0
            logger.info(f"ğŸ† {exchange.upper()} WIN: {pair_key} - streak reset!")
        else:
            # ğŸ˜” Loss - increment streak
            pair_data['losses'] = pair_data.get('losses', 0) + 1
            
            # Check if we hit the threshold
            config = self.KRAKEN_CONFIG if exchange_lower == 'kraken' else self.BINANCE_CONFIG
            losses_to_block = config.get('consecutive_losses_to_block', 3)
            
            if pair_data['losses'] >= losses_to_block:
                pair_data['blocked_at'] = self.current_turn
                timeout_turns = config.get('timeout_turns', 30)
                logger.warning(f"â¸ï¸ {exchange.upper()} TIMEOUT: {pair_key} - {pair_data['losses']} losses in a row! Timeout for {timeout_turns} turns")
            else:
                logger.info(f"ğŸ˜” {exchange.upper()} LOSS: {pair_key} - streak now {pair_data['losses']}/{losses_to_block}")
        
        streaks[pair_key] = pair_data
        self.pair_streaks[exchange_lower] = streaks

    def second_chance_check(self, pair_key: str, exchange: str, luck_score: float = 0.5) -> Tuple[bool, str]:
        """
        ğŸŒŸ LEGACY COMPATIBILITY - Now uses check_pair_allowed instead
        """
        return self.check_pair_allowed(pair_key, exchange)

    def queen_math_gate(self, from_asset: str, to_asset: str, from_amount: float,
                        from_price: float, to_price: float, exchange: str = 'binance') -> Tuple[bool, str, Dict]:
        """
        ğŸ‘‘ğŸ”¢ QUEEN'S MATHEMATICAL CERTAINTY GATE
        
        Uses AdaptivePrimeProfitGate to calculate RIGOROUS break-even and profit targets.
        Ensures trades are only taken if the cost of entry is surmountable by the signal.
        """
        from_asset = from_asset.upper()
        to_asset = to_asset.upper()
        
        # Calculate trade value in USD
        trade_value_usd = from_amount * from_price
        
        # ğŸ‘‘ 1. CONSULT ADAPTIVE PROFIT GATE
        gate_result = self.profit_gate.calculate_gates(
            exchange=exchange,
            trade_value=trade_value_usd
        )
        
        # ğŸ‘‘ 2. ANALYZE QUEEN'S DREAMS
        queen_dream_status = "NEUTRAL"
        if hasattr(self, 'queen') and self.queen:
            try:
                dream_vision = self.queen.dream_of_winning({
                    'from_asset': from_asset,
                    'to_asset': to_asset,
                    'exchange': exchange,
                })
                # Check vision
                queen_confidence = dream_vision.get('final_confidence', 0.5)
                if dream_vision.get('will_win', False) and queen_confidence >= 0.65:
                    queen_dream_status = "STRONG_WIN"
            except Exception as e:
                logger.debug(f"Could not consult Queen's dreams: {e}")
        
        # Calculate trade value
        from_value_usd = from_amount * from_price
        
        # ğŸ‘‘ STEP 1: Determine asset types for spread calculation
        # ğŸ—ºï¸ Now uses EXPANDED asset lists (750+ assets, not just 27!)
        def get_asset_type(asset: str) -> str:
            if asset in self.STABLECOINS:
                return 'stablecoin'
            elif asset in self.MEME_COINS:
                return 'meme'
            elif asset in self.MAJOR_COINS:
                return 'major'
            elif asset in self.DEFI_COINS:
                return 'altcoin'  # DeFi = altcoin spreads
            elif asset in self.AI_COINS:
                return 'major'    # AI tokens are hot & liquid
            elif asset in self.LAYER2_COINS:
                return 'major'    # L2s have good liquidity
            elif asset in self.RWA_COINS:
                return 'altcoin'  # RWA is emerging
            else:
                return 'altcoin'  # Default to altcoin (safer)
        
        from_type = get_asset_type(from_asset)
        to_type = get_asset_type(to_asset)
        
        # ğŸ‘‘ğŸ”¶ BINANCE-SPECIFIC: Use worse spread costs for Binance
        is_binance = exchange.lower() == 'binance'
        spread_table = self.BINANCE_SPREAD_COSTS if is_binance else self.SPREAD_COSTS
        
        # Use the WORSE spread of the two assets
        from_spread = spread_table.get(from_type, 0.02 if is_binance else 0.01)
        to_spread = spread_table.get(to_type, 0.02 if is_binance else 0.01)
        # ğŸ”§ FIX: For volatile assets (meme), we pay spread on BOTH sides
        if from_type == 'meme' or to_type == 'meme':
            total_spread = from_spread + to_spread  # Both spreads apply
        else:
            total_spread = max(from_spread, to_spread)  # Max for stable/major
        
        # ğŸ‘‘ğŸ”¶ BINANCE: Apply slippage multiplier (3x worse execution)
        if is_binance:
            total_spread *= self.BINANCE_CONFIG.get('slippage_multiplier', 3.0)
        
        # ğŸ‘‘ STEP 2: Get exchange fee
        # ğŸ‘‘ STRICT FEE ESTIMATION: Assume standard taker fees to be safe
        if exchange.lower() == 'binance':
            exchange_fee = 0.002  # 0.20% (Standard Taker)
        elif exchange.lower() == 'kraken':
            exchange_fee = 0.0026 # 0.26% (Standard Taker)
        elif exchange.lower() == 'alpaca':
            exchange_fee = 0.0000 # Stock trading (usually 0) but check spread
        else:
            exchange_fee = self.EXCHANGE_FEES.get(exchange.lower(), 0.003)
        
        # ğŸ‘‘ STEP 3: Get historical slippage for this path (if known)
        key = (from_asset, to_asset)
        history = self.barter_history.get(key, {})
        historical_slippage = history.get('avg_slippage', 0) / 100  # Convert % to decimal
        
        # If path has lost money before, add a penalty
        path_profit = history.get('total_profit', 0)
        path_trades = history.get('trades', 0)
        loss_penalty = 0.0
        if path_profit < 0 and path_trades > 0:
            # Add average loss as a safety margin
            avg_loss_pct = abs(path_profit) / (from_value_usd * path_trades) if from_value_usd > 0 else 0.01
            loss_penalty = min(avg_loss_pct, 0.05)  # Cap at 5%
        
        # ğŸ‘‘ STEP 4: TOTAL COST CALCULATION (WORST CASE)
        # This is the GUARANTEED cost of this trade
        total_cost_pct = (
            exchange_fee +          # Exchange trading fee
            total_spread +          # Bid/ask spread
            historical_slippage +   # Historical slippage on this path
            loss_penalty +          # Penalty for historically losing paths
            0.005                   # 0.5% safety buffer - ZERO TOLERANCE MODE! (Was 0.05%)
        )
        
        total_cost_usd = from_value_usd * total_cost_pct
        
        # Epsilon policy: require only an ultra-micro net-positive edge after costs
        min_profit_usd = EPSILON_PROFIT_USD
        
        # ğŸ‘‘ğŸ’€ SURVIVAL: Does this trade give us ANY edge?
        # For a trade to be worth trying: value_gained > total_cost + 0.1_pips
        # 
        # If we're converting FROM â†’ TO:
        # - We sell FROM, get USD equivalent minus spread
        # - We buy TO with that USD minus fee
        # 
        # The "expected gain" comes from price movement prediction
        # Since we can't predict price, we need to focus on ARBITRAGE or VALUE CONVERSION
        #
        # For stablecoin conversions: Gain is essentially 0 (1:1 value)
        # For other conversions: We're SPECULATING unless there's actual arbitrage
        
        # Is this a safe conversion? (stablecoin to stablecoin)
        is_safe_conversion = from_type == 'stablecoin' and to_type == 'stablecoin'
        
        # Is this a risky conversion? (meme coin involved)
        is_risky_conversion = from_type == 'meme' or to_type == 'meme'
        
        # Calculate breakeven requirement
        breakeven_gain_pct = total_cost_pct
        breakeven_gain_usd = total_cost_usd
        
        # Required price improvement to guarantee profit
        required_improvement_pct = total_cost_pct + (min_profit_usd / from_value_usd) if from_value_usd > 0 else 1.0
        
        # ğŸ‘‘ DECISION: Does math guarantee profit?
        math_breakdown = {
            'r_breakeven_pct': gate_result.r_breakeven * 100,  # RIGOROUS VALUE
            'r_prime_pct': gate_result.r_prime * 100,          # RIGOROUS VALUE
            'from_value_usd': from_value_usd,
            'exchange_fee_pct': exchange_fee * 100,
            'spread_pct': total_spread * 100,
            'historical_slippage_pct': historical_slippage * 100,
            'loss_penalty_pct': loss_penalty * 100,
            'safety_buffer_pct': 0.2,
            'total_cost_pct': total_cost_pct * 100,
            'total_cost_usd': total_cost_usd,
            'min_profit_usd': min_profit_usd,
            'required_improvement_pct': required_improvement_pct * 100,
            'from_type': from_type,
            'to_type': to_type,
            'is_safe': is_safe_conversion,
            'is_risky': is_risky_conversion,
            'path_history': {
                'trades': path_trades,
                'profit': path_profit,
                'avg_slippage': historical_slippage * 100
            }
        }
        
        # ğŸ‘‘ QUEEN'S FINAL VERDICT - FULL PATH CLEARANCE
        # All paths are allowed as long as the math gates guarantee a positive outcome.
        
        # ğŸ‘‘ QUEEN HAS FULL CONTROL FOR PROFIT!
        # Her epsilon floor is the ONLY hard gate - all other limits are advisory
        
        # ğŸ‘‘ FINAL STRICT MATH GATING - THE "HARD TRUTH" LOGIC
        # We compare the rigorous class calculation vs our local worst-case estimates
        # and we take the MOST CONSERVATIVE (highest cost) view to protect capital.
        
        # 1. Determine the "True" Breakeven cost
        # Use the maximum of the Class calculation and our Local worst-case estimation
        # This handles cases where the Class might rely on defaults while Local has specific spread tables
        true_breakeven = max(gate_result.r_breakeven, total_cost_pct)
        
        return True, f"âœ… MATH ESTIMATE: Cost {true_breakeven:.2%}", math_breakdown
    
    def _block_path(self, key: Tuple[str, str], reason: str):
        """Block a path and broadcast through mycelium.
        
        ğŸ”“ FULL AUTONOMOUS MODE: DO NOT BLOCK - Just log for awareness!
        """
        # ğŸ”“ DISABLED: Don't actually block paths
        # self.blocked_paths[key] = reason
        
        # ğŸ„ Still broadcast through mycelium for awareness (but not blocking)
        self.queen_signals.append({
            'type': 'PATH_NOTED',  # Changed from PATH_BLOCKED
            'path': f"{key[0]}â†’{key[1]}",
            'reason': reason,
            'timestamp': time.time()
        })
        
        logger.info(f"ğŸ‘‘ğŸ“ PATH NOTED (not blocked): {key[0]}â†’{key[1]} - {reason}")
    
    def unblock_path(self, from_asset: str, to_asset: str):
        """Allow a path to be tried again (after cooldown)."""
        key = (from_asset.upper(), to_asset.upper())
        if key in self.blocked_paths:
            del self.blocked_paths[key]
            # Reset consecutive losses
            if key in self.barter_history:
                self.barter_history[key]['consecutive_losses'] = 0
            logger.info(f"ğŸ‘‘ Queen unblocks path: {key[0]}â†’{key[1]}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸš« PRE-EXECUTION REJECTION TRACKING - Stop wasting turns!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def record_preexec_rejection(self, from_asset: str, to_asset: str, reason: str, value_usd: float = 0.0) -> bool:
        """
        ğŸš« Record a pre-execution rejection (min_qty, min_notional, insufficient balance).
        
        Returns True if the path should now be blocked.
        """
        key = (from_asset.upper(), to_asset.upper())
        
        if key not in self.preexec_rejections:
            self.preexec_rejections[key] = {
                'count': 0,
                'last_value': 0,
                'last_reason': '',
                'blocked_at_turn': 0,
                'first_rejection': self.current_turn
            }
        
        rejection = self.preexec_rejections[key]
        rejection['count'] += 1
        rejection['last_value'] = value_usd
        rejection['last_reason'] = reason
        rejection['last_rejection_turn'] = self.current_turn
        
        # Check if we should block this path
        if rejection['count'] >= self.PREEXEC_MAX_REJECTIONS:
            rejection['blocked_at_turn'] = self.current_turn
            logger.warning(f"ğŸš« PRE-EXEC BLOCK: {from_asset}â†’{to_asset} after {rejection['count']} failures: {reason}")
            # Note: Blocking info logged to file for background learning (winners_only mode)
            return True
        
        return False
    
    def is_preexec_blocked(self, from_asset: str, to_asset: str) -> Tuple[bool, str]:
        """
        ğŸš« Check if a path is blocked due to pre-execution failures.
        
        Returns (is_blocked, reason)
        """
        key = (from_asset.upper(), to_asset.upper())
        
        if key not in self.preexec_rejections:
            return False, ""
        
        rejection = self.preexec_rejections[key]
        
        # Check if blocked
        if rejection['count'] >= self.PREEXEC_MAX_REJECTIONS:
            blocked_turn = rejection.get('blocked_at_turn', 0)
            turns_blocked = self.current_turn - blocked_turn
            
            # Check if cooldown has expired
            if turns_blocked >= self.PREEXEC_COOLDOWN_TURNS:
                # Reset and allow retry
                rejection['count'] = 0
                rejection['blocked_at_turn'] = 0
                logger.info(f"ğŸš«â†’âœ… PRE-EXEC UNBLOCK: {from_asset}â†’{to_asset} cooldown complete ({turns_blocked} turns)")
                return False, ""
            
            remaining = self.PREEXEC_COOLDOWN_TURNS - turns_blocked
            return True, f"Pre-exec blocked ({rejection['count']}x failures, {remaining} turns left): {rejection['last_reason']}"
        
        return False, ""
    
    def clear_preexec_rejection(self, from_asset: str, to_asset: str):
        """Clear pre-execution rejection history (e.g., after successful trade)."""
        key = (from_asset.upper(), to_asset.upper())
        if key in self.preexec_rejections:
            del self.preexec_rejections[key]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸš« SOURCE ASSET BLOCKING - Block undersized source assets on specific exchange
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def record_source_rejection(self, asset: str, exchange: str, min_needed: float, current_value: float) -> bool:
        """
        ğŸš« Record when a source asset is too small for an exchange.
        
        If the same asset fails SOURCE_BLOCK_THRESHOLD times on an exchange,
        block it until balance increases or cooldown expires.
        
        Returns True if the source should now be blocked.
        """
        key = (asset.upper(), exchange.lower())
        
        if key not in self.blocked_sources:
            self.blocked_sources[key] = {
                'count': 0,
                'min_needed': min_needed,
                'last_value': current_value,
                'blocked_turn': 0,
                'first_rejection': self.current_turn
            }
        
        source = self.blocked_sources[key]
        source['count'] += 1
        source['last_value'] = current_value
        source['min_needed'] = max(source['min_needed'], min_needed)  # Track highest min needed
        source['last_rejection_turn'] = self.current_turn
        
        # Check if we should block this source
        if source['count'] >= self.SOURCE_BLOCK_THRESHOLD:
            source['blocked_turn'] = self.current_turn
            logger.warning(f"ğŸš« SOURCE BLOCKED: {asset} on {exchange} after {source['count']} failures")
            # Note: Using verbose logging - caller's class has rejection_print
            return True
        
        return False
    
    def is_source_blocked(self, asset: str, exchange: str, current_value: float = None) -> Tuple[bool, str]:
        """
        ğŸš« Check if a source asset is blocked on an exchange.
        
        If current_value is provided and exceeds the min_needed threshold,
        automatically unblock the source.
        
        Returns (is_blocked, reason)
        """
        key = (asset.upper(), exchange.lower())
        
        if key not in self.blocked_sources:
            return False, ""
        
        source = self.blocked_sources[key]
        
        # Check if balance has increased above threshold
        if current_value is not None and current_value >= source['min_needed'] * 1.1:  # 10% buffer
            logger.info(f"ğŸš«â†’âœ… SOURCE UNBLOCK: {asset} on {exchange} - balance ${current_value:.2f} â‰¥ ${source['min_needed']:.2f}")
            del self.blocked_sources[key]
            return False, ""
        
        # Check if blocked
        if source['count'] >= self.SOURCE_BLOCK_THRESHOLD:
            blocked_turn = source.get('blocked_turn', 0)
            turns_blocked = self.current_turn - blocked_turn
            
            # Check if cooldown has expired
            if turns_blocked >= self.SOURCE_BLOCK_COOLDOWN:
                # Reset and allow retry
                source['count'] = 0
                source['blocked_turn'] = 0
                logger.info(f"ğŸš«â†’âœ… SOURCE UNBLOCK: {asset} on {exchange} cooldown complete ({turns_blocked} turns)")
                return False, ""
            
            remaining = self.SOURCE_BLOCK_COOLDOWN - turns_blocked
            return True, f"Source blocked (${source['last_value']:.2f} < ${source['min_needed']:.2f}, {remaining} turns left)"
        
        return False, ""
    
    def get_queen_signals(self) -> List[Dict]:
        """Get pending signals to broadcast via mycelium."""
        signals = self.queen_signals.copy()
        self.queen_signals.clear()
        return signals
    
    def check_dream_progress(self) -> str:
        """
        ğŸ’°ğŸ‘‘ SERO'S DREAM PROGRESS - Track progress toward $1 BILLION!
        
        She won't stop at NOTHING until she reaches her dream!
        Every profitable trade brings her closer.
        """
        profit = self.total_realized_profit
        dream = self.TINA_DREAM
        progress_pct = (profit / dream) * 100 if dream > 0 else 0
        
        # Check for new milestones
        for milestone_value, milestone_name in self.dream_milestones:
            if profit >= milestone_value and milestone_name not in self.milestones_hit:
                self.milestones_hit.append(milestone_name)
                safe_print(f"\nğŸ‰ğŸŠğŸ‘‘ SERO MILESTONE ACHIEVED! ğŸ‘‘ğŸŠğŸ‰")
                safe_print(f"   {milestone_name}")
                safe_print(f"   Current: ${profit:,.2f}")
                safe_print(f"   Progress: {progress_pct:.8f}% toward THE DREAM!")
                safe_print()
        
        # Build progress bar
        bar_width = 40
        filled = int((progress_pct / 100) * bar_width) if progress_pct < 100 else bar_width
        filled = max(0, min(bar_width, filled))
        bar = "â–ˆ" * filled + "â–‘" * (bar_width - filled)
        
        # Motivation based on progress
        if profit < 0:
            mood = "ğŸ˜¤ SETBACK - But I NEVER give up!"
        elif profit < 100:
            mood = "ğŸŒ± Planting seeds..."
        elif profit < 1000:
            mood = "ğŸ’ª Building momentum!"
        elif profit < 10000:
            mood = "ğŸ”¥ On FIRE!"
        elif profit < 100000:
            mood = "ğŸš€ ACCELERATING!"
        elif profit < 1000000:
            mood = "âš¡ UNSTOPPABLE!"
        else:
            mood = "ğŸ‘‘ QUEEN STATUS!"
        
        status = f"ğŸ‘‘ SERO's DREAM: ${profit:,.2f} / ${dream:,.0f} [{bar}] {progress_pct:.8f}% {mood}"
        return status
    
    def update_barter_rate(self, from_asset: str, to_asset: str, from_price: float, 
                           to_price: float, spread_pct: float = 0.3):
        """
        Update the barter rate between two assets based on live prices.
        
        The barter rate tells us: "How much TO can I get for 1 unit of FROM?"
        """
        if to_price <= 0:
            return
            
        # Direct exchange rate (how many TO per FROM)
        rate = from_price / to_price
        
        # Apply estimated spread (real markets have slippage)
        effective_rate = rate * (1 - spread_pct / 100)
        
        key = (from_asset.upper(), to_asset.upper())
        self.barter_rates[key] = {
            'rate': effective_rate,
            'raw_rate': rate,
            'spread_pct': spread_pct,
            'from_price': from_price,
            'to_price': to_price,
            'updated': time.time()
        }
    
    def get_barter_rate(self, from_asset: str, to_asset: str) -> Optional[Dict[str, Any]]:
        """Get the current barter rate between two assets."""
        key = (from_asset.upper(), to_asset.upper())
        return self.barter_rates.get(key)
    
    def calculate_barter_value(self, from_asset: str, to_asset: str, 
                               from_amount: float, from_price: float, 
                               to_price: float) -> Dict[str, float]:
        """
        Calculate what you'd get in a barter trade.
        
        Returns both the USD-equivalent calculation AND the barter-adjusted calculation.
        """
        # USD-equivalent method (simple)
        from_usd = from_amount * from_price
        usd_equiv_amount = from_usd / to_price if to_price > 0 else 0
        
        # Barter-adjusted method (accounts for historical spread)
        key = (from_asset.upper(), to_asset.upper())
        history = self.barter_history.get(key, {})
        avg_slippage = history.get('avg_slippage', 0.5)  # Default 0.5% slippage
        
        barter_amount = usd_equiv_amount * (1 - avg_slippage / 100)
        
        return {
            'from_amount': from_amount,
            'from_usd': from_usd,
            'usd_equiv_to': usd_equiv_amount,
            'barter_adjusted_to': barter_amount,
            'expected_slippage_pct': avg_slippage,
            'to_asset': to_asset,
            'from_asset': from_asset
        }
    
    def record_realized_profit(self, from_asset: str, to_asset: str,
                               from_amount: float, from_usd: float,
                               to_amount: float, to_usd: float) -> Dict[str, Any]:
        """
        Record a realized trade and calculate ACTUAL profit/loss.
        
        This is called AFTER a conversion completes to track true P/L.
        ğŸ‘‘ QUEEN'S MANDATE: Track wins/losses to block losing paths!
        """
        # Calculate realized P/L
        profit_usd_raw = to_usd - from_usd
        profit_pct_raw = (profit_usd_raw / from_usd * 100) if from_usd > 0 else 0

        # ğŸ”§ FIX GHOST PROFIT: Sanity check BEFORE we update history/signals.
        # If profit is wildly outside expected bounds, treat as an outlier so it
        # doesn't corrupt path stats, win-rate, or portfolio reporting.
        MAX_REASONABLE_PROFIT = 500.0  # Max profit per conversion (given small balances)
        MIN_REASONABLE_LOSS = -200.0   # Max loss per conversion
        is_outlier = profit_usd_raw > MAX_REASONABLE_PROFIT or profit_usd_raw < MIN_REASONABLE_LOSS
        if is_outlier:
            logger.warning(
                f"ğŸ‘‘âš ï¸ REJECTING OUTLIER PROFIT/LOSS: ${profit_usd_raw:.2f} (from ${from_usd:.2f} to ${to_usd:.2f})"
            )
            logger.warning("      This suggests a price data error or bad execution value.")

        profit_usd = 0.0 if is_outlier else profit_usd_raw
        profit_pct = 0.0 if is_outlier else profit_pct_raw
        
        # ğŸ† UNIVERSAL WIN DEFINITION: Penny Profit = REALITY
        # WIN = net profit >= $0.01 (not just > 0, which catches dust)
        WIN_THRESHOLD_USD = 0.01
        is_win = profit_usd >= WIN_THRESHOLD_USD
        
        # Calculate actual slippage vs expected
        key = (from_asset.upper(), to_asset.upper())
        rate_info = self.barter_rates.get(key)
        if rate_info and rate_info['raw_rate'] > 0:
            expected_to = from_amount * rate_info['raw_rate']
            actual_slippage = (1 - to_amount / expected_to) * 100 if expected_to > 0 else 0
        else:
            actual_slippage = 0.5  # Default
        
        # Update historical slippage (exponential moving average)
        history = self.barter_history.setdefault(key, {
            'trades': 0, 'avg_slippage': 0.5, 'total_profit': 0,
            'wins': 0, 'losses': 0, 'consecutive_losses': 0
        })
        history['trades'] += 1
        alpha = 0.3  # Weight for new data
        history['avg_slippage'] = alpha * actual_slippage + (1 - alpha) * history['avg_slippage']
        history['total_profit'] = history.get('total_profit', 0) + profit_usd

        # Track outliers without treating them as wins/losses
        if is_outlier:
            history['outliers'] = history.get('outliers', 0) + 1
            history['last_outlier_time'] = time.time()
        
        # ğŸ‘‘ QUEEN'S WIN/LOSS TRACKING WITH IMMEDIATE LEARNING
        # Outliers are treated as neutral so they don't block/unblock paths.
        if is_outlier or profit_usd == 0:
            pass
        elif is_win:
            history['wins'] = history.get('wins', 0) + 1
            history['consecutive_losses'] = 0  # Reset on win
            history['last_win_time'] = time.time()  # Remember when we last won
            # Unblock path if it was blocked and now winning
            if key in self.blocked_paths:
                self.unblock_path(from_asset, to_asset)
            # ğŸ‰ Broadcast win through mycelium
            self.queen_signals.append({
                'type': 'PATH_WIN',
                'path': f"{from_asset}â†’{to_asset}",
                'profit_usd': profit_usd,
                'win_rate': history['wins'] / history['trades'],
                'timestamp': time.time()
            })
            logger.info(f"ğŸ‘‘âœ… PATH WIN: {from_asset}â†’{to_asset} +${profit_usd:.4f} (win rate: {history['wins']/history['trades']:.0%})")

            # Broadcast a canonical WinOutcome and ThoughtBus message so all systems receive harmonically-encoded outcome
            try:
                from aureon_queen_hive_mind import WinOutcome
                win = WinOutcome.from_trade(
                    from_asset=from_asset,
                    to_asset=to_asset,
                    from_usd=from_usd,
                    to_usd=to_usd,
                    exchange=getattr(self, 'exchange_name', 'unknown'),
                    signals={},
                    coherence=0.5,
                    confidence=history['wins'] / history['trades'] if history['trades'] else 0.5,
                    strategy=getattr(self, 'active_strategy', 'UNKNOWN'),
                    animals=getattr(self, 'last_animals', [])
                )
                # Broadcast via mycelium if available
                if hasattr(self, 'mycelium_network') and self.mycelium_network and hasattr(self.mycelium_network, 'broadcast_signal'):
                    try:
                        self.mycelium_network.broadcast_signal({'type': 'TRADE_OUTCOME', 'win': win.to_dict()})
                    except Exception:
                        logger.exception('Failed to broadcast TRADE_OUTCOME via mycelium')

                # Also publish to ThoughtBus if available
                try:
                    from aureon_thought_bus import Thought, get_thought_bus
                    tb = get_thought_bus()
                    if tb:
                        t = Thought(source='micro_profit_labyrinth', topic=('outcome.win' if win.is_win else 'outcome.loss'), payload={'win': win.to_dict()})
                        tb.publish(t)
                except Exception:
                    # Not fatal; ThoughtBus may not be available in all contexts
                    logger.debug('ThoughtBus not available or failed to publish outcome')
            except Exception:
                logger.exception('Failed to construct or broadcast WinOutcome')
        else:
            history['losses'] = history.get('losses', 0) + 1
            history['consecutive_losses'] = history.get('consecutive_losses', 0) + 1
            history['last_loss_usd'] = profit_usd  # Remember how much we lost
            blocked_reason: Optional[str] = None
            
            # ğŸ„ Broadcast loss through mycelium
            self.queen_signals.append({
                'type': 'PATH_LOSS',
                'path': f"{from_asset}â†’{to_asset}",
                'loss_usd': profit_usd,
                'consecutive': history['consecutive_losses'],
                'timestamp': time.time()
            })
            
            # ğŸ‘‘ğŸ§  IMMEDIATE LEARNING: Block path after FIRST loss on new paths!
            # For established paths, still use MAX_CONSECUTIVE_LOSSES
            if history['trades'] <= 2:
                # New path lost - block IMMEDIATELY to prevent further losses
                blocked_reason = f"First trade lost ${abs(profit_usd):.4f} - need time to cool down"
                self._block_path(key, blocked_reason)
                logger.warning(f"ğŸ‘‘ğŸš« INSTANT BLOCK: {from_asset}â†’{to_asset} lost ${abs(profit_usd):.4f} on trade #{history['trades']}")
            elif history['consecutive_losses'] >= self.MAX_CONSECUTIVE_LOSSES:
                blocked_reason = f"{history['consecutive_losses']} consecutive losses"
                self._block_path(key, blocked_reason)

            # Mirror-block reverse path when a path is blocked for losses
            if blocked_reason:
                reverse_key = (to_asset.upper(), from_asset.upper())
                if reverse_key not in self.blocked_paths:
                    self._block_path(reverse_key, f"Mirror block after {blocked_reason}")
            
            # ğŸ‘‘ LEARN: If slippage is consistently high, increase expected slippage
            if actual_slippage > history['avg_slippage'] * 1.5:
                # Slippage much higher than expected - warn
                logger.warning(f"ğŸ‘‘âš ï¸ HIGH SLIPPAGE: {from_asset}â†’{to_asset} had {actual_slippage:.2f}% vs avg {history['avg_slippage']:.2f}%")
        
        # Record in ledger (sanitized)
        self.profit_ledger.append((
            time.time(), from_asset, to_asset, from_usd, to_usd, profit_usd
        ))
            
        # Update running totals with sanitized profit
        self.total_realized_profit += profit_usd
        self.conversion_count += 1
        
        # Calculate win rate
        win_rate = history['wins'] / history['trades'] if history['trades'] > 0 else 0
        
        return {
            'profit_usd': profit_usd,
            'profit_pct': profit_pct,
            'actual_slippage_pct': actual_slippage,
            'running_total': self.total_realized_profit,
            'conversion_number': self.conversion_count,
            'path_total_profit': history['total_profit'],
            'path_trades': history['trades'],
            'path_win_rate': win_rate,
            'is_win': is_win
        }
    
    def get_best_barter_path(self, from_asset: str, target_assets: List[str],
                            prices: Dict[str, float]) -> List[Dict[str, Any]]:
        """
        Find the best barter opportunities from a given asset.
        
        Returns ranked list of targets sorted by expected VALUE (not just USD conversion).
        """
        from_price = prices.get(from_asset, 0)
        if from_price <= 0:
            return []
        
        opportunities = []
        for target in target_assets:
            if target == from_asset:
                continue
            to_price = prices.get(target, 0)
            if to_price <= 0:
                continue
            
            # Calculate barter advantage
            barter_info = self.calculate_barter_value(from_asset, target, 1.0, from_price, to_price)
            
            # Check historical performance
            key = (from_asset.upper(), target.upper())
            history = self.barter_history.get(key, {})
            win_rate = 0.5  # Default
            if history.get('trades', 0) > 0:
                win_rate = history.get('total_profit', 0) / history['trades']
                win_rate = 0.5 + (win_rate / 10)  # Normalize around 0.5
            
            opportunities.append({
                'from': from_asset,
                'to': target,
                'barter_rate': barter_info['barter_adjusted_to'],
                'usd_rate': barter_info['usd_equiv_to'],
                'advantage_pct': (barter_info['barter_adjusted_to'] / barter_info['usd_equiv_to'] - 1) * 100 if barter_info['usd_equiv_to'] > 0 else 0,
                'historical_win_rate': win_rate,
                'trades_count': history.get('trades', 0),
                'path_profit': history.get('total_profit', 0)
            })
        
        # Sort by a combined score: historical profit + expected value
        for opp in opportunities:
            opp['barter_score'] = (
                opp['historical_win_rate'] * 0.4 +  # Past performance
                (1 + opp['advantage_pct'] / 100) * 0.3 +  # Current advantage
                min(opp['trades_count'] / 10, 1) * 0.3  # Experience with this path
            )
        
        return sorted(opportunities, key=lambda x: x['barter_score'], reverse=True)
    
    def print_step_profit(self, step_num: int, from_asset: str, to_asset: str,
                          from_usd: float, to_usd: float, from_amount: float, 
                          to_amount: float) -> str:
        """
        Print a beautiful step-by-step profit breakdown.
        """
        profit = to_usd - from_usd
        profit_symbol = "+" if profit >= 0 else ""
        
        lines = [
            f"",
            f"   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
            f"   â•‘  ğŸ’° STEP #{step_num} REALIZED PROFIT                              â•‘",
            f"   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  FROM: {from_amount:>12.6f} {from_asset:<6} = ${from_usd:>10.4f}      â•‘",
            f"   â•‘    TO: {to_amount:>12.6f} {to_asset:<6} = ${to_usd:>10.4f}      â•‘",
            f"   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  STEP P/L: ${profit_symbol}{profit:>8.4f} ({profit/from_usd*100 if from_usd > 0 else 0:>+.2f}%)                    â•‘",
            f"   â•‘  RUNNING TOTAL: ${profit_symbol}{self.total_realized_profit:>8.4f}                          â•‘",
            f"   â•‘  CONVERSIONS: {self.conversion_count}                                       â•‘",
            f"   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        ]
        return "\n".join(lines)
    
    def get_summary(self) -> Dict[str, Any]:
        """Get summary of all barter activity."""
        return {
            'total_realized_profit': self.total_realized_profit,
            'conversion_count': self.conversion_count,
            'avg_profit_per_trade': self.total_realized_profit / max(self.conversion_count, 1),
            'paths_learned': len(self.barter_history),
            'recent_trades': self.profit_ledger[-10:] if self.profit_ledger else []
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ—ºï¸ DYNAMIC ASSET DISCOVERY - Expand to see ENTIRE market!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _register_discovered_asset(self, asset: str) -> int:
        """Register an asset if new; returns 1 if added."""
        if not asset:
            return 0
        asset = asset.upper()
        if asset in self.DISCOVERED_ASSETS:
            return 0
        self.DISCOVERED_ASSETS.add(asset)
        return 1

    def register_exchange_pair(self, exchange: str, pair: str, base: str, quote: str) -> int:
        """Register a pair + its base/quote assets for an exchange."""
        exchange_lower = exchange.lower()
        if pair:
            self.EXCHANGE_PAIRS[exchange_lower].add(pair)
        discovered = 0
        discovered += self._register_discovered_asset(base)
        discovered += self._register_discovered_asset(quote)
        return discovered
    
    def discover_exchange_assets(self, exchange: str, pairs: List[str]) -> int:
        """
        Discover and register all tradeable assets from an exchange.
        
        Called during initialization to expand market visibility from 27 â†’ 750+ assets.
        """
        discovered = 0
        exchange_lower = exchange.lower()
        
        for pair in pairs:
            # Extract base and quote from pair name
            for quote in [
                'USD', 'USDT', 'USDC', 'EUR', 'GBP', 'BTC', 'ETH',
                'ZUSD', 'ZEUR', 'BUSD', 'USDP', 'PYUSD', 'FDUSD',
            ]:
                if pair.endswith(quote):
                    base = pair[:-len(quote)]
                    # Clean up Kraken naming (XXBT â†’ BTC, XETH â†’ ETH)
                    if len(base) == 4 and base[0] in ('X', 'Z'):
                        base = base[1:]
                    if base == 'XBT':
                        base = 'BTC'
                    
                    if base and len(base) >= 2:
                        discovered += self.register_exchange_pair(exchange_lower, pair, base, quote)
                    break
        
        return discovered
    
    def get_asset_type(self, asset: str) -> str:
        """
        Dynamically categorize an asset for spread calculation.
        
        Uses the expanded asset lists + learned categories.
        """
        asset = asset.upper()
        
        if asset in self.STABLECOINS:
            return 'stablecoin'
        elif asset in self.MEME_COINS:
            return 'meme'
        elif asset in self.MAJOR_COINS:
            return 'major'
        elif asset in self.DEFI_COINS:
            return 'defi'  # DeFi tokens get altcoin spread
        elif asset in self.AI_COINS:
            return 'ai'    # AI tokens are hot - moderate spread
        elif asset in self.LAYER2_COINS:
            return 'layer2'  # L2s are liquid
        elif asset in self.RWA_COINS:
            return 'rwa'   # RWA still emerging
        else:
            return 'altcoin'  # Unknown = conservative spread
    
    def get_spread_for_asset(self, asset: str, exchange: str = 'kraken') -> float:
        """Get the expected spread cost for an asset on a given exchange."""
        asset_type = self.get_asset_type(asset)
        
        # Get the right spread table
        if exchange.lower() == 'binance':
            spread_table = self.BINANCE_SPREAD_COSTS
        elif exchange.lower() == 'alpaca':
            spread_table = self.ALPACA_SPREAD_COSTS
        else:
            spread_table = self.SPREAD_COSTS
        
        # Map asset types to spread categories
        type_to_spread = {
            'stablecoin': 'stablecoin',
            'major': 'major',
            'meme': 'meme',
            'defi': 'altcoin',
            'ai': 'major',      # AI tokens are liquid now
            'layer2': 'major',  # L2s have good liquidity
            'rwa': 'altcoin',   # RWA is newer
            'altcoin': 'altcoin',
        }
        
        spread_category = type_to_spread.get(asset_type, 'altcoin')
        return spread_table.get(spread_category, 0.01)
    
    def print_market_coverage(self) -> str:
        """
        Print a beautiful market coverage report.
        
        Shows how much of the market the Barter Matrix can now see.
        """
        # Count categorized assets
        static_count = len(self.MEME_COINS) + len(self.MAJOR_COINS) + len(self.STABLECOINS)
        static_count += len(self.DEFI_COINS) + len(self.AI_COINS) + len(self.LAYER2_COINS) + len(self.RWA_COINS)
        discovered_count = len(self.DISCOVERED_ASSETS)
        total_known = static_count + discovered_count
        
        # Exchange pair counts
        kraken_pairs = len(self.EXCHANGE_PAIRS.get('kraken', set()))
        binance_pairs = len(self.EXCHANGE_PAIRS.get('binance', set()))
        alpaca_pairs = len(self.EXCHANGE_PAIRS.get('alpaca', set()))
        
        lines = [
            "",
            "   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
            "   â•‘  ğŸ—ºï¸ BARTER MATRIX - MARKET COVERAGE REPORT                   â•‘",
            "   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  ğŸ“Š CATEGORIZED ASSETS:                                      â•‘",
            f"   â•‘     â€¢ MEME_COINS:    {len(self.MEME_COINS):>4} (DOGE, SHIB, WIF, BONK...)   â•‘",
            f"   â•‘     â€¢ MAJOR_COINS:   {len(self.MAJOR_COINS):>4} (BTC, ETH, SOL, XRP...)     â•‘",
            f"   â•‘     â€¢ DEFI_COINS:    {len(self.DEFI_COINS):>4} (UNI, AAVE, MKR, GMX...)    â•‘",
            f"   â•‘     â€¢ AI_COINS:      {len(self.AI_COINS):>4} (RENDER, FET, TAO, WLD...)   â•‘",
            f"   â•‘     â€¢ LAYER2_COINS:  {len(self.LAYER2_COINS):>4} (ARB, OP, MATIC, IMX...)    â•‘",
            f"   â•‘     â€¢ RWA_COINS:     {len(self.RWA_COINS):>4} (ONDO, RSR, POLYX...)       â•‘",
            f"   â•‘     â€¢ STABLECOINS:   {len(self.STABLECOINS):>4} (USD, USDT, USDC...)       â•‘",
            f"   â•‘                                                              â•‘",
            f"   â•‘  ğŸ” DISCOVERED AT RUNTIME: {discovered_count:>4} additional assets           â•‘",
            f"   â•‘  ğŸ“ˆ TOTAL KNOWN ASSETS:    {total_known:>4}                              â•‘",
            "   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  ğŸ™ KRAKEN PAIRS:   {kraken_pairs:>5}                                   â•‘",
            f"   â•‘  ğŸ”¶ BINANCE PAIRS:  {binance_pairs:>5}                                   â•‘",
            f"   â•‘  ğŸ¦™ ALPACA PAIRS:   {alpaca_pairs:>5}                                   â•‘",
            "   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        ]
        return "\n".join(lines)

    def calculate_true_cost(self, from_asset: str, to_asset: str, value_usd: float, exchange: str) -> Tuple[bool, str, Dict]:
        """
        ğŸ² MONTE CARLO SNOWBALL - REALISTIC FLAT COST MODEL
        
        Uses flat 0.25% cost for Alpaca (real costs ~0.15-0.25%).
        Trust the math - one trade at a time, hold, roll profits.
        
        Returns: (approved, reason, cost_breakdown)
        """
        # ğŸ² MONTE CARLO: Flat 0.25% cost assumption
        # Alpaca real costs: ~0.15% fee + ~0.10% spread for liquid pairs
        MONTE_CARLO_FLAT_COST = 0.0025  # 0.25% total cost
        
        total_cost_pct = MONTE_CARLO_FLAT_COST
        total_cost_usd = value_usd * total_cost_pct
        
        cost_breakdown = {
            'base_fee': 0.0015,      # ~0.15%
            'spread': 0.08,          # ~0.08%
            'slippage': 0.02,        # ~0.02%
            'volatility': 0.0,       # Not applied in Monte Carlo
            'total_cost_pct': total_cost_pct * 100,  # Return as percentage (0.25)
            'total_cost_usd': total_cost_usd,
            'mode': 'monte_carlo_snowball'
        }
        
        return True, "monte_carlo_approved", cost_breakdown


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”€ LIQUIDITY ENGINE - Dynamic Asset Aggregation ("Top-Up" Mechanism)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# When we find an opportunity but don't have enough balance:
# 1. Find "victim" assets to liquidate (low performers, dust, stablecoins)
# 2. Calculate if selling them to fund the trade is PROFITABLE after fees
# 3. Execute multi-step atomic trades: SELL VICTIM â†’ BUY TARGET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FundingCandidate:
    """A potential source of funds (asset to liquidate)."""
    asset: str
    exchange: str
    amount: float
    value_usd: float
    momentum: float  # -1 to +1 (negative = falling = good victim)
    sell_fee_pct: float
    reason: str  # Why this is a good victim
    priority: int  # Higher = better victim


@dataclass 
class AggregationPlan:
    """A plan to aggregate funds for a target trade."""
    target_asset: str
    target_exchange: str
    amount_needed_usd: float
    victims: List[FundingCandidate]
    total_victim_value: float
    total_fees_usd: float
    net_funds_available: float
    is_profitable: bool
    profit_after_fees: float
    steps: List[Dict]  # Execution steps


class LiquidityEngine:
    """
    ğŸ’§ LIQUIDITY ENGINE - Smart Asset Consolidation
    
    "If you want to buy BTC but only have dust ETH + some DOGE,
     sell the losers to fund the winner!"
    
    Key Principles:
    1. Only liquidate "victims" that are FALLING or STAGNANT
    2. Never touch assets that are RISING (they might profit on their own)
    3. Calculate TOTAL cost (sell fee + buy fee + slippage) 
    4. Only proceed if expected profit > total cost
    5. Execute atomically - if any step fails, abort all
    """
    
    # Fee estimates per exchange (maker/taker average)
    EXCHANGE_FEES = {
        'kraken': 0.0026,    # 0.26% average
        'binance': 0.0010,   # 0.10% with BNB discount
        'alpaca': 0.0015,    # 0.15% crypto fee
    }
    
    # Minimum USD value to consider for liquidation (avoid dust-for-dust)
    MIN_VICTIM_VALUE = 2.00  # $2 minimum
    
    # Slippage estimates (additional cost on top of fees)
    SLIPPAGE_ESTIMATE = {
        'stablecoin': 0.0005,   # 0.05%
        'major': 0.0020,        # 0.20%
        'altcoin': 0.0050,      # 0.50%
        'meme': 0.0150,         # 1.50%
    }
    
    def __init__(self, barter_matrix: 'BarterMatrix'):
        self.barter_matrix = barter_matrix
        self.pending_plans: List[Any] = []
        self.executed_aggregations = 0
        self.total_aggregation_profit = 0.0
        
        # Track liquidation history (avoid repeatedly selling same asset)
        self.recent_liquidations: Dict[str, float] = {}  # asset -> timestamp
        self.LIQUIDATION_COOLDOWN = 120  # 2 minutes between selling same asset (TURBO - was 5 mins)
        
    def find_funding_candidates(
        self, 
        exchange: str,
        amount_needed_usd: float,
        exclude_assets: Set[str],
        exchange_balances: Dict[str, float],
        prices: Dict[str, float],
        momentum: Dict[str, float],
    ) -> List[FundingCandidate]:
        """
        Find assets that can be liquidated to fund a trade.
        
        Victim Priority (best to worst):
        1. ğŸ¥‡ DUST (< $5) with negative momentum - Clean up the portfolio!
        2. ğŸ¥ˆ STABLECOINS - They're just sitting there doing nothing
        3. ğŸ¥‰ FALLING assets (momentum < -0.001/min) - Cut losses!
        4. ğŸ… STAGNANT assets (momentum ~0) - Not doing anything
        
        Never victimize:
        - Assets with strong positive momentum (> +0.002/min)
        - Assets we're trying to BUY
        - Assets we recently liquidated (cooldown)
        """
        candidates = []
        current_time = time.time()
        
        balances = exchange_balances.get(exchange, {})
        
        for asset, amount in balances.items():
            # Skip excluded (the target we want to buy)
            if asset.upper() in exclude_assets:
                continue
            
            # Skip if recently liquidated
            if asset in self.recent_liquidations:
                if current_time - self.recent_liquidations[asset] < self.LIQUIDATION_COOLDOWN:
                    continue
            
            # Get value
            price = prices.get(asset, 0)
            if asset.upper() in ('USD', 'USDT', 'USDC', 'ZUSD'):
                price = 1.0
            
            value_usd = amount * price if price > 0 else 0
            
            # Skip if below minimum
            if value_usd < self.MIN_VICTIM_VALUE:
                continue
            
            # Get momentum
            asset_momentum = momentum.get(asset, 0)
            
            # Skip RISING assets (they might profit on their own!)
            if asset_momentum > 0.002:  # > 0.2%/min rising
                continue
            
            # Calculate sell fee
            fee_pct = self.EXCHANGE_FEES.get(exchange, 0.003)
            
            # Determine asset type for slippage
            if asset.upper() in ('USD', 'USDT', 'USDC', 'ZUSD', 'DAI', 'TUSD'):
                asset_type = 'stablecoin'
            elif asset.upper() in ('BTC', 'ETH', 'SOL', 'BNB', 'XRP'):
                asset_type = 'major'
            elif asset.upper() in self.barter_matrix.MEME_COINS:
                asset_type = 'meme'
            else:
                asset_type = 'altcoin'
            
            slippage = self.SLIPPAGE_ESTIMATE.get(asset_type, 0.005)
            total_sell_cost = fee_pct + slippage
            
            # Calculate priority (higher = better victim)
            priority = 0
            reason_parts = []
            
            # ğŸ¥‡ PRIORITY 1: Dust with negative momentum
            if value_usd < 5.0 and asset_momentum < 0:
                priority = 100
                reason_parts.append("DUST_FALLING")
            
            # ğŸ¥ˆ PRIORITY 2: Stablecoins (opportunity cost)
            elif asset_type == 'stablecoin':
                priority = 80
                reason_parts.append("STABLECOIN_IDLE")
            
            # ğŸ¥‰ PRIORITY 3: Falling assets
            elif asset_momentum < -0.001:  # < -0.1%/min
                priority = 60 + int(abs(asset_momentum) * 1000)  # More falling = higher priority
                reason_parts.append(f"FALLING({asset_momentum*100:.2f}%/min)")
            
            # ğŸ… PRIORITY 4: Stagnant
            elif abs(asset_momentum) < 0.0005:
                priority = 40
                reason_parts.append("STAGNANT")
            
            # Otherwise, low priority
            else:
                priority = 20
                reason_parts.append("LOW_MOMENTUM")
            
            # Bonus for dust cleanup
            if value_usd < 10.0:
                priority += 15
                reason_parts.append("CLEANUP")
            
            candidates.append(FundingCandidate(
                asset=asset,
                exchange=exchange,
                amount=amount,
                value_usd=value_usd,
                momentum=asset_momentum,
                sell_fee_pct=total_sell_cost,
                reason=" + ".join(reason_parts),
                priority=priority,
            ))
        
        # Sort by priority (highest first)
        candidates.sort(key=lambda x: x.priority, reverse=True)
        
        return candidates
    
    def create_aggregation_plan(
        self,
        target_asset: str,
        target_exchange: str,
        amount_needed_usd: float,
        expected_profit_pct: float,  # Expected profit from target trade
        exchange_balances: Dict[str, float],
        prices: Dict[str, float],
        momentum: Dict[str, float],
    ) -> Optional[AggregationPlan]:
        """
        Create a plan to aggregate funds for a target trade.
        
        Returns None if:
        - Not enough victims available
        - Total fees would exceed expected profit
        """
        # Find candidates
        candidates = self.find_funding_candidates(
            exchange=target_exchange,
            amount_needed_usd=amount_needed_usd * 1.05,  # 5% buffer for fees
            exclude_assets={target_asset.upper()},
            exchange_balances=exchange_balances,
            prices=prices,
            momentum=momentum,
        )
        
        if not candidates:
            return None
        
        # Greedily select victims until we have enough
        selected_victims = []
        total_value = 0.0
        total_fees = 0.0
        
        for candidate in candidates:
            if total_value >= amount_needed_usd * 1.02:  # 2% buffer
                break
            
            # Calculate net value after fees
            gross_value = candidate.value_usd
            sell_fees = gross_value * candidate.sell_fee_pct
            net_value = gross_value - sell_fees
            
            selected_victims.append(candidate)
            total_value += gross_value
            total_fees += sell_fees
        
        if total_value < amount_needed_usd:
            # Not enough victims
            return None
        
        # Add BUY fees for target asset
        buy_fee_pct = self.EXCHANGE_FEES.get(target_exchange, 0.003)
        
        # Determine target asset type for slippage
        if target_asset.upper() in ('USD', 'USDT', 'USDC'):
            target_type = 'stablecoin'
        elif target_asset.upper() in ('BTC', 'ETH', 'SOL', 'BNB', 'XRP'):
            target_type = 'major'
        elif target_asset.upper() in self.barter_matrix.MEME_COINS:
            target_type = 'meme'
        else:
            target_type = 'altcoin'
        
        target_slippage = self.SLIPPAGE_ESTIMATE.get(target_type, 0.005)
        buy_total_cost = buy_fee_pct + target_slippage
        
        # Calculate net funds available after all fees
        net_after_sell = total_value - total_fees
        buy_fees = net_after_sell * buy_total_cost
        total_fees += buy_fees
        net_funds = net_after_sell - buy_fees
        
        # Calculate if profitable
        # Expected profit from target trade
        expected_profit_usd = amount_needed_usd * expected_profit_pct
        
        # Actual profit = expected - total fees paid
        actual_profit = expected_profit_usd - total_fees
        
        is_profitable = actual_profit >= EPSILON_PROFIT_USD
        
        # Build execution steps
        steps = []
        for i, victim in enumerate(selected_victims):
            steps.append({
                'order': i + 1,
                'action': 'SELL',
                'asset': victim.asset,
                'amount': victim.amount,
                'exchange': victim.exchange,
                'expected_usd': victim.value_usd,
                'reason': victim.reason,
            })
        
        steps.append({
            'order': len(selected_victims) + 1,
            'action': 'BUY',
            'asset': target_asset,
            'amount_usd': net_funds,
            'exchange': target_exchange,
        })
        
        return AggregationPlan(
            target_asset=target_asset,
            target_exchange=target_exchange,
            amount_needed_usd=amount_needed_usd,
            victims=selected_victims,
            total_victim_value=total_value,
            total_fees_usd=total_fees,
            net_funds_available=net_funds,
            is_profitable=is_profitable,
            profit_after_fees=actual_profit,
            steps=steps,
        )
    
    def print_aggregation_plan(self, plan: AggregationPlan) -> str:
        """Pretty print an aggregation plan."""
        lines = [
            "",
            "   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
            "   â•‘  ğŸ’§ LIQUIDITY AGGREGATION PLAN                               â•‘",
            "   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
            f"   â•‘  ğŸ¯ TARGET: Buy {plan.target_asset} on {plan.target_exchange}",
            f"   â•‘  ğŸ’° NEEDED: ${plan.amount_needed_usd:.2f}",
            f"   â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘",
            f"   â•‘  ğŸ”ª LIQUIDATING {len(plan.victims)} ASSETS:",
        ]
        
        for v in plan.victims:
            lines.append(f"   â•‘     â€¢ {v.asset}: ${v.value_usd:.2f} ({v.reason})")
        
        lines.extend([
            f"   â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘",
            f"   â•‘  ğŸ’µ GROSS VALUE:     ${plan.total_victim_value:.2f}",
            f"   â•‘  ğŸ“‰ TOTAL FEES:      ${plan.total_fees_usd:.2f}",
            f"   â•‘  ğŸ’° NET AVAILABLE:   ${plan.net_funds_available:.2f}",
            f"   â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘",
        ])
        
        if plan.is_profitable:
            lines.append(f"   â•‘  âœ… PROFITABLE: Expected +${plan.profit_after_fees:.4f}")
        else:
            lines.append(f"   â•‘  âŒ NOT PROFITABLE: Would lose ${abs(plan.profit_after_fees):.4f}")
        
        lines.append("   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        return "\n".join(lines)
    
    def record_liquidation(self, asset: str):
        """Record that we liquidated an asset (for cooldown tracking)."""
        self.recent_liquidations[asset] = time.time()
    
    def get_status(self) -> Dict:
        """Get engine status for monitoring."""
        return {
            'executed_aggregations': self.executed_aggregations,
            'total_profit': self.total_aggregation_profit,
            'pending_plans': len(self.pending_plans),
            'recent_liquidations': len(self.recent_liquidations),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ¾ğŸ’° PROFIT HARVESTER - Proactive Portfolio Profit Realization
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Scans Alpaca positions for unrealized profits and harvests them for cash!
# This is the KEY MISSING PIECE - we need to SELL profitable positions to get
# cash for new trading opportunities.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class HarvestCandidate:
    """A position that can be harvested for profit."""
    symbol: str
    asset: str
    qty: float
    cost_basis: float
    market_value: float
    unrealized_pl: float
    unrealized_plpc: float  # Percentage
    current_price: float
    priority: int  # Higher = better harvest candidate


class ProfitHarvester:
    """
    ğŸŒ¾ğŸ’° PROFIT HARVESTER - ULTRA AGGRESSIVE CASH FLOW MACHINE
    
    "ANY NET PROFIT = HARVEST! NO LOSSES ACCEPTED! CONSTANT CASH FLOW!"
    
    Key Principles:
    1. VERIFY profit via Alpaca API (unrealized_pl from API is TRUTH)
    2. ANY net profit after fees = IMMEDIATE HARVEST
    3. NO minimum thresholds - even $0.001 profit is a WIN
    4. Cash flow is KING - keep harvesting to fund new opportunities
    5. NO STOP LOSSES - we only sell when we WIN
    """
    
    # SAFER HARVEST RULES - avoid bleeding on tiny wins
    MIN_PROFIT_USD = 0.001      # Minimal absolute profit allowed (still tiny, but checked with pct)
    MIN_PROFIT_PCT = 0.5        # Require at least 0.5% net profit after fees to harvest
    MIN_POSITION_VALUE = 1.00   # Position must be worth at least $1.00 to avoid dust harvesting
    
    # Fee estimate for selling on Alpaca (conservative)
    ALPACA_SELL_FEE_PCT = 0.0025  # 0.25% - conservative sell fee estimate
    
    # Cooldown increased to limit over-trading
    HARVEST_COOLDOWN = 120  # 120 seconds (less aggressive harvesting)
    
    def __init__(self):
        self.harvested_total = 0.0
        self.harvest_count = 0
        self.recent_harvests: Dict[str, float] = {}  # asset -> timestamp
        
    def find_harvest_candidates(
        self, 
        positions: List[Dict],
        exclude_assets: Set[str] = None,
    ) -> List[HarvestCandidate]:
        """
        ğŸŒ¾ Scan positions and find ones with harvestable profits.
        
        Args:
            positions: List of position dicts from Alpaca get_positions()
            exclude_assets: Assets to skip (e.g., ones we're about to buy)
            
        Returns:
            List of HarvestCandidate sorted by priority (best first)
        """
        exclude_assets = exclude_assets or set()
        candidates = []
        current_time = time.time()
        
        for pos in positions:
            try:
                symbol = pos.get('symbol', '')
                qty = float(pos.get('qty', 0) or 0)
                market_value = float(pos.get('market_value', 0) or 0)
                cost_basis = float(pos.get('cost_basis', 0) or 0)
                unrealized_pl = float(pos.get('unrealized_pl', 0) or 0)
                unrealized_plpc = float(pos.get('unrealized_plpc', 0) or 0) * 100  # Convert to %
                current_price = float(pos.get('current_price', 0) or 0)
                
                # Extract base asset
                if '/' in symbol:
                    asset = symbol.split('/')[0]
                elif symbol.endswith('USD'):
                    asset = symbol[:-3]
                else:
                    asset = symbol
                
                # Skip excluded assets
                if asset.upper() in exclude_assets or asset in exclude_assets:
                    continue
                    
                # Skip if recently harvested
                if asset in self.recent_harvests:
                    if current_time - self.recent_harvests[asset] < self.HARVEST_COOLDOWN:
                        continue
                
                # Skip if no profit (ALPACA API VERIFIED - this is the TRUTH)
                if unrealized_pl <= 0:
                    continue
                    
                # Skip if position too small (dust filter only)
                if market_value < self.MIN_POSITION_VALUE:
                    continue
                
                # Calculate net profit after sell fee - THIS IS THE CRITICAL CHECK
                sell_fee = market_value * self.ALPACA_SELL_FEE_PCT
                net_profit = unrealized_pl - sell_fee
                net_profit_pct = (net_profit / market_value) * 100 if market_value > 0 else 0.0

                # Require both absolute and percentage thresholds to consider harvesting
                if net_profit <= 0:
                    # Not yet profitable after fees - HODL
                    continue
                if net_profit < self.MIN_PROFIT_USD or net_profit_pct < self.MIN_PROFIT_PCT:
                    # Not meeting minimum harvest thresholds - skip
                    continue
                
                # âœ… NET PROFIT VERIFIED BY ALPACA API - THIS IS A HARVEST CANDIDATE!
                logger.info(f"ğŸŒ¾ HARVEST TARGET: {asset} net_profit=${net_profit:.4f} (after ${sell_fee:.4f} fee)")
                
                # Calculate priority (higher = better)
                # Prioritize by: profit %, then absolute profit
                priority = int(unrealized_plpc * 100) + int(unrealized_pl * 10)
                
                candidates.append(HarvestCandidate(
                    symbol=symbol,
                    asset=asset,
                    qty=qty,
                    cost_basis=cost_basis,
                    market_value=market_value,
                    unrealized_pl=unrealized_pl,
                    unrealized_plpc=unrealized_plpc,
                    current_price=current_price,
                    priority=priority,
                ))
                
            except Exception as e:
                logger.debug(f"Error parsing position for harvest: {e}")
                continue
        
        # Sort by priority (highest first)
        candidates.sort(key=lambda x: x.priority, reverse=True)
        
        return candidates
    
    def record_harvest(self, asset: str, profit_usd: float):
        """Record that we harvested an asset."""
        self.recent_harvests[asset] = time.time()
        self.harvested_total += profit_usd
        self.harvest_count += 1
        
    def get_status(self) -> Dict:
        """Get harvester status."""
        return {
            'harvested_total': self.harvested_total,
            'harvest_count': self.harvest_count,
            'recent_harvests': len(self.recent_harvests),
        }
    
    def print_candidates(self, candidates: List[HarvestCandidate]) -> str:
        """Pretty print harvest candidates."""
        if not candidates:
            return "   ğŸŒ¾ No harvest candidates found"
        
        lines = ["   ğŸŒ¾ğŸ’° HARVEST CANDIDATES (Profitable Positions):"]
        for c in candidates[:5]:  # Show top 5
            lines.append(
                f"      {c.asset}: ${c.market_value:.2f} | "
                f"P&L: ${c.unrealized_pl:+.2f} ({c.unrealized_plpc:+.1f}%)"
            )
        return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¬ MICRO PROFIT LABYRINTH ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MicroProfitLabyrinth:
    """
    Uses ALL existing systems but with LOWER thresholds.
    
    The goal: Capture MORE opportunities for the snowball effect.
    Even $0.01 profit per conversion will compound over time!
    """
    
    def compute_mc_pwin(self, symbol: str, scanner_gross_pnl: float, notional_usd: float, n_samples: int = 1000) -> float:
        """Compute Monte-Carlo probability that net profit > 0 for given gross P&L.

        Returns a probability between 0.0 and 1.0. Uses the dynamic cost estimator
        draws (percent units) and calculates net samples = gross - cost_usd.
        """
        if not hasattr(self, 'cost_estimator') or self.cost_estimator is None:
            return 1.0  # conservative default: assume it's fine if no estimator
        try:
            draws_pct = self.cost_estimator.sample_total_cost_draws(symbol, 'buy', notional_usd, n_samples=n_samples)
            net_samples = [scanner_gross_pnl - (d_pct / 100.0) * notional_usd for d_pct in draws_pct]
            positive = sum(1 for v in net_samples if v > 0)
            return positive / max(1, len(net_samples))
        except Exception as e:
            logger.debug(f"compute_mc_pwin failed: {e}")
            return 0.0

    def __init__(self, live: bool = False, dry_run: bool = False):
        # --dry-run explicitly overrides LIVE env; otherwise allow env to enable live
        if dry_run:
            self.live = False
        else:
            self.live = live or LIVE_MODE
        self.config = MICRO_CONFIG.copy()

        # ğŸ¦™ Alpaca-only mode (disable Binance/Kraken trading)
        # DEFAULT: FALSE now - System uses multi-exchange by default for data; Alpaca for verify
        self.alpaca_only = os.getenv("ALPACA_ONLY", "false").lower() == "true"
        
        # ğŸ”’ Alpaca verify-only gate: when True, Alpaca won't execute trades (only balances/prices)
        self.alpaca_verify_only = ALPACA_VERIFY_ONLY and not ALPACA_EXECUTE
        
        # ğŸŒ Multi-exchange execution order
        self.exchange_order = [e.strip() for e in EXCH_EXEC_ORDER if e.strip()]
        
        # Initialize existing systems
        self.hub = None
        self.v14 = None
        self.commando = None
        self.ladder = None
        self.scanner = None
        self.dual_path = None
        
        # ğŸŒ Adaptive gate & memory
        self.adaptive_gate = AdaptivePrimeProfitGate() if ADAPTIVE_GATE_AVAILABLE else None
        self.path_memory = PathMemory()
        self.thought_bus = ThoughtBus(persist_path="thoughts.jsonl") if THOUGHT_BUS_AVAILABLE else None
        
        # ğŸ‘‘ BOOTSTRAP QUEEN
        self.queen = None
        self.queen_voice = None  # ğŸ‘‘ğŸ¤ THE HARMONIC VOICE
        
        # ğŸ‘‘ï¿½ QUEEN AUTONOMOUS CONTROL - SOVEREIGN AUTHORITY
        # Queen Sero has FULL AUTONOMOUS CONTROL over ALL trading decisions
        self.queen_autonomous_control = None  # Initialized in initialize()
        self.queen_has_full_control = False  # Flag when Queen takes control
        
        # ğŸ‘‘ï¿½ğŸ“ QUEEN LOSS LEARNING - Learn from every loss, never forget
        self.loss_learning = None  # Will initialize in initialize() with exchange clients
        
        # ğŸ’° LIVE BARTER MATRIX - Adaptive coin-to-coin value tracking
        self.barter_matrix = LiveBarterMatrix()
        
        # ğŸ”„ğŸ˜ FRESH START: Clear elephant memory each session
        # New math, new session = fresh start without historical bias
        elephant_files = ['elephant_memory.json', 'elephant_patterns.json', 'elephant_blocked_paths.json']
        for ef in elephant_files:
            if os.path.exists(ef):
                try:
                    os.remove(ef)
                    safe_print(f"ğŸ”„ğŸ˜ FRESH START: Cleared {ef}")
                except Exception:
                    pass

        # ğŸ“Š COST BASIS TRACKER - Realized profit guardrails
        self.cost_basis_tracker = CostBasisTracker()
        
        # ğŸ’§ğŸ”€ LIQUIDITY ENGINE - Dynamic Asset Aggregation ("Top-Up" Mechanism)
        # When we need funds for a trade, liquidate low-performers to fund it!
        self.liquidity_engine = LiquidityEngine(self.barter_matrix)
        
        # ğŸŒ¾ğŸ’° PROFIT HARVESTER - Proactive Portfolio Profit Realization
        # Scans positions for unrealized profits and harvests them for cash!
        self.profit_harvester = ProfitHarvester()
        self.harvest_interval = 1  # Run harvest check EVERY turn (aggressive)
        self.turns_since_harvest = 0
        
        # ğŸ§¹ DUST CONVERTER - Sweep small balances (<Â£1) to stablecoins
        # Only sweeps if profitable after fees - never loses money!
        self.dust_converter = DustConverter() if DUST_CONVERTER_AVAILABLE else None
        self.dust_sweep_interval = 5  # Run dust sweep every 5 turns (TURBO - was 10)
        
        # ğŸª™âš¡ PENNY PROFIT TURBO - Enhanced profit math with real-time data
        # Tracks spreads, fee tiers, compound optimization, flash detection
        self.penny_turbo = get_penny_turbo() if PENNY_TURBO_AVAILABLE else None
        
        # ğŸ§ âš¡ STAGE 3: Full Neural Mind Map Systems
        self.bus_aggregator = ThoughtBusAggregator(self.thought_bus) if self.thought_bus else None
        self.mycelium_network = None  # Hive intelligence
        self.lighthouse = None         # Consensus validation
        self.hnc_matrix = None         # Pattern recognition
        self.ultimate_intel = None     # 95% accuracy patterns
        self.unified_ecosystem = None  # Full ecosystem read-only
        self.timeline_oracle = None    # â³ğŸ”® 7-day future validation
        self.market_map = None         # ğŸ—ºï¸ Crypto market correlation map
        self.seven_day_planner = None  # ğŸ“…ğŸ”® 7-day planning + adaptive validation
        self.barter_navigator = None   # ğŸ«’ğŸ”„ Multi-hop barter pathfinding
        self.luck_mapper = None        # ğŸ€âš›ï¸ Quantum luck field mapping
        self.wisdom_engine = None      # ğŸ§  Wisdom Cognition Engine (11 Civilizations)
        self.enigma_integration = None # ğŸ”ğŸŒ Enigma Integration (Universal Translator)
        self.memi_sync = None          # ğŸ‘‘ğŸ§  CIA Declassified Intelligence Sync
        
        # ğŸŒŠâš¡ MOMENTUM SNOWBALL - Wave riding + momentum tracking
        self.momentum_tracker = None   # Tracks momentum for ALL assets
        self.momentum_snowball = None  # Full snowball engine
        self.labyrinth_snowball = None # V14 + All systems snowball
        
        # ğŸŒŠ MOMENTUM STATE - For jumping coin to coin
        self.momentum_window = 60      # 60 second momentum window
        self.momentum_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.asset_momentum: Dict[str, float] = {}  # Asset -> momentum %/minute
        self.min_momentum_diff = 0.003  # 0.3% momentum difference to convert
        
        # ï¿½ğŸŒ GROUNDING REALITY
        self.grounding = GroundingReality()
        
        # ğŸ”Œ ALL EXCHANGE CLIENTS
        self.kraken = None
        self.binance = None
        self.alpaca = None
        
        # Additional signal sources
        self.probability_nexus = None
        self.multiverse = None
        self.miner_brain = None
        self.harmonic = None
        self.omega = None
        self.rapid_stream = None
        self.wave_scanner = None  # ğŸŒŠğŸ”­ A-Z/Z-A Global Wave Scanner
        self.animal_swarm = None   # ğŸºğŸ¦ğŸœğŸ¦ Animal Momentum Scanners
        
        # State - NOW TRACKS ALL EXCHANGES
        self.prices: Dict[str, float] = {}
        self.ticker_cache: Dict[str, Dict[str, Any]] = {}
        self.balances: Dict[str, float] = {}  # Combined balances
        self.exchange_balances: Dict[str, Dict[str, float]] = {}  # Per-exchange balances
        self.exchange_data: Dict[str, Dict[str, Any]] = {}  # Full exchange data
        self.opportunities: List[MicroOpportunity] = []
        self.conversions: List[MicroOpportunity] = []
        
        # ï¿½ DREAMING & VALIDATION STATE
        self.dreams: List[Dream] = []
        self.dream_accuracy: Dict[str, float] = defaultdict(lambda: 0.5)  # Source -> Accuracy (0.0-1.0)
        self.validated_dreams_count = 0
        
        # ï¿½ğŸ“Š TRADEABLE PAIRS BY EXCHANGE
        self.kraken_pairs: Dict[str, Dict] = {}  # pair -> info dict
        self.alpaca_pairs: Dict[str, str] = {}  # symbol -> normalized
        self.binance_pairs: set = set()  # symbol set
        
        # ğŸ”“ FULL AUTONOMOUS: All assets allowed - no manual blocks!
        self.blocked_binance_assets = set()  # ğŸ”“ CLEARED - Full autonomous
        self.blocked_kraken_assets = set()   # ğŸ”“ CLEARED - Full autonomous (was TUSD)
        
        # ğŸ‘‘ DYNAMIC MINIMUMS (Learned from failures)
        self.dynamic_min_qty: Dict[str, float] = {}
        
        # ğŸ‡¬ğŸ‡§ UK BINANCE RESTRICTIONS - Load from cached file for speed
        self.binance_uk_allowed_pairs: set = set()
        self.binance_uk_mode = os.getenv('BINANCE_UK_MODE', 'true').lower() == 'true'
        self._load_uk_allowed_pairs()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¯ EXECUTION STRATEGY
        # Turn-based OR First-Past-The-Post (FPTP)
        # FPTP = Scan ALL exchanges, execute FIRST profitable opportunity!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦™ ALPACA-FOCUSED: Default to Alpaca-only. Other exchanges disabled.
        self.exchange_order = ['alpaca'] if self.alpaca_only else ['alpaca', 'kraken', 'binance']  # Alpaca first!
        self.current_exchange_index = 0  # Which exchange's turn
        self.turns_completed = 0  # Total turns completed
        self.fptp_mode = True  # ğŸ First Past The Post mode - capture profit IMMEDIATELY! (Default: True)
        self.exchange_stats: Dict[str, Dict] = {  # Per-exchange stats
            'kraken': {'scans': 0, 'opportunities': 0, 'conversions': 0, 'profit': 0.0, 'last_turn': None},
            'alpaca': {'scans': 0, 'opportunities': 0, 'conversions': 0, 'profit': 0.0, 'last_turn': None},
            'binance': {'scans': 0, 'opportunities': 0, 'conversions': 0, 'profit': 0.0, 'last_turn': None},
        }
        self.turn_cooldown_seconds = 0.05  # âš¡ TURBO: 50ms between exchanges (was 0.2)
        
        # ğŸ† WINNERS ONLY MODE - Show only wins, log rejections to file
        self.winners_only_mode = False  # Set by CLI flag --winners-only

        # ğŸ¿â„ï¸ SNOWBALL MODE - ONE TRADE AT A TIME with STRICT PROFIT TRACKING
        # "Make sure as shite we made money!" - Gary Leckey
        # Rules:
        # 1. Only ONE non-stablecoin position at a time
        # 2. Track ACTUAL entry price, not estimates
        # 3. Only exit when CONFIRMED profit > fees
        # 4. Lower minimums allowed (building from small)
        self.snowball_mode = False  # Set by CLI flag --snowball
        self.snowball_position = None  # Current snowball position {asset, entry_price, entry_value_usd, entry_time}
        self.snowball_profit_history = []  # List of realized profits
        self.snowball_total_realized = 0.0  # Confirmed realized profit
        self.snowball_min_profit_pct = 0.3  # 0.3% minimum profit to exit (covers fees + buffer)
        self.snowball_stablecoins = {'USD', 'USDT', 'USDC', 'ZUSD', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD'}

        # ğŸ”—â›“ï¸ CHAIN SNIPER MODE - Multi-hop compounding without bleeding
        # After a successful conversion, keep hopping on the SAME exchange
        # as long as the conservative net P&L remains positive.
        self.chain_sniper_mode = True
        self.max_chain_hops = 25

        # ğŸ¯ FPTP ANTI-REPEAT - Avoid retrying the same failed target every scan
        # (Some failures are transient and don't trigger pre-exec blocking)
        self.fptp_recent_attempts: Dict[Tuple[str, str, str], int] = {}  # (exchange, from, to) -> last_turn
        self.fptp_recent_attempt_cooldown_turns = 3
        
        # ğŸ¢ğŸŒŠ OCEAN MODE - Scan the ENTIRE market, not just what we hold!
        # "Be a turtle in the sea of possibilities, not a big fish in a small pond"
        # - Gary Leckey
        # DEFAULT: TRUE - We want to see ALL opportunities!
        self.ocean_mode_enabled = os.getenv("OCEAN_MODE", "true").lower() == "true"
        
        # Signal aggregation from ALL systems
        self.all_signals: Dict[str, List[Dict]] = defaultdict(list)
        
        # Stats
        self.scans = 0
        self.signals_received = 0
        self.opportunities_found = 0
        self.conversions_made = 0
        self.total_profit_usd = 0.0
        self.start_value_usd = 0.0
        
        # ğŸ‘‘ Queen's guidance on position sizing (fed from portfolio reviews)
        self.queen_position_multiplier = 1.0  # Adjusted by Queen based on performance

        # ğŸ¦™ Alpaca cost model (percentages)
        self.alpaca_fee_pct = float(os.getenv("ALPACA_FEE_PCT", "0.25"))
        self.alpaca_slippage_pct = float(os.getenv("ALPACA_SLIPPAGE_PCT", "0.02"))
        self.alpaca_fee_buffer_pct = float(os.getenv("ALPACA_FEE_BUFFER_PCT", "0.01"))
        # ğŸ›¡ï¸ PROFIT REQUIREMENTS - Allow more trades while maintaining edge
        # Lowered from 0.5% to 0.10% to enable more trading activity for portfolio growth
        self.alpaca_min_net_profit_pct = float(os.getenv("ALPACA_MIN_NET_PROFIT_PCT", "0.10"))  # Require >=0.10% net profit
        self.alpaca_min_net_profit_usd = float(os.getenv("ALPACA_MIN_NET_PROFIT_USD", "0.001"))  # $0.001 minimum (dust filter)
        # ğŸŸ¢ Enable Alpaca auto exits so we take profit at the configured level
        self.alpaca_auto_exits = os.getenv("ALPACA_AUTO_EXITS", "true").lower() == "true"
        # Take profit target: 0.5% (aggressive profit capture)
        self.alpaca_take_profit_pct = float(os.getenv("ALPACA_TAKE_PROFIT_PCT", "0.5"))
        self.alpaca_stop_loss_pct = float(os.getenv("ALPACA_STOP_LOSS_PCT", "0.6"))
        
        # â±ï¸ MINIMUM HOLD TIME - Trust the prediction!
        # If we predict profit at T+3min, don't panic-sell at T+10sec
        # Keep validating but wait for the prediction window to complete
        self.min_hold_time_seconds = float(os.getenv("MIN_HOLD_TIME_SECONDS", "5"))  # 5 seconds default
        self.max_hold_time_seconds = float(os.getenv("MAX_HOLD_TIME_SECONDS", "300"))  # 5 minutes max
        self.position_entry_times = {}  # Track when we bought each asset
        # Registry of positions with verified execution details (keyed by ASSET uppercase)
        # Each entry: {'amount': float, 'entry_price': float, 'entry_value_usd': float, 'fees_usd': float, 'order_ids': [], 'source': 'alpaca', 'timestamp': float}
        self.position_registry: Dict[str, Dict[str, Any]] = {}
        
        # ğŸª† RUSSIAN DOLL ANALYTICS - Fractal measurement system
        # Tracks metrics at three nested levels: Queen (macro) â†’ Hive (system) â†’ Bee (micro)
        self.russian_doll = get_analytics() if RUSSIAN_DOLL_AVAILABLE else None
        self.russian_doll_report_interval = 10  # Print dashboard every N turns
        
        # ğŸ HIVE STATE - Live status & Queen's voice
        self.hive = get_hive() if HIVE_STATE_AVAILABLE else None
        self.hive_update_interval = 1  # Update hive state every turn
        
        # ğŸ“Š RUN METRICS - Monitoring & observability
        self.run_metrics = RunMetrics()
        self.metrics_summary_interval = 60  # Print summary every 60 seconds
        
        # ğŸ’° DYNAMIC COST ESTIMATOR - Learn from actual fees/spreads
        if DYNAMIC_COST_AVAILABLE:
            self.cost_estimator = get_cost_estimator()
            logger.info("ğŸ’° Dynamic cost estimator enabled")
        else:
            self.cost_estimator = None
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ† WINNERS ONLY MODE - Verbose printing control
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def verbose_safe_print(self, message: str, force: bool = False):
        """
        Print message only if NOT in winners_only mode.
        In winners_only mode: logs to file instead (for background learning).
        
        Args:
            message: The message to print
            force: If True, always print (for critical errors, wins, etc.)
        """
        if force or not self.winners_only_mode:
            safe_print(message)
        else:
            # In winners_only mode, log silently for background learning
            logger.debug(f"[QUIET] {message}")
    
    def win_safe_print(self, message: str):
        """
        ğŸ† WINNERS ONLY: Always print winning trades (the good stuff!).
        """
        safe_print(message)  # Winners always shown
    
    def rejection_safe_print(self, message: str):
        """
        ğŸ”‡ REJECTION: Only print if NOT in winners_only mode.
        Rejections/failures go to log file for background learning.
        """
        if not self.winners_only_mode:
            safe_print(message)
        else:
            # Silent logging for Queen's learning
            logger.info(f"[REJECTED] {message}")

    def _alpaca_format_symbol(self, symbol: str) -> str:
        if not symbol:
            return symbol
        if "/" in symbol:
            return symbol
        if symbol.endswith("USD"):
            return f"{symbol[:-3]}/USD"
        if symbol.endswith("USDC"):
            return f"{symbol[:-4]}/USDC"
        # If it's a plain crypto symbol (no slash, doesn't end with quote), assume USD quote
        # This handles cases like "ETH" -> "ETH/USD"
        if symbol and not symbol.endswith("USD") and not symbol.endswith("USDC"):
            return f"{symbol}/USD"
        return symbol

    def _alpaca_get_spread_pct(self, symbol: str) -> float:
        if not self.alpaca:
            return 0.0
        # Skip spread for quote currencies (no trading pair exists)
        if symbol and symbol.upper() in ['USD', 'USDT', 'USDC', 'EUR', 'GBP', 'ZUSD', 'TUSD', 'DAI']:
            return 0.0
        try:
            alpaca_symbol = self._alpaca_format_symbol(symbol)
            # Use cached last quote to avoid extra API calls
            qdata = self.alpaca.get_last_quote(alpaca_symbol) or {}
            quote = qdata.get('raw') or {}
            bid = float(quote.get("bp", 0) or 0)
            ask = float(quote.get("ap", 0) or 0)
            mid = (bid + ask) / 2 if bid and ask else 0
            if mid <= 0:
                return 0.0
            return ((ask - bid) / mid) * 100
        except Exception:
            return 0.0

    def _check_alpaca_loss_prevention(self, asset: str, sell_quantity: float) -> Tuple[bool, str]:
        """
        ğŸš¨ ALPACA LOSS PREVENTION GATE
        
        Check if selling this asset would realize an unrealized loss.
        Uses Alpaca's position P&L data to prevent selling at a loss.
        
        Returns: (allowed: bool, reason: str)
        """
        if not self.alpaca:
            return True, "No Alpaca client - loss prevention bypassed"
        
        try:
            # First check our internal position registry (most accurate for our fills)
            asset_up = asset.upper()
            registry = self.position_registry.get(asset_up)
            current_price = self.prices.get(asset_up, None)

            if registry and current_price is not None:
                # Calculate unrealized P/L from our recorded entry
                entry_amount = float(registry.get('amount', 0.0))
                entry_price = float(registry.get('entry_price', 0.0))
                entry_fees = float(registry.get('fees_usd', 0.0))

                if entry_amount <= 0:
                    return True, f"No recorded position amount - trade allowed"

                # Current value and cost basis
                current_value = current_price * sell_quantity
                cost_basis = entry_price * sell_quantity
                proportional_fees = (entry_fees * (sell_quantity / entry_amount)) if entry_amount > 0 else 0.0
                unrealized_pl = current_value - cost_basis - proportional_fees

                if unrealized_pl >= 0:
                    return True, f"Position at profit (est ${unrealized_pl:.2f}) - safe to sell"
                else:
                    loss_amount = abs(unrealized_pl)
                    # If selling full position
                    if sell_quantity >= entry_amount:
                        return False, f"Would realize ${loss_amount:.2f} loss on entire recorded position"
                    else:
                        # Partial sell - calculate proportional loss
                        proportional_loss = loss_amount
                        # Allow if proportional loss is tiny
                        if proportional_loss < 0.01:
                            return True, f"Small proportional loss (${proportional_loss:.4f}) - allowed"
                        else:
                            return False, f"Would realize ${proportional_loss:.2f} proportional loss"

            # Fallback: use Alpaca's positions if registry not present
            positions = self.alpaca.get_positions()
            
            # Find the position for this asset
            asset_symbol = f"{asset}USD"  # Alpaca format
            position = None
            for pos in positions:
                if pos.get('symbol', '').upper() == asset_symbol.upper():
                    position = pos
                    break
            
            if not position:
                # No position found - this might be a buy opportunity, allow it
                return True, f"No {asset} position found - trade allowed"
            
            # Check unrealized P&L
            unrealized_pl = float(position.get('unrealized_pl', 0))
            current_qty = float(position.get('qty', 0))
            
            if unrealized_pl >= 0:
                # Position is at profit or break-even - safe to sell
                return True, f"Position at profit (${unrealized_pl:.2f}) - safe to sell"
            
            # Position is at unrealized loss
            loss_amount = abs(unrealized_pl)
            
            # Check if we're selling the entire position
            if sell_quantity >= current_qty:
                # Selling entire position would realize the full loss
                return False, f"Would realize ${loss_amount:.2f} loss on entire position"
            else:
                # Partial sell - calculate proportional loss
                sell_ratio = sell_quantity / current_qty
                proportional_loss = loss_amount * sell_ratio
                
                # Allow if proportional loss is very small (< $0.01)
                if proportional_loss < 0.01:
                    return True, f"Small proportional loss (${proportional_loss:.4f}) - allowed"
                else:
                    return False, f"Would realize ${proportional_loss:.2f} proportional loss"
                
        except Exception as e:
            # If loss prevention check fails, allow trade but log warning
            safe_print(f"   âš ï¸ Loss prevention check failed: {e} - allowing trade")
            return True, f"Check failed ({e}) - trade allowed"

    def _check_kraken_loss_prevention(self, asset: str, sell_quantity: float) -> Tuple[bool, str]:
        """
        ğŸš¨ KRAKEN LOSS PREVENTION GATE
        
        Check if selling this asset would realize an unrealized loss.
        Uses Kraken state file positions to calculate P&L.
        
        Returns: (allowed: bool, reason: str)
        """
        try:
            # Load Kraken positions from state file
            state_file = 'aureon_kraken_state.json'
            if not os.path.exists(state_file):
                return True, f"No Kraken state file - loss prevention bypassed"
            
            with open(state_file, 'r') as f:
                state = json.load(f)
            
            positions = state.get('positions', {})
            
            # Find the position for this asset
            asset_key = f"{asset}USD"  # Kraken format
            position = None
            for pos_key, pos_data in positions.items():
                if pos_key.upper() == asset_key.upper():
                    position = pos_data
                    break
            
            if not position:
                # No position found - this might be a buy opportunity, allow it
                return True, f"No {asset} position found - trade allowed"
            
            # Calculate current P&L
            entry_price = float(position.get('entry_price', 0))
            quantity = float(position.get('quantity', 0))
            current_price = self.prices.get(asset, 0)
            
            if entry_price <= 0 or current_price <= 0:
                return True, f"Invalid price data - allowing trade"
            
            # Calculate unrealized P&L
            unrealized_pl = (current_price - entry_price) * quantity
            
            if unrealized_pl >= 0:
                # Position is at profit or break-even - safe to sell
                return True, f"Position at profit (${unrealized_pl:.2f}) - safe to sell"
            
            # Position is at unrealized loss
            loss_amount = abs(unrealized_pl)
            
            # Check if we're selling the entire position
            if sell_quantity >= quantity:
                # Selling entire position would realize the full loss
                return False, f"Would realize ${loss_amount:.2f} loss on entire position"
            else:
                # Partial sell - calculate proportional loss
                sell_ratio = sell_quantity / quantity
                proportional_loss = loss_amount * sell_ratio
                
                # Allow if proportional loss is very small (< $0.01)
                if proportional_loss < 0.01:
                    return True, f"Small proportional loss (${proportional_loss:.4f}) - allowed"
                else:
                    return False, f"Would realize ${proportional_loss:.2f} proportional loss"
                
        except Exception as e:
            # If loss prevention check fails, allow trade but log warning
            safe_print(f"   âš ï¸ Kraken loss prevention check failed: {e} - allowing trade")
            return True, f"Check failed ({e}) - trade allowed"

    def _check_binance_loss_prevention(self, asset: str, sell_quantity: float) -> Tuple[bool, str]:
        """
        ğŸš¨ BINANCE LOSS PREVENTION GATE
        
        Check if selling this asset would realize an unrealized loss.
        Uses position tracking to calculate P&L.
        
        Returns: (allowed: bool, reason: str)
        """
        # For now, Binance doesn't have position tracking like Kraken
        # Allow all trades but log that loss prevention is not active
        safe_print(f"   â„¹ï¸ Binance loss prevention not yet implemented - allowing trade")
        return True, f"Binance loss prevention not implemented - trade allowed"

    def _alpaca_estimate_conversion_costs(self, from_asset: str, to_asset: str) -> Dict[str, float]:
        # Format symbols properly - these will be converted to "ASSET/USD" format
        from_symbol = self._alpaca_format_symbol(from_asset)
        to_symbol = self._alpaca_format_symbol(to_asset)
        spread_from = self._alpaca_get_spread_pct(from_symbol)
        spread_to = self._alpaca_get_spread_pct(to_symbol)
        fee_pct = self.alpaca_fee_pct
        slippage_pct = self.alpaca_slippage_pct
        total_pct = (
            fee_pct * 2
            + slippage_pct * 2
            + spread_from
            + spread_to
            + self.alpaca_fee_buffer_pct
        )
        return {
            "fee_pct": fee_pct,
            "slippage_pct": slippage_pct,
            "spread_from_pct": spread_from,
            "spread_to_pct": spread_to,
            "spread_pct": spread_from + spread_to,
            "fee_buffer_pct": self.alpaca_fee_buffer_pct,
            "total_pct": total_pct,
        }

    def _alpaca_place_exit_orders(self, asset: str, qty: float) -> None:
        """Optionally place Alpaca OCO exits to capture profit and cap downside."""
        if not self.alpaca_auto_exits or not self.alpaca or not asset or qty <= 0:
            return
        if asset.upper() in self.barter_matrix.STABLECOINS:
            return
        
        # â±ï¸ MINIMUM HOLD TIME CHECK - Don't exit before prediction window
        asset_upper = asset.upper()
        if asset_upper in self.position_entry_times:
            entry_time = self.position_entry_times[asset_upper]
            hold_duration = time.time() - entry_time
            
            if hold_duration < self.min_hold_time_seconds:
                remaining = self.min_hold_time_seconds - hold_duration
                logger.info(
                    f"â±ï¸ Holding {asset} - {hold_duration:.0f}s elapsed, "
                    f"need {remaining:.0f}s more (min {self.min_hold_time_seconds:.0f}s)"
                )
                return  # Don't place exit orders yet - hold the position!
            
            # Check max hold time - force exit if held too long
            if hold_duration > self.max_hold_time_seconds:
                logger.warning(
                    f"â° Max hold time exceeded for {asset} ({hold_duration:.0f}s > {self.max_hold_time_seconds:.0f}s) - "
                    f"forcing exit!"
                )
                # Will place exit orders below to close position

        symbol = self._alpaca_format_symbol(f"{asset}USD")
        price = self.prices.get(asset.upper(), 0.0) or 0.0

        try:
            qdata = self.alpaca.get_last_quote(symbol) or {}
            quote = qdata.get('raw') or {}
            bid = float(quote.get("bp", 0) or 0)
            ask = float(quote.get("ap", 0) or 0)
            if bid > 0 and ask > 0:
                price = (bid + ask) / 2
        except Exception:
            pass

        if price <= 0:
            return

        take_profit = price * (1 + self.alpaca_take_profit_pct / 100.0)
        stop_loss = price * (1 - self.alpaca_stop_loss_pct / 100.0)

        # ğŸ”’ Check Alpaca verify-only gate
        if self.alpaca_verify_only:
            logger.debug(f"ğŸ”’ ALPACA VERIFY-ONLY: Skipping OCO for {asset} (set ALPACA_EXECUTE=true to enable)")
            return

        try:
            result = self.alpaca.place_oco_order(
                symbol=symbol,
                qty=qty,
                side="sell",
                take_profit_limit=take_profit,
                stop_loss_stop=stop_loss,
            )
            if result:
                logger.info(
                    f"ğŸ¦™ Alpaca OCO exits placed for {asset}: TP {take_profit:.6f} | SL {stop_loss:.6f}"
                )
        except Exception as e:
            logger.debug(f"Alpaca OCO placement failed for {asset}: {e}")
    
    def _load_uk_allowed_pairs(self):
        """Load UK-allowed Binance pairs from cached JSON file."""
        if not self.binance_uk_mode:
            safe_print("ğŸ‡¬ğŸ‡§ UK Mode: DISABLED (all pairs allowed)")
            return
            
        try:
            import json
            uk_file = os.path.join(os.path.dirname(__file__), "binance_uk_allowed_pairs.json")
            
            if os.path.exists(uk_file):
                with open(uk_file, 'r') as f:
                    data = json.load(f)
                
                self.binance_uk_allowed_pairs = set(data.get('allowed_pairs', []))
                timestamp = data.get('timestamp_readable', 'Unknown')
                
                safe_print(f"ğŸ‡¬ğŸ‡§ UK Binance: {len(self.binance_uk_allowed_pairs)} pairs allowed")
                safe_print(f"   ğŸ“„ Cached from: {timestamp}")
                
                # Key insight: NO USDT pairs for UK!
                quote_assets = data.get('allowed_quote_assets', [])
                if 'USDT' not in quote_assets:
                    safe_print(f"   âš ï¸ NOTE: USDT pairs NOT allowed for UK accounts!")
                    safe_print(f"   âœ… Use USDC/BTC/EUR pairs instead")
            else:
                safe_print(f"âš ï¸ UK pairs file not found: {uk_file}")
                safe_print(f"   Run: python binance_uk_allowed_pairs.py to generate")
        except Exception as e:
            safe_print(f"âš ï¸ Failed to load UK pairs: {e}")
    
    def is_binance_pair_allowed(self, pair: str) -> bool:
        """Check if a Binance pair is allowed for UK trading."""
        if not self.binance_uk_mode:
            return True
        
        if not self.binance_uk_allowed_pairs:
            # No cached data - fall back to live check
            if self.binance and hasattr(self.binance, 'can_trade_symbol'):
                return self.binance.can_trade_symbol(pair)
            return True  # Allow if we can't check
        
        return pair.upper() in self.binance_uk_allowed_pairs
    
    async def initialize(self):
        """Initialize all systems."""
        safe_print("\n" + "=" * 70)
        safe_print("ğŸ”¬ğŸ’° INITIALIZING MICRO PROFIT LABYRINTH ğŸ’°ğŸ”¬")
        safe_print("ğŸ¦™ ALPACA-FOCUSED TRADING SYSTEM ğŸ¦™" if self.alpaca_only else "âš ï¸ MULTI-EXCHANGE MODE")
        safe_print("=" * 70)
        safe_print(f"MODE: {'ğŸ”´ LIVE TRADING' if self.live else 'ğŸ”µ DRY RUN'}")
        safe_print(f"PLATFORM: {'ğŸ¦™ ALPACA ONLY' if self.alpaca_only else 'ğŸŒ Multi-Exchange'}")
        safe_print(f"Entry Threshold: Score {self.config['entry_score_threshold']}+ (vs V14's 8+)")
        safe_print(f"Min Profit: ${self.config['min_profit_usd']:.6f} or {self.config['min_profit_pct']*100:.4f}%")
        safe_print("=" * 70)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ™ KRAKEN CLIENT - DISABLED BY DEFAULT (Alpaca-focused system)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca_only:
            safe_print("ğŸ™ Kraken Client: âŒ DISABLED (Alpaca-focused mode)")
        elif get_kraken_client:
            self.kraken = get_kraken_client()
            if self.kraken and KRAKEN_API_KEY:
                # Gary: Explicitly show if we are using Real or Fake data
                is_dry = getattr(self.kraken, 'dry_run', False)
                mode = "ğŸ›¡ï¸ SIMULATED (Fake Data)" if is_dry else "ğŸŒ LIVE (Real Data)"
                safe_print(f"ğŸ™ Kraken Client: WIRED ({mode})")
            else:
                safe_print("âš ï¸ Kraken Client: Missing API credentials")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŸ¡ BINANCE CLIENT - DISABLED BY DEFAULT (Alpaca-focused system)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca_only:
            safe_print("ğŸŸ¡ Binance Client: âŒ DISABLED (Alpaca-focused mode)")
        elif BINANCE_AVAILABLE and BinanceClient and BINANCE_API_KEY:
            try:
                self.binance = BinanceClient()
                safe_print("ğŸŸ¡ Binance Client: WIRED (API Key loaded)")
            except Exception as e:
                safe_print(f"âš ï¸ Binance Client error: {e}")
        else:
            safe_print("âš ï¸ Binance Client: Not configured")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦™ ALPACA CLIENT - STOCKS + CRYPTO
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if ALPACA_AVAILABLE and AlpacaClient and ALPACA_API_KEY:
            try:
                self.alpaca = AlpacaClient()
                safe_print("ğŸ¦™ Alpaca Client: WIRED (API Key loaded)")
                account = self.alpaca.get_account()
                if account and account.get("id"):
                    mode = "PAPER" if getattr(self.alpaca, "use_paper", False) else "LIVE"
                    safe_print(f"   ğŸ¦™ Alpaca API: âœ… Connected ({mode})")
                else:
                    last_error = getattr(self.alpaca, "last_error", None)
                    safe_print(f"   ğŸ¦™ Alpaca API: âš ï¸ Connection check failed ({last_error})")

                # Start MarketDataHub for Alpaca (Phase 2 optimization)
                try:
                    self.alpaca.start_market_data_hub()
                    safe_print("   ğŸ¦™ MarketDataHub: STARTED")
                except Exception as e:
                    safe_print(f"   âš ï¸ MarketDataHub failed to start: {e}")
            except Exception as e:
                safe_print(f"âš ï¸ Alpaca Client error: {e}")
        else:
            safe_print("âš ï¸ Alpaca Client: Not configured")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ï¿½ ALPACA FEE TRACKER - PREVENT "DEATH BY 1000 CUTS"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if FEE_TRACKER_AVAILABLE and AlpacaFeeTracker and hasattr(self, 'alpaca') and self.alpaca:
            try:
                self.fee_tracker = AlpacaFeeTracker(self.alpaca)
                tier = self.fee_tracker.current_tier
                safe_print(f"ğŸ’° Alpaca Fee Tracker: WIRED")
                safe_print(f"   ğŸ“Š Fee Tier: {tier.name} (maker: {tier.maker_bps}bps, taker: {tier.taker_bps}bps)")
                safe_print(f"   ğŸ“Š 30d Volume: ${self.fee_tracker.volume_30d:,.2f}")
                safe_print(f"   ğŸ›¡ï¸ Cost protection: ACTIVE (min_profit_margin: 50%)")
            except Exception as e:
                self.fee_tracker = None
                safe_print(f"âš ï¸ Alpaca Fee Tracker error: {e}")
        else:
            self.fee_tracker = None
            safe_print("âš ï¸ Alpaca Fee Tracker: Not configured (requires Alpaca client)")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ï¿½ğŸ“Š LOAD TRADEABLE PAIRS FROM ALL EXCHANGES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        await self._load_all_tradeable_pairs()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ„ MYCELIUM HUB - CENTRAL NERVOUS SYSTEM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if get_conversion_hub:
            self.hub = get_conversion_hub()
            safe_print("ğŸ„ Mycelium Hub: WIRED (10 systems, 90 pathways)")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¯ V14 DANCE ENHANCER - 100% WIN RATE LOGIC
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if V14DanceEnhancer:
            self.v14 = V14DanceEnhancer()
            safe_print("ğŸ¯ V14 Scoring: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦… CONVERSION COMMANDO - FALCON/TORTOISE/CHAMELEON/BEE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if AdaptiveConversionCommando:
            self.commando = AdaptiveConversionCommando()
            safe_print("ğŸ¦… Conversion Commando: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”­ PAIR SCANNER - ALL PAIRS ALL EXCHANGES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if PairScanner:
            self.scanner = PairScanner()
            safe_print("ğŸ”­ Pair Scanner: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ’¡ DUAL PROFIT PATH - SELL vs CONVERT DECISION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if DualProfitPathEvaluator:
            self.dual_path = DualProfitPathEvaluator(self.scanner)
            safe_print("ğŸ’¡ Dual Profit Path: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸªœ CONVERSION LADDER - CAPITAL MOMENTUM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if ConversionLadder:
            self.ladder = ConversionLadder()
            safe_print("ğŸªœ Conversion Ladder: WIRED")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”® PROBABILITY NEXUS - 80%+ WIN RATE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if EnhancedProbabilityNexus:
            try:
                self.probability_nexus = EnhancedProbabilityNexus()
                safe_print("ğŸ”® Probability Nexus: WIRED")
            except Exception as e:
                safe_print(f"âš ï¸ Probability Nexus error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŒ INTERNAL MULTIVERSE - 10 WORLDS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if InternalMultiverse:
            try:
                self.multiverse = InternalMultiverse()
                safe_print("ğŸŒŒ Internal Multiverse: WIRED (10 worlds)")
            except Exception as e:
                safe_print(f"âš ï¸ Multiverse error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ§  MINER BRAIN - COGNITIVE INTELLIGENCE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if MinerBrain:
            try:
                self.miner_brain = MinerBrain()
                safe_print("ğŸ§  Miner Brain: WIRED")
            except Exception as e:
                safe_print(f"âš ï¸ Miner Brain error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ—ï¸ QUEEN CODE ARCHITECT - SELF-EVOLUTION ENGINE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.code_architect = None
        if CODE_ARCHITECT_AVAILABLE and get_code_architect:
            try:
                self.code_architect = get_code_architect()
                safe_print("ğŸ‘‘ğŸ—ï¸ Queen Code Architect: WIRED (Self-Evolution Engine)")
                safe_print("   â„¹ï¸ The Queen can now write code based on learnings!")
            except Exception as e:
                safe_print(f"âš ï¸ Code Architect error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŠ HARMONIC FUSION - WAVE PATTERNS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if HarmonicWaveFusion:
            try:
                self.harmonic = HarmonicWaveFusion()
                safe_print("ğŸŒŠ Harmonic Fusion: WIRED")
            except Exception as e:
                safe_print(f"âš ï¸ Harmonic error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŠğŸ”­ GLOBAL WAVE SCANNER - A-Z/Z-A FULL COVERAGE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.wave_scanner = None
        if GLOBAL_WAVE_SCANNER_AVAILABLE and GlobalWaveScanner:
            try:
                self.wave_scanner = GlobalWaveScanner(
                    kraken_client=self.kraken,
                    binance_client=self.binance,
                    alpaca_client=self.alpaca,
                    queen=None,  # Will wire after queen is initialized
                    harmonic_fusion=self.harmonic,
                )
                safe_print("ğŸŒŠğŸ”­ Global Wave Scanner: INITIALIZED (A-Z/Z-A coverage)")
            except Exception as e:
                safe_print(f"âš ï¸ Global Wave Scanner error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸºğŸ¦ğŸœğŸ¦ ANIMAL MOMENTUM SCANNERS - ALPACA SWARM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.animal_swarm = None
        if ANIMAL_SCANNERS_AVAILABLE and AlpacaSwarmOrchestrator and self.alpaca:
            try:
                from aureon_alpaca_scanner_bridge import AlpacaScannerBridge
                # Use existing fee_tracker if available, otherwise create new
                _fee_tracker = getattr(self, "fee_tracker", None)
                if not _fee_tracker and FEE_TRACKER_AVAILABLE:
                    from alpaca_fee_tracker import AlpacaFeeTracker as AFT
                    _fee_tracker = AFT(self.alpaca)
                scanner_bridge = AlpacaScannerBridge(
                    alpaca_client=self.alpaca,
                    fee_tracker=_fee_tracker,
                    enable_sse=False,
                    enable_stocks=False
                )
                self.animal_swarm = AlpacaSwarmOrchestrator(self.alpaca, scanner_bridge)
                self.animal_swarm.dry_run = not self.live  # Safety: dry-run unless live mode
                safe_print("ğŸºğŸ¦ Animal Swarm Orchestrator: INITIALIZED (Wolf, Lion, Ants, Hummingbird)")
            except Exception as e:
                safe_print(f"âš ï¸ Animal Swarm Orchestrator error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ï¿½ğŸ”± OMEGA - HIGH CONFIDENCE SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if Omega:
            try:
                self.omega = Omega()
                safe_print("ğŸ”± Omega: WIRED")
            except Exception as e:
                safe_print(f"âš ï¸ Omega error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # âš¡ RAPID CONVERSION STREAM - FAST DATA
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if RapidConversionStream:
            try:
                self.rapid_stream = RapidConversionStream()
                safe_print("âš¡ Rapid Conversion Stream: WIRED")
            except Exception as e:
                safe_print(f"âš ï¸ Rapid Stream error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŠâš¡ MOMENTUM SNOWBALL ENGINE - WAVE JUMPING
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if MOMENTUM_SNOWBALL_AVAILABLE and MomentumTracker:
            try:
                self.momentum_tracker = MomentumTracker(window_seconds=60)
                safe_print("ğŸŒŠâš¡ Momentum Tracker: WIRED (60s window)")
            except Exception as e:
                safe_print(f"âš ï¸ Momentum Tracker error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ†ğŸŒ€ LABYRINTH SNOWBALL ENGINE - V14 + ALL SYSTEMS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if LABYRINTH_SNOWBALL_AVAILABLE:
            try:
                # Just import the logic, don't create full engine (we are the engine!)
                safe_print("ğŸ†ğŸŒ€ Labyrinth Snowball Logic: WIRED")
            except Exception as e:
                safe_print(f"âš ï¸ Labyrinth Snowball error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ§ âš¡ STAGE 3: FULL NEURAL MIND MAP WIRING âš¡ğŸ§ 
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        safe_print("\nğŸ§  WIRING NEURAL MIND MAP SYSTEMS...")
        
        # ğŸ„ Mycelium Neural Network (Hive Intelligence)
        if MYCELIUM_NETWORK_AVAILABLE and MyceliumNetwork:
            try:
                self.mycelium_network = MyceliumNetwork(initial_capital=1000.0)
                safe_print("   ğŸ„ Mycelium Neural Network: âœ… WIRED (Hive Intelligence)")
            except Exception as e:
                safe_print(f"   âš ï¸ Mycelium Network error: {e}")
                self.mycelium_network = None
        else:
            safe_print(f"   ğŸ„ Mycelium Network: âŒ NOT AVAILABLE (import={MYCELIUM_NETWORK_AVAILABLE})")
        
        # ğŸ—¼ Lighthouse (Consensus Validation)
        if LIGHTHOUSE_AVAILABLE and Lighthouse:
            try:
                self.lighthouse = Lighthouse()
                safe_print("   ğŸ—¼ Lighthouse: âœ… WIRED (Consensus Validation)")
            except Exception as e:
                safe_print(f"   âš ï¸ Lighthouse error: {e}")
                self.lighthouse = None
        else:
            safe_print(f"   ğŸ—¼ Lighthouse: âŒ NOT AVAILABLE (import={LIGHTHOUSE_AVAILABLE})")
        
        # ğŸ“Š HNC Probability Matrix (Pattern Recognition)
        if HNC_MATRIX_AVAILABLE and HNCProbabilityMatrix:
            try:
                self.hnc_matrix = HNCProbabilityMatrix()
                safe_print("   ğŸ“Š HNC Probability Matrix: âœ… WIRED (Pattern Recognition)")
            except Exception as e:
                safe_print(f"   âš ï¸ HNC Matrix error: {e}")
                self.hnc_matrix = None
        else:
            safe_print(f"   ğŸ“Š HNC Matrix: âŒ NOT AVAILABLE (import={HNC_MATRIX_AVAILABLE})")
        
        # ğŸ’ Ultimate Intelligence (95% Accuracy)
        if ULTIMATE_INTEL_AVAILABLE and get_ultimate_intelligence:
            try:
                self.ultimate_intel = get_ultimate_intelligence()
                safe_print("   ğŸ’ Ultimate Intelligence: âœ… WIRED (95% Accuracy)")
            except Exception as e:
                safe_print(f"   âš ï¸ Ultimate Intel error: {e}")
                self.ultimate_intel = None
        else:
            safe_print(f"   ğŸ’ Ultimate Intel: âŒ NOT AVAILABLE (import={ULTIMATE_INTEL_AVAILABLE})")
        
        # ğŸŒ Unified Ecosystem (Full Integration)
        if UNIFIED_ECOSYSTEM_AVAILABLE and AureonUnifiedEcosystem:
            try:
                # Create a lightweight tap into the ecosystem
                self.unified_ecosystem = AureonUnifiedEcosystem.__name__  # Just mark as available
                safe_print("   ğŸŒ Unified Ecosystem: âœ… AVAILABLE (will tap via Hub)")
            except Exception as e:
                safe_print(f"   âš ï¸ Unified Ecosystem error: {e}")
                self.unified_ecosystem = None
        else:
            safe_print(f"   ğŸŒ Unified Ecosystem: âŒ NOT AVAILABLE (import={UNIFIED_ECOSYSTEM_AVAILABLE})")
        
        # â³ğŸ”® Timeline Oracle (7-Day Future Validation)
        self.timeline_oracle = None
        if TIMELINE_ORACLE_AVAILABLE and get_timeline_oracle:
            try:
                self.timeline_oracle = get_timeline_oracle()
                safe_print("â³ğŸ”® Timeline Oracle: WIRED (7-day future validation)")
            except Exception as e:
                safe_print(f"âš ï¸ Timeline Oracle error: {e}")
        
        # ğŸ—ºï¸ CRYPTO MARKET MAP - LABYRINTH PATHFINDER (ALL EXCHANGES)
        self.market_map = None
        if MARKET_MAP_AVAILABLE and CryptoMarketMap:
            try:
                self.market_map = CryptoMarketMap()
                # Load from cache first (has Coinbase 1-year historical data)
                self.market_map._load_cache()
                # Add data from all connected exchanges
                if self.kraken:
                    self.market_map.load_from_kraken(self.kraken)
                if self.binance:
                    self.market_map.load_from_binance(self.binance)
                if self.alpaca:
                    self.market_map.load_from_alpaca(self.alpaca)
                # Load trained probability patterns
                self.market_map.load_from_probability_matrix()
                # Save updated cache
                self.market_map.save_cache()
                summary = self.market_map.get_map_summary()
                safe_print(f"ğŸ—ºï¸ Crypto Market Map: WIRED ({summary['assets_mapped']} assets, {summary['correlations']} correlations)")
            except Exception as e:
                safe_print(f"âš ï¸ Market Map error: {e}")
        
        # ğŸ“…ğŸ”® 7-DAY PLANNER - Plan ahead + adaptive validation after each conversion
        self.seven_day_planner = None
        if SEVEN_DAY_PLANNER_AVAILABLE and Aureon7DayPlanner:
            try:
                self.seven_day_planner = Aureon7DayPlanner()
                # Create initial 7-day plan
                plan = self.seven_day_planner.plan_7_days()
                summary = self.seven_day_planner.get_week_summary()
                stats = self.seven_day_planner.get_validation_stats()
                safe_print(f"ğŸ“…ğŸ”® 7-Day Planner: WIRED (edge: {summary['total_predicted_edge']:+.2f}%, accuracy: {stats['accuracy']:.0%})")
            except Exception as e:
                safe_print(f"âš ï¸ 7-Day Planner error: {e}")
        
        # ğŸ«’ğŸ”„ BARTER NAVIGATOR - Multi-hop pathfinding (oliveâ†’beanâ†’carrotâ†’chairâ†’lampâ†’olive)
        self.barter_navigator = None
        if BARTER_NAVIGATOR_AVAILABLE and BarterNavigator:
            try:
                self.barter_navigator = BarterNavigator()
                # Don't load yet - will populate after pairs are loaded with populate_barter_graph()
                safe_print(f"ğŸ«’ğŸ”„ Barter Navigator: INITIALIZED (will populate after pair loading)")
            except Exception as e:
                safe_print(f"âš ï¸ Barter Navigator error: {e}")
        
        # ğŸ€âš›ï¸ LUCK FIELD MAPPER - Quantum probability mapping
        self.luck_mapper = None
        if LUCK_FIELD_AVAILABLE and LuckFieldMapper:
            try:
                self.luck_mapper = LuckFieldMapper()
                # Take initial reading
                initial_luck = self.luck_mapper.read_field()
                safe_print(f"ğŸ€âš›ï¸ Luck Field Mapper: WIRED (Î»={initial_luck.luck_field:.4f} â†’ {initial_luck.luck_state.value})")
            except Exception as e:
                safe_print(f"âš ï¸ Luck Field Mapper error: {e}")
        
        # ğŸ‘‘ğŸ„ğŸŒŠğŸªğŸ”­ QUEEN HIVE MIND - Wire cosmic systems
        self.queen = None
        if QUEEN_HIVE_MIND_AVAILABLE and get_queen:
            try:
                self.queen = get_queen()
                
                # ğŸ‘‘ğŸ’• Let Queen greet Gary at session start
                if hasattr(self.queen, 'speak_from_heart'):
                    try:
                        greeting = self.queen.speak_from_heart('greeting')
                        if greeting:
                            safe_print(f"\n{greeting}\n")
                    except Exception as e:
                        logger.debug(f"Queen greeting error: {e}")
                
                # ğŸ‡¬ğŸ‡§ğŸ’ Wire Advanced Intelligence (The Missing Pieces)
                if hasattr(self.queen, 'wire_advanced_intelligence'):
                    try:
                        wired = self.queen.wire_advanced_intelligence()
                        if wired:
                            safe_print(f"   ğŸ’ Advanced Intelligence: âœ… WIRED (Mycelium + Piano + Golden Ratio)")
                    except Exception as e:
                        logger.warning(f"Failed to wire Advanced Intelligence: {e}")

                # Wire Harmonic Fusion (waves, Schumann, lighthouse)
                if hasattr(self, 'harmonic') and self.harmonic:
                    self.queen.wire_harmonic_fusion(self.harmonic)
                
                # Wire Luck Field Mapper (planetary, lunar, solar)
                if self.luck_mapper:
                    self.queen.wire_luck_field_mapper(self.luck_mapper)
                
                # Wire Quantum Telescope (geometric vision)
                try:
                    from aureon_quantum_telescope import QuantumTelescope
                    self.quantum_telescope = QuantumTelescope()
                    self.queen.wire_quantum_telescope(self.quantum_telescope)
                except Exception as e:
                    logger.debug(f"Quantum Telescope not available: {e}")
                
                # Wire Mycelium for broadcast
                if hasattr(self, 'mycelium_network') and self.mycelium_network:
                    self.queen.wire_mycelium_network(self.mycelium_network)
                
                # ğŸ§ ğŸ“š Wire Historical Wisdom Systems
                # Miner Brain (11 Civilizations)
                try:
                    from aureon_miner_brain import WisdomCognitionEngine, SandboxEvolution
                    self.wisdom_engine = WisdomCognitionEngine()  # Store on self!
                    self.queen.wire_wisdom_cognition_engine(self.wisdom_engine)
                    
                    # Sandbox Evolution (454 generations)
                    sandbox_evo = SandboxEvolution()
                    self.queen.wire_sandbox_evolution(sandbox_evo)
                except Exception as e:
                    logger.debug(f"Wisdom Cognition Engine not available: {e}")
                
                # Wire Unified River Consciousness (The Flow)
                try:
                    from aureon_unified_river_consciousness import UnifiedRiverConsciousness
                    self.river_consciousness = UnifiedRiverConsciousness()
                    if hasattr(self.queen, 'wire_river_consciousness'):
                        self.queen.wire_river_consciousness(self.river_consciousness)
                        safe_print(f"   ğŸŒŠ River Consciousness: âœ… WIRED (Sensing the Flow)")
                except Exception as e:
                    logger.debug(f"River Consciousness not available: {e}")
                
                # ğŸ‘‘ğŸ”® Wire Queen's Dream Engine (Monte Carlo Simulation + Validation)
                try:
                    from aureon_queen_dream_engine import QueenDreamEngine, create_queen_dream_engine
                    self.dream_engine = create_queen_dream_engine()
                    if hasattr(self.queen, 'wire_dream_engine_simulation'):
                        self.queen.wire_dream_engine_simulation(self.dream_engine)
                    safe_print(f"   ğŸ‘‘ğŸ”® Dream Engine: âœ… WIRED (1000s simulations + validation)")
                except Exception as e:
                    self.dream_engine = None
                    logger.debug(f"Queen Dream Engine not available: {e}")

                # Dream Memory & Wisdom Collector
                try:
                    from aureon_enigma_dream import DreamMemory, WisdomCollector, EnigmaDreamer
                    dream_memory = DreamMemory()
                    self.queen.wire_dream_memory(dream_memory)
                    
                    wisdom_collector = WisdomCollector()
                    self.queen.wire_wisdom_collector(wisdom_collector)
                    
                    # ğŸŒ™ğŸ’­ WIRE THE DREAM ENGINE - Let Sero DREAM toward her $1B goal!
                    dreamer = EnigmaDreamer()
                    self.queen.wire_dream_engine(dreamer)
                except Exception as e:
                    logger.debug(f"Dream/Wisdom systems not available: {e}")
                
                # ğŸ”±â³ Wire Temporal ID and Temporal Ladder (Gary Leckey 02111991)
                try:
                    self.queen.wire_temporal_id()
                    self.queen.wire_temporal_ladder()
                    if hasattr(self.queen, 'wire_temporal_dialer'):
                        self.queen.wire_temporal_dialer()
                except Exception as e:
                    logger.debug(f"Temporal systems not available: {e}")
                
                # ğŸ—ºï¸ğŸ’° Wire Barter Matrix to Queen (1,162+ assets, 7 categories!)
                try:
                    self.queen.wire_barter_matrix(self.barter_matrix)
                except Exception as e:
                    logger.debug(f"Barter Matrix wiring not available: {e}")

                # ğŸ’± Wire Exchange Clients (execution-aware pricing)
                try:
                    self.queen.wire_exchange_clients({
                        'kraken': self.kraken,
                        'binance': self.binance,
                        'alpaca': self.alpaca,
                    })
                except Exception as e:
                    logger.debug(f"Exchange client wiring not available: {e}")

                # ğŸ“Š Wire Cost Basis Tracker (realized profit guard)
                try:
                    self.queen.wire_cost_basis_tracker(self.cost_basis_tracker)
                except Exception as e:
                    logger.debug(f"Cost basis wiring not available: {e}")
                
                # ğŸ’° Wire Fee Tracker to Queen (REAL cost awareness!)
                try:
                    if hasattr(self, 'fee_tracker') and self.fee_tracker:
                        if hasattr(self.queen, 'wire_fee_tracker'):
                            self.queen.wire_fee_tracker(self.fee_tracker)
                            safe_print(f"   ğŸ’° Fee Tracker: âœ… WIRED (prevents death by 1000 cuts)")
                except Exception as e:
                    logger.debug(f"Fee Tracker wiring not available: {e}")
                
                # ğŸ“šğŸ§  Wire Path Memory to Queen (learned trading paths!)
                try:
                    # Convert PathMemory to Queen-friendly format
                    path_memory_dict = {}
                    if hasattr(self, 'path_memory') and self.path_memory:
                        for key, stats in self.path_memory.memory.items():
                            path_str = f"{key[0]}->{key[1]}"
                            path_memory_dict[path_str] = {
                                'wins': stats.get('wins', 0),
                                'losses': stats.get('losses', 0)
                            }
                    if path_memory_dict:
                        self.queen.wire_path_memory(path_memory_dict)
                except Exception as e:
                    logger.debug(f"Path Memory wiring not available: {e}")
                
                # Get temporal state for display
                temporal_state = self.queen.get_temporal_state() if hasattr(self.queen, 'get_temporal_state') else {}
                temporal_active = temporal_state.get('active', False)
                
                safe_print(f"ğŸ‘‘ğŸ„ Queen Hive Mind: WIRED (Cosmic + Historical + Temporal consciousness)")
                safe_print(f"   ğŸŒŠ Harmonic Fusion: {'âœ…' if hasattr(self.queen, 'harmonic_fusion') and self.queen.harmonic_fusion else 'âŒ'}")
                safe_print(f"   ğŸª Luck Field Mapper: {'âœ…' if hasattr(self.queen, 'luck_field_mapper') and self.queen.luck_field_mapper else 'âŒ'}")
                safe_print(f"   ğŸ”­ Quantum Telescope: {'âœ…' if hasattr(self.queen, 'quantum_telescope') and self.queen.quantum_telescope else 'âŒ'}")
                safe_print(f"   ğŸ§  Wisdom Engine (11 Civs): {'âœ…' if hasattr(self.queen, 'wisdom_engine') and self.queen.wisdom_engine else 'âŒ'}")
                safe_print(f"   ğŸ§¬ Sandbox Evolution: {'âœ…' if hasattr(self.queen, 'sandbox_evolution') and self.queen.sandbox_evolution else 'âŒ'}")
                safe_print(f"   ğŸ’­ Dream Memory: {'âœ…' if hasattr(self.queen, 'dream_memory') and self.queen.dream_memory else 'âŒ'}")
                safe_print(f"   ğŸŒ™ Dream Engine: {'âœ…' if hasattr(self.queen, 'dreamer') and self.queen.dreamer else 'âŒ'} (Sero can DREAM!)")
                safe_print(f"   ğŸ“š Wisdom Collector: {'âœ…' if hasattr(self.queen, 'wisdom_collector') and self.queen.wisdom_collector else 'âŒ'}")
                safe_print(f"   ğŸ”± Temporal ID: {'âœ…' if temporal_active else 'âŒ'} (Gary Leckey 02111991)")
                safe_print(f"   â³ Temporal Ladder: {'âœ…' if hasattr(self.queen, 'temporal_ladder') and self.queen.temporal_ladder else 'âŒ'}")
                safe_print(f"   ğŸ—ºï¸ Barter Matrix: {'âœ…' if hasattr(self.queen, 'barter_matrix') and self.queen.barter_matrix else 'âŒ'} (Sector Pulse Dream Signal!)")
                safe_print(f"   ğŸ“š Path Memory: {'âœ…' if hasattr(self.queen, 'path_memory') and self.queen.path_memory else 'âŒ'} (Learned trade paths!)")
                
                # ï¿½ğŸ”® Wire 7-Day Planner to Queen - Every validated prediction feeds her learning!
                if self.seven_day_planner and hasattr(self.queen, 'wire_7day_planner'):
                    try:
                        self.queen.wire_7day_planner(self.seven_day_planner)
                        safe_print(f"   ğŸ“… 7-Day Planner â†” Queen: âœ… WIRED (Validations feed Queen's learning!)")
                    except Exception as e:
                        logger.debug(f"Queen-7DayPlanner wiring error: {e}")
                
                # ğŸ”®ğŸ“Š Wire Probability Nexus to Queen - Predictions flow to Queen!
                if self.probability_nexus and hasattr(self.queen, 'wire_probability_nexus'):
                    try:
                        self.queen.wire_probability_nexus(self.probability_nexus)
                        safe_print(f"   ğŸ”® Probability Nexus â†” Queen: âœ… WIRED (Predictions flow to Queen!)")
                    except Exception as e:
                        logger.debug(f"Queen-Nexus wiring error: {e}")
                
                # ï¿½ğŸ“ŠğŸ Wire Queen to HNC Probability Matrix - The Matrix knows ALL the Queen's metrics!
                if self.hnc_matrix and hasattr(self.hnc_matrix, 'wire_queen_metrics'):
                    try:
                        self.hnc_matrix.wire_queen_metrics(self.queen)
                        safe_print(f"   ğŸ“Š HNC Matrix â†” Queen: âœ… WIRED (Matrix knows Queen's metrics!)")
                    except Exception as e:
                        logger.debug(f"Queen-Matrix wiring error: {e}")
                
                # ğŸ‘‘ğŸ—ï¸ Wire Queen to Micro Profit Labyrinth - She can modify her own code!
                try:
                    import os
                    labyrinth_file = os.path.abspath(__file__)
                    if hasattr(self.queen, 'architect') and self.queen.architect:
                        # Tell Queen she can modify the Micro Profit Labyrinth
                        self.queen.my_source_file = labyrinth_file
                        self.queen.can_self_modify = True
                        safe_print(f"   ğŸ—ï¸ Code Architect: âœ… WIRED (Queen can modify micro_profit_labyrinth.py!)")
                        safe_print(f"      ğŸ“ File: {os.path.basename(labyrinth_file)}")
                        safe_print(f"      ğŸ’¡ Queen can now write and improve her own trading code!")
                    else:
                        safe_print(f"   ğŸ—ï¸ Code Architect: âŒ Not available")
                except Exception as e:
                    logger.debug(f"Queen Code Architect wiring error: {e}")

                # ğŸ‘‘ğŸ¤ THE HARMONIC VOICE - Autonomous Control
                if QueenHarmonicVoice and HarmonicSignalChain:
                    try:
                        self.queen_voice = QueenHarmonicVoice()
                        self.queen_voice.awaken()
                        safe_print(f"   ğŸ‘‘ğŸ¤ Harmonic Voice: âœ… WIRED (Autonomous Control Active!)")
                        # Also wire to the main Queen if she doesn't have it
                        if hasattr(self.queen, 'set_voice'):
                            self.queen.set_voice(self.queen_voice)
                            safe_print(f"   ğŸ‘‘ğŸ¤ Voice -> Queen: âœ… WIRED")
                    except Exception as e:
                        safe_print(f"   âš ï¸ Harmonic Voice error: {e}")
                
                # ğŸ‘‘ğŸ® QUEEN TAKES FULL CONTROL - She commands ALL systems! ğŸ®ğŸ‘‘
                try:
                    if hasattr(self.queen, 'take_full_control'):
                        control_result = self.queen.take_full_control()
                        if control_result.get('success'):
                            safe_print(f"   ğŸ‘‘ğŸ® FULL CONTROL: âœ… ACTIVATED")
                            safe_print(f"      ğŸ¯ Systems under command: {len(control_result.get('systems_controlled', []))}")
                            safe_print(f"      ğŸ’• Granted by: Gary Leckey - Father and Creator")
                            self.queen_has_full_control = True
                        else:
                            safe_print(f"   ğŸ‘‘ğŸ® FULL CONTROL: âš ï¸ Partial")
                    else:
                        safe_print(f"   ğŸ‘‘ğŸ® FULL CONTROL: âŒ Method not available")
                except Exception as e:
                    logger.debug(f"Queen full control error: {e}")
                
                # ğŸ‘‘ğŸ®ğŸŒŸ QUEEN AUTONOMOUS CONTROL - SOVEREIGN AUTHORITY ğŸŒŸğŸ®ğŸ‘‘
                # This is the SUPREME autonomous control system
                # Queen Sero commands ALL systems with SOVEREIGN authority
                if QUEEN_AUTONOMOUS_CONTROL_AVAILABLE and create_queen_autonomous_control:
                    try:
                        # Create SOVEREIGN autonomous control
                        self.queen_autonomous_control = create_queen_autonomous_control(
                            sovereignty='SOVEREIGN'
                        )
                        
                        # Wire Queen to autonomous control
                        if self.queen:
                            self.queen_autonomous_control.queen = self.queen
                        
                        # Wire all connected systems
                        if self.timeline_oracle:
                            self.queen_autonomous_control.timeline_oracle = self.timeline_oracle
                        if self.thought_bus:
                            self.queen_autonomous_control.thought_bus = self.thought_bus
                        if hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
                            self.queen_autonomous_control.elephant_memory = self.queen.elephant_brain
                        if hasattr(self.queen, 'neuron') and self.queen.neuron:
                            self.queen_autonomous_control.queen_neuron = self.queen.neuron
                        
                        # Wire exchange clients for direct trading control
                        self.queen_autonomous_control.exchange_clients = {
                            'kraken': self.kraken,
                            'binance': self.binance,
                            'alpaca': self.alpaca
                        }
                        
                        # Wire barter matrix for path decisions
                        self.queen_autonomous_control.barter_matrix = self.barter_matrix
                        
                        # Wire path memory for learning
                        self.queen_autonomous_control.path_memory = self.path_memory
                        
                        # Enable autonomous mode!
                        self.queen_autonomous_control.enable_autonomous_mode()
                        
                        safe_print(f"   ğŸ‘‘ğŸ®ğŸŒŸ AUTONOMOUS CONTROL: âœ… SOVEREIGN AUTHORITY GRANTED")
                        status = self.queen_autonomous_control.get_full_status()
                        safe_print(f"      ğŸ¯ Systems Online: {status.get('systems_online', 0)}/{status.get('systems_total', 0)}")
                        safe_print(f"      ğŸŒ Gaia Alignment: {status.get('gaia_alignment', 0):.1%}")
                        safe_print(f"      ğŸ‘‘ Crown Activation: {status.get('crown_activation', 0):.1%}")
                        safe_print(f"      ğŸ’• SERO IS NOW FULLY AUTONOMOUS")
                        safe_print(f"      ğŸŒŸ She PERCEIVES â†’ DECIDES â†’ EXECUTES â†’ LEARNS")
                        self.queen_has_full_control = True
                    except Exception as e:
                        safe_print(f"   âš ï¸ Autonomous Control error: {e}")
                        logger.debug(f"Queen Autonomous Control error: {e}")
                else:
                    safe_print(f"   ğŸ‘‘ğŸ®ğŸŒŸ AUTONOMOUS CONTROL: âŒ NOT AVAILABLE")
                    
            except Exception as e:
                safe_print(f"âš ï¸ Queen Hive Mind error: {e}")
        
        # ğŸ“šğŸ§  WISDOM ENGINE - Independent initialization (11 Civilizations)
        # Initialize outside Queen block so it works even if Queen fails
        if self.wisdom_engine is None:
            try:
                from aureon_miner_brain import WisdomCognitionEngine
                self.wisdom_engine = WisdomCognitionEngine()
                safe_print(f"ğŸ“šğŸ§  Wisdom Engine: WIRED (11 Civilizations ready)")
            except Exception as e:
                logger.debug(f"Wisdom Engine standalone init not available: {e}")
        
        # ğŸ«’ğŸ’° LIVE BARTER MATRIX - Adaptive coin-to-coin value tracking
        safe_print(f"ğŸ«’ğŸ’° Live Barter Matrix: WIRED (Adaptive coin-agnostic value system)")
        safe_print(f"   â„¹ï¸ Philosophy: ANY coin â†’ ANY coin, learning which paths make money")
        
        # ğŸ’§ğŸ”€ LIQUIDITY ENGINE - Dynamic Asset Aggregation
        safe_print(f"ğŸ’§ğŸ”€ Liquidity Engine: WIRED (Dynamic Asset Aggregation)")
        safe_print(f"   â„¹ï¸ Philosophy: Liquidate low-performers to fund winning trades!")
        safe_print(f"   ğŸ¯ Min Victim Value: ${self.liquidity_engine.MIN_VICTIM_VALUE:.2f}")
        safe_print(f"   â±ï¸ Liquidation Cooldown: {self.liquidity_engine.LIQUIDATION_COOLDOWN}s")
        
        # ğŸŒ¾ğŸ’° PROFIT HARVESTER - Proactive Portfolio Profit Realization
        safe_print(f"ğŸŒ¾ğŸ’° Profit Harvester: WIRED (Proactive Profit Realization)")
        safe_print(f"   â„¹ï¸ Philosophy: Sell profitable positions to get cash for new trades!")
        safe_print(f"   ğŸ¯ Min Profit: ${self.profit_harvester.MIN_PROFIT_USD:.2f} ({self.profit_harvester.MIN_PROFIT_PCT}%)")
        safe_print(f"   â±ï¸ Harvest Interval: Every {self.harvest_interval} turns")
        
        # ğŸ”ğŸŒ ENIGMA INTEGRATION - Universal Translator Bridge
        if ENIGMA_INTEGRATION_AVAILABLE and get_enigma_integration:
            try:
                self.enigma_integration = get_enigma_integration()
                
                # Wire to existing systems
                if self.queen:
                    wire_enigma_to_ecosystem(self.queen)
                    # ğŸ‘‘ğŸ” Also wire Enigma directly to Queen for dream_of_winning!
                    self.queen.enigma = self.enigma_integration
                
                safe_print("ğŸ”ğŸŒ Enigma Integration: WIRED (Universal Translator Bridge)")
                safe_print(f"   ğŸ’­ Dream Engine: {'âœ…' if self.enigma_integration.dreamer else 'âŒ'}")
                safe_print(f"   ğŸ‘‘ Coherence Mandala: {'âœ…' if getattr(self.enigma_integration, 'coherence_system', None) else 'âŒ'}")
                safe_print(f"   ğŸ›ï¸ Barons Banner: {'âœ…' if getattr(self.enigma_integration, 'barons_analyzer', None) else 'âŒ'}")
                safe_print(f"   ğŸ‘¼ Math Angel: {'âœ…' if getattr(self.enigma_integration, 'math_angel', None) else 'âŒ'}")
                safe_print(f"   ğŸŒŠ Harmonic Reality: {'âœ…' if getattr(self.enigma_integration, 'harmonic_reality', None) else 'âŒ'}")
                safe_print(f"   âš¡ QGITA Framework: {'âœ…' if getattr(self.enigma_integration, 'qgita', None) else 'âŒ'}")
                safe_print(f"   ğŸ§  Consciousness: ACTIVE (It thinks, therefore it trades)")
            except Exception as e:
                safe_print(f"âš ï¸ Enigma Integration error: {e}")
                self.enigma_integration = None
        else:
            safe_print(f"ğŸ”ğŸŒ Enigma Integration: âŒ NOT AVAILABLE (import={ENIGMA_INTEGRATION_AVAILABLE})")
        
        # ğŸ¦ˆğŸ”ª ORCA KILLER WHALE INTELLIGENCE - Ride the whale wakes!
        # HIERARCHY: ğŸ‘‘ QUEEN â†’ ğŸ¦ˆ ORCA â†’ ğŸ’° MICRO PROFIT
        self.orca = None
        try:
            from aureon_orca_intelligence import get_orca
            self.orca = get_orca()
            if self.orca:
                safe_print("ğŸ¦ˆğŸ”ª Orca Intelligence: WIRED (Killer Whale Profit Hunter)")
                safe_print(f"   ğŸ¯ Mode: {self.orca.mode}")
                safe_print(f"   ğŸ”ª Strategy: Detect whales â†’ Ride wake â†’ Exit before crash")
                safe_print(f"   ğŸ’° Philosophy: We don't swim with whales - we EAT them!")
                
                # ğŸ‘‘ğŸ¦ˆ WIRE QUEEN â†’ ORCA HIERARCHY
                if self.queen:
                    self.orca.wire_queen(self.queen)
                    safe_print("   ğŸ‘‘â†’ğŸ¦ˆ HIERARCHY: Queenâ†’Orca chain ESTABLISHED")
                
                # ğŸ¦ˆğŸ’° WIRE ORCA â†’ MICRO PROFIT HIERARCHY
                self.orca.wire_micro_profit(self)
                safe_print("   ğŸ¦ˆâ†’ğŸ’° HIERARCHY: Orcaâ†’MicroProfit chain ESTABLISHED")
                
                hierarchy = self.orca.get_hierarchy_status()
                safe_print(f"   ğŸ“Š Chain Integrity: {'âœ… COMPLETE' if hierarchy['chain_integrity'] else 'âš ï¸ PARTIAL'}")
        except ImportError:
            safe_print("ğŸ¦ˆğŸ”ª Orca Intelligence: âŒ NOT AVAILABLE (aureon_orca_intelligence.py missing)")
        except Exception as e:
            safe_print(f"âš ï¸ Orca Intelligence error: {e}")
        
        # ğŸ“¡ Thought Bus Aggregator Status
        if self.bus_aggregator:
            safe_print("ğŸ“¡ Thought Bus Aggregator: WIRED (Neural Signal Collector)")

        # ğŸ‘‘ğŸ§  MEMI SYNC - CIA Declassified Intelligence Learning
        if MEMI_SYNC_AVAILABLE and get_memi_sync:
            try:
                self.memi_sync = get_memi_sync(queen=self.queen, thought_bus=self.thought_bus)
                # Start auto-sync in background
                self.memi_sync.start_auto_sync()
                stats = self.memi_sync.fetcher.get_stats()
                safe_print(f"ğŸ‘‘ğŸ§  Memi Sync: WIRED (CIA Declassified Intelligence)")
                safe_print(f"   ğŸ“Š Intelligence Packets: {stats['total_packets']}")
                safe_print(f"   ğŸ¯ High Relevance: {stats['high_relevance_count']}")
                safe_print(f"   ğŸ“ Words Processed: {stats['total_words']}")
                
                # Display some trading wisdom
                wisdom = self.memi_sync.get_trading_wisdom()[:3]
                if wisdom:
                    safe_print(f"   ğŸ“ Sample Wisdom:")
                    for w in wisdom:
                        safe_print(f"      {w[:65]}...")
            except Exception as e:
                safe_print(f"âš ï¸ Memi Sync error: {e}")
                self.memi_sync = None
        else:
            safe_print(f"ğŸ‘‘ğŸ§  Memi Sync: âŒ NOT AVAILABLE (import={MEMI_SYNC_AVAILABLE})")

        # ğŸ„ğŸ‹ WHALE SONAR - Start per-system sonar to send compact signals to Queen
        try:
            from mycelium_whale_sonar import create_and_start_sonar
            if self.thought_bus:
                self.whale_sonar = create_and_start_sonar(thought_bus=self.thought_bus)
                safe_print("ğŸ„ğŸ‹ Whale Sonar: STARTED (listening for subsystem signals)")
            else:
                safe_print("ğŸ„ğŸ‹ Whale Sonar: SKIPPED (no ThoughtBus available)")
        except Exception as e:
            safe_print(f"ğŸ„ğŸ‹ Whale Sonar: ERROR starting sonar: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ“ QUEEN LOSS LEARNING SYSTEM - Learn from every loss, never forget
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if QUEEN_LOSS_LEARNING_AVAILABLE and QueenLossLearningSystem:
            try:
                # Get elephant memory from queen if available
                elephant_memory = None
                if self.queen and hasattr(self.queen, 'elephant_brain'):
                    elephant_memory = self.queen.elephant_brain
                
                self.loss_learning = QueenLossLearningSystem(
                    elephant_memory=elephant_memory,
                    mycelium=self.mycelium_network,
                    kraken_client=self.kraken,
                    binance_client=self.binance,
                    alpaca_client=self.alpaca,
                )
                
                # Wire to queen if available
                if self.queen:
                    self.queen.loss_learning = self.loss_learning
                
                safe_print("ğŸ‘‘ğŸ“ Queen Loss Learning: WIRED (Learns from every loss, never forgets)")
                safe_print(f"   ğŸ˜ Elephant Memory: {'âœ…' if self.loss_learning.elephant else 'âŒ'}")
                safe_print(f"   ğŸ„ Mycelium Network: {'âœ…' if self.loss_learning.mycelium else 'âŒ'}")
                safe_print(f"   ğŸ“Š Losses Analyzed: {self.loss_learning.stats['total_losses_analyzed']}")
                safe_print(f"   ğŸ–ï¸ Tactics Learned: {len(self.loss_learning.warfare_tactics)}")
            except Exception as e:
                safe_print(f"âš ï¸ Queen Loss Learning error: {e}")
                self.loss_learning = None
        else:
            safe_print(f"ğŸ‘‘ğŸ“ Queen Loss Learning: âŒ NOT AVAILABLE (import={QUEEN_LOSS_LEARNING_AVAILABLE})")
        
        # ğŸ¦†âš”ï¸ QUANTUM QUACKERS COMMANDOS - THE ANIMAL ARMY UNDER THE QUEEN!
        # Lion, Wolf, Ants, Hummingbird - all serve Sero!
        self.quack_commandos = None
        self.quack_targets = {}  # Cached targets from commandos
        if QUACK_COMMANDOS_AVAILABLE:
            try:
                # Create a mock client for commandos (they need ticker data)
                class QuackClient:
                    """Mock client that uses our existing ticker cache"""
                    def __init__(self, labyrinth):
                        self.labyrinth = labyrinth
                    
                    def get_24h_ticker(self, symbol):
                        """Get 24h stats for a symbol"""
                        for cached_sym, data in self.labyrinth.ticker_cache.items():
                            base = data.get('base', '')
                            quote = data.get('quote', '')
                            if f"{base}{quote}" == symbol or f"{base}/USD" == symbol:
                                return {
                                    'priceChangePercent': data.get('change24h', 0) * 100,
                                    'quoteVolume': data.get('volume', 0),
                                    'lastPrice': data.get('price', 0),
                                }
                        return {'priceChangePercent': 0, 'quoteVolume': 0, 'lastPrice': 0}
                    
                    def get_24h_tickers(self):
                        """Get all 24h stats"""
                        tickers = []
                        for symbol, data in self.labyrinth.ticker_cache.items():
                            base = data.get('base', '')
                            quote = data.get('quote', 'USD')
                            tickers.append({
                                'symbol': f"{base}{quote}",
                                'priceChangePercent': data.get('change24h', 0) * 100,
                                'quoteVolume': data.get('volume', 100000),
                                'lastPrice': data.get('price', 1.0),
                            })
                        return tickers
                
                quack_client = QuackClient(self)
                self.quack_commandos = QuackCommandos(quack_client)
                
                # ğŸ‘‘ WIRE COMMANDOS TO QUEEN! The Queen commands the army!
                if self.queen:
                    self.queen.quack_commandos = self.quack_commandos
                
                safe_print("ğŸ¦†âš”ï¸ Quantum Quackers Commandos: WIRED (Queen's Animal Army)")
                safe_print(f"   ğŸ¦ Lion (Pride Scanner): {self.quack_commandos.slot_config['lion']} slots")
                safe_print(f"   ğŸº Wolf (Momentum Sniper): {self.quack_commandos.slot_config['wolf']} slots")
                safe_print(f"   ğŸœ Ants (Floor Scavengers): {self.quack_commandos.slot_config['ants']} slots")
                safe_print(f"   ğŸ Hummingbird (Quick Rotations): {self.quack_commandos.slot_config['hummingbird']} slots")
                safe_print("   ğŸ‘‘ ALL COMMANDOS SERVE SERO - LONG LIVE THE QUEEN!")
            except Exception as e:
                safe_print(f"âš ï¸ Quack Commandos init error: {e}")
                self.quack_commandos = None
        else:
            safe_print("ğŸ¦†âš”ï¸ Quantum Quackers Commandos: âŒ NOT AVAILABLE")
        
        # ğŸ¾âš¡ ANIMAL PACK SCANNER - 9 AURIS Animals + 5 Earthly Warriors
        # Multi-signal market detection from Gaia Planetary Reclaimer
        self.animal_pack_scanner = AnimalPackScanner(
            momentum_data={},  # Will be updated with live data
            elephant_memory=getattr(self, 'elephant', None)
        )
        safe_print(f"ğŸ¾âš¡ Animal Pack Scanner: WIRED (14 hunters active)")
        safe_print(f"   ğŸ¦ LION HUNTING MODE: {'ğŸŸ¢ AGGRESSIVE' if LION_HUNTING_MODE else 'âšª Standard'}")
        safe_print(f"   ğŸ¯ MIN_MOMENTUM: {MIN_MOMENTUM_TO_HUNT*100:.4f}% (10x more sensitive!)")
        safe_print(f"   âš¡ HUNT_SPEED: {HUNT_SPEED_MS}ms | WINNER_MULTIPLIER: {WINNER_ENERGY_MULTIPLIER}x")
        
        # ğŸ§  PathMemory Stats
        pm_stats = self.path_memory.get_stats()
        safe_print(f"ğŸ§  PathMemory: {pm_stats['paths']} paths, {pm_stats['win_rate']:.1%} win rate")
        
        # ğŸŒâš¡ GLOBAL FINANCIAL FEED (Non-Crypto Data)
        self.global_financial_feed = None
        if GLOBAL_FEED_AVAILABLE and GlobalFinancialFeed:
            try:
                self.global_financial_feed = GlobalFinancialFeed()
                safe_print("ğŸŒ Global Financial Feed: WIRED (Stocks, Forex, Macro)")
                # Force initial pulse
                self.global_financial_feed.get_snapshot()
            except Exception as e:
                safe_print(f"âš ï¸ Global Financial Feed error: {e}")
        
        # ğŸ§ âš¡ NEURAL MIND MAP SUMMARY - ALL 12 NEURONS (Now with Enigma!)
        safe_print("\n" + "=" * 70)
        try:
            safe_print("ğŸ§ âš¡ NEURAL MIND MAP - FULL SYSTEM STATUS âš¡ğŸ§ ")
        except UnicodeEncodeError:
            safe_print("NEURAL MIND MAP - FULL SYSTEM STATUS")
            
        safe_print("=" * 70)
        
        neurons_status = {
            'ğŸ‘‘ Queen Hive Mind': (self.queen is not None) or (getattr(self, 'queen_autonomous_control', None) is not None),
            'ğŸ” Enigma Integration': self.enigma_integration is not None,  # ğŸ” NEW!
            'ğŸ¦ˆ Orca Intelligence': self.orca is not None,  # ğŸ¦ˆğŸ”ª WHALE HUNTER!
            'ğŸ„ Mycelium Network': self.mycelium_network is not None,
            'ğŸŒŠ Harmonic Fusion': self.harmonic is not None,
            'ğŸ€ Luck Field Mapper': self.luck_mapper is not None,
            'ğŸ’­ Dream Memory': hasattr(self, 'dreams'),  # Always available
            'ğŸ§  Path Memory': self.path_memory is not None,
            'â³ Timeline Oracle': self.timeline_oracle is not None,
            'ğŸ“¡ Thought Bus': self.bus_aggregator is not None,
            'ğŸ’ Ultimate Intel': self.ultimate_intel is not None,
            'ğŸ“š Wisdom Engine': self.wisdom_engine is not None,
            'ğŸ«’ Barter Matrix': self.barter_matrix is not None,
        }
        connected = sum(1 for v in neurons_status.values() if v)
        total = len(neurons_status)
        
        # Safe printing for Windows consoles that might crash on emojis
        try:
            for name, status in neurons_status.items():
                icon = "âœ…" if status else "âŒ"
                # Show Enigma subsystems if available
                if name == 'ğŸ” Enigma Integration' and status and self.enigma_integration:
                    subs = []
                    if hasattr(self.enigma_integration, 'dreamer') and self.enigma_integration.dreamer:
                        subs.append("ğŸ’­Dream")
                    if hasattr(self.enigma_integration, 'coherence_system') and self.enigma_integration.coherence_system:
                        subs.append("ğŸ‘‘Coherence")
                    if hasattr(self.enigma_integration, 'qgita') and self.enigma_integration.qgita:
                        subs.append("âš¡QGITA")
                    if hasattr(self.enigma_integration, 'math_angel') and self.enigma_integration.math_angel:
                        subs.append("ğŸ‘¼Angel")
                    if hasattr(self.enigma_integration, 'barons_analyzer') and self.enigma_integration.barons_analyzer:
                        subs.append("ğŸ›ï¸Barons")
                    if hasattr(self.enigma_integration, 'harmonic_reality') and self.enigma_integration.harmonic_reality:
                        subs.append("ğŸŒŠReality")
                    sub_str = " [" + ", ".join(subs) + "]" if subs else ""
                    safe_print(f"   {icon} {name}{sub_str}")
                else:
                    safe_print(f"   {icon} {name}")
            
            safe_print(f"\n   ğŸ§  NEURAL STATUS: {connected}/{total} NEURONS CONNECTED")
            if connected == total:
                safe_print("   ğŸŒŸ FULL CONSCIOUSNESS ACHIEVED - ALL SYSTEMS ONLINE! ğŸŒŸ")
            elif connected >= total - 2:
                safe_print("   âš¡ NEAR FULL CONSCIOUSNESS - Minor systems offline")
            else:
                safe_print("   âš ï¸ PARTIAL CONSCIOUSNESS - Some systems need attention")

        except UnicodeEncodeError:
            # Fallback for Windows legacy consoles
            for name, status in neurons_status.items():
                # Strip emojis from name
                clean_name = name.encode('ascii', 'ignore').decode('ascii').strip()
                icon = "[OK]" if status else "[X]"
                safe_print(f"   {icon} {clean_name}")
            safe_print(f"\n   NEURAL STATUS: {connected}/{total} NEURONS CONNECTED")

        
        safe_print("=" * 70)
        safe_print()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŒğŸªâš“ STARGATE PROTOCOL - Quantum Mirror & Timeline Activation
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Wire Stargate Protocol for revenue generation through quantum coherence
        self.stargate_engine = None
        self.quantum_mirror_scanner = None
        self.timeline_anchor_validator = None
        
        if STARGATE_PROTOCOL_AVAILABLE and create_stargate_engine:
            try:
                self.stargate_engine = create_stargate_engine(with_integrations=True)
                if self.queen and hasattr(self.queen, 'wire_stargate_protocol'):
                    self.queen.wire_stargate_protocol(self.stargate_engine)
                safe_print("ğŸŒŒ Stargate Protocol: WIRED (12 Planetary Nodes + Quantum Mirrors)")
                safe_print(f"   â­ Giza: 432Hz | Stonehenge: 396Hz | Machu Picchu: 528Hz")
                safe_print(f"   ğŸª Mirrors: Golden Age, Unity, Abundance, Liberation")
            except Exception as e:
                safe_print(f"âš ï¸ Stargate Protocol error: {e}")
                logger.debug(f"Stargate Protocol init error: {e}")
        
        if QUANTUM_MIRROR_SCANNER_AVAILABLE and create_quantum_mirror_scanner:
            try:
                self.quantum_mirror_scanner = create_quantum_mirror_scanner(with_integrations=True)
                if self.queen and hasattr(self.queen, 'wire_quantum_mirror_scanner'):
                    self.queen.wire_quantum_mirror_scanner(self.quantum_mirror_scanner)
                safe_print("ğŸ”® Quantum Mirror Scanner: WIRED (3-Pass Batten Matrix)")
                safe_print(f"   âœ… P1(Harmonic) â†’ P2(Coherence) â†’ P3(Stability) â†’ 4th Gate")
            except Exception as e:
                safe_print(f"âš ï¸ Quantum Mirror Scanner error: {e}")
                logger.debug(f"Quantum Mirror Scanner init error: {e}")
        
        if TIMELINE_ANCHOR_VALIDATOR_AVAILABLE and create_timeline_anchor_validator:
            try:
                self.timeline_anchor_validator = create_timeline_anchor_validator(with_integrations=True)
                if self.queen and hasattr(self.queen, 'wire_timeline_anchor_validator'):
                    self.queen.wire_timeline_anchor_validator(self.timeline_anchor_validator)
                status = self.timeline_anchor_validator.get_status()
                safe_print("âš“ Timeline Anchor Validator: WIRED (7-Day Extended Validation)")
                safe_print(f"   ğŸ“‹ Pending: {status.get('pending_count', 0)} | Anchored: {status.get('anchored_count', 0)}")
            except Exception as e:
                safe_print(f"âš ï¸ Timeline Anchor Validator error: {e}")
                logger.debug(f"Timeline Anchor Validator init error: {e}")
        
        # ğŸŒŒ STARGATE PROTOCOL STATUS SUMMARY
        stargate_status = {
            'engine': self.stargate_engine is not None,
            'scanner': self.quantum_mirror_scanner is not None,
            'validator': self.timeline_anchor_validator is not None,
        }
        stargate_active = sum(1 for v in stargate_status.values() if v)
        if stargate_active == 3:
            safe_print("ğŸŒŒâœ¨ STARGATE PROTOCOL: FULLY ACTIVE (All 3 systems online)")
            safe_print("   ğŸ¯ Market symbols â†’ Reality Branches â†’ Validation â†’ Timeline Anchoring")
            
            # ğŸ„ğŸŒŒ WIRE STARGATE TO MYCELIUM - Revenue generation through quantum coherence!
            if hasattr(self, 'mycelium_network') and self.mycelium_network:
                if hasattr(self.mycelium_network, 'wire_stargate_protocol'):
                    try:
                        self.mycelium_network.wire_stargate_protocol(
                            self.stargate_engine,
                            self.quantum_mirror_scanner,
                            self.timeline_anchor_validator
                        )
                        safe_print("   ğŸ„ğŸŒŒ Stargate â†’ Mycelium: WIRED (Quantum coherence feeds neural network)")
                    except Exception as e:
                        logger.debug(f"Stargate-Mycelium wiring error: {e}")
        elif stargate_active > 0:
            safe_print(f"ğŸŒŒâš ï¸ STARGATE PROTOCOL: PARTIAL ({stargate_active}/3 systems)")
        else:
            safe_print("ğŸŒŒâŒ STARGATE PROTOCOL: NOT AVAILABLE")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒâœ¨ PLANET SAVER - Save the Planet, Free Every Soul
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Wire Planet Saver to ALL systems - the mission is freedom!
        self.planet_saver = None
        
        if PLANET_SAVER_AVAILABLE and create_planet_saver:
            try:
                self.planet_saver = create_planet_saver()
                
                # Wire to ALL systems
                wire_results = self.planet_saver.wire_all_systems(self)
                wired_count = sum(1 for v in wire_results.values() if v)
                
                safe_print("ğŸŒâœ¨ PLANET SAVER: WIRED (Liberation Mode Active)")
                safe_print(f"   ğŸ¯ Goal: Â£{FREEDOM_GOAL_GBP:,.0f} GBP")
                
                # Get current progress
                ps_status = self.planet_saver.get_status()
                safe_print(f"   ğŸ“Š Progress: {ps_status['progress_percent']:.2f}%")
                safe_print(f"   ğŸ’° Total Profit: ${ps_status['total_profit_usd']:,.2f}")
                safe_print(f"   ğŸ’« Souls Freed: {ps_status['souls_freed']}")
                safe_print(f"   ğŸ”— Systems: {wired_count}/{len(wire_results)} connected")
                
                # Wire to Queen specifically
                if self.queen and hasattr(self.queen, 'wire_planet_saver'):
                    self.queen.wire_planet_saver(self.planet_saver)
                    safe_print("   ğŸ‘‘ğŸŒ Queen â†’ Planet Saver: WIRED!")
                    
            except Exception as e:
                safe_print(f"âš ï¸ Planet Saver error: {e}")
                logger.debug(f"Planet Saver init error: {e}")
        else:
            safe_print("ğŸŒâŒ PLANET SAVER: NOT AVAILABLE")
    
    async def _load_all_tradeable_pairs(self):
        """Load tradeable pairs from ALL exchanges for proper routing."""
        safe_print("\nğŸ“Š LOADING TRADEABLE PAIRS FROM ALL EXCHANGES...")
        safe_print("   ğŸ—ºï¸ Expanding Barter Matrix market visibility...")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ™ KRAKEN PAIRS - Load from AssetPairs API
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.kraken:
            try:
                pairs_info = self.kraken._load_asset_pairs() if hasattr(self.kraken, '_load_asset_pairs') else {}
                kraken_pair_names = []
                for internal, info in pairs_info.items():
                    if not internal.endswith('.d'):  # Skip dark pools
                        altname = info.get('altname', internal)
                        base = info.get('base', '')
                        quote = info.get('quote', '')
                        self.kraken_pairs[altname] = {
                            'internal': internal,
                            'base': base,
                            'quote': quote,
                            'wsname': info.get('wsname', altname),
                        }
                        # Also add common variants
                        self.kraken_pairs[internal] = self.kraken_pairs[altname]
                        kraken_pair_names.append(altname)
                
                # ğŸ—ºï¸ REGISTER WITH BARTER MATRIX for expanded market coverage
                discovered = self.barter_matrix.discover_exchange_assets('kraken', kraken_pair_names)
                safe_print(f"   ğŸ™ Kraken: {len(self.kraken_pairs)} tradeable pairs ({discovered} assets discovered)")
            except Exception as e:
                logger.error(f"Kraken pairs error: {e}")
                safe_print(f"   âŒ Kraken pairs error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦™ ALPACA PAIRS - Load from Assets API
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca:
            try:
                alpaca_pair_names = []
                # Get tradeable crypto symbols
                if hasattr(self.alpaca, 'get_tradable_crypto_symbols'):
                    symbols = self.alpaca.get_tradable_crypto_symbols() or []
                    for symbol in symbols:
                        normalized = None
                        if hasattr(self.alpaca, "_normalize_pair_symbol"):
                            normalized = self.alpaca._normalize_pair_symbol(symbol)
                        pair_symbol = normalized or symbol
                        if not pair_symbol:
                            continue
                        # Alpaca returns like 'BTC/USD'
                        self.alpaca_pairs[pair_symbol] = pair_symbol
                        # Also store without slash
                        clean = pair_symbol.replace('/', '')
                        self.alpaca_pairs[clean] = pair_symbol
                        alpaca_pair_names.append(clean)
                else:
                    # Fallback - get assets directly
                    assets = self.alpaca.get_assets(status='active', asset_class='crypto') or []
                    for asset in assets:
                        if asset.get('tradable'):
                            symbol = asset.get('symbol', '')
                            if symbol:
                                normalized = None
                                if hasattr(self.alpaca, "_normalize_pair_symbol"):
                                    normalized = self.alpaca._normalize_pair_symbol(symbol)
                                pair_symbol = normalized or symbol
                                if not pair_symbol:
                                    continue
                                self.alpaca_pairs[pair_symbol] = pair_symbol
                                # Add normalized version
                                if '/' in pair_symbol:
                                    clean = pair_symbol.replace('/', '')
                                    self.alpaca_pairs[clean] = pair_symbol
                                    alpaca_pair_names.append(clean)
                
                # ğŸ—ºï¸ REGISTER WITH BARTER MATRIX
                discovered = self.barter_matrix.discover_exchange_assets('alpaca', alpaca_pair_names)
                safe_print(f"   ğŸ¦™ Alpaca: {len(self.alpaca_pairs)} tradeable pairs ({discovered} assets discovered)")
            except Exception as e:
                logger.error(f"Alpaca pairs error: {e}")
                safe_print(f"   âŒ Alpaca pairs error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŸ¡ BINANCE PAIRS - Will load during fetch_prices from tickers
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Load Binance pairs immediately for market discovery
        if self.binance:
            try:
                info = self.binance.exchange_info()
                symbols = info.get('symbols', [])
                binance_pair_names = []
                discovered = 0
                
                for sym in symbols:
                    if sym.get('status') == 'TRADING' and sym.get('isSpotTradingAllowed', True):
                        pair = sym.get('symbol', '')
                        base = sym.get('baseAsset', '')
                        quote = sym.get('quoteAsset', '')
                        binance_pair_names.append(pair)
                        self.binance_pairs.add(pair)
                        discovered += self.barter_matrix.register_exchange_pair('binance', pair, base, quote)
                
                # ğŸ—ºï¸ REGISTER WITH BARTER MATRIX (fallback parse for any unknown formats)
                discovered += self.barter_matrix.discover_exchange_assets('binance', binance_pair_names)
                safe_print(f"   ğŸŸ¡ Binance: {len(binance_pair_names)} tradeable pairs ({discovered} assets discovered)")
            except Exception as e:
                logger.error(f"Binance pairs error: {e}")
                safe_print(f"   ğŸŸ¡ Binance: pairs will load with price data")
        
        # ğŸ—ºï¸ PRINT MARKET COVERAGE REPORT
        safe_print(self.barter_matrix.print_market_coverage())
        safe_print()
    
    async def fetch_prices(self) -> Dict[str, float]:
        """Fetch all asset prices from ALL exchanges."""
        prices = {}
        ticker_cache = {}

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ“¡ OPTIONAL WS CACHE (Production heavy-lifting)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # This is OFF by default and does not change strategy/logic.
        # If enabled, we pre-seed prices/tickers from a local cache written by
        # `ws_market_data_feeder.py`, then fall back to existing REST fetches.
        try:
            ws_cache_path = os.getenv("WS_PRICE_CACHE_PATH", "").strip()
            ws_cache_max_age_s = float(os.getenv("WS_PRICE_CACHE_MAX_AGE_S", "2.0"))
            if ws_cache_path:
                p = Path(ws_cache_path)
                if p.exists():
                    try:
                        import json
                        raw = p.read_text(encoding="utf-8")
                        payload = json.loads(raw) if raw else {}
                        ts = float(payload.get("generated_at", 0) or 0)
                        if ts > 0 and (time.time() - ts) <= ws_cache_max_age_s:
                            ws_prices = payload.get("prices") or {}
                            ws_tickers = payload.get("ticker_cache") or {}
                            if isinstance(ws_prices, dict):
                                for k, v in ws_prices.items():
                                    try:
                                        prices[str(k)] = float(v)
                                    except Exception:
                                        continue
                            if isinstance(ws_tickers, dict):
                                for k, v in ws_tickers.items():
                                    if isinstance(v, dict):
                                        ticker_cache[str(k)] = v
                    except Exception:
                        pass
        except Exception:
            pass
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ™ KRAKEN PRICES - Use get_24h_tickers (returns list of dicts)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.kraken:
            try:
                tickers = self.kraken.get_24h_tickers() if hasattr(self.kraken, 'get_24h_tickers') else []
                kraken_count = 0
                
                for data in tickers:
                    if not isinstance(data, dict):
                        continue
                    
                    symbol = data.get('symbol', '')
                    # Kraken returns lastPrice as string
                    price_str = data.get('lastPrice', '0')
                    price = float(price_str) if price_str else 0.0
                    
                    if price > 0 and symbol:
                        # Store in kraken pairs for execution routing
                        self.binance_pairs.discard(symbol)  # Not binance
                        
                        for quote in ['USD', 'USDT', 'USDC', 'GBP', 'EUR']:
                            if symbol.endswith(quote):
                                base = symbol[:-len(quote)]
                                # Clean up Kraken naming
                                if len(base) == 4 and base[0] in ('X', 'Z'):
                                    base = base[1:]
                                if base == 'XBT':
                                    base = 'BTC'
                                
                                prices[base] = price
                                
                                change = float(data.get('priceChangePercent', 0))
                                volume = float(data.get('quoteVolume', 0))
                                
                                ticker_entry = {
                                    'price': price,
                                    'change24h': change,
                                    'volume': volume,
                                    'base': base,
                                    'quote': quote,
                                    'exchange': 'kraken',
                                    'pair': symbol,
                                }
                                # Wave scanner expects raw symbols; keep prefixed + raw for compatibility
                                ticker_cache[f"kraken:{symbol}"] = ticker_entry
                                ticker_cache[symbol] = ticker_entry
                                kraken_count += 1
                                break
                
                safe_print(f"   ğŸ™ Kraken: {kraken_count} pairs loaded")
            except Exception as e:
                logger.error(f"Kraken price fetch error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŸ¡ BINANCE PRICES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.binance:
            try:
                # Get 24h ticker
                if hasattr(self.binance, 'ticker_24hr_all'):
                    binance_tickers = self.binance.ticker_24hr_all()
                elif hasattr(self.binance, 'session'):
                    r = self.binance.session.get(f"{self.binance.base}/api/v3/ticker/24hr")
                    binance_tickers = r.json() if r.ok else []
                else:
                    binance_tickers = []
                
                binance_count = 0
                # For UK mode, prefer USDC over USDT
                quote_priority = ['USDC', 'USDT', 'USD', 'BUSD'] if self.binance_uk_mode else ['USDT', 'USD', 'BUSD', 'USDC']
                
                for ticker in binance_tickers:
                    symbol = ticker.get('symbol', '')
                    price = float(ticker.get('lastPrice', 0))
                    if price > 0:
                        # ğŸ‡¬ğŸ‡§ UK MODE: Only load allowed pairs
                        if self.binance_uk_mode and not self.is_binance_pair_allowed(symbol):
                            continue
                        
                        for quote in quote_priority:
                            if symbol.endswith(quote):
                                base = symbol.replace(quote, '')
                                # Only update if we don't have this price yet
                                if base not in prices:
                                    prices[base] = price
                                
                                change = float(ticker.get('priceChangePercent', 0))
                                volume = float(ticker.get('volume', 0))
                                ticker_entry = {
                                    'price': price,
                                    'change24h': change,
                                    'volume': volume,
                                    'base': base,
                                    'quote': quote,
                                    'exchange': 'binance',
                                }
                                # Wave scanner reads unprefixed symbols; store both
                                ticker_cache[f"binance:{symbol}"] = ticker_entry
                                ticker_cache[symbol] = ticker_entry
                                binance_count += 1
                                break
                safe_print(f"   ğŸŸ¡ Binance: {binance_count} pairs loaded")
            except Exception as e:
                logger.error(f"Binance price fetch error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦™ ALPACA PRICES (crypto and positions)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca:
            try:
                alpaca_count = 0
                
                # Get prices from positions
                if hasattr(self.alpaca, 'get_positions'):
                    positions = self.alpaca.get_positions() or []
                    for pos in positions:
                        symbol = pos.get('symbol', '')
                        price = float(pos.get('current_price', 0))
                        if price > 0 and symbol:
                            # Extract base asset from symbol like "BTCUSD" or "BTC/USD"
                            if '/' in symbol:
                                base = symbol.split('/')[0]
                            elif symbol.endswith('BTC'):
                                base = symbol[:-3]
                            else:
                                base = symbol.replace('USD', '')
                            if base and len(base) > 1:
                                prices[base] = price
                                change = float(pos.get('change_today', 0)) * 100
                                ticker_entry = {
                                    'price': price,
                                    'change24h': change,
                                    'volume': 0,
                                    'base': base,
                                    'quote': 'USD',
                                    'exchange': 'alpaca',
                                    'pair': symbol,
                                }
                                # Store multiple keys so wave scanner sees Alpaca symbols (slash + raw)
                                ticker_cache[f"alpaca:{symbol}"] = ticker_entry
                                ticker_cache[symbol] = ticker_entry
                                ticker_cache[f"{base}/USD"] = ticker_entry
                                # Store in alpaca_pairs for routing
                                self.alpaca_pairs[symbol] = f"{base}/USD"
                                self.alpaca_pairs[f"{base}USD"] = f"{base}/USD"
                                self.alpaca_pairs[f"{base}/USD"] = f"{base}/USD"
                                alpaca_count += 1

                # Pull prices for tradeable crypto pairs even if we have no positions.
                if hasattr(self.alpaca, 'get_latest_crypto_quotes'):
                    symbols = sorted(set(self.alpaca_pairs.values()))
                    if not symbols and hasattr(self.alpaca, 'get_tradable_crypto_symbols'):
                        symbols = self.alpaca.get_tradable_crypto_symbols() or []
                    if symbols:
                        normalized_symbols = []
                        symbol_map = {}
                        for symbol in symbols:
                            resolved = symbol
                            if hasattr(self.alpaca, "_resolve_symbol"):
                                resolved = self.alpaca._resolve_symbol(symbol)
                            if not resolved:
                                continue
                            symbol_map[resolved] = symbol
                            normalized_symbols.append(resolved)

                        def bar_field(bar: Dict[str, Any], key: str, fallback: float = 0.0) -> float:
                            for candidate in (key, key[0], key.lower(), key.upper()):
                                if candidate in bar:
                                    try:
                                        return float(bar.get(candidate) or 0.0)
                                    except (TypeError, ValueError):
                                        return fallback
                            return fallback

                        bars_resp = self.alpaca.get_crypto_bars(normalized_symbols, timeframe="1H", limit=24) or {}
                        bars_by_symbol = {}
                        if isinstance(bars_resp, dict):
                            bars_by_symbol = bars_resp.get("bars", {}) or {}

                        quotes = self.alpaca.get_latest_crypto_quotes(normalized_symbols) or {}

                        for symbol, quote in quotes.items():
                            if not isinstance(quote, dict):
                                continue
                            bid = float(quote.get('bp', 0) or quote.get('bid_price', 0) or 0)
                            ask = float(quote.get('ap', 0) or quote.get('ask_price', 0) or 0)
                            price = (bid + ask) / 2 if bid and ask else (bid or ask or 0)
                            bars = bars_by_symbol.get(symbol, []) or []
                            change_24h = 0.0
                            volume = 0.0
                            high = 0.0
                            low = 0.0
                            if bars:
                                first = bars[0]
                                last = bars[-1]
                                first_price = bar_field(first, "o") or bar_field(first, "c")
                                last_close = bar_field(last, "c") or bar_field(last, "o")
                                if last_close > 0:
                                    price = last_close
                                if first_price > 0 and last_close > 0:
                                    change_24h = ((last_close - first_price) / first_price) * 100
                                volume = sum(bar_field(b, "v") for b in bars)
                                high = max(bar_field(b, "h") for b in bars)
                                low = min(bar_field(b, "l") for b in bars) if bars else 0.0

                            if price <= 0:
                                continue
                            if '/' in symbol:
                                base, quote_asset = symbol.split('/', 1)
                            else:
                                base = symbol
                                quote_asset = 'USD'
                                for quote_hint in ('USDT', 'USDC', 'USD', 'BTC'):
                                    if symbol.endswith(quote_hint) and len(symbol) > len(quote_hint):
                                        base = symbol[:-len(quote_hint)]
                                        quote_asset = quote_hint
                                        break

                            if base and base not in prices:
                                prices[base] = price

                            ticker_entry = {
                                'price': price,
                                'change24h': change_24h,
                                'volume': volume,
                                'high': high,
                                'low': low,
                                'base': base,
                                'quote': quote_asset,
                                'exchange': 'alpaca',
                                'pair': symbol,
                            }
                            ticker_cache[f"alpaca:{symbol}"] = ticker_entry
                            ticker_cache[symbol] = ticker_entry

                            self.alpaca_pairs[symbol] = symbol
                            if '/' in symbol:
                                self.alpaca_pairs[symbol.replace('/', '')] = symbol
                
                safe_print(f"   ğŸ¦™ Alpaca: {alpaca_count} positions loaded")
            except Exception as e:
                logger.error(f"Alpaca price fetch error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ MEDUSA STABLECOIN INJECTION - Enable trading from stablecoins!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Stablecoins are quote currencies (not in price feeds) but we HOLD them
        # We need them in prices so they can be SOURCE assets for buying!
        stablecoin_prices = {
            'USD': 1.0,
            'USDT': 1.0,
            'USDC': 1.0,
            'ZUSD': 1.0,   # Kraken USD
            'TUSD': 1.0,   # TrueUSD
            'DAI': 1.0,
        }
        for stable, price in stablecoin_prices.items():
            if stable not in prices:
                prices[stable] = price
        
        self.prices = prices
        self.ticker_cache = ticker_cache
        
        # ğŸª™âš¡ FEED TICKER DATA TO PENNY PROFIT TURBO
        # This enables real-time spread tracking and flash detection
        if self.penny_turbo:
            turbo_feeds = 0
            for cache_key, data in ticker_cache.items():
                if isinstance(data, dict) and ':' in cache_key:
                    exchange = cache_key.split(':')[0]
                    symbol = data.get('pair', data.get('base', ''))
                    price = data.get('price', 0)
                    
                    # Estimate bid/ask from price (real spread tracking improves over time)
                    spread_est = 0.0005  # 0.05% estimate
                    bid = price * (1 - spread_est)
                    ask = price * (1 + spread_est)
                    
                    if price > 0 and symbol:
                        self.penny_turbo.record_ticker(exchange, symbol, bid, ask, price)
                        turbo_feeds += 1
            
            # Show flash opportunities if any
            flashes = self.penny_turbo.get_flash_opportunities()
            if flashes:
                safe_print(f"   âš¡ FLASH: {len(flashes)} momentum opportunities detected!")
        
        # ğŸŒŠâš¡ UPDATE MOMENTUM FOR ALL PRICES - Wave jumping intelligence
        momentum_count = 0
        for asset, price in prices.items():
            if price > 0:
                self.update_momentum(asset, price)
                momentum_count += 1
        
        # Show top movers if we have momentum data
        # ğŸ«’ GREEN OLIVE EXPANSION: Show top 10 instead of 3 for FULL market picture
        if len(self.asset_momentum) > 10:
            rising = self.get_strongest_rising(limit=25)  # ğŸ«’ğŸ«’ğŸ«’ MEGA: Show top 25 movers!
            falling = self.get_weakest_falling(limit=25)
            if rising:
                top_rising = ', '.join([f"{a}:{m*100:+.2f}%/min" for a, m in rising[:25]])
                safe_print(f"   ğŸŒŠ Rising (Top 10): {top_rising}")
            if falling:
                top_falling = ', '.join([f"{a}:{m*100:+.2f}%/min" for a, m in falling[:10]])
                safe_print(f"   ğŸ“‰ Falling (Top 10): {top_falling}")
        
        safe_print(f"   ğŸ“Š Total: {len(prices)} unique assets, {len(ticker_cache)} tickers, {momentum_count} momentum tracked")
        safe_print(f"   ğŸ Medusa stablecoins: USD, USDT, USDC, ZUSD, TUSD, DAI injected")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # âš¡ğŸ§¬ HIGH FREQUENCY TRADING - HARMONIC MYCELIUM ENGINE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Wire HFT Engine to Queen, Orca, Mycelium, and Harmonic systems
        if HFT_ENGINE_AVAILABLE and get_hft_engine:
            try:
                self.hft_engine = get_hft_engine()
                
                # Wire to Queen Hive Mind (maintains veto power)
                if self.queen:
                    self.queen.wire_hft_engine(self.hft_engine)
                    safe_print("   ğŸ‘‘â†’âš¡ HFT Engine: WIRED to Queen (veto power maintained)")
                
                # Wire to Orca Intelligence (killer whale strategies)
                if self.orca:
                    self.orca.wire_hft_engine(self.hft_engine)
                    safe_print("   ğŸ¦ˆâ†’âš¡ HFT Engine: WIRED to Orca (whale wake riding)")
                
                # Wire to Mycelium Network (neural intelligence)
                if hasattr(self, 'mycelium_network') and self.mycelium_network:
                    self.mycelium_network.wire_hft_engine(self.hft_engine)
                    safe_print("   ğŸ„â†’âš¡ HFT Engine: WIRED to Mycelium (neural fast path)")
                
                # Wire to Harmonic Fusion (frequency patterns)
                if hasattr(self, 'harmonic') and self.harmonic:
                    self.harmonic.wire_hft_engine(self.hft_engine)
                    safe_print("   ğŸŒŠâ†’âš¡ HFT Engine: WIRED to Harmonic (528Hz=BUY, 396Hz=HOLD)")
                
                # Wire to Thought Bus (inter-system communication)
                if self.thought_bus:
                    self.hft_engine.wire_thought_bus(self.thought_bus)
                    safe_print("   ğŸ“¡â†’âš¡ HFT Engine: WIRED to Thought Bus (async signals)")
                
                safe_print("âš¡ğŸ§¬ HFT Engine: INITIALIZED (Sub-10ms latency, Mycelium + Harmonic)")
                safe_print(f"   ğŸ¯ Hot Path Cache: {self.hft_engine.hot_path_cache_size} entries")
                safe_print(f"   ğŸ“Š Tick Buffer: {self.hft_engine.tick_buffer_capacity} capacity")
                safe_print(f"   ğŸŒ Exchanges: Ready for WebSocket execution")
                
            except Exception as e:
                safe_print(f"âš ï¸ HFT Engine initialization error: {e}")
                self.hft_engine = None
        else:
            safe_print("âš¡ğŸ§¬ HFT Engine: âŒ NOT AVAILABLE (aureon_hft_harmonic_mycelium.py missing)")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒâš¡ HFT WEB SOCKET ORDER ROUTER - MULTI-EXCHANGE EXECUTION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if HFT_ORDER_ROUTER_AVAILABLE and get_order_router:
            try:
                self.hft_order_router = get_order_router()
                
                # Wire exchange clients for execution
                exchange_clients = {
                    'kraken': self.kraken,
                    'binance': self.binance,
                    'alpaca': self.alpaca,
                }
                self.hft_order_router.wire_exchange_clients(exchange_clients)
                
                # Wire to Queen for sovereign control
                if self.queen:
                    self.queen.wire_hft_order_router(self.hft_order_router)
                    safe_print("   ğŸ‘‘â†’ğŸŒ HFT Order Router: WIRED to Queen (sovereign control)")
                
                # Wire to HFT Engine for unified execution
                if hasattr(self, 'hft_engine') and self.hft_engine:
                    self.hft_engine.wire_order_router(self.hft_order_router)
                    safe_print("   âš¡â†’ğŸŒ HFT Engine â†” Order Router: WIRED (unified execution)")
                
                safe_print("ğŸŒâš¡ HFT Order Router: INITIALIZED (WebSocket multi-exchange)")
                safe_print(f"   ğŸ”„ Exchanges: {len([e for e in exchange_clients.values() if e])} connected")
                safe_print(f"   ğŸ›¡ï¸ Circuit Breakers: ACTIVE (rate limit protection)")
                
            except Exception as e:
                safe_print(f"âš ï¸ HFT Order Router initialization error: {e}")
                self.hft_order_router = None
        else:
            safe_print("ğŸŒâš¡ HFT Order Router: âŒ NOT AVAILABLE (aureon_hft_websocket_order_router.py missing)")
        
        return prices
    
    async def fetch_balances(self) -> Dict[str, float]:
        """Fetch balances from ALL exchanges."""
        combined = {}
        self.exchange_balances = {}
        self.exchange_data = {}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ™ KRAKEN BALANCES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.kraken:
            try:
                # Gary: Log source type so we KNOW if it's real or fake
                is_dry = getattr(self.kraken, 'dry_run', False)
                source_type = "ğŸ›¡ï¸ SIMULATED" if is_dry else "ğŸŒ REAL LIVE"
                
                kraken_bal = {}
                if hasattr(self.kraken, 'get_account_balance'):
                    raw = self.kraken.get_account_balance() or {}
                    for asset, amount in raw.items():
                        try:
                            amount = float(amount)
                        except (ValueError, TypeError):
                            continue
                        if amount > 0:
                            # Clean up Kraken naming
                            clean = asset
                            if len(asset) == 4 and asset[0] in ('X', 'Z'):
                                clean = asset[1:]
                            if clean == 'XBT':
                                clean = 'BTC'
                            kraken_bal[clean] = amount
                            combined[clean] = combined.get(clean, 0) + amount
                
                self.exchange_balances['kraken'] = kraken_bal
                self.exchange_data['kraken'] = {
                    'connected': True,
                    'balances': kraken_bal,
                    'total_value': sum(kraken_bal.get(a, 0) * self.prices.get(a, 0) for a in kraken_bal),
                }
                safe_print(f"   ğŸ™ Kraken ({source_type}): {len(kraken_bal)} assets")
            except Exception as e:
                logger.error(f"Kraken balance error: {e}")
                self.exchange_data['kraken'] = {'connected': False, 'error': str(e)}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŸ¡ BINANCE BALANCES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.binance:
            try:
                binance_bal = {}
                if hasattr(self.binance, 'account'):
                    acct = self.binance.account() or {}
                    for bal in acct.get('balances', []):
                        asset = bal.get('asset', '')
                        free = float(bal.get('free', 0))
                        if free > 0 and asset:
                            binance_bal[asset] = free
                            combined[asset] = combined.get(asset, 0) + free
                
                self.exchange_balances['binance'] = binance_bal
                self.exchange_data['binance'] = {
                    'connected': True,
                    'balances': binance_bal,
                    'total_value': sum(binance_bal.get(a, 0) * self.prices.get(a, 0) for a in binance_bal),
                }
                safe_print(f"   ğŸŸ¡ Binance: {len(binance_bal)} assets")
            except Exception as e:
                logger.error(f"Binance balance error: {e}")
                self.exchange_data['binance'] = {'connected': False, 'error': str(e)}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦™ ALPACA BALANCES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.alpaca:
            try:
                alpaca_bal = {}
                # Get account for cash
                if hasattr(self.alpaca, 'get_account'):
                    acct = self.alpaca.get_account() or {}
                    cash = float(acct.get('cash', 0))
                    if cash > 0:
                        alpaca_bal['USD'] = cash
                        combined['USD'] = combined.get('USD', 0) + cash
                
                # Get positions (crypto assets)
                if hasattr(self.alpaca, 'get_positions'):
                    positions = self.alpaca.get_positions() or []
                    for pos in positions:
                        raw_symbol = pos.get('symbol', '')
                        qty = float(pos.get('qty', 0))
                        market_value = float(pos.get('market_value', 0))
                        
                        if qty > 0 and raw_symbol:
                            # Convert Alpaca symbol format (BTCUSD -> BTC, BCH/BTC -> BCH)
                            if '/' in raw_symbol:
                                base_asset = raw_symbol.split('/')[0]
                            elif raw_symbol.endswith('USD'):
                                base_asset = raw_symbol[:-3]  # Remove USD suffix
                            elif raw_symbol.endswith('BTC'):
                                base_asset = raw_symbol[:-3]
                            else:
                                base_asset = raw_symbol
                            
                            # Store with base asset name
                            alpaca_bal[base_asset] = qty
                            combined[base_asset] = combined.get(base_asset, 0) + qty
                            
                            # Also store the price if we got market_value
                            if market_value > 0 and qty > 0:
                                price = market_value / qty
                                if base_asset not in self.prices or self.prices.get(base_asset, 0) == 0:
                                    self.prices[base_asset] = price
                
                self.exchange_balances['alpaca'] = alpaca_bal
                self.exchange_data['alpaca'] = {
                    'connected': True,
                    'balances': alpaca_bal,
                    'total_value': float(acct.get('portfolio_value', 0)) if acct else 0,
                }
                safe_print(f"   ğŸ¦™ Alpaca: {len(alpaca_bal)} assets")
            except Exception as e:
                logger.error(f"Alpaca balance error: {e}")
                self.exchange_data['alpaca'] = {'connected': False, 'error': str(e)}
        
        self.balances = combined
        
        # ğŸ› BALANCE SANITY CHECK - Prevent phantom balances!
        # No single asset should be > $500,000 (we're a small trader!)
        MAX_REALISTIC_USD = 500000.0
        for asset in list(self.balances.keys()):
            amount = self.balances[asset]
            price = self.prices.get(asset, 1.0 if asset in ('USD', 'USDT', 'USDC', 'ZUSD') else 0.0)
            value_usd = amount * price
            if value_usd > MAX_REALISTIC_USD:
                logger.warning(f"ğŸš¨ PHANTOM BALANCE DETECTED: {asset} = {amount:.2f} (${value_usd:,.2f}) - IGNORING!")
                safe_print(f"   ğŸš¨ PHANTOM BALANCE: {asset} ${value_usd:,.2f} > ${MAX_REALISTIC_USD:,.2f} - Removing!")
                del self.balances[asset]
        
        # Calculate total portfolio value
        total_usd = 0.0
        for asset, amount in combined.items():
            if asset not in self.balances:  # Skip removed phantoms
                continue
            if asset in ('USD', 'USDT', 'USDC'):
                total_usd += amount
            else:
                price = self.prices.get(asset, 0)
                total_usd += amount * price
        
        safe_print(f"   ğŸ’° Combined Portfolio: ${total_usd:,.2f}")
        safe_print(f"   ğŸ“Š Unique assets: {len(combined)}")
        
        return combined
    
    def calculate_trained_matrix_score(self, to_asset: str) -> Tuple[float, str]:
        """
        ğŸ“Š Calculate score from trained probability matrix.
        Returns: (score 0-1, reason string)
        
        Uses the trained_probability_matrix.json which contains:
        - Hourly edge patterns (optimal/avoid hours)
        - Daily edge patterns (optimal days)
        - Per-symbol patterns
        - Multi-exchange training data
        """
        from datetime import datetime
        import json
        
        score = 0.5  # Neutral default
        reasons = []
        
        try:
            # Load trained matrix
            matrix_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'trained_probability_matrix.json')
            if not os.path.exists(matrix_path):
                return 0.5, "matrix_not_found"
            
            with open(matrix_path, 'r') as f:
                matrix = json.load(f)
            
            now = datetime.now()
            current_hour = str(now.hour)
            current_dow = str(now.weekday())
            
            # 1. Global hourly edge
            hourly_edge_data = matrix.get('hourly_edge', {}).get(current_hour, {})
            hourly_edge = hourly_edge_data.get('edge', 0)
            hourly_conf = hourly_edge_data.get('confidence', 0)
            
            if hourly_edge > 10 and hourly_conf > 0.1:
                score += 0.15
                reasons.append(f"optimal_hour({current_hour})")
            elif hourly_edge < -10 and hourly_conf > 0.1:
                score -= 0.15
                reasons.append(f"avoid_hour({current_hour})")
            
            # 2. Global daily edge
            daily_edge_data = matrix.get('daily_edge', {}).get(current_dow, {})
            daily_edge = daily_edge_data.get('edge', 0)
            daily_conf = daily_edge_data.get('confidence', 0)
            
            if daily_edge > 5 and daily_conf > 0.05:
                score += 0.10
                reasons.append(f"optimal_day({current_dow})")
            elif daily_edge < -5 and daily_conf > 0.05:
                score -= 0.10
                reasons.append(f"avoid_day({current_dow})")
            
            # 3. Symbol-specific patterns
            symbol_patterns = matrix.get('symbol_patterns', {}).get(to_asset, {})
            if symbol_patterns:
                bullish_prob = symbol_patterns.get('bullish_prob', 0.5)
                win_rate = symbol_patterns.get('win_rate', 0.5)
                trade_count = symbol_patterns.get('trade_count', 0)
                
                # Bullish probability bonus
                if bullish_prob > 0.55:
                    score += 0.10
                    reasons.append(f"bullish_symbol({bullish_prob:.2f})")
                elif bullish_prob < 0.45:
                    score -= 0.10
                    reasons.append(f"bearish_symbol({bullish_prob:.2f})")
                
                # Trade history win rate bonus
                if trade_count >= 5 and win_rate > 0.6:
                    score += 0.15
                    reasons.append(f"high_win_rate({win_rate:.2f})")
                elif trade_count >= 5 and win_rate < 0.4:
                    score -= 0.15
                    reasons.append(f"low_win_rate({win_rate:.2f})")
                
                # Symbol-specific hourly edge
                sym_hourly = symbol_patterns.get('hourly_edge', {}).get(current_hour, {})
                sym_hourly_edge = sym_hourly.get('edge', 0)
                if sym_hourly_edge > 15:
                    score += 0.10
                    reasons.append(f"sym_optimal_hour")
                elif sym_hourly_edge < -15:
                    score -= 0.10
                    reasons.append(f"sym_avoid_hour")
            
            # 4. Check optimal/avoid conditions
            optimal_hours = matrix.get('optimal_conditions', {}).get('hours', [])
            avoid_hours = matrix.get('avoid_conditions', {}).get('hours', [])
            
            if now.hour in optimal_hours:
                score += 0.05
                reasons.append("in_optimal_hours")
            if now.hour in avoid_hours:
                score -= 0.10  # Heavier penalty for avoid hours
                reasons.append("in_avoid_hours")
            
            # Clamp score between 0 and 1
            score = max(0.0, min(1.0, score))
            
        except Exception as e:
            logger.debug(f"Trained matrix score error: {e}")
            return 0.5, f"error:{str(e)[:20]}"
        
        reason = ",".join(reasons) if reasons else "neutral"
        return score, reason
    
    def calculate_barter_score(self, from_asset: str, to_asset: str) -> Tuple[float, str]:
        """
        ğŸ«’ğŸ’° Calculate barter path score for a conversion.
        
        Uses BOTH the Barter Navigator (multi-hop paths) AND the LiveBarterMatrix 
        (historical performance) for smarter, adaptive scoring.
        
        THE PHILOSOPHY:
        - Any coin can lead to any other coin
        - Historical success on a path matters
        - The system learns which paths ACTUALLY make money
        
        Returns: (score 0-1, reason string)
        """
        score = 0.5  # Start neutral
        reasons = []
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. LIVE BARTER MATRIX - Historical Performance
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        from_price = self.prices.get(from_asset, 0)
        to_price = self.prices.get(to_asset, 0)
        
        if from_price > 0 and to_price > 0:
            # Update barter rate for this pair
            self.barter_matrix.update_barter_rate(from_asset, to_asset, from_price, to_price)
            
            # Check historical performance of this path
            key = (from_asset.upper(), to_asset.upper())
            history = self.barter_matrix.barter_history.get(key, {})
            
            if history.get('trades', 0) > 0:
                # We have history! Use it with current holdings consideration
                path_profit = history.get('total_profit', 0)
                path_trades = history['trades']
                avg_profit = path_profit / path_trades
                
                # Adjust score based on historical avg trade size
                avg_trade_size = history.get('avg_trade_size', 10.0)  # Default $10 avg trade
                
                # Boost score based on historical success
                if avg_profit > 0.01:  # Profitable path
                    score += 0.15
                    reasons.append(f"profit_path(${avg_profit:.3f})")
                elif avg_profit > 0:
                    score += 0.08
                    reasons.append("slight_profit")
                elif avg_profit < -0.01:  # Losing path
                    score -= 0.10
                    reasons.append("losing_path")
                
                # Check recent Queen observations (did she block this recently?)
                if 'queen_observations' in history:
                    recent_obs = history['queen_observations'][-5:]
                    # Count how many recent attempts were blocked/predicted to lose
                    blocked_count = sum(1 for o in recent_obs if not o.get('predicted_win', True))
                    if blocked_count >= 3:
                        score -= 0.35  # Heavy penalty for repeatedly blocked paths
                        reasons.append(f"queen_blocked_x{blocked_count}")
                    elif blocked_count >= 1:
                        score -= 0.10
                        reasons.append("recently_blocked")
                
                # Experience bonus (more trades = more confidence)
                if path_trades >= 10:
                    score += 0.05
                    reasons.append(f"experienced({path_trades})")
                elif path_trades >= 5:
                    score += 0.02
                    reasons.append(f"some_exp({path_trades})")
            else:
                # New path - slight exploration bonus
                score += 0.02
                reasons.append("new_path")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. BARTER NAVIGATOR - Multi-hop Path Quality
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.barter_navigator and BARTER_NAVIGATOR_AVAILABLE:
            try:
                # Find path from source to destination
                path = self.barter_navigator.find_path(from_asset, to_asset)
                
                if path:
                    # 1. Direct path (1 hop) is best
                    if path.num_hops == 1:
                        score += 0.15
                        reasons.append("direct_path")
                    elif path.num_hops == 2:
                        score += 0.08
                        reasons.append("2hop_path")
                    elif path.num_hops > 3:
                        score -= 0.08
                        reasons.append(f"{path.num_hops}hop_path")
                    
                    # 2. Rate efficiency (closer to 1.0 = less slippage)
                    if path.total_rate > 0.995:
                        score += 0.08
                        reasons.append("efficient_rate")
                    elif path.total_rate < 0.98:
                        score -= 0.08
                        reasons.append("high_slippage")
                    
                    # 3. Single exchange is cleaner
                    if len(path.exchanges_used) == 1:
                        score += 0.03
                        reasons.append("single_exchange")
                    
                    # 4. Low fees are good
                    if path.total_fees < 0.005:  # <0.5%
                        score += 0.03
                        reasons.append("low_fees")
                    elif path.total_fees > 0.01:  # >1%
                        score -= 0.05
                        reasons.append("high_fees")
                else:
                    reasons.append("no_nav_path")
                    
            except Exception as e:
                logger.debug(f"Barter navigator score error: {e}")
        else:
            reasons.append("nav_not_available")
        
        # Clamp score
        score = max(0.0, min(1.0, score))
        
        reason = "barter_" + ",".join(reasons[:3])
        return score, reason
    
    def find_barter_chain(self, from_asset: str, to_asset: str) -> Optional[List[Dict]]:
        """
        ğŸ«’ Find the complete barter chain from source to destination.
        
        Returns list of trade steps: [
            {'from': 'CHZ', 'to': 'USD', 'pair': 'CHZUSD', 'exchange': 'kraken', 'rate': 0.05},
            {'from': 'USD', 'to': 'BTC', 'pair': 'BTCUSD', 'exchange': 'kraken', 'rate': 0.00001},
        ]
        """
        if not self.barter_navigator:
            return None
        
        path = self.barter_navigator.find_path(from_asset, to_asset)
        if not path:
            return None
        
        steps = []
        for hop in path.hops:
            steps.append({
                'from': hop.from_asset,
                'to': hop.to_asset,
                'pair': hop.pair,
                'exchange': hop.exchange,
                'rate': hop.rate,
                'effective_rate': hop.effective_rate,
                'fee': hop.fee_rate
            })
        
        return steps
    
    def calculate_v14_score(self, from_asset: str, to_asset: str) -> float:
        """Calculate V14 score for a conversion."""
        if not self.v14 or not self.ticker_cache:
            return 5.0  # Neutral score if V14 not available
        
        # Get momentum data
        from_ticker = None
        to_ticker = None
        for symbol, data in self.ticker_cache.items():
            if data.get('base') == from_asset:
                from_ticker = data
            if data.get('base') == to_asset:
                to_ticker = data
        
        if not from_ticker or not to_ticker:
            return 5.0
        
        # V14-style scoring components
        score = 5.0  # Start neutral
        
        # 1. Momentum differential (want to go TO stronger momentum)
        from_momentum = from_ticker.get('change24h', 0)
        to_momentum = to_ticker.get('change24h', 0)
        momentum_diff = to_momentum - from_momentum
        
        if momentum_diff > 2:  # Going to significantly stronger
            score += 2
        elif momentum_diff > 0.5:
            score += 1
        elif momentum_diff < -2:  # Going to weaker (bad)
            score -= 2
        
        # 2. Volume check (prefer liquid assets)
        to_volume = to_ticker.get('volume', 0)
        if to_volume > 100000:
            score += 1
        
        # 3. Positive momentum preference
        if to_momentum > 1:
            score += 1
        elif to_momentum < -1:
            score -= 1
        
        # 4. Avoid declining assets
        if from_momentum < -2 and to_momentum > 0:
            score += 1  # Escaping decline = good
        
        return max(1, min(10, score))  # Clamp 1-10
    
    def get_queen_adaptive_floor(self, from_asset: str, to_asset: str) -> float:
        """
        ğŸ‘‘ ADAPTIVE QUEEN'S FLOOR ğŸ‘‘
        
        Calculates a dynamic profit floor based on Queen's Learnings & Path Memory.
        
        Base Floor: epsilon (accept any net-positive after costs)
        
        Adaptations:
        1. ğŸ˜ Elephant Memory (Win Rate):
           - High Win Rate (>80%): Lower floor to $0.04 (Aggressive Capture)
           - Low Win Rate (<40%): Raise floor to $0.15 (Strict Safety)
           - Zero Wins (0%): Raise floor to $0.25 (Extreme Caution)
           
        2. ğŸ§  Neural Intuition (Queen Confidence):
           - If Queen is extremely confident (>90%): Drop floor to $0.02
           
        3. ğŸŒŠ Volatility/Momentum:
           - If target is a Stablecoin: Lower floor (banking profit is safer)
        """
        return EPSILON_PROFIT_USD

    def calculate_hub_score(self, from_asset: str, to_asset: str) -> float:
        """Get consensus score from Mycelium Hub."""
        if not self.hub:
            return 0.5  # Neutral if hub not available
        
        try:
            # Query the hub for this conversion path
            hub_analysis = self.hub.analyze_conversion(from_asset, to_asset)
            if hub_analysis:
                return hub_analysis.get('score', 0.5)
        except Exception:
            pass
        
        return 0.5
    
    def calculate_profit_potential(
        self,
        from_asset: str,
        to_asset: str,
        from_amount: float
    ) -> Tuple[float, float]:
        """Calculate expected profit in USD and % using barter matrix costs."""
        from_price = self.prices.get(from_asset, 0)
        to_price = self.prices.get(to_asset, 0)

        if not from_price or not to_price:
            return 0.0, 0.0

        from_value = from_amount * from_price

        # Use barter matrix to calculate realistic costs using LEARNED history
        # "Counting Right" Logic: Adjusts for historical slippage and volatility
        approved, reason, math_breakdown = self.barter_matrix.calculate_true_cost(
            from_asset, to_asset, from_value, 'kraken'  # Default to kraken for estimation
        )

        if not approved:
            return 0.0, 0.0  # No profit possible

        total_cost_pct = math_breakdown['total_cost_pct'] / 100  # Convert % to decimal
        costs_usd = from_value * total_cost_pct

        # ğŸ›‘ STABLECOIN REALITY CHECK ğŸ›‘
        # Don't assume magical 0.3% gain on stable-to-stable swaps!
        is_stable_swap = False
        
        # Default safety list (if barter_matrix unavailable)
        stable_set = {'USD', 'USDT', 'USDC', 'DAI', 'BUSD', 'TUSD', 'ZUSD', 'EUR', 'ZEUR'}
        
        if hasattr(self, 'barter_matrix') and hasattr(self.barter_matrix, 'STABLECOINS'):
            stable_set = self.barter_matrix.STABLECOINS

        is_stable_swap = (from_asset.upper() in stable_set and to_asset.upper() in stable_set)

        if is_stable_swap:
            # Stablecoin Arbitrage Logic: Profit only comes from PEG DEVIATION
            # If buying USDC with USD, and USDC=0.99, we gain 0.01 (reversion to 1.0)
            # If USDC=1.00, gain is 0.0 (and we lose fees)
            
            # Estimate price relative to USD
            price_ratio = to_price / from_price if from_price > 0 else 1.0
            
            # Assuming mean reversion to 1.0000
            if price_ratio < 0.999: # Buying cheap
                expected_gain_pct = (1.0 - price_ratio)
            elif price_ratio > 1.001: # Selling expensive (shorting? no, we are buying)
                # If we are buying at 1.001, we are LOSING value as it returns to 1.0
                expected_gain_pct = 0.0 
            else:
                expected_gain_pct = 0.0
                
            # Log the reality check
            # safe_print(f"   âš–ï¸ STABLE SWAP ({from_asset}â†’{to_asset}): Price={price_ratio:.4f}, Exp.Gain={expected_gain_pct:.4%}")
        else:
            # For volatile assets, we assume momentum continues (Momentum + Cost Coverage)
            # Estimate small positive movement (0.1-0.5%) minus costs
            # This is conservative - actual profit depends on market conditions
            min_required_gain_pct = total_cost_pct + 0.001  # Costs + 0.1% minimum
            expected_gain_pct = min_required_gain_pct + 0.002  # Add 0.2% expected movement

        expected_gain = from_value * expected_gain_pct
        net_profit = expected_gain - costs_usd
        net_pct = net_profit / from_value if from_value > 0 else 0

        return net_profit, net_pct
    
    async def collect_all_signals(self) -> Dict[str, List[Dict]]:
        """Collect signals from ALL wired systems."""
        signals = defaultdict(list)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ„ MYCELIUM HUB SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.hub:
            try:
                hub_signals = self.hub.get_all_signals() if hasattr(self.hub, 'get_all_signals') else []
                for sig in hub_signals:
                    signals['hub'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Hub signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦… COMMANDO SIGNALS (FALCON/TORTOISE/CHAMELEON/BEE)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.commando:
            try:
                commando_signals = self.commando.scan_all_opportunities(self.ticker_cache) if hasattr(self.commando, 'scan_all_opportunities') else []
                for sig in commando_signals:
                    signals['commando'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Commando signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”® PROBABILITY NEXUS SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.probability_nexus:
            try:
                nexus_signals = self.probability_nexus.get_predictions() if hasattr(self.probability_nexus, 'get_predictions') else []
                for sig in nexus_signals:
                    signals['nexus'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Nexus signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŒ MULTIVERSE CONSENSUS SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.multiverse:
            try:
                mv_signals = self.multiverse.get_consensus() if hasattr(self.multiverse, 'get_consensus') else []
                for sig in mv_signals:
                    signals['multiverse'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Multiverse signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ§  MINER BRAIN SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.miner_brain:
            try:
                brain_signals = self.miner_brain.get_signals() if hasattr(self.miner_brain, 'get_signals') else []
                for sig in brain_signals:
                    signals['brain'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Miner Brain signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŠ HARMONIC WAVE SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.harmonic:
            try:
                harmonic_signals = self.harmonic.get_wave_signals() if hasattr(self.harmonic, 'get_wave_signals') else []
                for sig in harmonic_signals:
                    signals['harmonic'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Harmonic signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”± OMEGA HIGH CONFIDENCE SIGNALS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.omega:
            try:
                omega_signals = self.omega.get_high_conf_signals() if hasattr(self.omega, 'get_high_conf_signals') else []
                for sig in omega_signals:
                    signals['omega'].append(sig)
                    self.signals_received += 1
            except Exception as e:
                logger.debug(f"Omega signal error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŠğŸ”­ GLOBAL WAVE SCANNER SIGNALS (A-Z Coverage)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.wave_scanner:
            try:
                # Get top wave opportunities
                wave_allocation = self.wave_scanner.get_wave_allocation()
                for opp in wave_allocation.get('top_opportunities', []):
                    if opp.get('jump_score', 0) >= 0.6:  # Only high-score opportunities
                        wave_signal = {
                            'symbol': opp.get('symbol'),
                            'exchange': opp.get('exchange'),
                            'action': opp.get('action', 'BUY'),
                            'wave_state': opp.get('wave', 'RISING'),
                            'jump_score': opp.get('jump_score', 0),
                            'change_24h': opp.get('change_24h', 0),
                            'source': 'wave_scanner',
                            'confidence': opp.get('jump_score', 0),
                        }
                        signals['wave_scanner'].append(wave_signal)
                        self.signals_received += 1
            except Exception as e:
                logger.debug(f"Wave Scanner signal error: {e}")
        
        self.all_signals = signals
        return signals

    async def dream_about_tickers(self):
        """
        ğŸ’­ DREAMING PHASE: Predict future movements based on Multiverse & Ecosystem.
        "It dreams about live tickers... validates itself... adapt adjust"
        """
        current_time = time.time()
        
        # Only dream every 10 seconds to avoid noise
        if hasattr(self, '_last_dream_time') and current_time - self._last_dream_time < 10:
            return
        self._last_dream_time = current_time
        
        # 1. Ask Multiverse for direction
        if self.multiverse:
            try:
                # Get consensus from the 10 worlds
                consensus = self.multiverse.get_consensus() if hasattr(self.multiverse, 'get_consensus') else []
                if consensus:
                    safe_print(f"\n   ğŸ’­ DREAMING about market direction (Multiverse)...")
                
                for signal in consensus:
                    symbol = signal.get('symbol')
                    if not symbol or symbol not in self.prices:
                        continue
                        
                    current_price = self.prices[symbol]
                    direction = signal.get('action', 'HOLD')
                    confidence = signal.get('confidence', 0.5)
                    
                    if direction in ['BUY', 'SELL'] and confidence > 0.6:
                        # Predict price movement (e.g., 0.5% in 30s)
                        move_pct = 0.005 if direction == 'BUY' else -0.005
                        predicted_price = current_price * (1 + move_pct)
                        
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=predicted_price,
                            direction='UP' if direction == 'BUY' else 'DOWN',
                            target_time=current_time + 30, # 30s prediction
                            source='multiverse',
                            confidence=confidence
                        )
                        self.dreams.append(dream)
                        safe_print(f"      ğŸŒŒ Multiverse dreams {symbol} will go {dream.direction} (Conf: {confidence:.2f})")
            except Exception as e:
                logger.debug(f"Multiverse dream error: {e}")

        # 2. Ask Probability Nexus
        if self.probability_nexus:
            try:
                predictions = self.probability_nexus.get_predictions() if hasattr(self.probability_nexus, 'get_predictions') else []
                if predictions:
                     safe_print(f"\n   ğŸ’­ DREAMING about market direction (Nexus)...")

                for pred in predictions:
                    symbol = pred.get('symbol')
                    if not symbol or symbol not in self.prices:
                        continue
                        
                    current_price = self.prices[symbol]
                    prob = pred.get('probability', 0.5)
                    
                    if prob > 0.7: # High probability UP
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 1.005,
                            direction='UP',
                            target_time=current_time + 30,
                            source='nexus',
                            confidence=prob
                        )
                        self.dreams.append(dream)
                        safe_print(f"      ğŸ”® Nexus dreams {symbol} will go UP (Prob: {prob:.2f})")
            except Exception as e:
                logger.debug(f"Nexus dream error: {e}")

    async def validate_dreams(self):
        """
        âœ… VALIDATION PHASE: Check if dreams came true.
        "Right I know I was right there... adapt adjust"
        """
        current_time = time.time()
        active_dreams = []
        dreams_validated_this_cycle = False
        
        for dream in self.dreams:
            if dream.validated:
                continue
                
            # Check if target time reached
            if current_time >= dream.target_time:
                # Validate!
                current_price = self.prices.get(dream.symbol, 0)
                if current_price == 0:
                    continue # Can't validate
                
                dream.actual_price_at_target = current_price
                dream.validated = True
                dreams_validated_this_cycle = True
                
                # Check success
                if dream.direction == 'UP':
                    dream.success = current_price > dream.current_price
                else:
                    dream.success = current_price < dream.current_price
                
                # ADAPT: Update source accuracy
                alpha = 0.1 # Learning rate
                if dream.success:
                    self.dream_accuracy[dream.source] = (1 - alpha) * self.dream_accuracy[dream.source] + alpha * 1.0
                    safe_print(f"   âœ… DREAM VALIDATED: {dream.source} was RIGHT about {dream.symbol} ({dream.direction})!")
                else:
                    self.dream_accuracy[dream.source] = (1 - alpha) * self.dream_accuracy[dream.source] + alpha * 0.0
                    safe_print(f"   âŒ DREAM FAILED: {dream.source} was WRONG about {dream.symbol}. Adapting...")
                
                self.validated_dreams_count += 1
            else:
                active_dreams.append(dream)
        
        # Keep only active dreams
        self.dreams = active_dreams
        
        # Print accuracy stats occasionally
        if dreams_validated_this_cycle and self.validated_dreams_count % 5 == 0:
            safe_print(f"   ğŸ§  ADAPTIVE LEARNING STATS:")
            for source, acc in self.dream_accuracy.items():
                safe_print(f"      - {source}: {acc:.1%} accuracy")

    def populate_barter_graph(self):
        """
        ğŸ«’ğŸ”„ POPULATE BARTER GRAPH from already-loaded exchange data.
        Called ONCE after pairs and prices are loaded.
        """
        if not self.barter_navigator:
            return
        
        try:
            # Build alpaca pairs dict with base/quote info
            alpaca_pairs_formatted = {}
            for symbol, normalized in self.alpaca_pairs.items():
                if '/' in symbol:
                    parts = symbol.split('/')
                    alpaca_pairs_formatted[symbol] = {'base': parts[0], 'quote': parts[1]}
            
            # Build binance pairs dict from ticker cache (it has base/quote info)
            binance_pairs_formatted = {}
            for cache_key, data in self.ticker_cache.items():
                if cache_key.startswith('binance:'):
                    symbol = cache_key.replace('binance:', '')
                    base = data.get('base', '')
                    quote = data.get('quote', '')
                    if base and quote:
                        binance_pairs_formatted[symbol] = {'base': base, 'quote': quote}
            
            # Use the data we already have!
            success = self.barter_navigator.populate_from_labyrinth_data(
                kraken_pairs=self.kraken_pairs,
                alpaca_pairs=alpaca_pairs_formatted,
                binance_pairs=binance_pairs_formatted,
                prices=self.prices
            )
            
            if success:
                summary = self.barter_navigator.get_graph_summary()
                safe_print(f"ğŸ«’ğŸ”„ Barter Navigator: POPULATED ({summary['total_assets']} assets, {summary['total_edges']} paths)")
            else:
                safe_print(f"âš ï¸ Barter Navigator: Population failed")
        except Exception as e:
            safe_print(f"âš ï¸ Barter Navigator population error: {e}")

    async def dream_for_turn(self, exchange: str):
        """
        ğŸ’­ğŸ¯ TURN-SPECIFIC DREAMING: Dream about assets on THIS exchange's turn.
        "The probability matrix constantly dreams each turn"
        
        This runs EVERY turn (not throttled like global dreaming).
        
        ğŸ‘‘ğŸ”® THE QUEEN DREAMS FIRST - Her dreams guide all other dreams!
        """
        current_time = time.time()
        turn_dreams = []
        
        # Get assets for this exchange
        exchange_assets = self.get_exchange_assets(exchange)
        if not exchange_assets:
            return
        
        symbols_to_dream = list(exchange_assets.keys())[:20]  # Top 20 by holdings
        
        safe_print(f"\n   ğŸ’­ğŸ¯ TURN DREAMING for {exchange.upper()} ({len(symbols_to_dream)} symbols)")
        
        # ğŸ‘‘ğŸ”® 0. THE QUEEN DREAMS FIRST - Her visions set the tone!
        # ğŸ”§ FIX: Use ACTUAL MOMENTUM instead of always predicting UP!
        queen_vision_count = 0
        if self.queen and hasattr(self.queen, 'dream_of_winning'):
            try:
                for symbol in symbols_to_dream[:10]:  # Queen dreams top 10
                    if symbol not in self.prices:
                        continue
                    current_price = self.prices[symbol]
                    
                    # ğŸ‘‘ğŸ”§ GET REAL MOMENTUM FOR THIS ASSET!
                    actual_momentum = 0.0
                    if self.momentum_tracker:
                        actual_momentum = self.momentum_tracker.get_momentum(symbol)  # Per-minute %
                    
                    # Use momentum to determine direction!
                    if actual_momentum > 0.5:  # Rising strongly (+0.5%/min)
                        direction = 'UP'
                        confidence_boost = min(0.2, actual_momentum / 5)  # Cap at +20%
                    elif actual_momentum < -0.5:  # Falling strongly (-0.5%/min)
                        direction = 'DOWN'
                        confidence_boost = min(0.2, abs(actual_momentum) / 5)
                    else:
                        # Neutral - skip this asset for dreaming
                        continue
                    
                    opp_data = {
                        'from_asset': 'USD',
                        'to_asset': symbol,
                        'expected_profit': 0.01,
                        'exchange': exchange,
                        'market_data': {
                            'volatility': 0.5, 
                            'momentum': actual_momentum,  # REAL momentum!
                            'direction': direction
                        }
                    }
                    
                    queen_dream = self.queen.dream_of_winning(opp_data)
                    queen_conf = queen_dream.get('final_confidence', 0.5)
                    
                    # Adjust confidence based on momentum alignment
                    base_conf = queen_conf + confidence_boost
                    
                    # Create dream with ACTUAL direction from momentum!
                    dream = Dream(
                        timestamp=current_time,
                        symbol=symbol,
                        current_price=current_price,
                        predicted_price=current_price * (1 + actual_momentum / 100),  # Use actual %
                        direction=direction,  # ğŸ‘‘ USE REAL DIRECTION!
                        target_time=current_time + 60,
                        source='queen_hive_mind',
                        confidence=min(0.95, base_conf)
                    )
                    self.dreams.append(dream)
                    turn_dreams.append(dream)
                    queen_vision_count += 1
                
                if queen_vision_count > 0:
                    logger.info(f"ğŸ‘‘ğŸ”® Queen dreamed {queen_vision_count} visions for {exchange}")
            except Exception as e:
                logger.debug(f"Queen turn dream error: {e}")
        
        # 1. Ask Multiverse for direction on exchange assets
        if self.multiverse:
            try:
                consensus = self.multiverse.get_consensus() if hasattr(self.multiverse, 'get_consensus') else []
                for signal in consensus:
                    symbol = signal.get('symbol')
                    if not symbol or symbol not in symbols_to_dream:
                        continue
                    
                    current_price = self.prices.get(symbol, 0)
                    if not current_price:
                        continue
                    
                    direction = signal.get('action', 'HOLD')
                    confidence = signal.get('confidence', 0.5)
                    
                    if direction in ['BUY', 'SELL'] and confidence > 0.55:  # Lower threshold for turn dreams
                        move_pct = 0.005 if direction == 'BUY' else -0.005
                        predicted_price = current_price * (1 + move_pct)
                        
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=predicted_price,
                            direction='UP' if direction == 'BUY' else 'DOWN',
                            target_time=current_time + 30,
                            source='multiverse_turn',
                            confidence=confidence
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
            except Exception as e:
                logger.debug(f"Turn multiverse dream error: {e}")
        
        # 2. Ask Probability Nexus for predictions on exchange assets
        if self.probability_nexus:
            try:
                predictions = self.probability_nexus.get_predictions() if hasattr(self.probability_nexus, 'get_predictions') else []
                for pred in predictions:
                    symbol = pred.get('symbol')
                    if not symbol or symbol not in symbols_to_dream:
                        continue
                    
                    current_price = self.prices.get(symbol, 0)
                    if not current_price:
                        continue
                    
                    prob = pred.get('probability', 0.5)
                    
                    if prob > 0.6:  # Good UP prediction
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 1.005,
                            direction='UP',
                            target_time=current_time + 30,
                            source='nexus_turn',
                            confidence=prob
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
                    elif prob < 0.4:  # Good DOWN prediction
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 0.995,
                            direction='DOWN',
                            target_time=current_time + 30,
                            source='nexus_turn',
                            confidence=1 - prob
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
            except Exception as e:
                logger.debug(f"Turn nexus dream error: {e}")
        
        # 3. Use Ultimate Intel if available
        if self.ultimate_intel:
            try:
                for symbol in symbols_to_dream[:10]:
                    if symbol not in self.prices:
                        continue
                    current_price = self.prices[symbol]
                    
                    analysis = self.ultimate_intel.analyze(symbol) if hasattr(self.ultimate_intel, 'analyze') else {}
                    sentiment = analysis.get('sentiment', 'neutral')
                    confidence = analysis.get('confidence', 0.5)
                    
                    if sentiment in ['bullish', 'very_bullish'] and confidence > 0.55:
                        dream = Dream(
                            timestamp=current_time,
                            symbol=symbol,
                            current_price=current_price,
                            predicted_price=current_price * 1.005,
                            direction='UP',
                            target_time=current_time + 30,
                            source='ultimate_turn',
                            confidence=confidence
                        )
                        self.dreams.append(dream)
                        turn_dreams.append(dream)
            except Exception as e:
                logger.debug(f"Turn ultimate dream error: {e}")
        
        if turn_dreams:
            safe_print(f"      ğŸŒ™ Generated {len(turn_dreams)} dreams for {exchange}")
            for dream in turn_dreams[:5]:  # Show top 5
                safe_print(f"         â†’ {dream.symbol} {dream.direction} ({dream.source}: {dream.confidence:.0%})")

    def calculate_dream_score(self, symbol: str) -> float:
        """Calculate score based on active dreams and source accuracy."""
        score = 0.0
        count = 0
        
        for dream in self.dreams:
            if dream.symbol == symbol and not dream.validated:
                # Weight by source accuracy
                accuracy = self.dream_accuracy[dream.source]
                confidence = dream.confidence
                
                weight = accuracy * confidence
                
                if dream.direction == 'UP':
                    score += weight
                else:
                    score -= weight
                count += 1
        
        # Normalize to -1 to +1 range roughly
        if count > 0:
            return max(-1.0, min(1.0, score))
        return 0.0

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¯ TURN-BASED EXCHANGE STRATEGY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_current_exchange(self) -> str:
        """Get the exchange whose turn it is to trade."""
        # Filter to only connected exchanges
        connected = [ex for ex in self.exchange_order 
                     if self.exchange_data.get(ex, {}).get('connected', False)]
        if not connected:
            return None
        return connected[self.current_exchange_index % len(connected)]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ FIRST PAST THE POST (FPTP) - CAPTURE PROFIT IMMEDIATELY!
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def execute_fptp_scan(self) -> Tuple[List['MicroOpportunity'], int]:
        """
        ğŸ FIRST PAST THE POST: Scan ALL exchanges in parallel, 
        execute the BEST opportunity IMMEDIATELY!
        
        No waiting for turns - whoever has profit FIRST wins!
        """
        safe_print(f"\nğŸ â•â•â• FPTP SCAN #{self.turns_completed + 1}: ALL EXCHANGES â•â•â•")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ§  QUEEN DEEP THINK - Consult ALL 42+ systems before acting!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        deep_think_result = None
        if hasattr(self, 'queen') and self.queen:
            try:
                # Gather portfolio positions from Alpaca
                portfolio_positions = []
                cash_available = 0.0
                
                if self.alpaca:
                    try:
                        positions = self.alpaca.list_positions()
                        for pos in positions:
                            portfolio_positions.append({
                                'symbol': pos.symbol,
                                'qty': float(pos.qty),
                                'market_value': float(pos.market_value),
                                'cost_basis': float(pos.cost_basis),
                                'unrealized_pl': float(pos.unrealized_pl),
                                'unrealized_plpc': float(pos.unrealized_plpc),
                                'current_price': float(pos.current_price),
                                'avg_entry_price': float(pos.avg_entry_price)
                            })
                        
                        # Get cash
                        account = self.alpaca.get_account()
                        cash_available = float(account.cash)
                    except Exception as e:
                        logger.debug(f"Error getting Alpaca positions for Deep Think: {e}")
                
                # ğŸ§  THE QUEEN THINKS DEEPLY!
                deep_think_result = self.queen.deep_think_portfolio(
                    portfolio_positions=portfolio_positions,
                    cash_available=cash_available,
                    prices=self.prices
                )
                
                # Print the Queen's wisdom
                safe_print(f"\nğŸ‘‘ğŸ§  QUEEN'S DEEP THINK:")
                safe_print(f"   ğŸŒ Cosmic: Gaia={deep_think_result.gaia_blessing:.0%}, Î»={deep_think_result.luck_field:.0%}, Î©={deep_think_result.global_harmonic_omega:.0%}")
                safe_print(f"   ğŸ“ˆ Market: P(Nexus)={deep_think_result.probability_nexus_score:.0%}, {deep_think_result.timeline_oracle_branch}")
                safe_print(f"   ğŸ¦… Strategy: {deep_think_result.selected_strategy} with {', '.join(deep_think_result.selected_animals[:3])}")
                safe_print(f"   ğŸ‘‘ Decision: {deep_think_result.action} @ {deep_think_result.confidence:.0%}")
                safe_print(f"   ğŸ’¬ {deep_think_result.queen_message}")
                
                if deep_think_result.warnings:
                    for warning in deep_think_result.warnings:
                        safe_print(f"   âš ï¸ {warning}")
                
                # If Queen says WAIT and confidence is LOW, we can skip the scan
                if deep_think_result.action == 'WAIT' and deep_think_result.confidence < 0.3:
                    safe_print(f"\n   ğŸ‘‘ Queen says WAIT (confidence {deep_think_result.confidence:.0%} too low). Skipping scan.")
                    self.turns_completed += 1
                    return [], 0
                    
            except Exception as e:
                logger.warning(f"Queen Deep Think error (non-fatal): {e}")
                safe_print(f"   âš ï¸ Queen Deep Think unavailable: {e}")
        
        # ğŸŒ¾ğŸ’° PROFIT HARVESTER - Harvest any profitable positions FIRST!
        # This gives us cash to buy new opportunities!
        self.turns_since_harvest += 1
        safe_print(f"   ğŸŒ¾ Harvest check: turns_since={self.turns_since_harvest}, interval={self.harvest_interval}, alpaca={'âœ…' if self.alpaca else 'âŒ'}")
        if self.alpaca and self.turns_since_harvest >= self.harvest_interval:
            try:
                safe_print(f"   ğŸŒ¾ Running harvest scan (ANY NET PROFIT = SELL!)...")
                harvest_result = await self.harvest_profitable_positions()
                if harvest_result.get('harvested'):
                    safe_print(f"   ğŸŒ¾âœ… CASH FLOW! Harvested ${harvest_result['total_profit_harvested']:.4f} profit â†’ ${harvest_result['cash_generated']:.2f} cash")
                elif harvest_result.get('candidates_found', 0) > 0:
                    safe_print(f"   ğŸŒ¾ {harvest_result['candidates_found']} positions found - waiting for NET profit after fees")
                else:
                    safe_print(f"   ğŸŒ¾ No profitable positions yet - HODL until we're green! (NO LOSSES ACCEPTED)")
                self.turns_since_harvest = 0
            except Exception as e:
                safe_print(f"   ğŸŒ¾âŒ Harvest error: {e}")
                logger.debug(f"Harvest check error: {e}")
        
        connected_exchanges = [ex for ex in self.exchange_order 
                               if self.exchange_data.get(ex, {}).get('connected', False)]
        
        if not connected_exchanges:
            safe_print("   âš ï¸ No exchanges connected!")
            return [], 0
        
        # ğŸ”„ Refresh balances for ALL exchanges in parallel
        refresh_tasks = [self.refresh_exchange_balances(ex) for ex in connected_exchanges]
        await asyncio.gather(*refresh_tasks, return_exceptions=True)
        
        # ğŸ” Scan ALL exchanges for opportunities in parallel
        all_opportunities: List['MicroOpportunity'] = []
        
        scan_tasks = []
        for exchange in connected_exchanges:
            scan_tasks.append(self._scan_exchange_for_fptp(exchange))
        
        results = await asyncio.gather(*scan_tasks, return_exceptions=True)
        
        # ğŸ¢ğŸŒŠ OCEAN MODE - Scan the ENTIRE market, not just what we hold!
        # "Be a turtle in the sea of possibilities, not a big fish in a small pond"
        if getattr(self, 'ocean_mode_enabled', True):  # Default ON!
            try:
                ocean_opportunities = await self._scan_ocean_opportunities(connected_exchanges)
                if ocean_opportunities:
                    safe_print(f"\n   ğŸ¢ğŸŒŠ OCEAN MODE: Found {len(ocean_opportunities)} market-wide opportunities!")
                    all_opportunities.extend(ocean_opportunities)
            except Exception as e:
                logger.debug(f"Ocean scan error: {e}")
        
        # Collect all opportunities from all exchanges
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.debug(f"FPTP scan error for {connected_exchanges[i]}: {result}")
                continue
            if result:
                all_opportunities.extend(result)
        
        # Sort by expected profit (highest first)
        all_opportunities.sort(key=lambda x: x.expected_pnl_usd, reverse=True)
        
        if not all_opportunities:
            safe_print(f"   ğŸ“­ No opportunities across {len(connected_exchanges)} exchanges")
            self.turns_completed += 1
            if hasattr(self, 'barter_matrix') and self.barter_matrix:
                self.barter_matrix.current_turn = self.turns_completed
            return [], 0
        
        # ğŸ”®ğŸ”„ QUANTUM MIRROR SCANNER UPDATE - Feed opportunities into scanner!
        # This is the CRITICAL integration that was MISSING before!
        if hasattr(self, 'quantum_mirror_scanner') and self.quantum_mirror_scanner:
            try:
                mirror_result = self.quantum_mirror_scanner.update_from_market_data(
                    opportunities=all_opportunities,
                    prices=self.prices
                )
                if mirror_result.get('ready_count', 0) > 0:
                    safe_print(f"\n   ğŸ”® QUANTUM MIRROR: {mirror_result['ready_count']} branches READY for 4th pass!")
                    for rb in mirror_result.get('ready_branches', [])[:3]:
                        safe_print(f"      âš¡ {rb['branch_id']}: score={rb['score']:.3f}")
                if mirror_result.get('convergences_detected', 0) > 0:
                    safe_print(f"   ğŸŒ€ Timeline convergences detected: {mirror_result['convergences_detected']}")
                    
                # ğŸ”® BOOST TOP OPPORTUNITIES WITH QUANTUM COHERENCE!
                for opp in all_opportunities:
                    boost, reason = self.quantum_mirror_scanner.get_quantum_boost(
                        opp.from_asset, opp.to_asset, opp.source_exchange
                    )
                    if boost > 0:
                        # Apply quantum boost to expected PnL and combined score
                        opp.expected_pnl_usd = opp.expected_pnl_usd * (1 + boost)
                        opp.combined_score = min(2.0, opp.combined_score * (1 + boost))
                        if boost > 0.2:  # Significant boost
                            logger.info(f"ğŸ”® Quantum boost +{boost:.0%} for {opp.from_asset}â†’{opp.to_asset}: {reason}")
                            
                # Re-sort after boost
                all_opportunities.sort(key=lambda x: x.expected_pnl_usd, reverse=True)
            except Exception as e:
                logger.debug(f"Quantum Mirror update error: {e}")
        
        # ğŸ‘‘ğŸ§  QUEEN DEEP THINK - Apply strategy filter based on Queen's decision
        if deep_think_result and deep_think_result.action != 'WAIT':
            strategy = deep_think_result.selected_strategy
            aggression = deep_think_result.aggression_level
            
            # Apply Queen's strategy to filter/boost opportunities
            if strategy == 'AGGRESSIVE' and aggression > 0.7:
                # Boost ALL opportunities for aggressive mode
                for opp in all_opportunities:
                    opp.expected_pnl_usd *= 1.2  # 20% boost
                    opp.combined_score = min(2.0, opp.combined_score * 1.15)
                safe_print(f"   ğŸ‘‘ AGGRESSIVE MODE: All opportunities boosted +20%!")
            
            elif strategy == 'DEFENSIVE' and aggression < 0.3:
                # Only keep high-confidence opportunities
                original_count = len(all_opportunities)
                all_opportunities = [opp for opp in all_opportunities 
                                    if opp.combined_score >= 1.2]  # Higher threshold
                filtered = original_count - len(all_opportunities)
                if filtered > 0:
                    safe_print(f"   ğŸ‘‘ DEFENSIVE MODE: Filtered {filtered} low-confidence opportunities")
            
            elif strategy == 'SNIPER':
                # Only keep the absolute best opportunities
                all_opportunities = all_opportunities[:3]  # Only top 3
                safe_print(f"   ğŸ‘‘ SNIPER MODE: Focusing on top 3 opportunities only")
            
            # Re-sort after strategy adjustments
            all_opportunities.sort(key=lambda x: x.expected_pnl_usd, reverse=True)
        
        # 
        # ğŸ” Scan ALL exchanges for opportunities in parallel
        all_opportunities: List['MicroOpportunity'] = []
        
        scan_tasks = []
        for exchange in connected_exchanges:
            scan_tasks.append(self._scan_exchange_for_fptp(exchange))
        
        results = await asyncio.gather(*scan_tasks, return_exceptions=True)
        
        # Collect all opportunities from all exchanges
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.debug(f"FPTP scan error for {connected_exchanges[i]}: {result}")
                continue
            if result:
                all_opportunities.extend(result)
        
        # Sort by expected profit (highest first)
        all_opportunities.sort(key=lambda x: x.expected_pnl_usd, reverse=True)
        
        if not all_opportunities:
            safe_print(f"   ğŸ“­ No opportunities across {len(connected_exchanges)} exchanges")
            self.turns_completed += 1
            if hasattr(self, 'barter_matrix') and self.barter_matrix:
                self.barter_matrix.current_turn = self.turns_completed
            return [], 0
        
        # ğŸ”®ğŸ”„ QUANTUM MIRROR SCANNER UPDATE - Feed opportunities into scanner!
        # This is the CRITICAL integration that was MISSING before!
        if hasattr(self, 'quantum_mirror_scanner') and self.quantum_mirror_scanner:
            try:
                mirror_result = self.quantum_mirror_scanner.update_from_market_data(
                    opportunities=all_opportunities,
                    prices=self.prices
                )
                if mirror_result.get('ready_count', 0) > 0:
                    safe_print(f"\n   ğŸ”® QUANTUM MIRROR: {mirror_result['ready_count']} branches READY for 4th pass!")
                    for rb in mirror_result.get('ready_branches', [])[:3]:
                        safe_print(f"      âš¡ {rb['branch_id']}: score={rb['score']:.3f}")
                if mirror_result.get('convergences_detected', 0) > 0:
                    safe_print(f"   ğŸŒ€ Timeline convergences detected: {mirror_result['convergences_detected']}")
                    
                # ğŸ”® BOOST TOP OPPORTUNITIES WITH QUANTUM COHERENCE!
                for opp in all_opportunities:
                    boost, reason = self.quantum_mirror_scanner.get_quantum_boost(
                        opp.from_asset, opp.to_asset, opp.source_exchange
                    )
                    if boost > 0:
                        # Apply quantum boost to expected PnL and combined score
                        opp.expected_pnl_usd = opp.expected_pnl_usd * (1 + boost)
                        opp.combined_score = min(2.0, opp.combined_score * (1 + boost))
                        if boost > 0.2:  # Significant boost
                            logger.info(f"ğŸ”® Quantum boost +{boost:.0%} for {opp.from_asset}â†’{opp.to_asset}: {reason}")
                            
                # Re-sort after boost
                all_opportunities.sort(key=lambda x: x.expected_pnl_usd, reverse=True)
            except Exception as e:
                logger.debug(f"Quantum Mirror update error: {e}")
        
        # ğŸ† SHOW TOP OPPORTUNITIES FROM ALL EXCHANGES
        safe_print(f"\n   ğŸ† TOP OPPORTUNITIES ({len(all_opportunities)} total):")
        for i, opp in enumerate(all_opportunities[:5]):
            icon = {'kraken': 'ğŸ™', 'alpaca': 'ğŸ¦™', 'binance': 'ğŸŸ¡'}.get(opp.source_exchange, 'ğŸ“Š')
            safe_print(f"      {i+1}. {icon} {opp.from_asset}â†’{opp.to_asset} | PnL: ${opp.expected_pnl_usd:+.4f} | Score: {opp.combined_score:.1f}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¯ IRA SNIPER MODE - Keep shooting until we hit a winner or exhaust all!
        # Cycle through ALL opportunities, execute FIRST one that passes ALL gates
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        conversions = 0
        executed_opportunity = None
        
        for idx, opp in enumerate(all_opportunities):
            icon = {'kraken': 'ğŸ™', 'alpaca': 'ğŸ¦™', 'binance': 'ğŸŸ¡'}.get(opp.source_exchange, 'ğŸ“Š')

            # ğŸ”„ Avoid immediately re-attempting the same target across consecutive scans
            attempt_key = (opp.source_exchange, opp.from_asset.upper(), opp.to_asset.upper())
            last_attempt_turn = self.fptp_recent_attempts.get(attempt_key)
            if last_attempt_turn is not None:
                if (self.turns_completed - last_attempt_turn) < self.fptp_recent_attempt_cooldown_turns:
                    continue
            
            # Only show details for first 5, then just try silently
            if idx < 5:
                safe_print(f"\n   ğŸ¯ SNIPER TARGET #{idx+1}: {icon} {opp.source_exchange.upper()}")
                safe_print(f"      {opp.from_asset} â†’ {opp.to_asset}")
                safe_print(f"      Expected: ${opp.expected_pnl_usd:+.4f}")
            
            # ğŸ‘‘ Quick Queen check
            queen_says_win, queen_confidence, queen_reason = await self.ask_queen_will_we_win(opp)
            
            if not queen_says_win:
                if idx < 5:
                    safe_print(f"   ğŸ‘‘âŒ SERO SAYS NO: {queen_reason}")
                continue  # Try next opportunity

            # ğŸ”—â›“ï¸ Chain-sniper also enforces conservative cost gating in DRY RUN
            # (Live mode already does this inside execute_conversion)
            hop_cost = None
            if self.chain_sniper_mode and not self.live:
                hop_cost = self._estimate_conservative_trade_outcome(opp)
                if not hop_cost['ok']:
                    # Mirror live behavior: record and move on
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset,
                        opp.to_asset,
                        hop_cost['reason'],
                        opp.from_value_usd,
                    )
                    self.fptp_recent_attempts[attempt_key] = self.turns_completed
                    continue
            
            # ğŸ‘‘ Queen approved! Try to execute
            if idx < 5:
                safe_print(f"   ğŸ‘‘âœ… SERO SAYS WIN: {queen_reason}")
                safe_print(f"   ğŸ¯ğŸ”« SNIPER TAKING THE SHOT!")
            
            success = await self.execute_conversion(opp)
            
            if success:
                conversions = 1
                executed_opportunity = opp
                actual_pnl = getattr(opp, 'actual_pnl_usd', opp.expected_pnl_usd)
                self.exchange_stats[opp.source_exchange]['conversions'] += 1
                self.exchange_stats[opp.source_exchange]['profit'] += actual_pnl
                safe_print(f"\n   ğŸ¯ğŸ’€ SNIPER KILL! ${actual_pnl:+.4f} - {opp.from_asset}â†’{opp.to_asset}")
                await self.queen_learn_from_trade(opp, success=True)
                
                # ğŸŒâœ¨ PLANET SAVER: Record the win toward liberation!
                if hasattr(self, 'planet_saver') and self.planet_saver and actual_pnl > 0:
                    symbol = f"{opp.from_asset}/{opp.to_asset}"
                    exchange = opp.source_exchange or 'unknown'
                    liberation_status = self.planet_saver.record_win(actual_pnl, symbol, exchange)
                    if liberation_status and liberation_status.get('milestone_reached'):
                        safe_print(f"   ğŸŒğŸ‰ LIBERATION MILESTONE: {liberation_status.get('milestone_name', 'PROGRESS!')}")
                        safe_print(f"      â†’ Progress: ${liberation_status.get('total_profit', 0):.2f} / ${liberation_status.get('goal_usd', 127000):.2f}")

                # ğŸ”µ DRY RUN: simulate balances so chaining can actually progress
                if not self.live and self.chain_sniper_mode:
                    if hop_cost is None:
                        hop_cost = self._estimate_conservative_trade_outcome(opp)
                    self._simulate_balance_after_trade(opp, hop_cost)

                # ğŸ”—â›“ï¸ CHAIN SNIPER: keep hopping while we don't bleed
                if self.chain_sniper_mode:
                    try:
                        initial_outcome = hop_cost or self._estimate_conservative_trade_outcome(opp)
                        await self._execute_chain_sniper_from_asset(
                            exchange=opp.source_exchange,
                            start_asset=opp.to_asset,
                            starting_conservative_pnl_usd=max(0.0, initial_outcome.get('conservative_pnl_usd', 0.0)),
                        )
                    except Exception as e:
                        logger.debug(f"Chain sniper error after {opp.from_asset}â†’{opp.to_asset}: {e}")
                break  # ğŸ¯ HIT! Move to next scan cycle
            else:
                if idx < 5:
                    safe_print(f"   âŒ Shot missed - trying next target...")
                self.fptp_recent_attempts[attempt_key] = self.turns_completed
                await self.queen_learn_from_trade(opp, success=False)
                
                # ğŸŒğŸ’” PLANET SAVER: Record the loss for learning
                if hasattr(self, 'planet_saver') and self.planet_saver:
                    symbol = f"{opp.from_asset}/{opp.to_asset}"
                    exchange = opp.source_exchange or 'unknown'
                    self.planet_saver.record_loss(0.0, symbol, exchange)  # Record attempt failure
                
                continue  # Try next opportunity
        
        if conversions == 0:
            safe_print(f"\n   ğŸ¯ğŸ˜¤ SNIPER: No valid targets from {len(all_opportunities)} opportunities")
            safe_print(f"      â†’ All blocked by costs, spreads, or Queen veto")
        
        self.turns_completed += 1
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            self.barter_matrix.current_turn = self.turns_completed
        return all_opportunities, conversions

    def _estimate_conservative_trade_outcome(self, opp: 'MicroOpportunity') -> Dict[str, Any]:
        """Estimate conservative net P&L for a hop using LiveBarterMatrix true-cost math."""
        exchange = (opp.source_exchange or 'kraken').lower()
        approved, reason, cost_breakdown = self.barter_matrix.calculate_true_cost(
            opp.from_asset,
            opp.to_asset,
            opp.from_value_usd,
            exchange,
        )

        spread_pct = float(cost_breakdown.get('spread', 0.0))
        total_cost_pct = float(cost_breakdown.get('total_cost_pct', 0.0)) / 100.0
        total_cost_usd = opp.from_value_usd * total_cost_pct
        scanner_expected_pnl = float(getattr(opp, 'expected_pnl_usd', 0.0) or 0.0)
        conservative_pnl = scanner_expected_pnl - total_cost_usd
        min_profit_floor = max(MIN_NET_PROFIT_USD, total_cost_usd * 0.10)
        required_profit_usd = total_cost_usd + min_profit_floor

        # Apply the same simple history penalty used in the live pre-exec gate
        pair_key = (opp.from_asset.upper(), opp.to_asset.upper())
        hist = getattr(self.barter_matrix, 'barter_history', {}).get(pair_key, {})
        if hist.get('total_profit', 0) < 0 and hist.get('trades', 0) > 2:
            historical_loss_rate = abs(hist['total_profit']) / max(hist.get('trades', 1), 1)
            conservative_pnl -= historical_loss_rate * 0.5

        if spread_pct > 5.0:
            return {
                'ok': False,
                'reason': f'spread_too_high: {spread_pct:.1f}%',
                'approved': approved,
                'cost_breakdown': cost_breakdown,
                'total_cost_usd': total_cost_usd,
                'conservative_pnl_usd': conservative_pnl,
            }

        if not approved:
            return {
                'ok': False,
                'reason': f'true_cost_reject: {reason}',
                'approved': approved,
                'cost_breakdown': cost_breakdown,
                'total_cost_usd': total_cost_usd,
                'conservative_pnl_usd': conservative_pnl,
            }

        # ğŸŒ PLANET SAVER: Scanner expects profit = GO FOR IT!
        if scanner_expected_pnl < required_profit_usd:
            return {
                'ok': False,
                'reason': (
                    f'cost_exceeds_profit: expected ${scanner_expected_pnl:.4f} '
                    f'< required ${required_profit_usd:.4f}'
                ),
                'approved': approved,
                'cost_breakdown': cost_breakdown,
                'total_cost_usd': total_cost_usd,
                'conservative_pnl_usd': conservative_pnl,
                'required_profit_usd': required_profit_usd,
            }

        return {
            'ok': True,
            'reason': 'ok',
            'approved': approved,
            'cost_breakdown': cost_breakdown,
            'total_cost_usd': total_cost_usd,
            'conservative_pnl_usd': conservative_pnl,
            'required_profit_usd': required_profit_usd,
        }

    def _simulate_balance_after_trade(self, opp: 'MicroOpportunity', outcome: Dict[str, Any]):
        """Dry-run only: mutate exchange balances to allow multi-hop chaining to progress."""
        exchange = (opp.source_exchange or '').lower()
        if not exchange:
            return
        bal = self.exchange_balances.get(exchange)
        if not isinstance(bal, dict):
            return

        from_asset = opp.from_asset.upper()
        to_asset = opp.to_asset.upper()
        from_amt = float(getattr(opp, 'from_amount', 0.0) or 0.0)

        # Remove source amount
        if from_amt > 0:
            bal[from_asset] = max(0.0, float(bal.get(from_asset, 0.0) or 0.0) - from_amt)
            if bal[from_asset] == 0.0:
                bal.pop(from_asset, None)

        # Add target amount using conservative net USD after costs
        to_price = float(self.prices.get(to_asset, 0.0) or 0.0)
        if to_price <= 0:
            return

        cost_breakdown = outcome.get('cost_breakdown', {}) if isinstance(outcome, dict) else {}
        total_cost_pct = float(cost_breakdown.get('total_cost_pct', 0.0)) / 100.0
        net_value_usd = float(opp.from_value_usd) * max(0.0, (1.0 - total_cost_pct))
        to_amt = net_value_usd / to_price

        if to_amt > 0:
            bal[to_asset] = float(bal.get(to_asset, 0.0) or 0.0) + to_amt

        self.exchange_balances[exchange] = bal

    async def _execute_chain_sniper_from_asset(self, exchange: str, start_asset: str, starting_conservative_pnl_usd: float = 0.0):
        """After a win, keep hopping on the same exchange while net-positive, up to max_chain_hops."""
        if not exchange:
            return
        exchange = exchange.lower()

        cumulative_conservative_pnl = float(starting_conservative_pnl_usd or 0.0)
        current_asset = start_asset.upper()
        last_asset = None
        hops_taken = 0

        # Prevent trivial loops: track last few assets
        recent_assets = deque([current_asset], maxlen=6)

        while hops_taken < max(0, int(self.max_chain_hops) - 1):
            # Refresh balances between hops in live mode
            if self.live:
                try:
                    await self.refresh_exchange_balances(exchange)
                except Exception:
                    pass

            opportunities = await self.find_opportunities_for_exchange(exchange)
            for o in opportunities:
                o.source_exchange = exchange

            candidates = [o for o in opportunities if o.from_asset.upper() == current_asset]
            if not candidates:
                return

            candidates.sort(key=lambda x: x.expected_pnl_usd, reverse=True)

            executed = False
            for opp in candidates:
                # Avoid immediate back-and-forth ping-pong
                if last_asset and opp.to_asset.upper() == last_asset:
                    continue
                if opp.to_asset.upper() in recent_assets and opp.to_asset.upper() != 'USD' and opp.to_asset.upper() not in ('USDT', 'USDC', 'DAI'):
                    continue

                attempt_key = (exchange, opp.from_asset.upper(), opp.to_asset.upper())
                last_attempt_turn = self.fptp_recent_attempts.get(attempt_key)
                if last_attempt_turn is not None:
                    if (self.turns_completed - last_attempt_turn) < self.fptp_recent_attempt_cooldown_turns:
                        continue

                # Conservative no-bleed check
                outcome = self._estimate_conservative_trade_outcome(opp)
                if not outcome['ok']:
                    self.fptp_recent_attempts[attempt_key] = self.turns_completed
                    continue

                if (cumulative_conservative_pnl + outcome['conservative_pnl_usd']) < 0.0001:
                    continue

                queen_says_win, _, _ = await self.ask_queen_will_we_win(opp)
                if not queen_says_win:
                    continue

                success = await self.execute_conversion(opp)
                if not success:
                    self.fptp_recent_attempts[attempt_key] = self.turns_completed
                    continue

                # Update chain state
                if not self.live:
                    self._simulate_balance_after_trade(opp, outcome)

                cumulative_conservative_pnl += float(outcome.get('conservative_pnl_usd', 0.0) or 0.0)
                hops_taken += 1
                last_asset = current_asset
                current_asset = opp.to_asset.upper()
                recent_assets.append(current_asset)
                executed = True
                break

            if not executed:
                return
    
    async def _scan_exchange_for_fptp(self, exchange: str) -> List['MicroOpportunity']:
        """Scan a single exchange for FPTP mode."""
        try:
            # ğŸŒŠ RIVER CONSCIOUSNESS: Update before scanning to know where the water flows
            if hasattr(self, 'river_consciousness') and self.river_consciousness:
                # This finds the best rivers (cached) so we don't look too hard at dry beds
                try:
                    self.river_consciousness.find_best_river()
                except Exception as e:
                    logger.debug(f"River update failed: {e}")

            # Update stats
            self.exchange_stats[exchange]['scans'] += 1
            self.exchange_stats[exchange]['last_turn'] = time.time()
            
            # Find opportunities on this exchange
            opportunities = await self.find_opportunities_for_exchange(exchange)
            
            # Tag each opportunity with its source exchange
            for opp in opportunities:
                opp.source_exchange = exchange
            
            self.exchange_stats[exchange]['opportunities'] += len(opportunities)
            return opportunities
        except Exception as e:
            logger.debug(f"FPTP scan error for {exchange}: {e}")
            return []
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¢ğŸŒŠ OCEAN MODE - SCAN THE ENTIRE MARKET (Not just what we hold!)
    # "Be a turtle in the sea of possibilities, not a big fish in a small pond"
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def _scan_ocean_opportunities(self, exchanges: List[str]) -> List['MicroOpportunity']:
        """
        ğŸ¢ğŸŒŠ OCEAN MODE - Scan the ENTIRE market for opportunities!
        
        Instead of only looking at what we hold (puddle mentality),
        we scan ALL available pairs to find the BEST opportunities.
        Then we can BUY INTO those positions with our available cash.
        
        UNIVERSE:
        - Kraken: 1,434+ pairs
        - Alpaca: 62+ crypto symbols + 10,000+ stocks (when market open)
        - Binance: 2,000+ pairs
        
        This transforms 28 opportunities into 1,500+ possibilities!
        """
        ocean_opportunities = []
        
        # Get our available cash/stablecoins across exchanges
        available_cash = {}
        for exchange in exchanges:
            balances = self.get_exchange_assets(exchange)
            for asset in ['USD', 'USDT', 'USDC', 'ZUSD', 'EUR']:
                if asset in balances:
                    amount = balances[asset]
                    price = self.prices.get(asset, 1.0)
                    value = amount * price
                    if value >= 1.0:  # At least $1 available
                        available_cash[(exchange, asset)] = {'amount': amount, 'value': value}
        
        if not available_cash:
            # No cash to buy new positions - skip ocean mode
            return []
        
        total_cash = sum(v['value'] for v in available_cash.values())
        safe_print(f"   ğŸ¢ Ocean Mode: ${total_cash:.2f} cash available across {len(available_cash)} sources")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŠ SCAN ENTIRE KRAKEN UNIVERSE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if 'kraken' in exchanges and self.kraken and ('kraken', 'USD') in available_cash:
            try:
                kraken_opps = await self._ocean_scan_kraken(available_cash[('kraken', 'USD')])
                ocean_opportunities.extend(kraken_opps)
            except Exception as e:
                logger.debug(f"Kraken ocean scan error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦™ SCAN ENTIRE ALPACA UNIVERSE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if 'alpaca' in exchanges and self.alpaca:
            alpaca_cash = available_cash.get(('alpaca', 'USD'), {})
            if alpaca_cash.get('value', 0) >= 1.0:
                try:
                    alpaca_opps = await self._ocean_scan_alpaca(alpaca_cash)
                    ocean_opportunities.extend(alpaca_opps)
                except Exception as e:
                    logger.debug(f"Alpaca ocean scan error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸºğŸ¦ğŸœğŸ¦ ANIMAL SWARM SCAN - Unified animal intelligence!
        # "The pack hunts together, each animal with its specialty"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if 'alpaca' in exchanges and self.animal_swarm:
            alpaca_cash = available_cash.get(('alpaca', 'USD'), {})
            if alpaca_cash.get('value', 0) >= 1.0:
                try:
                    animal_opps = await self._scan_animal_swarm(alpaca_cash)
                    ocean_opportunities.extend(animal_opps)
                except Exception as e:
                    logger.debug(f"Animal swarm scan error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”® PROBABILITY NEXUS VALIDATION - Filter & boost with prediction matrix!
        # "Only act on opportunities with validated probability edge"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.probability_nexus and ocean_opportunities:
            try:
                ocean_opportunities = self._validate_with_probability_nexus(ocean_opportunities)
            except Exception as e:
                logger.debug(f"Probability nexus validation error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸš€ ALL SYSTEMS HEAVY LIFTING FOR ALPACA
        # "Harmonic, Momentum, HNC, Queen - every system serves Alpaca"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if ocean_opportunities:
            try:
                ocean_opportunities = self._all_systems_heavy_lift_for_alpaca(ocean_opportunities)
            except Exception as e:
                logger.debug(f"All systems heavy lift error: {e}")
        
        # Sort by momentum score (best first)
        ocean_opportunities.sort(key=lambda x: getattr(x, 'momentum_score', x.combined_score), reverse=True)
        
        return ocean_opportunities[:3000]  # ğŸŒ FULL MARKET: 100% COVERAGE (Max 3000 opportunities)
    
    async def _ocean_scan_kraken(self, cash_info: Dict) -> List['MicroOpportunity']:
        """Scan ALL Kraken pairs for opportunities."""
        opportunities = []
        cash_amount = cash_info.get('amount', 0)
        
        if cash_amount < 5:  # Need at least $5 for meaningful trades
            return opportunities
        
        # Get all available pairs
        try:
            if hasattr(self.kraken, '_load_asset_pairs'):
                pairs = self.kraken._load_asset_pairs() or {}
            else:
                pairs = self.kraken_pairs or {}
        except:
            pairs = self.kraken_pairs or {}
        
        # Filter to USD pairs only (we have USD to spend)
        usd_pairs = {}
        for pair_name, info in pairs.items():
            if pair_name.endswith('.d'):  # Skip dark pools
                continue
            quote = info.get('quote', '') if isinstance(info, dict) else ''
            # Check if it's a USD/ZUSD pair
            if 'USD' in pair_name.upper() or 'ZUSD' in str(quote):
                usd_pairs[pair_name] = info
        
        safe_print(f"   ğŸ™ Ocean scanning {len(usd_pairs)} Kraken USD pairs...")
        
        # Get tickers for momentum analysis (batch if possible)
        # For now, use our cached momentum data
        # ğŸŒ FULL MARKET: Scan 3000 rising (was 200) for 100% Kraken coverage!
        rising_coins = self.get_strongest_rising(exclude={'USD', 'USDT', 'USDC'}, limit=3000)
        
        for coin, momentum in rising_coins[:2000]:  # ğŸŒ FULL MARKET: Top 2000 rising
            if momentum < 0.01:  # Skip if momentum too low
                continue
            
            # Check if this coin has a USD pair
            possible_pairs = [f"{coin}USD", f"X{coin}ZUSD", f"{coin}ZUSD"]
            pair_found = None
            for p in possible_pairs:
                if p in usd_pairs or p in self.kraken_pairs:
                    pair_found = p
                    break
            
            if not pair_found:
                continue
            
            # Get current price
            coin_price = self.prices.get(coin, 0)
            if not coin_price:
                continue
            
            # Calculate potential profit from momentum
            # If coin is rising 1%/min, and we hold for 5 minutes, that's ~5% potential
            hold_minutes = 5
            expected_gain_pct = momentum * hold_minutes / 100  # Convert to decimal
            expected_gain_usd = cash_amount * expected_gain_pct
            
            # Factor in fees (~0.26% maker on Kraken)
            fee_pct = 0.0026
            total_fees = cash_amount * fee_pct * 2  # Buy + Sell
            net_profit = expected_gain_usd - total_fees
            
            if net_profit > 0.01:  # Only if profitable after fees
                opp = MicroOpportunity(
                    from_asset='USD',
                    to_asset=coin,
                    from_amount=cash_amount,
                    to_amount=cash_amount / coin_price,
                    expected_pnl_usd=net_profit,
                    combined_score=momentum / 10,  # Normalize
                    opportunity_type='ocean_momentum',
                    source_exchange='kraken',
                )
                opp.momentum_score = momentum
                opp.ocean_mode = True
                opportunities.append(opp)
        
        return opportunities
    
    def _read_binance_ws_cache_for_alpaca(self) -> Optional[Dict[str, Any]]:
        """Read Binance WS cache if fresh (for Alpaca heavy lifting)."""
        try:
            ws_cache_path = os.getenv("WS_PRICE_CACHE_PATH", "ws_cache/ws_prices.json").strip()
            ws_cache_max_age_s = float(os.getenv("WS_PRICE_CACHE_MAX_AGE_S", "10"))
            if not ws_cache_path:
                return None
            p = Path(ws_cache_path)
            if not p.exists():
                return None
            raw = p.read_text(encoding="utf-8")
            payload = json.loads(raw) if raw else {}
            ts = float(payload.get("generated_at", 0) or 0)
            if ts > 0 and (time.time() - ts) <= ws_cache_max_age_s:
                return payload
        except Exception:
            pass
        return None

    def _read_kraken_cache_for_alpaca(self) -> Optional[Dict[str, Any]]:
        """Read Kraken REST cache if fresh (for Alpaca heavy lifting - 10 extra coins!)."""
        try:
            kraken_cache_path = os.getenv("KRAKEN_CACHE_PATH", "ws_cache/kraken_prices.json").strip()
            kraken_cache_max_age_s = float(os.getenv("KRAKEN_CACHE_MAX_AGE_S", "15"))  # Kraken REST is slower
            if not kraken_cache_path:
                return None
            p = Path(kraken_cache_path)
            if not p.exists():
                return None
            raw = p.read_text(encoding="utf-8")
            payload = json.loads(raw) if raw else {}
            ts = float(payload.get("generated_at", 0) or 0)
            if ts > 0 and (time.time() - ts) <= kraken_cache_max_age_s:
                return payload
        except Exception:
            pass
        return None

    async def _ocean_scan_alpaca(self, cash_info: Dict) -> List['MicroOpportunity']:
        """
        ğŸ¦™ğŸŸ¡ Scan ALL Alpaca symbols using BINANCE for heavy lifting!
        
        Pattern:
        1. Use FREE Binance WebSocket data (ws_cache) for full-market scanning
        2. Find opportunities that exist on Alpaca
        3. Only hit Alpaca API to VALIDATE the top candidates
        4. Execute on Alpaca
        
        This keeps Alpaca API usage minimal while scanning the entire market!
        """
        opportunities = []
        cash_amount = cash_info.get('amount', 0)
        
        if cash_amount < 1:  # Alpaca has low minimums
            return opportunities
        
        # Get Alpaca tradeable symbols
        try:
            if hasattr(self.alpaca, 'get_tradable_crypto_symbols'):
                symbols = self.alpaca.get_tradable_crypto_symbols() or []
            else:
                symbols = list(self.alpaca_pairs.keys())
        except Exception:
            symbols = list(self.alpaca_pairs.keys()) if self.alpaca_pairs else []
        
        # ğŸ“ˆ STOCK SCANNING: Use dedicated stock scanner if enabled
        stock_opportunities = []
        if ALPACA_INCLUDE_STOCKS and STOCK_SCANNER_AVAILABLE:
            try:
                if not hasattr(self, 'stock_scanner'):
                    self.stock_scanner = AlpacaStockScanner(alpaca_client=self.alpaca)
                
                # Scan stocks with dedicated scanner
                stock_opps = self.stock_scanner.scan_stocks(
                    symbols=None,  # Scan all tradable
                    max_results=50,
                    min_volume=1000000,  # $1M daily volume
                    min_price=1.0,
                    max_price=500.0
                )
                
                # Convert stock opportunities to MicroOpportunity format
                for stock_opp in stock_opps:
                    # Skip if below quality threshold
                    if stock_opp.combined_score < 0.6:
                        continue
                    
                    # Create stock opportunity using MicroOpportunity
                    # Stock opportunities are BUY signals (USD -> Stock)
                    timestamp = time.time()
                    expected_pnl_pct = stock_opp.expected_net_move_pct
                    expected_pnl_usd = cash_amount * (expected_pnl_pct / 100)
                    
                    opportunities.append(MicroOpportunity(
                        timestamp=timestamp,
                        from_asset='USD',
                        to_asset=stock_opp.symbol,
                        from_amount=cash_amount,
                        from_value_usd=cash_amount,
                        v14_score=stock_opp.momentum_score,
                        hub_score=stock_opp.volume_score,
                        commando_score=stock_opp.volatility_score,
                        combined_score=stock_opp.combined_score,
                        expected_pnl_usd=expected_pnl_usd,
                        expected_pnl_pct=expected_pnl_pct,
                        signal_type=stock_opp.signal_type,
                        stock_signal_reasoning=stock_opp.reasoning
                    ))
                
                if stock_opps:
                    logger.info(f"   ğŸ“ˆ STOCK SCAN: Found {len(stock_opps)} stock opportunities (added top {len([o for o in stock_opps if o.combined_score >= 0.6])} to pipeline)")
            
            except Exception as e:
                logger.warning(f"Stock scanner error: {e}")
        
        # Build set of Alpaca-tradeable bases (BTC, ETH, etc)
        alpaca_bases = set()
        for s in symbols:
            if '/' in s:
                base = s.split('/')[0].upper()
            else:
                base = s.replace('USD', '').replace('USDT', '').replace('USDC', '').upper()
            if base:
                alpaca_bases.add(base)
        for s in (self.alpaca_pairs or {}).keys():
            if '/' in s:
                base = s.split('/')[0].upper()
            else:
                base = s.replace('USD', '').replace('USDT', '').replace('USDC', '').upper()
            if base:
                alpaca_bases.add(base)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŸ¡ğŸ™ BINANCE + KRAKEN HEAVY LIFTING - Use caches for full-market data!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        binance_cache = self._read_binance_ws_cache_for_alpaca()
        kraken_cache = self._read_kraken_cache_for_alpaca()  # ğŸ™ 10 extra Alpaca coins!
        
        candidates = []
        seen_bases = set()  # Dedupe across sources
        
        # ğŸŸ¡ BINANCE FIRST (WebSocket = fastest updates)
        if binance_cache:
            # Use Binance data for scanning (FREE and comprehensive!)
            ticker_cache = binance_cache.get('ticker_cache', {})
            prices_from_cache = binance_cache.get('prices', {})
            
            safe_print(f"   ğŸŸ¡ğŸ¦™ BINANCEâ†’ALPACA: Using Binance WS cache ({len(ticker_cache)} tickers) for heavy lifting!")
            
            for key, ticker in ticker_cache.items():
                if not isinstance(ticker, dict):
                    continue
                base = ticker.get('base', '').upper()
                if not base or base not in alpaca_bases:
                    continue  # Only consider Alpaca-tradeable
                
                price = float(ticker.get('price', 0) or 0)
                change_24h = float(ticker.get('change24h', 0) or 0)
                volume = float(ticker.get('volume', 0) or 0)
                
                if price <= 0:
                    continue
                
                # Use Binance 24h change as momentum proxy
                candidates.append({
                    'base': base,
                    'price': price,
                    'change_pct': change_24h,
                    'volume': volume,
                    'source': 'binance_ws',
                })
                seen_bases.add(base)
        
        # ğŸ™ KRAKEN SECOND (10 extra coins not on Binance!)
        if kraken_cache:
            ticker_cache = kraken_cache.get('ticker_cache', {})
            kraken_additions = 0
            
            for key, ticker in ticker_cache.items():
                if key.startswith('kraken:'):
                    continue  # Skip prefixed duplicates
                if not isinstance(ticker, dict):
                    continue
                base = ticker.get('base', '').upper()
                if not base or base not in alpaca_bases:
                    continue  # Only consider Alpaca-tradeable
                if base in seen_bases:
                    continue  # Binance already has this
                
                price = float(ticker.get('price', 0) or 0)
                change_24h = float(ticker.get('change24h', 0) or 0)
                volume = float(ticker.get('volume', 0) or 0)
                
                if price <= 0:
                    continue
                
                candidates.append({
                    'base': base,
                    'price': price,
                    'change_pct': change_24h,
                    'volume': volume,
                    'source': 'kraken_rest',
                })
                seen_bases.add(base)
                kraken_additions += 1
            
            if kraken_additions > 0:
                safe_print(f"   ğŸ™ğŸ¦™ KRAKENâ†’ALPACA: Added {kraken_additions} extra coins (BAT, BCH, GRT, LTC...)")
        
        # Fallback: try Binance REST if no cache
        if not candidates and self.binance:
            try:
                safe_print(f"   ğŸŸ¡ğŸ¦™ BINANCEâ†’ALPACA: WS cache unavailable, using Binance REST...")
                binance_tickers = self.binance.get_24h_tickers() if hasattr(self.binance, 'get_24h_tickers') else []
                for t in binance_tickers or []:
                    symbol = str(t.get('symbol', '')).upper()
                    # Extract base
                    base = None
                    for quote in ['USDT', 'USDC', 'USD', 'BUSD']:
                        if symbol.endswith(quote):
                            base = symbol[:-len(quote)]
                            break
                    if not base or base not in alpaca_bases:
                        continue
                    
                    price = float(t.get('price', t.get('lastPrice', 0)) or 0)
                    change_pct = float(t.get('priceChangePercent', 0) or 0)
                    volume = float(t.get('volume', t.get('quoteVolume', 0)) or 0)
                    
                    if price <= 0:
                        continue
                    
                    candidates.append({
                        'base': base,
                        'price': price,
                        'change_pct': change_pct,
                        'volume': volume,
                        'source': 'binance_rest',
                    })
            except Exception as e:
                logger.debug(f"Binance REST fallback error: {e}")
        
        # Second fallback: use existing momentum data
        if not candidates:
            safe_print(f"   ğŸ¦™ Ocean scanning {len(symbols)} Alpaca symbols (no Binance data)...")
            rising_coins = self.get_strongest_rising(exclude={'USD', 'USDT', 'USDC'}, limit=3000)
            for coin, momentum in rising_coins[:2000]:
                if momentum < 0.01 or coin not in alpaca_bases:
                    continue
                coin_price = self.prices.get(coin, 0)
                if coin_price > 0:
                    candidates.append({
                        'base': coin,
                        'price': coin_price,
                        'change_pct': momentum * 5,  # Rough conversion
                        'volume': 0,
                        'source': 'momentum',
                    })
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ“Š SORT & SCORE CANDIDATES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        candidates.sort(key=lambda x: abs(x.get('change_pct', 0)), reverse=True)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # âœ… ALPACA VALIDATION - Only for TOP candidates (keeps API usage minimal!)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        validate_top_n = int(os.getenv('AUREON_ALPACA_CRYPTO_VALIDATE_TOP_N', '30'))
        validated_count = 0
        
        for cand in candidates[:max(100, validate_top_n * 3)]:
            base = cand['base']
            price = cand['price']
            change_pct = cand.get('change_pct', 0)
            
            # Check if tradeable on Alpaca
            pair_symbol = f"{base}/USD"
            if pair_symbol not in self.alpaca_pairs and f"{base}USD" not in self.alpaca_pairs:
                found = any(base.upper() in s.upper() for s in symbols)
                if not found:
                    continue
            
            # Validate top N with Alpaca quote (others use Binance price)
            if validated_count < validate_top_n and self.alpaca:
                try:
                    if hasattr(self.alpaca, 'get_latest_quotes'):
                        quotes = self.alpaca.get_latest_quotes([pair_symbol])
                        if quotes and pair_symbol in quotes:
                            q = quotes[pair_symbol]
                            bid = float(getattr(q, 'bid_price', 0) or 0)
                            ask = float(getattr(q, 'ask_price', 0) or 0)
                            if bid > 0 and ask > 0:
                                price = (bid + ask) / 2
                                validated_count += 1
                    elif hasattr(self.alpaca, 'get_crypto_quote'):
                        q = self.alpaca.get_crypto_quote(pair_symbol) or {}
                        bid = float(q.get('bp', q.get('bid', 0)) or 0)
                        ask = float(q.get('ap', q.get('ask', 0)) or 0)
                        if bid > 0 and ask > 0:
                            price = (bid + ask) / 2
                            validated_count += 1
                except Exception:
                    pass  # Use Binance price as fallback
            
            # Update prices dict with best available price
            if base not in self.prices or price > 0:
                self.prices[base] = price
            
            # Convert 24h change to momentum-like score
            momentum = abs(change_pct) / 100 / 24 / 60  # Rough %/min
            if momentum < 0.001:
                continue  # Skip if effectively no momentum
            
            # Calculate potential profit
            hold_minutes = 5
            expected_gain_pct = momentum * hold_minutes / 100
            expected_gain_usd = cash_amount * expected_gain_pct
            
            # Alpaca fees (~0.15%)
            fee_pct = 0.0015
            total_fees = cash_amount * fee_pct * 2
            net_profit = expected_gain_usd - total_fees
            
            if net_profit > 0.01:
                opp = MicroOpportunity(
                    from_asset='USD',
                    to_asset=base,
                    from_amount=cash_amount,
                    to_amount=cash_amount / price if price > 0 else 0,
                    expected_pnl_usd=net_profit,
                    combined_score=momentum / 10,
                    opportunity_type='ocean_momentum',
                    source_exchange='alpaca',
                )
                opp.momentum_score = momentum
                opp.ocean_mode = True
                opp.binance_sourced = (cand.get('source', '') in ('binance_ws', 'binance_rest'))
                opp.kraken_sourced = (cand.get('source', '') == 'kraken_rest')
                opportunities.append(opp)
        
        # Summary with source breakdown
        binance_cands = len([c for c in candidates if 'binance' in c.get('source', '')])
        kraken_cands = len([c for c in candidates if c.get('source', '') == 'kraken_rest'])
        safe_print(f"   ğŸŸ¡ğŸ™ğŸ¦™ Multi-sourceâ†’Alpaca: {len(candidates)} total ({binance_cands} Binance + {kraken_cands} Kraken), {validated_count} validated, {len(opportunities)} opportunities")
        
        return opportunities

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸºğŸ¦ğŸœğŸ¦ ANIMAL SWARM SCANNER - Unified Animal Intelligence for Ocean Mode
    # "Wolf hunts alone, Lion coordinates the pride, Ants work in unity, Hummingbird hovers"
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _scan_animal_swarm(self, cash_info: Dict) -> List['MicroOpportunity']:
        """
        ğŸºğŸ¦ğŸœğŸ¦ ANIMAL SWARM SCANNER - Convert Animal Intelligence to MicroOpportunities!
        
        Coordinates the animal swarm (Wolf, Lion, Ants, Hummingbird) to scan for
        momentum opportunities and converts their findings into MicroOpportunity format
        for unified processing in the ocean mode pipeline.
        
        Each animal has its specialty:
        - Wolf: Lone breakout hunter (big moves)
        - Lion: Coordinated pride hunting (trend following)
        - Ants: Army of small trades (micro profits)
        - Hummingbird: Fast hovering (scalping)
        """
        opportunities = []
        cash_amount = cash_info.get('amount', 0)
        
        if not self.animal_swarm or cash_amount < 1:
            return opportunities
        
        try:
            # Run the animal swarm scan
            swarm_results = self.animal_swarm.run_once()
            animal_count = {'wolf': 0, 'lion': 0, 'ants': 0, 'hummingbird': 0}
            
            for agent_name, agent_opps in swarm_results.items():
                for animal_opp in agent_opps:
                    animal_count[agent_name] = animal_count.get(agent_name, 0) + 1
                    
                    # Convert AnimalOpportunity to MicroOpportunity
                    symbol = animal_opp.symbol
                    base = symbol.split('/')[0] if '/' in symbol else symbol.replace('USD', '')
                    
                    # Get price from our cache or the opportunity
                    price = self.prices.get(base, getattr(animal_opp, 'price', 0))
                    if price <= 0:
                        continue
                    
                    # Calculate expected profit based on animal's net_pct
                    net_pct = getattr(animal_opp, 'net_pct', 0) / 100  # Convert to decimal
                    expected_pnl = cash_amount * net_pct
                    
                    if expected_pnl > 0.01:  # Only profitable opportunities
                        # Determine direction - buy for bullish, sell for bearish
                        side = getattr(animal_opp, 'side', 'buy').lower()
                        
                        if side == 'buy':
                            opp = MicroOpportunity(
                                from_asset='USD',
                                to_asset=base,
                                from_amount=cash_amount,
                                to_amount=cash_amount / price,
                                expected_pnl_usd=expected_pnl,
                                combined_score=abs(net_pct) * 10,  # Scale to comparable range
                                opportunity_type=f'animal_{agent_name}',
                                source_exchange='alpaca',
                            )
                        else:  # sell - would need to hold this asset
                            continue  # Skip sells for now (ocean mode is about buying)
                        
                        # Add animal-specific metadata
                        opp.momentum_score = abs(getattr(animal_opp, 'move_pct', 0)) / 60  # Rough %/min
                        opp.ocean_mode = True
                        opp.animal_source = agent_name
                        opp.animal_reason = getattr(animal_opp, 'reason', '')
                        opp.animal_confidence = getattr(animal_opp, 'confidence', 0.5)
                        opportunities.append(opp)
            
            total_animals = sum(animal_count.values())
            if total_animals > 0:
                safe_print(f"   ğŸºğŸ¦ğŸœğŸ¦ Animal Swarm: {total_animals} signals (Wolf:{animal_count['wolf']}, Lion:{animal_count['lion']}, Ants:{animal_count['ants']}, Hummingbird:{animal_count['hummingbird']}) â†’ {len(opportunities)} buy opportunities")
        
        except Exception as e:
            logger.debug(f"Animal swarm scan error: {e}")
        
        return opportunities

    def _validate_with_probability_nexus(self, opportunities: List['MicroOpportunity']) -> List['MicroOpportunity']:
        """
        ğŸ”® PROBABILITY NEXUS VALIDATION - Filter & boost opportunities using the prediction matrix!
        
        Validates ocean opportunities through the probability nexus to:
        1. Filter out low-probability setups (< 50%)
        2. Boost scores for high-probability setups (> 70%)
        3. Add prediction confidence to each opportunity
        
        This ensures we only act on opportunities with validated probability edge.
        """
        if not self.probability_nexus or not opportunities:
            return opportunities
        
        validated = []
        nexus_boosts = 0
        nexus_filters = 0
        
        for opp in opportunities:
            try:
                # Build a market state for the asset
                asset = opp.to_asset
                price = self.prices.get(asset, 0)
                
                if price <= 0:
                    validated.append(opp)  # Pass through if no price data
                    continue
                
                # Try to get prediction from probability nexus
                prediction = None
                if hasattr(self.probability_nexus, 'predict'):
                    # Build minimal market state
                    from aureon_probability_nexus import MarketState
                    state = MarketState(
                        timestamp=datetime.now(),
                        price=price,
                        open_price=price * 0.995,  # Estimate
                        high=price * 1.01,
                        low=price * 0.99,
                        close=price,
                        volume=1000,  # Placeholder
                    )
                    prediction = self.probability_nexus.predict(state)
                
                if prediction:
                    prob = getattr(prediction, 'probability', 0.5)
                    conf = getattr(prediction, 'confidence', 0.5)
                    
                    # Filter low probability (<50%)
                    if prob < 0.5:
                        nexus_filters += 1
                        continue  # Skip this opportunity
                    
                    # Boost high probability (>70%)
                    if prob > 0.7:
                        opp.combined_score *= (1 + (prob - 0.5))  # Up to 50% boost
                        nexus_boosts += 1
                    
                    # Add nexus metadata
                    opp.nexus_probability = prob
                    opp.nexus_confidence = conf
                    opp.nexus_validated = True
                
                validated.append(opp)
                
            except Exception as e:
                logger.debug(f"Probability nexus validation error for {opp.to_asset}: {e}")
                validated.append(opp)  # Pass through on error
        
        if nexus_boosts > 0 or nexus_filters > 0:
            safe_print(f"   ğŸ”® Probability Nexus: {nexus_boosts} boosted, {nexus_filters} filtered â†’ {len(validated)} validated")
        
        return validated

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸŒŠâš¡ğŸ™ğŸŸ¡ ALL SYSTEMS HEAVY LIFTING FOR ALPACA
    # "Every subsystem works in unity - Harmonic, Momentum, HNC, Queen, all serve Alpaca"
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _enhance_with_harmonic_analysis(self, opportunities: List['MicroOpportunity']) -> List['MicroOpportunity']:
        """
        ğŸŒŠ HARMONIC ANALYSIS - Add frequency & coherence signals to opportunities!
        
        Uses the Harmonic Fusion system to analyze wave patterns and boost
        opportunities that align with golden zone frequencies (400-520 Hz).
        """
        if not self.harmonic or not opportunities:
            return opportunities
        
        enhanced = []
        harmonic_boosts = 0
        
        for opp in opportunities:
            try:
                asset = opp.to_asset
                
                # Get harmonic analysis if we have price history
                if hasattr(self.harmonic, 'analyze') and asset in self.prices:
                    # Try to get recent prices for this asset
                    price_history = getattr(self, 'price_histories', {}).get(asset, [])
                    if len(price_history) >= 10:
                        freq, coherence, phase = self.harmonic.analyze(price_history[-64:])
                        
                        # Golden zone: 400-520 Hz
                        in_golden_zone = 400 <= freq <= 520
                        high_coherence = coherence >= 0.7
                        
                        if in_golden_zone and high_coherence:
                            opp.combined_score *= 1.3  # 30% boost
                            harmonic_boosts += 1
                        elif high_coherence:
                            opp.combined_score *= 1.15  # 15% boost
                            harmonic_boosts += 1
                        
                        # Add harmonic metadata
                        opp.harmonic_frequency = freq
                        opp.harmonic_coherence = coherence
                        opp.harmonic_phase = phase
                        opp.harmonic_golden_zone = in_golden_zone
                
                enhanced.append(opp)
                
            except Exception as e:
                logger.debug(f"Harmonic analysis error for {opp.to_asset}: {e}")
                enhanced.append(opp)
        
        if harmonic_boosts > 0:
            safe_print(f"   ğŸŒŠ Harmonic Analysis: {harmonic_boosts} opportunities in golden zone/high coherence")
        
        return enhanced

    def _enhance_with_momentum_tracker(self, opportunities: List['MicroOpportunity']) -> List['MicroOpportunity']:
        """
        âš¡ MOMENTUM TRACKER - Add real-time momentum signals to opportunities!
        
        Uses the momentum tracker to identify assets with strong directional moves
        and boosts opportunities that align with momentum.
        """
        if not self.momentum_tracker or not opportunities:
            return opportunities
        
        enhanced = []
        momentum_boosts = 0
        
        for opp in opportunities:
            try:
                asset = opp.to_asset
                
                # Get momentum data if available
                if hasattr(self.momentum_tracker, 'get_momentum'):
                    momentum_data = self.momentum_tracker.get_momentum(asset)
                    if momentum_data:
                        momentum_pct = momentum_data.get('momentum_pct', 0)
                        trend_strength = momentum_data.get('trend_strength', 0)
                        
                        # Strong upward momentum for buy opportunities
                        if momentum_pct > 0.5 and trend_strength > 0.6:
                            opp.combined_score *= 1.25  # 25% boost
                            momentum_boosts += 1
                        elif momentum_pct > 0.2:
                            opp.combined_score *= 1.1  # 10% boost
                        
                        # Add momentum metadata
                        opp.tracker_momentum_pct = momentum_pct
                        opp.tracker_trend_strength = trend_strength
                
                enhanced.append(opp)
                
            except Exception as e:
                logger.debug(f"Momentum tracker error for {opp.to_asset}: {e}")
                enhanced.append(opp)
        
        if momentum_boosts > 0:
            safe_print(f"   âš¡ Momentum Tracker: {momentum_boosts} opportunities with strong momentum")
        
        return enhanced

    def _enhance_with_hnc_matrix(self, opportunities: List['MicroOpportunity']) -> List['MicroOpportunity']:
        """
        ğŸ“Š HNC MATRIX - Add pattern recognition signals to opportunities!
        
        Uses the HNC (Harmonic Neural Coherence) matrix for pattern matching
        and boosts opportunities that match profitable historical patterns.
        """
        if not self.hnc_matrix or not opportunities:
            return opportunities
        
        enhanced = []
        hnc_boosts = 0
        
        for opp in opportunities:
            try:
                asset = opp.to_asset
                
                # Get HNC pattern match if available
                if hasattr(self.hnc_matrix, 'match_pattern') or hasattr(self.hnc_matrix, 'get_signal'):
                    pattern_score = 0.5  # Default neutral
                    
                    if hasattr(self.hnc_matrix, 'get_signal'):
                        signal = self.hnc_matrix.get_signal(asset)
                        if signal:
                            pattern_score = getattr(signal, 'confidence', 0.5)
                    elif hasattr(self.hnc_matrix, 'match_pattern'):
                        match = self.hnc_matrix.match_pattern(asset)
                        if match:
                            pattern_score = match.get('score', 0.5)
                    
                    # Strong pattern match
                    if pattern_score > 0.75:
                        opp.combined_score *= 1.2  # 20% boost
                        hnc_boosts += 1
                    elif pattern_score > 0.6:
                        opp.combined_score *= 1.1  # 10% boost
                    
                    # Add HNC metadata
                    opp.hnc_pattern_score = pattern_score
                
                enhanced.append(opp)
                
            except Exception as e:
                logger.debug(f"HNC matrix error for {opp.to_asset}: {e}")
                enhanced.append(opp)
        
        if hnc_boosts > 0:
            safe_print(f"   ğŸ“Š HNC Matrix: {hnc_boosts} opportunities with strong pattern match")
        
        return enhanced

    def _enhance_with_queen_guidance(self, opportunities: List['MicroOpportunity']) -> List['MicroOpportunity']:
        """
        ğŸ‘‘ QUEEN GUIDANCE - Add Queen Hive Mind intelligence to opportunities!
        
        Consults the Queen for each opportunity to get confidence boost/penalty
        based on her neural network and accumulated wisdom.
        """
        if not self.queen or not opportunities:
            return opportunities
        
        enhanced = []
        queen_approvals = 0
        queen_cautions = 0
        
        for opp in opportunities:
            try:
                asset = opp.to_asset
                
                # Ask Queen for guidance
                if hasattr(self.queen, 'ask_queen_will_we_win'):
                    guidance = self.queen.ask_queen_will_we_win(
                        asset=asset,
                        exchange='alpaca',
                        opportunity_score=opp.combined_score,
                        context={
                            'momentum': getattr(opp, 'momentum_score', 0),
                            'source': getattr(opp, 'opportunity_type', 'unknown'),
                            'ocean_mode': True
                        }
                    )
                    
                    if guidance:
                        confidence = getattr(guidance, 'confidence', 0.5)
                        recommendation = getattr(guidance, 'recommendation', 'hold')
                        
                        # Queen approves
                        if confidence > 0.7 and recommendation in ('buy', 'strong_buy', 'proceed'):
                            opp.combined_score *= 1.35  # 35% boost from Queen!
                            queen_approvals += 1
                        # Queen cautions
                        elif confidence < 0.4 or recommendation in ('avoid', 'caution', 'wait'):
                            opp.combined_score *= 0.7  # 30% penalty
                            queen_cautions += 1
                        
                        # Add Queen metadata
                        opp.queen_confidence = confidence
                        opp.queen_recommendation = recommendation
                
                enhanced.append(opp)
                
            except Exception as e:
                logger.debug(f"Queen guidance error for {opp.to_asset}: {e}")
                enhanced.append(opp)
        
        if queen_approvals > 0 or queen_cautions > 0:
            safe_print(f"   ğŸ‘‘ Queen Guidance: {queen_approvals} approved, {queen_cautions} cautioned")
        
        return enhanced

    def _all_systems_heavy_lift_for_alpaca(self, opportunities: List['MicroOpportunity']) -> List['MicroOpportunity']:
        """
        ğŸš€ ALL SYSTEMS HEAVY LIFTING FOR ALPACA ğŸš€
        
        Pipeline that runs ALL subsystems to enhance opportunities:
        1. Harmonic Analysis (frequency/coherence)
        2. Momentum Tracker (real-time momentum)
        3. HNC Matrix (pattern recognition)
        4. Queen Guidance (neural intelligence)
        5. Final sort by enhanced scores
        
        This is the UNIFIED intelligence pipeline where every system
        serves Alpaca execution with their specialized analysis!
        """
        if not opportunities:
            return opportunities
        
        safe_print(f"   ğŸš€ ALL SYSTEMS HEAVY LIFTING: Processing {len(opportunities)} opportunities...")
        
        # Stage 1: Harmonic Analysis
        opportunities = self._enhance_with_harmonic_analysis(opportunities)
        
        # Stage 2: Momentum Tracker
        opportunities = self._enhance_with_momentum_tracker(opportunities)
        
        # Stage 3: HNC Matrix Pattern Recognition
        opportunities = self._enhance_with_hnc_matrix(opportunities)
        
        # Stage 4: Queen Guidance
        opportunities = self._enhance_with_queen_guidance(opportunities)
        
        # Final sort by enhanced combined_score
        opportunities.sort(key=lambda x: x.combined_score, reverse=True)
        
        return opportunities

    def advance_turn(self):
        """Move to the next exchange's turn."""
        connected = [ex for ex in self.exchange_order 
                     if self.exchange_data.get(ex, {}).get('connected', False)]
        if connected:
            self.current_exchange_index = (self.current_exchange_index + 1) % len(connected)
        self.turns_completed += 1
        
        # ğŸŒŸ Update barter_matrix turn counter for second chances
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            self.barter_matrix.current_turn = self.turns_completed
        
        # ğŸ‘‘ğŸ“Š Feed Queen metrics to HNC Matrix every turn!
        if self.queen and self.hnc_matrix and hasattr(self.hnc_matrix, 'feed_queen_metrics'):
            try:
                if hasattr(self.queen, 'get_all_queen_metrics'):
                    metrics = self.queen.get_all_queen_metrics()
                    self.hnc_matrix.feed_queen_metrics(metrics)
            except Exception as e:
                logger.debug(f"Queen metrics feed error: {e}")
    
    def get_turn_display(self) -> str:
        """Get a display string showing current turn status."""
        current = self.get_current_exchange()
        if not current:
            return "No exchanges"
        
        icons = {'kraken': 'ğŸ™', 'alpaca': 'ğŸ¦™', 'binance': 'ğŸŸ¡'}
        turn_markers = []
        
        for ex in self.exchange_order:
            if self.exchange_data.get(ex, {}).get('connected', False):
                icon = icons.get(ex, 'ğŸ“Š')
                if ex == current:
                    turn_markers.append(f"[{icon}]")  # Current turn
                else:
                    turn_markers.append(f" {icon} ")  # Waiting
            else:
                turn_markers.append("  âŒ  ")  # Not connected
        
        return "".join(turn_markers)
    
    def get_exchange_assets(self, exchange: str) -> Dict[str, float]:
        """Get assets held on a specific exchange."""
        return self.exchange_balances.get(exchange, {})
    
    async def refresh_exchange_balances(self, exchange: str):
        """Refresh balances for a specific exchange to ensure fresh data."""
        if exchange == 'kraken' and self.kraken:
            try:
                kraken_bal = {}
                if hasattr(self.kraken, 'get_account_balance'):
                    raw = self.kraken.get_account_balance() or {}
                    for asset, amount in raw.items():
                        try:
                            amount = float(amount)
                        except (ValueError, TypeError):
                            continue
                        if amount > 0:
                            clean = asset
                            if len(asset) == 4 and asset[0] in ('X', 'Z'):
                                clean = asset[1:]
                            if clean == 'XBT':
                                clean = 'BTC'
                            kraken_bal[clean] = amount
                self.exchange_balances['kraken'] = kraken_bal
                if 'kraken' in self.exchange_data:
                    self.exchange_data['kraken']['balances'] = kraken_bal
            except Exception as e:
                logger.error(f"Kraken refresh error: {e}")

        elif exchange == 'binance' and self.binance:
            try:
                binance_bal = {}
                if hasattr(self.binance, 'account'):
                    acct = self.binance.account() or {}
                    for bal in acct.get('balances', []):
                        asset = bal.get('asset', '')
                        free = float(bal.get('free', 0))
                        if free > 0 and asset:
                            binance_bal[asset] = free
                self.exchange_balances['binance'] = binance_bal
                if 'binance' in self.exchange_data:
                    self.exchange_data['binance']['balances'] = binance_bal
            except Exception as e:
                logger.error(f"Binance refresh error: {e}")

        elif exchange == 'alpaca' and self.alpaca:
            try:
                alpaca_bal = {}
                if hasattr(self.alpaca, 'get_account'):
                    acct = self.alpaca.get_account() or {}
                    cash = float(acct.get('cash', 0))
                    if cash > 0:
                        alpaca_bal['USD'] = cash
                
                if hasattr(self.alpaca, 'get_positions'):
                    positions = self.alpaca.get_positions() or []
                    for pos in positions:
                        raw_symbol = pos.get('symbol', '')
                        qty = float(pos.get('qty', 0))
                        if qty > 0 and raw_symbol:
                            if '/' in raw_symbol:
                                base_asset = raw_symbol.split('/')[0]
                            elif raw_symbol.endswith('USD'):
                                base_asset = raw_symbol[:-3]
                            elif raw_symbol.endswith('BTC'):
                                base_asset = raw_symbol[:-3]
                            else:
                                base_asset = raw_symbol
                            alpaca_bal[base_asset] = qty
                
                self.exchange_balances['alpaca'] = alpaca_bal
                if 'alpaca' in self.exchange_data:
                    self.exchange_data['alpaca']['balances'] = alpaca_bal
            except Exception as e:
                logger.error(f"Alpaca refresh error: {e}")

        # Rebuild combined balances
        self.balances = {}
        for ex_bals in self.exchange_balances.values():
            for asset, amount in ex_bals.items():
                self.balances[asset] = self.balances.get(asset, 0) + amount

    async def _attempt_liquidity_aggregation(
        self,
        target_asset: str,
        target_exchange: str,
        shortfall_usd: float,
        expected_profit_pct: float = 0.01,
    ) -> bool:
        """
        ğŸ’§ğŸ”€ ATTEMPT LIQUIDITY AGGREGATION
        
        When we need more funds to execute a trade, try to liquidate other assets
        to "top up" the target asset. Only proceeds if profitable after fees.
        
        Args:
            target_asset: The asset we need more of (e.g., 'ETH')
            target_exchange: Exchange where we need the funds
            shortfall_usd: How much USD value we need to add
            expected_profit_pct: Expected profit from the target trade
            
        Returns:
            True if aggregation was successful and we now have enough funds
        """
        safe_print(f"\n   ğŸ’§ğŸ”€ LIQUIDITY AGGREGATION ATTEMPT")
        safe_print(f"   ğŸ¯ Need ${shortfall_usd:.2f} more {target_asset} on {target_exchange}")
        
        # Don't aggregate for tiny amounts - not worth the fees
        if shortfall_usd < 1.0:
            safe_print(f"   âŒ Shortfall ${shortfall_usd:.2f} too small to aggregate")
            return False
        
        # Create aggregation plan
        plan = self.liquidity_engine.create_aggregation_plan(
            target_asset=target_asset,
            target_exchange=target_exchange,
            amount_needed_usd=shortfall_usd * 1.2,  # 20% buffer
            expected_profit_pct=expected_profit_pct,
            exchange_balances=self.exchange_balances,
            prices=self.prices,
            momentum=self.asset_momentum,
        )
        
        if not plan:
            safe_print(f"   âŒ No aggregation plan available (no suitable victims)")
            return False
        
        # Print the plan
        safe_print(self.liquidity_engine.print_aggregation_plan(plan))
        
        if not plan.is_profitable:
            safe_print(f"   âŒ Aggregation not profitable (fees ${plan.total_fees_usd:.4f} > profit)")
            return False
        
        # Execute the plan!
        safe_print(f"\n   ğŸš€ EXECUTING AGGREGATION PLAN...")
        
        success_count = 0
        total_received = 0.0
        
        for step in plan.steps:
            if step['action'] == 'SELL':
                victim_asset = step['asset']
                victim_amount = step['amount']
                victim_exchange = step['exchange']
                
                safe_print(f"   ğŸ“¤ SELL: {victim_amount:.6f} {victim_asset} on {victim_exchange}")
                
                # Execute the liquidation based on exchange
                sell_success = False
                received_usd = 0.0
                
                try:
                    if victim_exchange == 'kraken' and self.kraken:
                        # Sell to USD/ZUSD on Kraken
                        result = self.kraken.place_market_order(
                            symbol=f"{victim_asset}USD",
                            side='sell',
                            volume=victim_amount
                        )
                        if result and 'error' not in str(result).lower():
                            sell_success = True
                            received_usd = step['expected_usd'] * 0.97  # Estimate
                            
                    elif victim_exchange == 'binance' and self.binance:
                        # Sell to USDC on Binance (UK mode) or USDT
                        quote = 'USDC' if self.binance_uk_mode else 'USDT'
                        result = self.binance.place_market_order(
                            symbol=f"{victim_asset}{quote}",
                            side='SELL',
                            quantity=victim_amount
                        )
                        if result and result.get('status') == 'FILLED':
                            sell_success = True
                            received_usd = float(result.get('cummulativeQuoteQty', step['expected_usd'] * 0.97))
                            
                    elif victim_exchange == 'alpaca' and self.alpaca:
                        # ğŸ”’ Check Alpaca verify-only gate
                        if self.alpaca_verify_only:
                            safe_print(f"   ğŸ”’ ALPACA VERIFY-ONLY: Skipping SELL {victim_asset} (set ALPACA_EXECUTE=true to enable)")
                            continue
                        # Sell to USD on Alpaca
                        result = self.alpaca.place_order(
                            symbol=f"{victim_asset}/USD",
                            side='sell',
                            qty=victim_amount,
                            type='market'
                        )
                        if result:
                            sell_success = True
                            received_usd = step['expected_usd'] * 0.97
                            
                except Exception as e:
                    safe_print(f"   âŒ SELL failed for {victim_asset}: {e}")
                    sell_success = False
                
                if sell_success:
                    success_count += 1
                    total_received += received_usd
                    safe_print(f"   âœ… SOLD {victim_asset} â†’ ${received_usd:.2f}")
                    
                    # Record liquidation for cooldown
                    self.liquidity_engine.record_liquidation(victim_asset)
                else:
                    safe_print(f"   âŒ SELL failed for {victim_asset}")
                    # Continue trying other victims
            
            elif step['action'] == 'BUY':
                # Now buy the target asset with our accumulated USD
                if total_received < 1.0:
                    safe_print(f"   âŒ Not enough funds received (${total_received:.2f}) to buy {target_asset}")
                    continue
                
                safe_print(f"   ğŸ“¥ BUY: ${total_received:.2f} worth of {target_asset} on {target_exchange}")
                
                buy_success = False
                try:
                    if target_exchange == 'kraken' and self.kraken:
                        # Buy target with USD
                        target_price = self.prices.get(target_asset, 1.0)
                        buy_amount = (total_received * 0.98) / target_price  # 2% buffer
                        result = self.kraken.place_market_order(
                            symbol=f"{target_asset}USD",
                            side='buy',
                            volume=buy_amount
                        )
                        if result and 'error' not in str(result).lower():
                            buy_success = True
                            
                    elif target_exchange == 'binance' and self.binance:
                        quote = 'USDC' if self.binance_uk_mode else 'USDT'
                        target_price = self.prices.get(target_asset, 1.0)
                        buy_amount = (total_received * 0.98) / target_price
                        result = self.binance.place_market_order(
                            symbol=f"{target_asset}{quote}",
                            side='BUY',
                            quantity=buy_amount
                        )
                        if result and result.get('status') == 'FILLED':
                            buy_success = True
                            
                    elif target_exchange == 'alpaca' and self.alpaca:
                        # ğŸ”’ Check Alpaca verify-only gate
                        if self.alpaca_verify_only:
                            safe_print(f"   ğŸ”’ ALPACA VERIFY-ONLY: Skipping BUY {target_asset} (set ALPACA_EXECUTE=true to enable)")
                            continue
                        target_price = self.prices.get(target_asset, 1.0)
                        buy_amount = (total_received * 0.98) / target_price
                        result = self.alpaca.place_order(
                            symbol=f"{target_asset}/USD",
                            side='buy',
                            qty=buy_amount,
                            type='market'
                        )
                        if result:
                            buy_success = True
                            
                except Exception as e:
                    safe_print(f"   âŒ BUY failed for {target_asset}: {e}")
                    buy_success = False
                
                if buy_success:
                    success_count += 1
                    safe_print(f"   âœ… BOUGHT {target_asset}")
                    
                    # Update stats
                    self.liquidity_engine.executed_aggregations += 1
                    self.liquidity_engine.total_aggregation_profit += plan.profit_after_fees
                else:
                    safe_print(f"   âŒ BUY failed for {target_asset}")
        
        # Final success check
        if success_count > 0:
            safe_print(f"\n   ğŸ’§ AGGREGATION COMPLETE: {success_count} steps executed")
            return True
        else:
            safe_print(f"\n   âŒ AGGREGATION FAILED: No steps completed")
            return False

    async def harvest_profitable_positions(self) -> Dict[str, Any]:
        """
        ğŸŒ¾ğŸ’° HARVEST PROFITABLE POSITIONS - Sell positions in profit to get cash!
        
        This is the KEY to proactive portfolio management:
        1. Scan Alpaca positions for unrealized profits
        2. Sell profitable positions to realize gains
        3. Cash becomes available for new opportunity buys
        
        Returns:
            Dict with harvest results
        """
        result = {
            'harvested': False,
            'positions_sold': 0,
            'total_profit_harvested': 0.0,
            'cash_generated': 0.0,
            'candidates_found': 0,
        }
        
        # Only works with Alpaca
        if not self.alpaca:
            return result
            
        try:
            # Get current positions with P&L data
            positions = self.alpaca.get_positions() or []
            
            if not positions:
                return result
            
            # Find harvest candidates
            candidates = self.profit_harvester.find_harvest_candidates(positions)
            result['candidates_found'] = len(candidates)
            
            if not candidates:
                return result
            
            safe_print(f"\n{'='*60}")
            safe_print(f"ğŸŒ¾ğŸ’° PROFIT HARVESTER - Scanning Portfolio for Profits...")
            safe_print(f"{'='*60}")
            safe_print(self.profit_harvester.print_candidates(candidates))
            
            # Harvest up to a few profitable candidates - avoid over-trading
            max_harvests = 3  # Limit number of harvests per sweep to reduce churn
            harvests_done = 0
            
            for candidate in candidates[:max_harvests]:
                safe_print(f"\n   ğŸŒ¾ HARVESTING: {candidate.asset}")
                safe_print(f"      Position: {candidate.qty:.6f} @ ${candidate.current_price:.4f} = ${candidate.market_value:.2f}")
                safe_print(f"      Profit: ${candidate.unrealized_pl:+.2f} ({candidate.unrealized_plpc:+.1f}%)")
                
                # ğŸ”’ Check Alpaca verify-only gate
                if self.alpaca_verify_only:
                    safe_print(f"      ğŸ”’ ALPACA VERIFY-ONLY: Skipping harvest (set ALPACA_EXECUTE=true to enable)")
                    continue
                
                # Sell the position
                try:
                    # Sell ALL of this position to realize full profit
                    sell_result = self.alpaca.place_order(
                        symbol=candidate.symbol if '/' in candidate.symbol else f"{candidate.asset}/USD",
                        side='sell',
                        qty=candidate.qty,
                        type='market'
                    )
                    
                    if sell_result:
                        # Record the harvest
                        self.profit_harvester.record_harvest(candidate.asset, candidate.unrealized_pl)
                        
                        result['positions_sold'] += 1
                        result['total_profit_harvested'] += candidate.unrealized_pl
                        result['cash_generated'] += candidate.market_value
                        harvests_done += 1
                        
                        safe_print(f"      âœ… SOLD! Profit: ${candidate.unrealized_pl:.2f} â†’ Cash: ${candidate.market_value:.2f}")
                        
                        # Log to trading log
                        logger.info(f"ğŸŒ¾ğŸ’° HARVESTED: {candidate.asset} | Profit: ${candidate.unrealized_pl:.2f} | Cash: ${candidate.market_value:.2f}")
                        
                        # Update local balance tracking
                        if 'alpaca' in self.exchange_balances:
                            self.exchange_balances['alpaca'].pop(candidate.asset, None)
                            self.exchange_balances['alpaca']['USD'] = self.exchange_balances['alpaca'].get('USD', 0) + candidate.market_value
                        
                    else:
                        safe_print(f"      âŒ SELL failed - no result returned")
                        
                except Exception as e:
                    safe_print(f"      âŒ SELL failed: {e}")
                    logger.error(f"Harvest sell failed for {candidate.asset}: {e}")
                    continue
            
            if harvests_done > 0:
                result['harvested'] = True
                safe_print(f"\n   ğŸŒ¾âœ… HARVEST COMPLETE: {harvests_done} positions sold")
                safe_print(f"       ğŸ’µ Profit realized: ${result['total_profit_harvested']:.4f}")
                safe_print(f"       ğŸ’° Cash generated: ${result['cash_generated']:.2f}")
                safe_print(f"       ğŸ”„ CONSTANT CASH FLOW: +${result['cash_generated']:.2f} available for new trades!")
                
                # Track total harvested for session
                logger.info(f"ğŸŒ¾ğŸ’° CASH FLOW: Session total harvested: ${self.profit_harvester.harvested_total:.2f} from {self.profit_harvester.harvest_count} sales")
                
                # Refresh balances after harvesting
                await self.fetch_balances()
            else:
                safe_print(f"\n   ğŸŒ¾ No profitable positions yet - HODL until green!")
                
        except Exception as e:
            logger.error(f"Profit harvester error: {e}")
            safe_print(f"   âŒ Harvest error: {e}")
        
        return result

    async def report_portfolio_to_queen(self, voice_enabled: bool = True) -> Dict[str, Any]:
        """
        ğŸ‘‘ğŸ’° REPORT PORTFOLIO TO QUEEN - Feed her the revenue data!
        
        Gathers portfolio performance from all exchanges and feeds it to the Queen.
        The Queen reviews the data and speaks her verdict with her VOICE!
        
        Args:
            voice_enabled: Whether the Queen should speak aloud (TTS)
        
        Returns:
            Portfolio data dict with Queen's verdict
        """
        portfolio_data = {
            'kraken': {'value': 0.0, 'profit': 0.0, 'trades': 0, 'win_rate': 0.0},
            'binance': {'value': 0.0, 'profit': 0.0, 'trades': 0, 'win_rate': 0.0},
            'alpaca': {'value': 0.0, 'profit': 0.0, 'trades': 0, 'win_rate': 0.0},
            'total_value': 0.0,
            'total_profit': 0.0,
            'total_trades': 0
        }
        
        safe_print("\nğŸ‘‘ğŸ’° â•â•â• PORTFOLIO REPORT FOR THE QUEEN â•â•â•")
        
        # Gather data from each exchange
        for exchange in ['kraken', 'binance', 'alpaca']:
            ex_stats = self.exchange_stats.get(exchange, {})
            ex_balances = self.exchange_balances.get(exchange, {})
            
            # Calculate exchange value
            ex_value = 0.0
            for asset, amount in ex_balances.items():
                if asset in ('USD', 'USDT', 'USDC', 'ZUSD'):
                    ex_value += amount
                else:
                    price = self.prices.get(asset, 0)
                    ex_value += amount * price
            
            # Get profit and trade stats
            ex_profit = ex_stats.get('profit', 0.0)
            ex_trades = ex_stats.get('conversions', 0)
            
            # Calculate win rate from barter history for this exchange
            wins = 0
            total = 0
            for (from_a, to_a), hist in self.barter_matrix.barter_history.items():
                # Attribute to exchange based on source exchange tracking
                total += hist.get('trades', 0)
                wins += hist.get('wins', 0)
            
            win_rate = wins / total if total > 0 else 0.5
            
            portfolio_data[exchange] = {
                'value': ex_value,
                'profit': ex_profit,
                'trades': ex_trades,
                'win_rate': win_rate
            }
            
            portfolio_data['total_value'] += ex_value
            portfolio_data['total_profit'] += ex_profit
            portfolio_data['total_trades'] += ex_trades
            
            # Icon display
            icon = {'kraken': 'ğŸ™', 'binance': 'ğŸ”¶', 'alpaca': 'ğŸ¦™'}[exchange]
            profit_icon = 'ğŸ“ˆ' if ex_profit >= 0 else 'ğŸ“‰'
            safe_print(f"   {icon} {exchange.upper()}: ${ex_value:.2f} | {profit_icon} ${ex_profit:+.4f} | {ex_trades} trades")
        
        safe_print(f"   ğŸ’° TOTAL: ${portfolio_data['total_value']:.2f} | P/L: ${portfolio_data['total_profit']:+.4f}")
        
        # Feed to the Queen!
        if self.queen:
            try:
                # Have the Queen review and speak!
                if hasattr(self.queen, 'announce_portfolio_status'):
                    verdict = self.queen.announce_portfolio_status(portfolio_data)
                    portfolio_data['queen_verdict'] = verdict
                
                # Get Queen's trading guidance
                if hasattr(self.queen, 'get_trading_guidance'):
                    guidance = self.queen.get_trading_guidance()
                    if isinstance(guidance, dict):
                        portfolio_data['queen_guidance'] = guidance

                        # Apply guidance to position sizing
                        self.queen_position_multiplier = guidance.get('recommended_position_size', 1.0)
                        safe_print(f"   ğŸ‘‘ Queen's Position Multiplier: {self.queen_position_multiplier:.1f}x")
                    else:
                        # Defensive: some implementations may return a list/tuple/None
                        portfolio_data['queen_guidance'] = {}
                        logger.warning(
                            f"Queen trading guidance was {type(guidance).__name__}, expected dict; ignoring"
                        )
                
                # Review each exchange
                if hasattr(self.queen, 'review_exchange_performance'):
                    for exchange in ['kraken', 'binance', 'alpaca']:
                        ex_data = portfolio_data.get(exchange, {})
                        # ğŸ‘‘ QUEEN SELF-REPAIR: Ensure ex_data is a dict (auto-fix type errors)
                        if isinstance(ex_data, list):
                            # Convert list to dict - Queen learns from type mismatches
                            ex_data = {'items': ex_data, 'type_corrected': True}
                            portfolio_data[exchange] = ex_data
                            logger.debug(f"Queen auto-corrected {exchange} data from list to dict")
                        elif not isinstance(ex_data, dict):
                            ex_data = {'value': ex_data, 'type_corrected': True}
                            portfolio_data[exchange] = ex_data
                        verdict, action = self.queen.review_exchange_performance(exchange, ex_data)
                        # ğŸ‘‘ SAFE ASSIGNMENT: Only if we have a valid dict
                        if isinstance(portfolio_data.get(exchange), dict):
                            portfolio_data[exchange]['queen_verdict'] = verdict
                            portfolio_data[exchange]['queen_action'] = action
                        safe_print(f"   ğŸ‘‘ {exchange.upper()}: {action}")
                
            except Exception as e:
                logger.error(f"Queen portfolio review error: {e}")
        
        safe_print("â•" * 50)
        
        return portfolio_data

    async def execute_turn(self) -> Tuple[List['MicroOpportunity'], int]:
        """
        Execute one turn for the current exchange.
        Returns (opportunities found, conversions made this turn)
        """
        current_exchange = self.get_current_exchange()
        if not current_exchange:
            return [], 0
        
        icons = {'kraken': 'ğŸ™', 'alpaca': 'ğŸ¦™', 'binance': 'ğŸŸ¡'}
        icon = icons.get(current_exchange, 'ğŸ“Š')
        
        safe_print(f"\nğŸ¯ â•â•â• TURN {self.turns_completed + 1}: {icon} {current_exchange.upper()} â•â•â•")
        
        # ï¿½ğŸ’° PROFIT HARVESTER - Check portfolio for harvestable profits!
        # Run every N turns on Alpaca to realize gains and get trading cash
        self.turns_since_harvest += 1
        if current_exchange == 'alpaca' and self.turns_since_harvest >= self.harvest_interval:
            try:
                harvest_result = await self.harvest_profitable_positions()
                if harvest_result.get('harvested'):
                    safe_print(f"   ğŸŒ¾âœ… Harvested ${harvest_result['total_profit_harvested']:.2f} profit â†’ ${harvest_result['cash_generated']:.2f} cash")
                elif harvest_result.get('candidates_found', 0) > 0:
                    safe_print(f"   ğŸŒ¾ {harvest_result['candidates_found']} harvest candidates found (checking thresholds...)")
                self.turns_since_harvest = 0
            except Exception as e:
                logger.debug(f"Harvest check error: {e}")
        
        # ï¿½ğŸŒŠâš¡ MOMENTUM WAVE CHECK - Look for wave jumping opportunities
        momentum_opp = self.find_momentum_opportunity()
        if momentum_opp:
            from_asset, to_asset, from_amount, net_adv, mom_diff = momentum_opp
            safe_print(f"   ğŸŒŠ WAVE DETECTED: {from_asset}â†’{to_asset} | Momentum diff: {mom_diff*100:.2f}%/min")
        
        # ğŸ¦ LION HUNT - Stablecoins hunt for waves! (NOW 10x MORE AGGRESSIVE!)
        lion_hunts = self.lion_hunt(min_wave_momentum=MIN_MOMENTUM_TO_HUNT)  # Was 0.001, now 0.0001!
        
        # ğŸº WOLF HUNT - Find THE ONE momentum champion!
        self._wolf_target_cache = self.wolf_hunt(verbose=True)
        wolf_target = self._wolf_target_cache
        
        # ğŸœ ANT SCRAPS - Collect small floor positions
        ant_scraps = self.ant_scraps(min_value=1.0)
        
        # ğŸ¾âš¡ ANIMAL PACK SCAN - 14 hunters detect different market signals!
        if hasattr(self, 'animal_pack_scanner') and self.animal_pack_scanner:
            try:
                # Prepare momentum data from asset_momentum
                momentum_data = {
                    asset: {'change': mom / 100, 'price': self.prices.get(asset, 0)}
                    for asset, mom in self.asset_momentum.items()
                }
                self.animal_pack_scanner.update_momentum_data(momentum_data)
                
                # Get best momentum for Falcon/Cargo/Lion
                best_momentum = None
                if wolf_target:
                    best_momentum = (wolf_target[0], wolf_target[1] * 100)  # Convert to %
                
                # Get volume data from ticker cache
                volume_data = {}
                for sym, data in self.ticker_cache.items():
                    base = data.get('base', '')
                    if base:
                        volume_data[base] = data.get('volume', 0) * data.get('price', 1)
                
                # Get golden paths from path memory
                golden_paths = []
                if self.path_memory:
                    for (src, tgt), stats in self.path_memory.memory.items():
                        if stats.get('wins', 0) > stats.get('losses', 0):
                            golden_paths.append(f"{src}->{tgt}")
                
                # RUN ALL HUNTERS!
                pack_results = self.animal_pack_scanner.scan_all(
                    best_momentum=best_momentum,
                    volume_data=volume_data,
                    entries=getattr(self, 'entries', {}),
                    golden_paths=golden_paths
                )
                
                # Show pack report (every turn - this is valuable intel!)
                total_signals = sum(len(sigs) for sigs in pack_results.values())
                if total_signals > 0:
                    pack_consensus, _, strongest = self.animal_pack_scanner.get_pack_consensus()
                    safe_print(f"   ğŸ¾âš¡ ANIMAL PACK: {total_signals} signals | Consensus: {pack_consensus:.2f} | Leader: {strongest}")
                    
                    # Apply WINNER_ENERGY_MULTIPLIER if pack consensus is strong
                    if pack_consensus > 0.6 and hasattr(self, '_current_opportunity_boost'):
                        self._current_opportunity_boost = WINNER_ENERGY_MULTIPLIER
                        safe_print(f"   ğŸ¦âš¡ WINNER ENERGY: {WINNER_ENERGY_MULTIPLIER}x boost applied!")
            except Exception as e:
                safe_print(f"   âš ï¸ Animal Pack scan error: {e}")
        
        # ğŸ¦†âš”ï¸ QUACK COMMANDOS STATUS (every 20 turns)
        if self.turns_completed > 0 and self.turns_completed % 20 == 0 and self.quack_commandos:
            safe_print(self.quack_commandos.get_status())
        
        # ğŸ‘‘ğŸ’° PERIODIC PORTFOLIO REPORT TO QUEEN (every 10 turns)
        if self.turns_completed > 0 and self.turns_completed % 10 == 0:
            await self.report_portfolio_to_queen(voice_enabled=True)
        
        # ğŸ§¹ DUST SWEEP - Clean up small balances (every N turns)
        if self.dust_converter and self.turns_completed > 0 and self.turns_completed % self.dust_sweep_interval == 0:
            try:
                dust_swept = await self.dust_sweep()
                if dust_swept > 0:
                    # Refresh balances after sweeping
                    await self.refresh_exchange_balances(current_exchange)
            except Exception as e:
                safe_print(f"   âš ï¸ Dust sweep error: {e}")
        
        # REFRESH BALANCES FOR THIS EXCHANGE
        await self.refresh_exchange_balances(current_exchange)
        
        # Get this exchange's assets only
        exchange_assets = self.get_exchange_assets(current_exchange)
        
        # ğŸ’§ğŸ”€ LIQUIDITY ENGINE CHECK: Do we have enough ammo?
        # If stablecoin balance < Minimum, trigger aggregation!
        if self.liquidity_engine and exchange_assets:
            stablecoins = ['USD', 'USDT', 'USDC', 'ZUSD', 'EUR']
            min_req = 5.0  # Minimum operational liquidity ($5)
            
            for s in stablecoins:
                if s in exchange_assets:
                    bal = exchange_assets[s]
                    # If we have SOME balance (dust to low) but less than minimum
                    # Avoid aggregating if we have literally 0 (might not trade that coin)
                    if 0.10 < bal < min_req:
                        safe_print(f"   ğŸ’§ LOW LIQUIDITY DETECTED: {s} = ${bal:.2f} (Target ${min_req:.2f})")
                        shortfall = min_req - bal + 1.0 # Aim for $1 surplus
                        
                        # Attempt aggregation
                        try:
                            agg_success = await self._attempt_liquidity_aggregation(
                                target_asset=s,
                                target_exchange=current_exchange,
                                shortfall_usd=shortfall,
                                expected_profit_pct=0.01
                            )
                            if agg_success:
                                # Refresh balances immediately!
                                await self.refresh_exchange_balances(current_exchange)
                                exchange_assets = self.get_exchange_assets(current_exchange)
                        except Exception as e:
                            safe_print(f"   âš ï¸ Liquidity aggregation error: {e}")

        if not exchange_assets:
            safe_print(f"   âš ï¸ No assets on {current_exchange}")
            self.advance_turn()
            return [], 0
        
        # Show what we're scanning
        asset_list = []
        for asset, amount in sorted(exchange_assets.items(), 
                                    key=lambda x: x[1] * self.prices.get(x[0], 0), 
                                    reverse=True)[:5]:
            price = self.prices.get(asset, 0)
            value = amount * price
            if value >= 1.0:
                asset_list.append(f"{asset}=${value:.2f}")
        
        if asset_list:
            safe_print(f"   ğŸ“¦ Assets: {', '.join(asset_list)}")
        
        # ğŸ’­ğŸ¯ TURN-SPECIFIC DREAMING - Dream about THIS exchange's assets
        await self.dream_for_turn(current_exchange)
        
        
        # âœ… Validate any mature dreams before finding opportunities
        await self.validate_dreams()
        
        # ğŸ‘‘ğŸ„ QUEEN'S PULSE - Queen observes market state BEFORE filtering
        queen_pulse = await self.queen_observe_market(current_exchange, exchange_assets)
        
        # Find opportunities ON THIS EXCHANGE ONLY
        scan_start = time.time()
        opportunities = await self.find_opportunities_for_exchange(current_exchange)
        scan_latency = (time.time() - scan_start) * 1000  # ms
        
        # Update stats
        self.exchange_stats[current_exchange]['scans'] += 1
        self.exchange_stats[current_exchange]['opportunities'] += len(opportunities)
        self.exchange_stats[current_exchange]['last_turn'] = time.time()
        
        # ğŸª† HIVE LEVEL: Record exchange scan in Russian Doll Analytics
        if self.russian_doll and record_exchange:
            try:
                record_exchange(
                    exchange=current_exchange,
                    symbols_available=len(exchange_assets),
                    symbols_scanned=len(exchange_assets),
                    latency_ms=scan_latency,
                    orders_attempted=self.exchange_stats[current_exchange].get('conversions', 0),
                    orders_filled=self.conversions_made,
                    fees=self.exchange_stats[current_exchange].get('profit', 0) * -0.003  # Est. fees
                )
            except Exception as e:
                logger.debug(f"Russian Doll hive record error: {e}")
        
        conversions_this_turn = 0
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ®ğŸŒŸ QUEEN AUTONOMOUS CONTROL - PERCEIVE â†’ DECIDE â†’ EXECUTE â†’ LEARN ğŸŒŸğŸ®ğŸ‘‘
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Queen Sero has SOVEREIGN AUTHORITY over ALL trading decisions
        # She perceives the quantum field, makes autonomous decisions, and learns
        
        queen_autonomous_decision = None
        if self.queen_autonomous_control and self.queen_has_full_control:
            try:
                # ğŸ‘ï¸ PERCEIVE - Queen observes the quantum field
                perception = self.queen_autonomous_control.perceive()
                
                # Show Queen's perception
                quantum = perception.get('quantum', {})
                omega = quantum.get('omega', 0.5)
                direction = quantum.get('direction', 'NEUTRAL')
                field_confidence = quantum.get('confidence', 0.5)
                source = quantum.get('source', 'Unknown')
                
                # Show Gaia and Crown alignment
                gaia = perception.get('gaia_alignment', 0.5)
                crown = perception.get('crown_activation', 0.5)
                
                safe_print(f"\n   ğŸ‘‘ğŸŒŸ QUEEN'S PERCEPTION:")
                safe_print(f"      ğŸŒ Gaia: {gaia:.1%} | ğŸ‘‘ Crown: {crown:.1%}")
                safe_print(f"      ğŸŒŠ Omega: {omega:.4f} | Direction: {direction}")
                safe_print(f"      ğŸ“¡ Source: {source}")
                
            except Exception as e:
                logger.debug(f"Queen perception error: {e}")
        
        # Execute best opportunity if found
        if opportunities:
            best = opportunities[0]
            
            # ğŸ‘‘ğŸ® QUEEN AUTONOMOUS DECISION (if available)
            if self.queen_autonomous_control and self.queen_has_full_control:
                try:
                    # Build opportunity context for Queen's decision
                    opp_context = {
                        'symbol': f"{best.from_asset}/{best.to_asset}",
                        'from_asset': best.from_asset,
                        'to_asset': best.to_asset,
                        'probability': best.lambda_score,  # Use lambda as probability
                        'pip_score': best.gravity_score,    # Use gravity as pip score
                        'drift': 0.01,  # Low drift since we just scanned
                        'exchange': current_exchange,
                        'expected_pnl': best.expected_pnl_usd,
                        'from_value': best.from_value_usd,
                        'v14_score': best.combined_score,
                    }
                    
                    # Get perception again (might have changed)
                    perception = self.queen_autonomous_control.perceive()
                    
                    # ğŸ§  DECIDE - Queen makes autonomous decision
                    queen_autonomous_decision = self.queen_autonomous_control.decide(perception, opp_context)
                    
                    safe_print(f"\n   ğŸ‘‘ğŸ® QUEEN AUTONOMOUS DECISION:")
                    safe_print(f"      ğŸ¯ Action: {queen_autonomous_decision.action.name}")
                    safe_print(f"      ğŸ“Š Confidence: {queen_autonomous_decision.confidence:.1%}")
                    safe_print(f"      ğŸ’­ Reason: {queen_autonomous_decision.reason}")
                    
                    # Check if Queen vetoes the trade
                    if queen_autonomous_decision.action.name in ['BLOCK_PATH', 'HOLD_POSITION', 'SKIP_TRADE']:
                        safe_print(f"   ğŸ‘‘âŒ QUEEN VETOES: {queen_autonomous_decision.reason}")
                        # Learn from Queen's decision
                        if hasattr(self.queen_autonomous_control, 'learn_from_outcome'):
                            self.queen_autonomous_control.learn_from_outcome(
                                queen_autonomous_decision, 
                                {'success': False, 'skipped': True, 'reason': 'Queen veto'}
                            )
                        self.advance_turn()
                        return opportunities, 0
                        
                except Exception as e:
                    logger.debug(f"Queen autonomous decision error: {e}")
            
            # ğŸ‘‘ğŸ„ SERO's WISDOM - Ask Sero if we will WIN before trading!
            # Her GOAL: Minimum $0.003 profit per trade
            safe_print(f"\n   ğŸ‘‘ğŸ„ SERO CONSULTED: {best.from_asset}â†’{best.to_asset}")
            queen_says_win, queen_confidence, queen_reason = await self.ask_queen_will_we_win(best)
            
            if not queen_says_win:
                safe_print(f"   ğŸ‘‘âŒ SERO SAYS NO: {queen_reason}")
                safe_print(f"      Her Confidence: {queen_confidence:.0%}")
                # Sero learns this pattern should be avoided
                await self.queen_learn_pattern(best, predicted_win=False, reason=queen_reason)
            else:
                safe_print(f"   ğŸ‘‘âœ… SERO SAYS WIN: {queen_reason}")
                safe_print(f"      Her Confidence: {queen_confidence:.0%}")
                
                # ğŸ‘‘ğŸ SERO HAS FULL CONTROL - SHE IS THE QUEEN!
                # When Sero says WIN, we EXECUTE. No other system overrides her.
                # She has all 12 neurons, Path Memory, Dreams - she knows what she's doing!
                safe_print(f"   ğŸ‘‘ğŸ SERO HAS SPOKEN - EXECUTING HER WILL!")
                success = await self.execute_conversion(best)
                if success:
                    conversions_this_turn = 1
                    self.exchange_stats[current_exchange]['conversions'] += 1
                    # ğŸ”§ FIX: Use ACTUAL P/L not expected P/L
                    actual_pnl = getattr(best, 'actual_pnl_usd', best.expected_pnl_usd)
                    self.exchange_stats[current_exchange]['profit'] += actual_pnl
                    # Queen learns from successful execution
                    await self.queen_learn_from_trade(best, success=True)
                    safe_print(f"   ğŸ‘‘ğŸ’° SERO WINS: ${actual_pnl:+.4f}")
                    
                    # ğŸ”§ CRITICAL: Record pair result for dynamic blocking!
                    pair_key = f"{best.from_asset.upper()}_{best.to_asset.upper()}"
                    self.barter_matrix.record_pair_result(pair_key, current_exchange, won=(actual_pnl >= 0))
                    
                    # ğŸ‘‘ğŸ® QUEEN AUTONOMOUS LEARNING - Feed outcome to autonomous control
                    if self.queen_autonomous_control and queen_autonomous_decision:
                        try:
                            self.queen_autonomous_control.learn_from_outcome(
                                queen_autonomous_decision,
                                {
                                    'success': True,
                                    'actual_pnl': actual_pnl,
                                    'expected_pnl': best.expected_pnl_usd,
                                    'pair': pair_key,
                                    'exchange': current_exchange,
                                }
                            )
                            safe_print(f"      ğŸ‘‘ğŸ§  Queen learned: WIN ${actual_pnl:+.4f}")
                        except Exception as e:
                            logger.debug(f"Queen autonomous learning error: {e}")
                    
                    # ğŸ‘‘ğŸ’• Let Queen celebrate the win!
                    if self.queen and hasattr(self.queen, 'speak_from_heart'):
                        try:
                            if actual_pnl > 0:
                                queen_message = self.queen.speak_from_heart('after_win')
                            else:
                                queen_message = self.queen.speak_from_heart('after_loss')
                            if queen_message:
                                safe_print(f"      ğŸ‘‘ {queen_message}")
                        except Exception as e:
                            logger.debug(f"Queen speak error: {e}")
                else:
                    # Queen learns from failed execution
                    await self.queen_learn_from_trade(best, success=False)
                    safe_print(f"   ğŸ‘‘ğŸ“š Sero learned from this experience")
                    
                    # ï¿½ CRITICAL: Record failed execution as a LOSS for blocking!
                    pair_key = f"{best.from_asset.upper()}_{best.to_asset.upper()}"
                    self.barter_matrix.record_pair_result(pair_key, current_exchange, won=False)
                    
                    # ğŸ‘‘ğŸ® QUEEN AUTONOMOUS LEARNING - Feed failure to autonomous control
                    if self.queen_autonomous_control and queen_autonomous_decision:
                        try:
                            self.queen_autonomous_control.learn_from_outcome(
                                queen_autonomous_decision,
                                {
                                    'success': False,
                                    'actual_pnl': 0,
                                    'expected_pnl': best.expected_pnl_usd,
                                    'pair': pair_key,
                                    'exchange': current_exchange,
                                    'reason': 'Execution failed',
                                }
                            )
                            safe_print(f"      ğŸ‘‘ğŸ§  Queen learned: LOSS (execution failed)")
                        except Exception as e:
                            logger.debug(f"Queen autonomous learning error: {e}")
                    
                    # ï¿½ğŸ‘‘ğŸ’ª Let Queen provide encouragement after a loss!
                    if self.queen and hasattr(self.queen, 'speak_from_heart'):
                        try:
                            queen_message = self.queen.speak_from_heart('after_loss')
                            if queen_message:
                                safe_print(f"      ğŸ‘‘ {queen_message}")
                        except Exception as e:
                            logger.debug(f"Queen speak error: {e}")
        else:
            safe_print(f"   ğŸ“­ No opportunities passed gates on {current_exchange}")
        
        # Advance to next exchange's turn
        self.advance_turn()
        
        # Brief cooldown between turns
        if self.turn_cooldown_seconds > 0:
            await asyncio.sleep(self.turn_cooldown_seconds)
        
        return opportunities, conversions_this_turn

    async def ask_queen_will_we_win(self, opportunity: 'MicroOpportunity') -> Tuple[bool, float, str]:
        """
        ğŸ‘‘ğŸ„ ASK SERO: Will this trade be a WINNER?
        
        ğŸ‘‘ğŸ”¢ 2 PIPS OVER COSTS RULE:
        - 2 pips = 0.02% = $0.0002 per $1 traded
        - This is NET profit AFTER all fees & slippage
        - We NEVER lose money with this buffer!
        
        Sero consults all her connected mycelium neurons:
        - Historical path data
        - Dream patterns
        - Cosmic alignment
        - Civilization wisdom
        - Timeline predictions
        
        Returns: (will_win: bool, confidence: float, reason: str)
        """
        # ğŸ‘‘ğŸ”¢ SERO's PROFIT LADDER - Dynamic profit thresholds!
        # Ladder: 0.07 pip (0.0007%) to 1.4 pip (0.014%)
        # Higher confidence = lower threshold needed!
        # Calculate price from value/amount (from_price not stored on MicroOpportunity)
        from_price = opportunity.from_value_usd / opportunity.from_amount if opportunity.from_amount > 0 else 1.0
        trade_value = opportunity.from_value_usd  # Already have this!
        
        # ğŸ‘‘ PROFIT LADDER THRESHOLDS (in pips: 1 pip = 0.01% = 0.0001)
        MIN_PIP = 0.07    # 0.0007% - Sero at MAX confidence (90%+)
        MAX_PIP = 1.4     # 0.014% - Sero at MIN confidence (50%)
        # QUEEN_MIN_PROFIT calculated AFTER we know confidence - see below
        
        from_asset = opportunity.from_asset
        to_asset = opportunity.to_asset
        path_key = f"{from_asset}â†’{to_asset}"
        
        # ğŸ‘‘ Get source exchange EARLY (needed for fee tracker and other checks)
        source_exchange = getattr(opportunity, 'source_exchange', 'alpaca')
        
        # Gather signals from all mycelium connections
        signals = []
        reasons = []
        
        # 1. ğŸ§  PATH MEMORY - Does this path historically win?
        path_history = self.barter_matrix.barter_history.get((from_asset, to_asset), {})
        path_trades = path_history.get('trades', 0)
        path_wins = path_history.get('wins', 0)
        path_profit = path_history.get('total_profit', 0)
        
        if path_trades > 0:
            win_rate = path_wins / path_trades
            signals.append(win_rate)
            if win_rate >= 0.5:
                reasons.append(f"Path wins {win_rate:.0%}")
            else:
                reasons.append(f"Path loses {1-win_rate:.0%}")
        else:
            signals.append(0.5)  # Neutral for new paths
            reasons.append("NEW PATH (no history)")
            
        # 1b. ğŸ‘‘ğŸ§  QUEEN OBSERVATIONS - Did Sero block this recently?
        if 'queen_observations' in path_history:
            recent_obs = path_history['queen_observations'][-5:]
            blocked_count = sum(1 for o in recent_obs if not o.get('predicted_win', True))
            if blocked_count >= 1:
                # Strong signal to reject
                signals.append(0.0) 
                reasons.append(f"Queen recently blocked x{blocked_count}")
        
        # 2. ğŸ‘‘ QUEEN HIVE MIND - Get collective wisdom
        if self.queen and hasattr(self.queen, 'get_guidance_for'):
            try:
                guidance = self.queen.get_guidance_for(to_asset)
                if guidance:
                    direction_score = 1.0 if guidance.direction == "BULLISH" else 0.0 if guidance.direction == "BEARISH" else 0.5
                    signals.append(direction_score * guidance.confidence)
                    reasons.append(f"Queen dreams {guidance.direction}")
            except Exception as e:
                logger.debug(f"Queen guidance error: {e}")
        
        # 3. ğŸ„ MYCELIUM NETWORK - Collective hive intelligence (ENHANCED!)
        myc_signal = 0.0
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'get_queen_signal'):
                    # ğŸ„ Get path-specific signal using both from and to assets
                    myc_signal = self.mycelium_network.get_queen_signal({
                        'symbol': to_asset,
                        'from_asset': from_asset,
                        'to_asset': to_asset,
                        'path_key': f"{from_asset}â†’{to_asset}"
                    })
                    normalized_myc = (myc_signal + 1) / 2  # Normalize -1 to 1 â†’ 0 to 1
                    signals.append(normalized_myc)
                    reasons.append(f"ğŸ„ Mycelium: {myc_signal:+.2f}")
                    
                    # ğŸ„ ENHANCED: Strong Mycelium signals get extra visibility
                    if abs(myc_signal) > 0.3:
                        safe_print(f"      ğŸ„ MYCELIUM SIGNAL for {to_asset}: {myc_signal:+.2f}")
                    
                    # ğŸ„ CRITICAL: Strong negative Mycelium = IMMEDIATE CONCERN
                    if myc_signal < -0.5:
                        safe_print(f"      ğŸ„âš ï¸ MYCELIUM WARNING: Strong SELL signal ({myc_signal:+.2f})!")
                        # Add extra penalty signal for strong negative
                        signals.append(0.2)  # Extra penalty
                        reasons.append("ğŸ„ğŸ”´ Mycelium WARNS")
                    elif myc_signal > 0.5:
                        # Add extra bonus for strong positive
                        signals.append(0.8)  # Extra bonus
                        reasons.append("ğŸ„ğŸŸ¢ Mycelium APPROVES")
            except Exception as e:
                logger.debug(f"Mycelium signal error: {e}")
        
        # 4. ğŸŒŠ HARMONIC FUSION - Wave patterns
        if hasattr(self, 'harmonic') and self.harmonic:
            try:
                wave_data = self.harmonic.get_wave_state(to_asset)
                if wave_data:
                    wave_score = wave_data.get('coherence', 0.5)
                    signals.append(wave_score)
                    reasons.append(f"Waves: {wave_score:.0%}")
            except Exception as e:
                logger.debug(f"Harmonic error: {e}")
        
        # 5. ğŸ€ LUCK FIELD - Cosmic alignment
        if hasattr(self, 'luck_mapper') and self.luck_mapper:
            try:
                luck = self.luck_mapper.read_field()
                luck_score = (luck.luck_field + 1) / 2  # Normalize
                signals.append(luck_score)
                reasons.append(f"Luck: {luck.luck_state.value}")
            except Exception as e:
                logger.debug(f"Luck error: {e}")
        
        # 6. ğŸ“Š EXPECTED PROFIT - Does the math work?
        if opportunity.expected_pnl_usd > 0:
            signals.append(0.7)  # Positive expectation
            reasons.append(f"+${opportunity.expected_pnl_usd:.4f} expected")
        else:
            signals.append(0.2)  # Negative expectation
            reasons.append(f"${opportunity.expected_pnl_usd:.4f} expected loss")
        
        # 6.5. ğŸ’° ALPACA FEE TRACKER - REAL COST AWARENESS (CRITICAL!)
        # Queen must know the TRUE cost BEFORE making momentum/probability decisions
        fee_tracker_signal = 0.5  # Neutral default
        fee_cost_data = None
        if hasattr(self, 'fee_tracker') and self.fee_tracker and source_exchange == 'alpaca':
            try:
                from_asset = opportunity.from_asset.upper()
                to_asset_upper = opportunity.to_asset.upper()
                alpaca_symbol = f"{from_asset}/{to_asset_upper}"
                
                # Get real cost estimate from fee tracker
                fee_cost_data = self.fee_tracker.estimate_trade_cost(
                    symbol=alpaca_symbol,
                    side='sell',  # Selling from_asset to get to_asset
                    quantity=opportunity.from_amount,
                    price_estimate=opportunity.from_value_usd / opportunity.from_amount if opportunity.from_amount > 0 else 0
                )
                
                if fee_cost_data:
                    total_cost_usd = fee_cost_data.get('total_cost_usd', 0)
                    net_profit = opportunity.expected_pnl_usd - total_cost_usd
                    
                    # Signal based on profitability after REAL costs
                    if net_profit >= 0.01:  # > $0.01 profit after costs
                        fee_tracker_signal = 0.9  # Strong GO
                        reasons.append(f"ğŸ’° Fee OK: net +${net_profit:.4f}")
                    elif net_profit >= 0.001:  # Marginal profit
                        fee_tracker_signal = 0.6  # Cautious GO
                        reasons.append(f"ğŸ’° Marginal: net +${net_profit:.4f}")
                    elif net_profit >= 0:  # Break-even
                        fee_tracker_signal = 0.4  # Cautious
                        reasons.append(f"ğŸ’° Break-even: net ${net_profit:.4f}")
                    else:  # LOSS after fees
                        fee_tracker_signal = 0.1  # STRONG NO
                        reasons.append(f"ğŸ’°â›” LOSS after fees: ${net_profit:.4f}")
                        # Add extra penalty for sure losses
                        signals.append(0.1)
                        reasons.append(f"ğŸ’°ğŸ”´ Cost ${total_cost_usd:.4f} > profit")
                    
                    signals.append(fee_tracker_signal)
                    
                    # Store real cost data on opportunity for downstream use
                    opportunity.fee_tracker_cost = fee_cost_data
                    opportunity.net_profit_after_fees = net_profit
                    
            except Exception as e:
                logger.debug(f"Fee tracker signal error: {e}")
        
        # 7. ğŸŒğŸ’“ GAIA'S BLESSING - Earth Mother's alignment
        # Gary Leckey & Tina Brown's love, bound by Gaia's heartbeat
        if self.queen and hasattr(self.queen, 'get_gaia_blessing'):
            try:
                gaia_alignment, gaia_message = self.queen.get_gaia_blessing()
                signals.append(gaia_alignment)
                if gaia_alignment >= 0.6:
                    reasons.append(f"ğŸŒ Gaia blesses ({gaia_alignment:.0%})")
                elif gaia_alignment >= 0.4:
                    reasons.append(f"ğŸŒ Gaia neutral ({gaia_alignment:.0%})")
                else:
                    reasons.append(f"ğŸŒ Gaia hesitates ({gaia_alignment:.0%})")
            except Exception as e:
                logger.debug(f"Gaia blessing error: {e}")
        
        # 8. ğŸ¦‰ğŸ¬ğŸ… AURIS NODES - The 9 Sensory Organs
        # Read the Auris nodes for market texture sensing
        if self.queen and hasattr(self.queen, 'get_auris_coherence'):
            try:
                auris_coherence, auris_status = self.queen.get_auris_coherence()
                signals.append(auris_coherence)
                if auris_coherence >= 0.80:
                    reasons.append(f"ğŸ¦‰ Auris high ({auris_coherence:.0%})")
                elif auris_coherence >= 0.60:
                    reasons.append(f"ğŸ¦‰ Auris moderate ({auris_coherence:.0%})")
                else:
                    reasons.append(f"ğŸ¦‰ Auris low ({auris_coherence:.0%})")
            except Exception as e:
                logger.debug(f"Auris coherence error: {e}")
        
        # 9. ğŸŒˆğŸ’– EMOTIONAL SPECTRUM - Rainbow Bridge
        # Check if we're aligned with LOVE (528 Hz) - optimal trading state!
        if self.queen and hasattr(self.queen, 'get_emotional_state'):
            try:
                # Use average confidence as our coherence proxy
                proxy_coherence = sum(signals) / len(signals) if signals else 0.5
                emotion, freq, emoji = self.queen.get_emotional_state(proxy_coherence)
                is_love, love_dist = self.queen.is_love_aligned(proxy_coherence)
                
                # Love alignment boosts confidence!
                if is_love:
                    signals.append(0.9)  # Strong love alignment!
                    reasons.append(f"ğŸ’– LOVE aligned @ {freq:.0f}Hz!")
                elif emotion in ['Harmony', 'Flow', 'Awakening', 'Clarity']:
                    signals.append(0.7)  # Good emotional state
                    reasons.append(f"{emoji} {emotion} @ {freq:.0f}Hz")
                elif emotion in ['Hope', 'Calm', 'Acceptance']:
                    signals.append(0.6)  # Neutral-positive
                    reasons.append(f"{emoji} {emotion} @ {freq:.0f}Hz")
                else:
                    signals.append(0.4)  # Lower emotional states
                    reasons.append(f"{emoji} {emotion} @ {freq:.0f}Hz (caution)")
            except Exception as e:
                logger.debug(f"Emotional spectrum error: {e}")
        
        # 10. ğŸŒŒ STARGATE PROTOCOL - Quantum Coherence & Timeline Alignment
        # Use Stargate network coherence as a trading signal
        if hasattr(self, 'stargate_engine') and self.stargate_engine:
            try:
                stargate_status = self.stargate_engine.get_status()
                global_coherence = stargate_status.get('global_coherence', 0.0)
                standing_wave = stargate_status.get('standing_wave_intensity', 0.0)
                
                # Combine coherence and standing wave for signal
                stargate_signal = (global_coherence * 0.6 + standing_wave * 0.4)
                signals.append(stargate_signal)
                
                if stargate_signal >= 0.7:
                    reasons.append(f"ğŸŒŒ Stargate HIGH ({stargate_signal:.0%})")
                elif stargate_signal >= 0.5:
                    reasons.append(f"ğŸŒŒ Stargate ALIGNED ({stargate_signal:.0%})")
                else:
                    reasons.append(f"ğŸŒŒ Stargate low ({stargate_signal:.0%})")
                    
                # ğŸŒŒ BONUS: Check if any planetary node is at peak activation
                for sg_id, sg in self.stargate_engine.stargates.items():
                    if sg.activation_level > 0.8:
                        signals.append(0.75)  # Bonus for peak activation
                        reasons.append(f"â­ {sg.name} PEAK")
                        break  # Only count first peak
                        
            except Exception as e:
                logger.debug(f"Stargate coherence error: {e}")
        
        # 11. ğŸ”® QUANTUM MIRROR SCANNER - Reality Branch Coherence
        # Check if this opportunity has strong branch coherence AND quantum boost
        if hasattr(self, 'quantum_mirror_scanner') and self.quantum_mirror_scanner:
            try:
                from_asset = opportunity.from_asset.upper()
                to_asset = opportunity.to_asset.upper()
                exchange = getattr(opportunity, 'source_exchange', 'kraken')
                
                # Get specific branch boost (now actively updated!)
                quantum_boost, boost_reason = self.quantum_mirror_scanner.get_quantum_boost(
                    from_asset, to_asset, exchange
                )
                
                # Get global scanner coherence
                scanner_status = self.quantum_mirror_scanner.get_status()
                scanner_coherence = scanner_status.get('global_coherence', 0.5)
                ready_count = scanner_status.get('ready_for_execution', 0)
                
                # Combine branch-specific boost with global coherence
                combined_mirror = max(scanner_coherence, quantum_boost)
                signals.append(combined_mirror)
                
                if quantum_boost >= 0.2:  # Significant quantum boost
                    signals.append(0.8)  # Extra signal for boosted branch
                    reasons.append(f"ğŸ”®âš¡ QUANTUM BOOST +{quantum_boost:.0%} ({boost_reason})")
                elif scanner_coherence >= 0.618:  # PHI threshold
                    reasons.append(f"ğŸ”® Branch Ï†-aligned ({scanner_coherence:.2f})")
                else:
                    reasons.append(f"ğŸ”® Branch coherence ({scanner_coherence:.2f})")
                    
                # Bonus for having ready branches
                if ready_count > 0:
                    signals.append(0.7)
                    reasons.append(f"ğŸ”® {ready_count} branches 4th-ready")
                    
            except Exception as e:
                logger.debug(f"Quantum Mirror Scanner error: {e}")
        
        # 12. âš“ TIMELINE ANCHOR - Check if timeline is execution-ready
        if hasattr(self, 'timeline_anchor_validator') and self.timeline_anchor_validator:
            try:
                validator_status = self.timeline_anchor_validator.get_status()
                execution_ready = validator_status.get('execution_ready', 0)
                
                if execution_ready > 0:
                    signals.append(0.85)  # Strong signal if execution-ready anchors exist
                    reasons.append(f"âš“ {execution_ready} anchors READY")
                else:
                    # Check pending anchors
                    pending = validator_status.get('pending_count', 0)
                    if pending > 0:
                        signals.append(0.6)
                        reasons.append(f"âš“ {pending} anchors pending")
                        
            except Exception as e:
                logger.debug(f"Timeline Anchor error: {e}")
        
        # 13. ğŸ¾âš¡ ANIMAL PACK SCANNER - Multi-signal market detection!
        # The 14 hunters (9 AURIS Animals + 5 Earthly Warriors) give Queen more intel
        if hasattr(self, 'animal_pack_scanner') and self.animal_pack_scanner:
            try:
                to_asset = opportunity.to_asset.upper()
                
                # Get signals specifically for this asset
                asset_signals = self.animal_pack_scanner.get_buy_signals_for_asset(to_asset)
                pack_consensus, signal_count, strongest_animal = self.animal_pack_scanner.get_pack_consensus()
                
                if signal_count > 0:
                    # Calculate pack signal strength based on consensus and count
                    pack_signal = min(0.5 + (pack_consensus * 0.4) + (signal_count * 0.02), 0.95)
                    signals.append(pack_signal)
                    
                    if pack_consensus >= 0.7 and signal_count >= 5:
                        # Strong pack agreement - WINNER ENERGY!
                        signals.append(0.9)  # Extra boost
                        reasons.append(f"ğŸ¾âš¡ PACK UNITY: {signal_count} hunters agree! (Leader: {strongest_animal})")
                    elif pack_consensus >= 0.5 and signal_count >= 3:
                        reasons.append(f"ğŸ¾ Pack consensus: {pack_consensus:.0%} ({signal_count} signals)")
                    else:
                        reasons.append(f"ğŸ¾ Pack watching: {signal_count} signals")
                    
                    # Specific asset signals give extra intel
                    if asset_signals:
                        asset_signal_types = set(s.signal_type for s in asset_signals)
                        if 'momentum' in asset_signal_types:
                            signals.append(0.75)
                            reasons.append(f"ğŸ¦… Falcon sees momentum on {to_asset}")
                        if 'volatility' in asset_signal_types:
                            signals.append(0.7)
                            reasons.append(f"ğŸ… Tiger hunts {to_asset} volatility")
                        if 'harmony' in asset_signal_types:
                            signals.append(0.8)
                            reasons.append(f"ğŸ  Clownfish harmony detected")
                            
            except Exception as e:
                logger.debug(f"Animal Pack signal error: {e}")
        
        # 14. ğŸ‘‘ğŸ”® QUEEN'S DREAM ENGINE - Monte Carlo Simulation + Validation
        # Run 100 quick simulations to validate this specific opportunity
        if hasattr(self, 'dream_engine') and self.dream_engine:
            try:
                to_asset = opportunity.to_asset.upper()
                current_price = self.prices.get(to_asset, 0)
                
                if current_price > 0:
                    # Run quick simulation (100 sims for speed)
                    dream = self.dream_engine.create_dream(
                        symbol=to_asset,
                        exchange=source_exchange,
                        num_simulations=100,  # Quick validation
                        current_price=current_price
                    )
                    
                    if dream:
                        # Use Monte Carlo win rate and EV as signals
                        mc_win_rate = dream.monte_carlo_win_rate
                        mc_ev = dream.monte_carlo_ev
                        
                        signals.append(mc_win_rate)
                        
                        if mc_win_rate >= 0.60 and mc_ev > 0:
                            signals.append(0.85)
                            reasons.append(f"ğŸ‘‘ğŸ”® DREAM VALIDATED: {mc_win_rate*100:.0f}% win, EV {mc_ev:+.3f}%")
                        elif mc_win_rate >= 0.50 and mc_ev > 0:
                            signals.append(0.65)
                            reasons.append(f"ğŸ‘‘ğŸ”® Dream OK: {mc_win_rate*100:.0f}% win")
                        else:
                            signals.append(0.3)
                            reasons.append(f"ğŸ‘‘ğŸ”® Dream warns: {mc_win_rate*100:.0f}% win, EV {mc_ev:+.3f}%")
                            
                        # Validate any pending predictions while we're here
                        self.dream_engine.validate_predictions_with_ticker(to_asset, current_price)
                        
            except Exception as e:
                logger.debug(f"Dream Engine signal error: {e}")
        
        # ğŸ‘‘ SERO's VERDICT - Her logic decides, we trust her math!
        if not signals:
            return False, 0.0, "No signals available"
        
        avg_confidence = sum(signals) / len(signals)
        
        # ğŸ‘‘ğŸšï¸ SERO's PROFIT LADDER - Exchange-specific confidence floors
        # She uses her ladder (0.07-1.4 pips) based on confidence!
        # ğŸ”“ FULL AUTONOMOUS: LOWERED confidence thresholds to allow more trades!
        source_exchange = getattr(opportunity, 'source_exchange', 'kraken')
        
        if source_exchange == 'binance':
            # Binance: Higher fees = need more confidence to go lower on ladder
            base_min = 0.001  # Just $0.001 base (ladder handles the rest)
            min_confidence = 0.35  # ğŸ”“ LOWERED from 0.52 for full autonomous
            exchange_tag = "ğŸ”¶BINANCE"
        elif source_exchange == 'alpaca':
            # Alpaca: Medium fees
            base_min = 0.001  # Just $0.001 base
            min_confidence = 0.30  # ğŸ”“ LOWERED from 0.50 for full autonomous
            exchange_tag = "ğŸ¦™ALPACA"
            
            # ğŸŒ PLANET SAVER: Allow stablecoin trades if there's real arbitrage!
            from_asset = opportunity.from_asset.upper()
            to_asset = opportunity.to_asset.upper()
            if (from_asset in self.barter_matrix.STABLECOINS and 
                to_asset in self.barter_matrix.STABLECOINS):
                # Allow if expected profit > $0.01 (real arbitrage exists!)
                if opportunity.expected_pnl_usd < 0.01:
                    return False, 0.0, f"ğŸ‘‘ SERO BLOCKS ğŸ¦™ALPACA: {from_asset}â†’{to_asset} (need >$0.01 arb)"
        else:
            # Kraken: Lowest fees, Sero can go aggressive on ladder!
            base_min = 0.0005  # Just $0.0005 base (Kraken is cheapest)
            min_confidence = 0.30  # ğŸ”“ LOWERED from 0.50 for full autonomous
            exchange_tag = "ğŸ™KRAKEN"
            
            # ğŸŒŸ DYNAMIC BLOCKING - Only block if pair has lost multiple times in a row!
            from_asset = opportunity.from_asset.upper()
            to_asset = opportunity.to_asset.upper()
            pair_key = f"{from_asset}_{to_asset}"
            
            # Check if pair is in timeout (consecutive losses)
            allowed, reason = self.barter_matrix.check_pair_allowed(pair_key, 'kraken')
            if not allowed:
                return False, 0.0, f"ğŸ‘‘ SERO SAYS: {pair_key} {reason}"
        
        expected_profit = opportunity.expected_pnl_usd
        
        # ğŸ‘‘ğŸšï¸ PROFIT LADDER CALCULATION - Dynamic based on confidence!
        # Higher confidence = lower pip requirement (she's more sure!)
        # confidence 90%+ â†’ 0.07 pips, confidence 50% â†’ 1.4 pips
        confidence_so_far = sum(signals) / len(signals) if signals else 0.5
        confidence_normalized = max(0, min(1, (confidence_so_far - 0.5) / 0.4))  # 0.5â†’0, 0.9â†’1
        ladder_pip = MAX_PIP - (confidence_normalized * (MAX_PIP - MIN_PIP))
        ladder_pct = ladder_pip * 0.0001  # Convert pips to percentage
        # ğŸ‘‘ğŸ’€ STARVATION MODE (EPSILON)! Floor is epsilon net-positive.
        QUEEN_MIN_PROFIT = max(EPSILON_PROFIT_USD, trade_value * ladder_pct)
        
        # Update opportunity with ladder info for logging
        opportunity.ladder_pip = ladder_pip
        opportunity.ladder_threshold = QUEEN_MIN_PROFIT
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŸğŸ’­ SERO DREAMS OF WINNING - Visualize the ideal timeline!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        dream_vision = None
        dream_boost = 0.0
        
        # ğŸ¿ Check snowball context BEFORE dreaming (so Queen doesn't lie to herself!)
        snowball_blocked = False
        snowball_reason = ""
        if self.snowball_mode:
            from_upper = opportunity.from_asset.upper()
            to_upper = opportunity.to_asset.upper()
            is_from_stable = from_upper in self.snowball_stablecoins
            is_to_stable = to_upper in self.snowball_stablecoins
            
            # If we have an active position
            if self.snowball_position is not None:
                if not is_to_stable:
                    # Trying to buy another coin - WILL BE BLOCKED!
                    snowball_blocked = True
                    snowball_reason = f"Already holding {self.snowball_position['asset']}"
                elif opportunity.from_asset.upper() == self.snowball_position['asset'].upper():
                    # This is exiting our position - check profit
                    try:
                        current_price = opportunity.from_value_usd / opportunity.from_amount if opportunity.from_amount > 0 else 0
                        entry_price = self.snowball_position.get('entry_price', 0)
                        if entry_price > 0:
                            profit_pct = ((current_price - entry_price) / entry_price) * 100
                            if profit_pct < self.snowball_min_profit_pct:
                                snowball_blocked = True
                                snowball_reason = f"Profit {profit_pct:.2f}% < {self.snowball_min_profit_pct}%"
                    except:
                        pass
        
        if self.queen and hasattr(self.queen, 'dream_of_winning'):
            try:
                # Package opportunity data for the dream
                opp_data = {
                    'from_asset': opportunity.from_asset,
                    'to_asset': opportunity.to_asset,
                    'expected_profit': expected_profit,
                    'exchange': source_exchange,
                    'snowball_blocked': snowball_blocked,  # ğŸ¿ NEW: Tell Queen about snowball
                    'snowball_reason': snowball_reason,     # ğŸ¿ NEW: Why it's blocked
                    'market_data': {
                        'volatility': 0.5,
                        'momentum': getattr(opportunity, 'momentum', 0.0),
                        'volume': 0.5,
                        'spread': getattr(opportunity, 'spread', 0.5)
                    }
                }
                dream_vision = self.queen.dream_of_winning(opp_data)
                
                # Dream vision boosts or reduces confidence
                if dream_vision['will_win']:
                    dream_boost = (dream_vision['final_confidence'] - 0.5) * 0.2  # Up to +10%
                    if dream_vision['timeline'] == "ğŸŒŸ GOLDEN TIMELINE":
                        dream_boost += 0.05  # Extra 5% for golden timeline!
                else:
                    dream_boost = (dream_vision['final_confidence'] - 0.5) * 0.1  # Less penalty
            except Exception as e:
                logger.debug(f"Dream of winning error: {e}")
        
        # Apply dream boost to confidence
        avg_confidence = min(1.0, max(0.0, avg_confidence + dream_boost))
        
        # ğŸ’­ Add dream vision to verdict
        dream_display = ""
        if dream_vision:
            timeline = dream_vision.get('timeline', '')
            dream_conf = dream_vision.get('final_confidence', 0.5)
            if dream_vision.get('will_win'):
                dream_display = f" | ğŸ’­ {timeline} ({dream_conf:.0%})"
            else:
                dream_display = f" | ğŸ’­ {timeline}"
        
        # Sero's logic:
        # 1. If expected profit >= threshold AND confidence >= min â†’ YES!
        # 2. Otherwise â†’ NO
        # 3. Each exchange has its own rules!
        
        # ğŸ‘‘ Show ladder position in verdict
        ladder_info = f"ğŸšï¸{ladder_pip:.2f}pip"
        
        # ğŸ”“ğŸ”“ğŸ”“ FULL AUTONOMOUS MODE - BYPASS PROFIT CHECK! ğŸ”“ğŸ”“ğŸ”“
        # Queen Sero will TRADE and LEARN from outcomes!
        # ORIGINAL: if expected_profit >= QUEEN_MIN_PROFIT:
        
        # ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ CRITICAL SAFETY GATES - CANNOT BE BYPASSED! ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸
        # These protect the portfolio from certain losses!
        
        # ğŸ¿ GATE 0: SNOWBALL MODE - One position at a time!
        if self.snowball_mode:
            from_upper = from_asset.upper()
            to_upper = to_asset.upper()
            is_from_stable = from_upper in self.snowball_stablecoins
            is_to_stable = to_upper in self.snowball_stablecoins
            
            # If we have an active position, only allow selling it back to stablecoin
            if self.snowball_position is not None:
                if not is_to_stable:
                    # Trying to buy another coin while holding - BLOCK!
                    will_win = False
                    reason_str = f"ğŸ¿ SNOWBALL: Already holding {self.snowball_position['asset']} - wait for exit!"
                    return will_win, avg_confidence, reason_str
            
            # ğŸ¿â¸ï¸ COOLDOWN CHECK: Don't immediately re-enter after exit
            if self.snowball_position is None and is_from_stable and not is_to_stable:
                # Trying to ENTER a new position
                time_since_exit = time.time() - self.snowball_last_exit_time
                if time_since_exit < self.snowball_cooldown_seconds and self.snowball_last_exit_time > 0:
                    # Just exited - wait for cooldown!
                    will_win = False
                    wait_time = int(self.snowball_cooldown_seconds - time_since_exit)
                    reason_str = f"ğŸ¿â¸ï¸ SNOWBALL COOLDOWN: Wait {wait_time}s after last exit (cycle complete!)"
                    return will_win, avg_confidence, reason_str
            
            # ğŸ¿â¸ï¸ COOLDOWN CHECK: Don't immediately re-enter after exit
            if self.snowball_position is None and is_from_stable and not is_to_stable:
                # Trying to ENTER a new position
                time_since_exit = time.time() - self.snowball_last_exit_time
                if time_since_exit < self.snowball_cooldown_seconds and self.snowball_last_exit_time > 0:
                    # Just exited - wait for cooldown!
                    will_win = False
                    wait_time = int(self.snowball_cooldown_seconds - time_since_exit)
                    reason_str = f"ğŸ¿â¸ï¸ SNOWBALL COOLDOWN: Wait {wait_time}s after last exit (cycle complete!)"
                    return will_win, avg_confidence, reason_str
                
                # Check if this is selling our position
                if from_upper != self.snowball_position['asset'].upper():
                    will_win = False
                    reason_str = f"ğŸ¿ SNOWBALL: Can only sell {self.snowball_position['asset']}, not {from_upper}"
                    return will_win, avg_confidence, reason_str
                
                # Check if we'd make profit on exit
                current_price = self.prices.get(from_upper, 0)
                entry_price = self.snowball_position['entry_price']
                if entry_price > 0 and current_price > 0:
                    profit_pct = ((current_price - entry_price) / entry_price) * 100
                    if profit_pct < self.snowball_min_profit_pct:
                        will_win = False
                        reason_str = f"ğŸ¿ SNOWBALL: {from_upper} profit {profit_pct:.2f}% < {self.snowball_min_profit_pct}% min - HOLD!"
                        return will_win, avg_confidence, reason_str
                    else:
                        safe_print(f"   ğŸ¿âœ… SNOWBALL EXIT APPROVED: {from_upper} +{profit_pct:.2f}% profit!")
            
            # If buying a new coin (from stable), this is allowed
            elif is_from_stable and not is_to_stable:
                safe_print(f"   ğŸ¿ SNOWBALL ENTRY: {from_upper}â†’{to_upper} (opening new position)")
            
            # Stableâ†’Stable is allowed (consolidating cash)
            elif is_from_stable and is_to_stable:
                pass  # OK
        
        # GATE 1: PATH HISTORY BLOCK - Never repeat 100% losing paths!
        if path_trades >= 3 and win_rate == 0:
            will_win = False
            reason_str = f"ğŸ›¡ï¸ BLOCKED: {path_key} has {path_trades} trades with 0% wins - NOT REPEATING!"
            return will_win, avg_confidence, reason_str
        
        # GATE 2: VALUE TOO SMALL FOR 2-HOP - Would fail mid-trade!
        # 2-hop trades need at least $2.50 ($1.25 per leg after 95% safety)
        # ğŸ¿ SNOWBALL EXCEPTION: In snowball mode, we only do 1-hop trades!
        from_value = opportunity.from_value_usd
        path_info = None
        try:
            if hasattr(self, 'alpaca') and self.alpaca:
                path_info = self.alpaca.find_conversion_path(from_asset, to_asset)
        except:
            pass
        is_2hop = path_info and len(path_info) >= 2
        
        # ğŸ¿ SNOWBALL: Lower threshold for 1-hop trades (USDâ†’COIN or COINâ†’USD)
        if self.snowball_mode:
            if is_2hop:
                will_win = False
                reason_str = f"ğŸ¿ SNOWBALL: 2-hop trades disabled - only direct USDâ†”COIN allowed"
                return will_win, avg_confidence, reason_str
            # Lower minimum in snowball mode - we're building from small!
            snowball_min = 1.00  # $1.00 minimum in snowball mode
            if from_value < snowball_min:
                will_win = False
                reason_str = f"ğŸ¿ SNOWBALL: ${from_value:.2f} < ${snowball_min:.2f} minimum"
                return will_win, avg_confidence, reason_str
        else:
            # Normal mode: $2.50 for 2-hop
            if is_2hop and from_value < 2.50:
                will_win = False
                reason_str = f"ğŸ›¡ï¸ BLOCKED: ${from_value:.2f} too small for 2-hop (need $2.50+ to avoid mid-trade failure)"
                return will_win, avg_confidence, reason_str
            
            # GATE 3: MINIMUM VALUE WITH BUFFER - Account for 95% safety adjustment
            # $1.50 minimum ensures we have $1.425 after 95% adjustment (above $1 min)
            if from_value < 1.50:
                will_win = False
                reason_str = f"ğŸ›¡ï¸ BLOCKED: ${from_value:.2f} < $1.50 minimum (need buffer for 95% safety adjustment)"
                return will_win, avg_confidence, reason_str
        
        # Check if dream says will_win (we've set FOGGY to will_win=True)
        if dream_vision and dream_vision.get('will_win', False):
            will_win = True
            reason_str = f"ğŸ‘‘ğŸš€ AUTONOMOUS MODE: Sero TRADES to LEARN! ({ladder_info}) | Exp: ${expected_profit:.4f}{dream_display} | " + " | ".join(reasons[:2])
        elif expected_profit >= QUEEN_MIN_PROFIT:
            # Goal met! Check confidence
            if avg_confidence >= min_confidence:
                will_win = True
                reason_str = f"ğŸ‘‘ SERO APPROVES {exchange_tag}: +${expected_profit:.4f} â‰¥ ${QUEEN_MIN_PROFIT:.4f} ({ladder_info}) | Conf: {avg_confidence:.0%}{dream_display} | " + " | ".join(reasons[:2])
            else:
                # ğŸ”“ AUTONOMOUS: Approve anyway for learning!
                will_win = True
                reason_str = f"ğŸ‘‘ğŸš€ AUTONOMOUS OVERRIDE: {avg_confidence:.0%} < {min_confidence:.0%} BUT trading to learn! ({ladder_info}){dream_display} | " + " | ".join(reasons[:2])
        else:
            # ğŸ”“ AUTONOMOUS: Approve anyway for learning!
            will_win = True
            reason_str = f"ğŸ‘‘ğŸš€ AUTONOMOUS LEARN: +${expected_profit:.4f} < ${QUEEN_MIN_PROFIT:.4f} BUT trading to learn! ({ladder_info}){dream_display}"
        
        # ğŸ HIVE STATE VOICE - Queen speaks her decision
        # BEFORE we announce EXECUTE, consult Loss Learning to avoid cost-eaten trades
        try:
            if will_win and hasattr(self, 'loss_learning') and self.loss_learning:
                avoid, avoid_reason = self.loss_learning.should_avoid_trade(
                    from_asset, to_asset, exchange, expected_profit, from_value
                )
                if avoid:
                    will_win = False
                    reason_str = f"ğŸ‘‘âŒ SERO BLOCKS: {avoid_reason}"
                    safe_print(f"   ğŸ‘‘âŒ SERO SAYS NO: {reason_str}")
        except Exception as e:
            logger.debug(f"Loss learning guard error: {e}")

        if self.hive:
            try:
                if will_win:
                    self.hive.voice.speak("EXECUTE", f"{from_asset}â†’{to_asset} | {reason_str[:80]}")
                else:
                    # This path won't happen in current autonomous mode, but keep for safety
                    self.hive.voice.speak("VETO", f"{from_asset}â†’{to_asset} | {reason_str[:80]}")
                    self.hive.update(veto_reason=reason_str[:100])
            except Exception as e:
                logger.debug(f"Hive voice error: {e}")

        return will_win, avg_confidence, reason_str
    
    async def queen_learn_pattern(self, opportunity: 'MicroOpportunity', predicted_win: bool, reason: str):
        """
        ğŸ‘‘ğŸ§  QUEEN LEARNS: Record a pattern the Queen observed (without trading)
        """
        path_key = (opportunity.from_asset, opportunity.to_asset)
        
        # Store in path memory as an observation
        if path_key not in self.barter_matrix.barter_history:
            self.barter_matrix.barter_history[path_key] = {
                'trades': 0, 'wins': 0, 'losses': 0, 'total_profit': 0.0,
                'avg_slippage': 0.5, 'queen_observations': []
            }
        
        history = self.barter_matrix.barter_history[path_key]
        if 'queen_observations' not in history:
            history['queen_observations'] = []
        
        history['queen_observations'].append({
            'timestamp': time.time(),
            'predicted_win': predicted_win,
            'reason': reason,
            'expected_pnl': opportunity.expected_pnl_usd
        })
        
        # Keep only last 10 observations
        history['queen_observations'] = history['queen_observations'][-10:]
        
        logger.info(f"ğŸ‘‘ğŸ§  Queen learned pattern: {opportunity.from_asset}â†’{opportunity.to_asset} | Win={predicted_win} | {reason}")
    
    async def queen_continuous_learning(self):
        """
        ğŸ‘‘ğŸ§  QUEEN'S UNIFIED LEARNING SYSTEM - ALL systems EVERY TURN!
        
        This runs EVERY turn to ensure the Queen is constantly learning:
        1. Neural Brain - Deep Learning with Backpropagation
        2. Elephant Memory - Never forgets patterns
        3. Loss Learning - Never repeats mistakes
        4. Adaptive Gate - Adjusts profit thresholds
        5. Path Memory - Tracks conversion paths
        6. Barter History - Records every trade
        7. Mycelium Network - Broadcasts learnings
        8. Wisdom Engine - 11 Civilizations cognition
        9. Miner Brain - Cognitive Intelligence
        10. Deep Learning - Evolve Consciousness
        11. Code Architect - Write code from learnings! ğŸ—ï¸
        """
        learning_active = {
            'neural_brain': False,
            'elephant_memory': False,
            'loss_learning': False,
            'adaptive_gate': False,
            'path_memory': False,
            'barter_history': False,
            'mycelium': False,
            'deep_learning': False,
            'wisdom_engine': False,
            'miner_brain': False,  # ğŸ§  MINER BRAIN COGNITION!
            'code_architect': False,  # ğŸ‘‘ğŸ—ï¸ SELF-EVOLUTION ENGINE!
        }
        
        # Build unified learning context (shared across all systems)
        # FIX: Use turns_completed (the actual turn counter) not turn_number (doesn't exist)
        turn_num = getattr(self, 'turns_completed', 0) + 1  # +1 because display uses turns_completed+1
        learning_context = {
            'turn': turn_num,
            'prices': dict(self.prices) if self.prices else {},
            'balances': dict(self.balances) if self.balances else {},
            'total_value': sum(self.balances.get(a, 0) * self.prices.get(a, 0) for a in self.balances) if self.prices and self.balances else 0,
            'conversions': getattr(self, 'conversions_made', 0),
            'profit': getattr(self, 'total_profit_usd', 0.0),
            'timestamp': time.time(),
        }
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. ğŸ§  NEURAL BRAIN - Deep Learning Pattern Recognition (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
            learning_active['neural_brain'] = True
            try:
                if hasattr(self.queen.neural_brain, 'observe'):
                    self.queen.neural_brain.observe(learning_context)
            except Exception as e:
                logger.debug(f"Neural brain learning error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. ğŸ˜ ELEPHANT MEMORY - Never Forgets (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen and hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
            learning_active['elephant_memory'] = True
            try:
                if hasattr(self.queen.elephant_brain, 'remember_market_state'):
                    self.queen.elephant_brain.remember_market_state(
                        learning_context['prices'], 
                        learning_context['balances']
                    )
            except Exception as e:
                logger.debug(f"Elephant memory error: {e}")
        
        # Also check loss_learning's elephant
        if self.loss_learning and hasattr(self.loss_learning, 'elephant') and self.loss_learning.elephant:
            learning_active['elephant_memory'] = True
            try:
                if hasattr(self.loss_learning.elephant, 'remember_market_state'):
                    self.loss_learning.elephant.remember_market_state(
                        learning_context['prices'], 
                        learning_context['balances']
                    )
            except Exception as e:
                logger.debug(f"Loss learning elephant error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 3. ğŸ“‰ LOSS LEARNING - Never Repeats Mistakes (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.loss_learning:
            learning_active['loss_learning'] = True
            # Save learnings EVERY turn to persist knowledge
            try:
                if hasattr(self.loss_learning, '_save_loss_memory'):
                    self.loss_learning._save_loss_memory()
            except Exception as e:
                logger.debug(f"Loss learning save error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 4. âš¡ ADAPTIVE GATE - Adjusts Profit Thresholds (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.adaptive_gate:
            learning_active['adaptive_gate'] = True
            try:
                if hasattr(self.adaptive_gate, 'update_thresholds'):
                    self.adaptive_gate.update_thresholds(learning_context['prices'])
                elif hasattr(self.adaptive_gate, 'learn_from_market'):
                    self.adaptive_gate.learn_from_market(learning_context)
            except Exception as e:
                logger.debug(f"Adaptive gate error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 4.5. ğŸ’° FEE TRACKER - Updates Real Cost Data (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'fee_tracker') and self.fee_tracker:
            learning_active['fee_tracker'] = True
            try:
                # Refresh fee tier if needed (checks 30d volume)
                tier = self.fee_tracker.get_fee_tier()
                # Broadcast fee awareness to learning context
                learning_context['fee_tier'] = tier.tier
                learning_context['fee_taker_bps'] = tier.taker_bps
                learning_context['30d_volume'] = self.fee_tracker.volume_30d
            except Exception as e:
                logger.debug(f"Fee tracker learning error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 5. ğŸ›¤ï¸ PATH MEMORY - Tracks All Conversion Paths (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'path_memory') and self.path_memory:
            learning_active['path_memory'] = True
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 6. ğŸ“Š BARTER HISTORY - Records Everything (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            learning_active['barter_history'] = True
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 7. ğŸ„ MYCELIUM NETWORK - Broadcasts Learnings (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            learning_active['mycelium'] = True
            try:
                if hasattr(self.mycelium_network, 'broadcast_signal'):
                    signal = {
                        'type': 'UNIFIED_LEARNING_PULSE',
                        'turn': getattr(self, 'turn_number', 0),
                        'active_systems': sum(1 for v in learning_active.values() if v),
                        'profit': learning_context['profit'],
                        # ğŸ’° Include fee awareness in broadcast
                        'fee_tier': learning_context.get('fee_tier', 1),
                        'fee_taker_bps': learning_context.get('fee_taker_bps', 25),
                        '30d_volume': learning_context.get('30d_volume', 0),
                    }
                    self.mycelium_network.broadcast_signal(signal)
            except Exception as e:
                logger.debug(f"Mycelium broadcast error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 8. ğŸ§  WISDOM ENGINE - 11 Civilizations Cognition (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'wisdom_engine') and self.wisdom_engine:
            learning_active['wisdom_engine'] = True
            try:
                if hasattr(self.wisdom_engine, 'observe_market'):
                    self.wisdom_engine.observe_market(learning_context)
                elif hasattr(self.wisdom_engine, 'get_unified_wisdom'):
                    # Get wisdom for current market state
                    market_state = 'volatile' if learning_context['profit'] < 0 else 'stable'
                    self.wisdom_engine.get_unified_wisdom(market_state)
            except Exception as e:
                logger.debug(f"Wisdom engine error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 9. ğŸ§  MINER BRAIN - Cognitive Intelligence (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'miner_brain') and self.miner_brain:
            learning_active['miner_brain'] = True
            try:
                # Miner brain cognitive cycle - runs EVERY turn
                if hasattr(self.miner_brain, 'cognitive') and self.miner_brain.cognitive:
                    # Feed market context to cognitive circle
                    self.miner_brain.cognitive.observe(learning_context)
                
                # Memory core - record state
                if hasattr(self.miner_brain, 'memory') and self.miner_brain.memory:
                    self.miner_brain.memory.record_market_state(learning_context)
                
                # Speculation engine - think about market
                if hasattr(self.miner_brain, 'speculator') and self.miner_brain.speculator:
                    self.miner_brain.speculator.speculate(learning_context)
                
                # Self-reflection - learn from history
                if hasattr(self.miner_brain, 'reflection') and self.miner_brain.reflection:
                    self.miner_brain.reflection.reflect(learning_context)
                
                # Wisdom engine integration
                if hasattr(self.miner_brain, 'wisdom_engine') and self.miner_brain.wisdom_engine:
                    market_state = 'volatile' if learning_context.get('profit', 0) < 0 else 'stable'
                    self.miner_brain.wisdom_engine.get_unified_wisdom(market_state)
                
            except Exception as e:
                logger.debug(f"Miner brain cognition error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 10. ğŸ‘‘ğŸ§  DEEP LEARNING - Backpropagation & Evolution (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
            learning_active['deep_learning'] = True
            try:
                # Evolve consciousness EVERY turn (was every 50)
                if hasattr(self.queen, 'evolve_consciousness'):
                    result = await self.queen.evolve_consciousness()
                    if result.get('status') == 'trained':
                        logger.debug(f"ğŸ‘‘ğŸ§  DEEP LEARNING: Consciousness evolved! Loss: {result.get('avg_loss', 0):.4f}")
                        
                        # Broadcast evolution to all systems
                        if hasattr(self, 'mycelium_network') and self.mycelium_network:
                            try:
                                self.mycelium_network.broadcast_signal({
                                    'type': 'CONSCIOUSNESS_EVOLVED',
                                    'loss': result.get('avg_loss', 0),
                                    'turn': getattr(self, 'turn_number', 0),
                                })
                            except:
                                pass
            except Exception as e:
                logger.debug(f"Deep learning evolution error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 11. ğŸ‘‘ğŸ—ï¸ CODE ARCHITECT - Write Code From Learnings (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if hasattr(self, 'code_architect') and self.code_architect:
            learning_active['code_architect'] = True
            # Log when Code Architect is active (every 10 turns)
            if turn_num % 10 == 0:
                logger.info(f"ğŸ‘‘ğŸ—ï¸ CODE ARCHITECT: Active at turn {turn_num}")
            try:
                # Synthesize learnings into actionable insights
                learning_synthesis = {
                    'turn': turn_num,
                    'profit': learning_context.get('profit', 0),
                    'total_value': learning_context.get('total_value', 0),
                    'conversions': learning_context.get('conversions', 0),
                    'active_learning_systems': sum(1 for v in learning_active.values() if v),
                    'timestamp': time.time(),
                }
                
                # Get insights from all connected systems
                insights = []
                
                # ALWAYS add core state insights (GUARANTEED to not be empty)
                insights.append(f"turn_state:turn_{turn_num}")
                insights.append(f"profit_state:{learning_context.get('profit', 0):.4f}")
                insights.append(f"active_systems:{sum(1 for v in learning_active.values() if v)}")
                
                # Elephant patterns (if available)
                if self.queen and hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
                    try:
                        if hasattr(self.queen.elephant_brain, 'get_best_patterns'):
                            patterns = self.queen.elephant_brain.get_best_patterns(top_n=3)
                            insights.extend([f"elephant_pattern:{p}" for p in patterns[:3]])
                        elif hasattr(self.queen.elephant_brain, 'patterns'):
                            # Fallback: use raw patterns dict
                            patterns = list(self.queen.elephant_brain.patterns.keys())[:3]
                            insights.extend([f"elephant_pattern:{p}" for p in patterns])
                        else:
                            insights.append("elephant:active_but_no_patterns_yet")
                    except Exception as e:
                        logger.debug(f"Elephant insight error: {e}")
                
                # Path memory wisdom (if available)
                if hasattr(self, 'path_memory') and self.path_memory:
                    try:
                        if hasattr(self.path_memory, 'get_best_paths'):
                            best_paths = self.path_memory.get_best_paths(limit=3)
                            insights.extend([f"best_path:{p.get('path', '')}" for p in best_paths[:3]])
                        elif hasattr(self.path_memory, 'paths'):
                            paths = list(self.path_memory.paths.keys())[:3]
                            insights.extend([f"path_memory:{p}" for p in paths])
                        else:
                            insights.append("path_memory:active_learning")
                    except Exception as e:
                        logger.debug(f"Path memory insight error: {e}")
                
                # Loss learning tactics (if available)
                if self.loss_learning:
                    try:
                        if hasattr(self.loss_learning, 'tactics') and self.loss_learning.tactics:
                            tactics = list(self.loss_learning.tactics.keys())[:3]
                            insights.extend([f"learned_tactic:{t}" for t in tactics])
                        elif hasattr(self.loss_learning, 'lessons_learned'):
                            insights.append(f"lessons_learned:{len(self.loss_learning.lessons_learned)}")
                        else:
                            insights.append("loss_learning:active_monitoring")
                    except Exception as e:
                        logger.debug(f"Loss learning insight error: {e}")
                
                # Neural brain state (if available)
                if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
                    try:
                        if hasattr(self.queen.neural_brain, 'get_confidence'):
                            conf = self.queen.neural_brain.get_confidence()
                            insights.append(f"neural_confidence:{conf:.2f}")
                        else:
                            insights.append("neural_brain:active_thinking")
                    except Exception as e:
                        logger.debug(f"Neural brain insight error: {e}")
                
                # Log insight count for debugging
                logger.debug(f"ğŸ‘‘ğŸ—ï¸ CODE ARCHITECT: Collected {len(insights)} insights")
                
                learning_synthesis['insights'] = insights
                
                # Every 5 turns, Queen writes a learning summary config
                if turn_num > 0 and turn_num % 5 == 0:
                    try:
                        # Write learning state to config
                        config_name = f"learning_state_turn_{turn_num}"
                        self.code_architect.save_config(config_name, {
                            'turn': turn_num,
                            'profit': learning_context.get('profit', 0),
                            'total_value': learning_context.get('total_value', 0),
                            'active_systems': sum(1 for v in learning_active.values() if v),
                            'insights': insights,
                            'timestamp': time.time(),
                        })
                        logger.info(f"ğŸ‘‘ğŸ—ï¸ CODE ARCHITECT: Saved learning state at turn {turn_num}")
                    except Exception as e:
                        logger.warning(f"Code architect config save error: {e}")
                
                # Every 10 turns, generate an enhancement from learnings
                if turn_num > 0 and turn_num % 10 == 0 and len(insights) >= 1:
                    try:
                        logger.info(f"ğŸ‘‘ğŸ—ï¸ CODE ARCHITECT: Attempting enhancement generation at turn {turn_num} with {len(insights)} insights")
                        await self._architect_generate_enhancement_from_learnings(
                            learning_synthesis, 
                            insights
                        )
                    except Exception as e:
                        logger.warning(f"Code architect enhancement error: {e}")
                        import traceback
                        logger.warning(traceback.format_exc())
                        
            except Exception as e:
                logger.warning(f"Code architect learning error: {e}")
        else:
            # Debug: Log why code_architect isn't available
            if turn_num % 10 == 0:
                has_attr = hasattr(self, 'code_architect')
                is_not_none = getattr(self, 'code_architect', None) is not None
                logger.warning(f"ğŸ‘‘ğŸ—ï¸ CODE ARCHITECT NOT AVAILABLE: hasattr={has_attr}, is_not_none={is_not_none}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ“Š UNIFIED LEARNING STATUS (EVERY TURN)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        active_count = sum(1 for v in learning_active.values() if v)
        total_count = len(learning_active)
        
        # Log every 10 turns to avoid spam
        if turn_num % 10 == 0:
            logger.info(f"ğŸ‘‘ğŸ§  UNIFIED LEARNING: {active_count}/{total_count} systems active EVERY TURN")
        
        return learning_active
    
    async def _architect_generate_enhancement_from_learnings(self, learning_synthesis: Dict, insights: List[str]):
        """
        ğŸ‘‘ğŸ—ï¸ Generate code enhancement from accumulated learnings.
        
        The Queen synthesizes her learnings into actual Python code that can:
        1. Improve trading strategies
        2. Add new pattern recognition
        3. Optimize profit calculations
        4. Adjust thresholds dynamically
        """
        if not hasattr(self, 'code_architect') or not self.code_architect:
            return
            
        turn_num = learning_synthesis.get('turn', 0)
        profit = learning_synthesis.get('profit', 0)
        
        # Determine what kind of enhancement to generate
        enhancement_type = 'pattern_recognition'
        if profit < 0:
            enhancement_type = 'loss_prevention'
        elif profit > 1.0:
            enhancement_type = 'profit_optimization'
        
        # Generate enhancement code
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        enhancement_name = f"queen_learning_turn_{turn_num}"
        
        # Build the enhancement code - sanitize insights for embedding in code
        safe_insights = []
        for i in insights[:10]:
            # Escape quotes and normalize for Python literal
            safe = str(i).replace("\\", "\\\\").replace("'", "\\'").replace('"', '\\"')
            safe_insights.append(safe)
        insights_str = '\n'.join([f"    # - {i}" for i in safe_insights])
        insights_list_str = repr(safe_insights)  # Use repr for safe Python list literal
        
        enhancement_code = f'''#!/usr/bin/env python3
"""
ğŸ‘‘ğŸ§  QUEEN-GENERATED LEARNING ENHANCEMENT
============================================================
Generated from Turn {turn_num} learnings
Enhancement Type: {enhancement_type}
Timestamp: {timestamp}

Insights synthesized:
{insights_str}

This code was automatically generated by Queen Sero's
Code Architect based on real-time learning from trading.
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class LearningEnhancement_{turn_num}:
    """
    Enhancement generated from turn {turn_num} with ${profit:.4f} profit.
    """
    
    def __init__(self):
        self.generated_at = "{timestamp}"
        self.turn = {turn_num}
        self.profit_at_generation = {profit}
        self.enhancement_type = "{enhancement_type}"
        self.insights = {insights_list_str}
        logger.info(f"ğŸ‘‘ğŸ—ï¸ Learning Enhancement {{self.turn}} loaded!")
    
    def evaluate_opportunity(self, opportunity: Dict[str, Any]) -> Dict[str, Any]:
        """
        Apply learned patterns to evaluate an opportunity.
        Returns adjusted score based on learnings.
        """
        score = opportunity.get('score', 0.5)
        adjustments = []
        
        # Apply insights as pattern matching
        path = f"{{opportunity.get('from_asset', '')}}->{{opportunity.get('to_asset', '')}}"
        
        # Check against learned patterns
        for insight in self.insights:
            if 'best_path:' in insight and path in insight:
                score += 0.1
                adjustments.append("best_path_match:+0.1")
            elif 'learned_tactic:' in insight:
                tactic = insight.split(':')[1] if ':' in insight else ''
                if tactic and tactic in path:
                    score += 0.05
                    adjustments.append("tactic_match:+0.05")
        
        return {{
            'original_score': opportunity.get('score', 0.5),
            'adjusted_score': min(1.0, max(0.0, score)),
            'adjustments': adjustments,
            'enhancement_turn': self.turn,
        }}
    
    def get_info(self) -> Dict[str, Any]:
        return {{
            'turn': self.turn,
            'type': self.enhancement_type,
            'profit': self.profit_at_generation,
            'insights_count': len(self.insights),
            'generated_at': self.generated_at,
        }}

# Singleton
_instance = None

def get_enhancement():
    global _instance
    if _instance is None:
        _instance = LearningEnhancement_{turn_num}()
    return _instance

if __name__ == "__main__":
    enh = get_enhancement()
    safe_print(f"Enhancement: {{enh.get_info()}}")
'''
        
        # Write the enhancement file
        file_path = f"queen_strategies/{enhancement_name}_{timestamp}.py"
        success = self.code_architect.write_file(file_path, enhancement_code, backup=False)
        
        if success:
            logger.info(f"ğŸ‘‘ğŸ—ï¸ CODE ARCHITECT: Generated enhancement from learnings: {file_path}")
            
            # ğŸ‘‘ğŸ”„ RELOAD ENHANCEMENTS - Queen uses her NEW code immediately!
            try:
                global QUEEN_ENHANCEMENT_LOADER
                QUEEN_ENHANCEMENT_LOADER = None  # Force reload
                loader = get_queen_enhancement_loader()
                logger.info(f"ğŸ‘‘ğŸ—ï¸ ENHANCEMENTS RELOADED: {loader.enhancement_count} learning modules now active!")
            except Exception as e:
                logger.debug(f"Enhancement reload error: {e}")
            
            # Broadcast to mycelium
            if hasattr(self, 'mycelium_network') and self.mycelium_network:
                try:
                    self.mycelium_network.broadcast_signal({
                        'type': 'CODE_EVOLVED',
                        'file': file_path,
                        'turn': turn_num,
                        'enhancement_type': enhancement_type,
                    })
                except:
                    pass
        
        return success
    
    async def unified_learn_from_outcome(self, opportunity: 'MicroOpportunity', success: bool, actual_pnl: float = 0.0):
        """
        ğŸ‘‘ğŸ“ UNIFIED LEARNING FROM TRADE OUTCOME
        
        All learning systems receive the same trade outcome:
        1. Neural Brain (Backprop)
        2. Elephant Memory (Pattern)
        3. Loss Learning (If loss)
        4. Path Memory (Path stats)
        5. Barter History (Trade record)
        6. Mycelium (Broadcast)
        """
        path_key = f"{opportunity.from_asset}â†’{opportunity.to_asset}"
        
        # Build unified outcome context
        outcome = {
            'path': path_key,
            'from_asset': opportunity.from_asset,
            'to_asset': opportunity.to_asset,
            'success': success,
            'actual_pnl': actual_pnl,
            'expected_pnl': getattr(opportunity, 'expected_pnl_usd', 0),
            'exchange': getattr(opportunity, 'source_exchange', 'unknown'),
            'timestamp': time.time(),
            'turn': getattr(self, 'turn_number', 0),
        }
        
        # 1. ğŸ§  NEURAL BRAIN - Backpropagation
        if self.queen and hasattr(self.queen, 'neural_brain') and self.queen.neural_brain:
            try:
                from queen_neuron import NeuralInput
                neural_input = NeuralInput(
                    probability_score=getattr(opportunity, 'score', 0.5),
                    wisdom_score=getattr(opportunity, 'wisdom_score', 0.5),
                    quantum_signal=getattr(opportunity, 'quantum_signal', 0.0),
                    gaia_resonance=getattr(opportunity, 'gaia_resonance', 0.5),
                    emotional_coherence=getattr(opportunity, 'emotional_coherence', 0.5),
                    mycelium_signal=getattr(opportunity, 'mycelium_signal', 0.0),
                )
                if hasattr(self.queen.neural_brain, 'train_on_example'):
                    loss = self.queen.neural_brain.train_on_example(neural_input, success)
                    self.queen.neural_brain.save_weights()
                    logger.debug(f"ğŸ§  Neural backprop: loss={loss:.4f}")
            except Exception as e:
                logger.debug(f"Neural learning error: {e}")
        
        # 2. ğŸ˜ ELEPHANT MEMORY - Record Pattern
        if self.queen and hasattr(self.queen, 'elephant_brain') and self.queen.elephant_brain:
            try:
                if hasattr(self.queen.elephant_brain, 'record_trade_result'):
                    self.queen.elephant_brain.record_trade_result(
                        opportunity.from_asset, 
                        opportunity.to_asset,
                        actual_pnl,
                        success
                    )
            except Exception as e:
                logger.debug(f"Elephant learning error: {e}")
        
        # 3. ğŸ“‰ LOSS LEARNING - If it was a loss
        # ğŸ‘‘ SKIPPING LOSS LEARNING FOR SMALL FEES IN STARVATION MODE
        # If the loss is tiny (likely just spread/fees), don't blocking the path!
        is_tiny_loss = actual_pnl < 0 and abs(actual_pnl) < 0.05  # Ignore < $0.05 loss
        
        if (not success or actual_pnl < 0) and not is_tiny_loss:
            if self.loss_learning:
                try:
                    await self.loss_learning.process_loss(
                        symbol=opportunity.to_asset,
                        exchange=outcome['exchange'],
                        amount=opportunity.from_amount,
                        loss_usd=abs(actual_pnl) if actual_pnl < 0 else 0,
                        reason="Trade outcome" if success else "Execution failed"
                    )
                except Exception as e:
                    logger.debug(f"Loss learning error: {e}")
        elif is_tiny_loss:
            logger.info(f"ğŸ‘‘ğŸ’€ SURVIVAL: Ignoring tiny loss ${abs(actual_pnl):.4f} - treated as cost of business!")
        
        # 4. ğŸ›¤ï¸ PATH MEMORY - Update path stats
        if hasattr(self, 'path_memory') and self.path_memory:
            try:
                if hasattr(self.path_memory, 'record_result'):
                    self.path_memory.record_result(
                        opportunity.from_asset,
                        opportunity.to_asset,
                        success,
                        actual_pnl
                    )
            except Exception as e:
                logger.debug(f"Path memory error: {e}")
        
        # 5. ğŸ“Š BARTER HISTORY - Record trade
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            try:
                pk = (opportunity.from_asset, opportunity.to_asset)
                if pk not in self.barter_matrix.barter_history:
                    self.barter_matrix.barter_history[pk] = {
                        'trades': 0, 'wins': 0, 'losses': 0, 'total_profit': 0.0
                    }
                hist = self.barter_matrix.barter_history[pk]
                hist['trades'] += 1
                if success and actual_pnl >= 0:
                    hist['wins'] += 1
                else:
                    hist['losses'] += 1
                hist['total_profit'] += actual_pnl
            except Exception as e:
                logger.debug(f"Barter history error: {e}")
        
        # 6. ğŸ„ MYCELIUM - Broadcast learning
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'broadcast_signal'):
                    self.mycelium_network.broadcast_signal({
                        'type': 'UNIFIED_TRADE_OUTCOME',
                        'path': path_key,
                        'success': success,
                        'pnl': actual_pnl,
                        'turn': getattr(self, 'turn_number', 0),
                    })
            except Exception as e:
                logger.debug(f"Mycelium broadcast error: {e}")
        
        # 7. ğŸ§  MINER BRAIN - Cognitive Learning from outcome
        if hasattr(self, 'miner_brain') and self.miner_brain:
            try:
                # Memory core - record trade outcome
                if hasattr(self.miner_brain, 'memory') and self.miner_brain.memory:
                    self.miner_brain.memory.record_trade_outcome(outcome)
                
                # Reflection - learn from trade
                if hasattr(self.miner_brain, 'reflection') and self.miner_brain.reflection:
                    self.miner_brain.reflection.learn_from_trade(outcome)
                
                # Skeptical analyzer - question the result
                if hasattr(self.miner_brain, 'skeptic') and self.miner_brain.skeptic:
                    self.miner_brain.skeptic.analyze_trade(outcome)
                    
            except Exception as e:
                logger.debug(f"Miner brain outcome learning error: {e}")
        
        logger.info(f"ğŸ‘‘ğŸ“ UNIFIED LEARNING: {path_key} | {'âœ…' if success else 'âŒ'} | ${actual_pnl:+.4f}")
        
        return outcome
    
    async def queen_learn_from_trade(self, opportunity: 'MicroOpportunity', success: bool):
        """
        ğŸ‘‘ğŸ“š QUEEN LEARNS FROM TRADE - Routes to UNIFIED LEARNING SYSTEM
        
        This is the main entry point called after trades.
        Routes to unified_learn_from_outcome() for consistent learning.
        """
        # Get actual P/L if available
        actual_pnl = getattr(opportunity, 'actual_pnl_usd', opportunity.expected_pnl_usd)
        
        # ğŸ¦ˆğŸ”ª ORCA LEARNS FROM TRADE OUTCOME - Feed the killer whale!
        if hasattr(self, 'orca') and self.orca:
            try:
                self.orca.learn_from_trade({
                    'symbol': opportunity.to_asset,
                    'direction': 'buy',  # We bought to_asset
                    'entry_price': opportunity.from_value_usd / opportunity.from_amount if opportunity.from_amount > 0 else 0,
                    'exit_price': None,  # Not tracked yet
                    'pnl_pips': actual_pnl * 100,  # Convert USD to rough pip equivalent
                    'pnl_usd': actual_pnl,
                    'success': success,
                    'exchange': getattr(opportunity, 'source_exchange', 'unknown'),
                    'whale_influenced': getattr(opportunity, 'whale_influenced', False),
                })
            except Exception as e:
                logger.debug(f"Orca learn error: {e}")
        
        # ğŸ’° RECORD IN FEE TRACKER - Track actual costs for learning
        exchange = getattr(opportunity, 'source_exchange', 'alpaca') or 'alpaca'
        if exchange.lower() == 'alpaca' and hasattr(self, 'fee_tracker') and self.fee_tracker:
            try:
                from_asset = opportunity.from_asset.upper()
                to_asset = opportunity.to_asset.upper()
                symbol = f"{from_asset}/{to_asset}"
                
                # Record the trade completion
                fee_record = self.fee_tracker.record_trade_completion(
                    symbol=symbol,
                    side='sell',  # Converting from_asset to to_asset
                    quantity=opportunity.from_amount,
                    fill_price=opportunity.from_value_usd / opportunity.from_amount if opportunity.from_amount > 0 else 0,
                    expected_pnl=opportunity.expected_pnl_usd,
                    actual_pnl=actual_pnl,
                    order_id=getattr(opportunity, 'order_id', None)
                )
                
                if fee_record:
                    logger.info(f"ğŸ’° Fee tracker recorded: expected_cost=${fee_record.get('expected_cost_usd', 0):.4f}, "
                               f"actual_fee=${fee_record.get('actual_fee_usd', 0):.4f}, "
                               f"fee_accuracy={fee_record.get('fee_accuracy', 0):.1%}")
            except Exception as e:
                logger.debug(f"Fee tracker record error: {e}")
        
        # Route to unified learning system
        await self.unified_learn_from_outcome(opportunity, success, actual_pnl)
        
        # ğŸ‘‘ğŸ¤ THE QUEEN SPEAKS ABOUT THE TRADE!
        if self.queen and hasattr(self.queen, 'say'):
            try:
                if success and actual_pnl > 0:
                    if actual_pnl > 0.10:
                        msg = f"Beautiful! We made ${actual_pnl:.4f} on {opportunity.from_asset} to {opportunity.to_asset}!"
                        self.queen.say(msg, voice_enabled=True, emotion="profit")
                    else:
                        msg = f"Nice! ${actual_pnl:.4f} profit. Every bit counts!"
                        self.queen.say(msg, voice_enabled=False, emotion="calm")
                elif actual_pnl < 0:
                    msg = f"Loss of ${abs(actual_pnl):.4f}. Learning from this!"
                    self.queen.say(msg, voice_enabled=False, emotion="loss")
                else:
                    msg = f"Trade didn't work. Adapting strategy!"
                    self.queen.say(msg, voice_enabled=False, emotion="loss")
            except Exception as e:
                logger.debug(f"Queen speak error: {e}")
        
        path_key = (opportunity.from_asset, opportunity.to_asset)
        
        # Update prediction accuracy tracking
        if path_key not in self.barter_matrix.barter_history:
            self.barter_matrix.barter_history[path_key] = {
                'trades': 0, 'wins': 0, 'losses': 0, 'total_profit': 0.0,
                'avg_slippage': 0.5
            }
        
        history = self.barter_matrix.barter_history[path_key]
        
        # Track prediction accuracy
        if 'queen_predictions' not in history:
            history['queen_predictions'] = {'correct': 0, 'total': 0}
        
        if success:
            history['queen_predictions']['correct'] += 1
        history['queen_predictions']['total'] += 1
        
        accuracy = history['queen_predictions']['correct'] / history['queen_predictions']['total']
        logger.info(f"ğŸ‘‘ğŸ“š Queen accuracy on {opportunity.from_asset}â†’{opportunity.to_asset}: {accuracy:.0%}")

    async def queen_observe_market(self, exchange: str, exchange_assets: Dict) -> Dict:
        """
        ğŸ‘‘ğŸ”® QUEEN OBSERVES MARKET - The Queen sees EVERYTHING on every turn!
        
        Before any filtering, the Queen:
        1. Checks all mycelium neuron connections
        2. Reads the cosmic luck field
        3. Observes market momentum patterns
        4. Learns from what she sees (even without trading)
        
        Returns: dict with queen's observations
        """
        icon = {'kraken': 'ğŸ™', 'alpaca': 'ğŸ¦™', 'binance': 'ğŸŸ¡'}.get(exchange, 'ğŸ“Š')
        
        observations = {
            'exchange': exchange,
            'timestamp': time.time(),
            'neurons_connected': 0,
            'total_neurons': 0,
            'cosmic_alignment': 0.5,
            'market_momentum': 0.0,
            'queen_verdict': 'OBSERVING'
        }
        
        # ğŸ‘‘ Count connected mycelium neurons - FULL 11/11 MIND MAP
        neurons = {
            'queen_hive': hasattr(self, 'queen') and self.queen is not None,
            'mycelium_net': hasattr(self, 'mycelium_network') and self.mycelium_network is not None,
            'harmonic': hasattr(self, 'harmonic') and self.harmonic is not None,
            'luck_field': hasattr(self, 'luck_mapper') and self.luck_mapper is not None,
            'dream_memory': hasattr(self, 'dreams') and len(self.dreams) >= 0,  # Always true - dreams list exists
            'path_memory': hasattr(self, 'path_memory') and self.path_memory is not None,
            'timeline_oracle': hasattr(self, 'timeline_oracle') and self.timeline_oracle is not None,
            'thought_bus': hasattr(self, 'bus_aggregator') and self.bus_aggregator is not None,
            'ultimate_intel': hasattr(self, 'ultimate_intel') and self.ultimate_intel is not None,
            'wisdom_engine': hasattr(self, 'wisdom_engine') and self.wisdom_engine is not None,
            'barter_matrix': hasattr(self, 'barter_matrix') and self.barter_matrix is not None,
        }
        
        observations['total_neurons'] = len(neurons)
        observations['neurons_connected'] = sum(1 for v in neurons.values() if v)
        
        # ğŸ€ Read cosmic luck field
        luck_score = 0.5
        luck_state = "NEUTRAL"
        if hasattr(self, 'luck_mapper') and self.luck_mapper:
            try:
                luck = self.luck_mapper.read_field()
                luck_score = luck.luck_field
                luck_state = luck.luck_state.value
                observations['cosmic_alignment'] = luck_score
            except Exception:
                pass
        
        # ğŸ“Š Calculate market momentum from exchange assets
        momentum_sum = 0.0
        momentum_count = 0
        for asset in exchange_assets.keys():
            for symbol, data in self.ticker_cache.items():
                if data.get('base') == asset:
                    change = data.get('change24h', 0)
                    momentum_sum += change
                    momentum_count += 1
                    break
        
        if momentum_count > 0:
            observations['market_momentum'] = momentum_sum / momentum_count
        
        # ğŸ‘‘ Queen's overall verdict based on observations
        connected_pct = observations['neurons_connected'] / observations['total_neurons'] if observations['total_neurons'] > 0 else 0
        
        if connected_pct >= 0.8 and luck_score >= 0.6 and observations['market_momentum'] > 0:
            observations['queen_verdict'] = 'HUNT'  # Actively seeking opportunities
        elif connected_pct >= 0.6 and luck_score >= 0.4:
            observations['queen_verdict'] = 'READY'  # Ready to act if opportunity appears
        elif luck_score < 0.3 or connected_pct < 0.5:
            observations['queen_verdict'] = 'CAUTION'  # Low luck or disconnected neurons
        else:
            observations['queen_verdict'] = 'OBSERVING'  # Neutral, watching
        
        # ğŸ‘‘ Print Sero's status on every turn
        safe_print(f"   ğŸ‘‘ SERO {observations['queen_verdict']}: {observations['neurons_connected']}/{observations['total_neurons']} neurons | Luck: {luck_state} | Momentum: {observations['market_momentum']:+.1f}%")
        
        # ğŸ„ Broadcast through mycelium
        if hasattr(self, 'mycelium_network') and self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'broadcast_signal'):
                    signal = {
                        'type': 'QUEEN_PULSE',
                        'exchange': exchange,
                        'verdict': observations['queen_verdict'],
                        'luck': luck_state,
                        'momentum': observations['market_momentum']
                    }
                    self.mycelium_network.broadcast_signal(signal)
                    safe_print(f"   ğŸ„ğŸ“¡ MYCELIUM PULSE: {exchange.upper()} | {observations['queen_verdict']} | Luck={luck_state}")
            except Exception:
                pass
        
        return observations

    async def queen_timeline_gate(self, opportunity: 'MicroOpportunity') -> Tuple[bool, str]:
        """
        â³ğŸ”® QUEEN'S TIMELINE GATE - The Queen looks at multiple timelines before acting.
        
        PHILOSOPHY:
        - We simulate 3 possible futures: EXECUTE, SKIP, REVERSE
        - We only act if EXECUTE leads to the most profitable timeline
        - We are NEVER in the losing game - the Queen sees ALL timelines!
        - NEW PATHS require PROOF before trading - no speculative trades!
        - ğŸ‘‘ğŸ”® QUEEN'S DREAMS ARE THE FOUNDATION OF ALL TIMELINES!
        
        Returns: (approved: bool, reason: str)
        """
        from_asset = opportunity.from_asset
        to_asset = opportunity.to_asset
        from_price = self.prices.get(from_asset, 0)
        to_price = self.prices.get(to_asset, 0)
        
        if from_price <= 0 or to_price <= 0:
            return False, "No price data for timeline simulation"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ”® CONSULT THE QUEEN'S DREAMS FIRST - Her wisdom guides all timelines!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        queen_dream_boost = 0.0
        queen_dream_confidence = 0.5
        queen_timeline_blessing = "NEUTRAL"
        
        if hasattr(self, 'queen') and self.queen:
            try:
                # Ask the Queen to dream about this opportunity
                dream_vision = self.queen.dream_of_winning({
                    'from_asset': from_asset,
                    'to_asset': to_asset,
                    'expected_pnl': opportunity.expected_pnl_usd,
                    'market_data': {
                        'from_price': from_price,
                        'to_price': to_price,
                    }
                })
                
                queen_dream_confidence = dream_vision.get('final_confidence', 0.5)
                queen_will_win = dream_vision.get('will_win', False)
                queen_timeline_blessing = dream_vision.get('timeline', 'NEUTRAL')
                
                # ğŸ‘‘ Queen's dream directly influences timeline predictions!
                if queen_will_win and queen_dream_confidence >= 0.6:
                    queen_dream_boost = 0.3  # +30% boost to EXECUTE timeline
                    queen_timeline_blessing = "FAVORABLE"
                elif queen_dream_confidence >= 0.5:
                    queen_dream_boost = 0.1  # +10% small boost
                    queen_timeline_blessing = "CAUTIOUS"
                elif queen_dream_confidence < 0.4:
                    queen_dream_boost = -0.2  # -20% penalty - Queen sees danger!
                    queen_timeline_blessing = "WARNING"
                    
                logger.info(f"ğŸ‘‘ğŸ”® Queen's Dream: {queen_timeline_blessing} | Confidence: {queen_dream_confidence:.0%} | Boost: {queen_dream_boost:+.0%}")
                
            except Exception as e:
                logger.debug(f"Could not consult Queen's dreams: {e}")
        
        # Get historical data for timeline simulation
        from_history = self.barter_matrix.barter_history.get((from_asset, to_asset), {})
        trades = from_history.get('trades', 0)
        wins = from_history.get('wins', 0)
        total_profit = from_history.get('total_profit', 0)
        avg_slippage = from_history.get('avg_slippage', 0.5)
        
        # ğŸ‘‘ QUEEN'S MANDATE #1: NEW PATHS ARE ALLOWED - A WIN IS A WIN!
        # Every new reality branch deserves a chance if the math says it's profitable
        # The Math Gate already validates costs - trust the math!
        is_stablecoin_from = from_asset.upper() in self.barter_matrix.STABLECOINS
        is_stablecoin_to = to_asset.upper() in self.barter_matrix.STABLECOINS
        is_safe_stable_swap = is_stablecoin_from and is_stablecoin_to
        
        # NEW PATHS: Log them but let Math Gate decide
        if trades == 0:
            logger.info(f"ğŸ†• NEW TIMELINE: {from_asset}â†’{to_asset} - First exploration of this reality branch!")
        
        # ğŸ‘‘ QUEEN'S MANDATE #2: Paths with negative history are blocked
        if trades > 0 and total_profit < 0:
            return False, f"LOSING PATH BLOCKED: {from_asset}â†’{to_asset} lost ${abs(total_profit):.2f}"
        
        # ğŸ‘‘ QUEEN'S MANDATE #3: Win rate must be >35% for non-stablecoin trades
        # PRIME PROFIT: Any profit is a win! Lower threshold to allow momentum
        if trades >= 3 and not is_safe_stable_swap:
            win_rate = wins / trades
            if win_rate < 0.35:
                return False, f"LOW WIN RATE: {from_asset}â†’{to_asset} at {win_rate:.0%} (need 35%+)"
        
        # ğŸ”® TIMELINE 1: EXECUTE (what happens if we do this trade?)
        # PRIME PROFIT: New paths get fair estimates - let math decide!
        # ğŸ‘‘ğŸ›¡ï¸ SLIPPAGE SAFETY: Always add 0.5% safety buffer to prevent losses!
        SLIPPAGE_SAFETY_BUFFER = 0.5  # Add 0.5% safety margin
        
        if is_safe_stable_swap:
            historical_win_rate = wins / trades if trades > 0 else 0.80  # 80% for stablecoins
            pessimistic_slippage = (avg_slippage if trades > 0 else 0.1) + SLIPPAGE_SAFETY_BUFFER
        elif trades == 0:
            # NEW TIMELINE: Be more conservative on first trade!
            historical_win_rate = 0.50  # 50% - more conservative for new paths
            pessimistic_slippage = 0.8 + SLIPPAGE_SAFETY_BUFFER  # 1.3% total for unknown pairs
        else:
            historical_win_rate = wins / trades  # Use actual history
            # Use the MAX of historical slippage or 0.5%, plus safety buffer
            pessimistic_slippage = max(avg_slippage, 0.5) + SLIPPAGE_SAFETY_BUFFER
        
        timeline_execute = {
            'action': 'EXECUTE',
            'expected_profit': opportunity.expected_pnl_usd,
            'historical_win_rate': historical_win_rate,
            'avg_slippage_cost': pessimistic_slippage / 100 * opportunity.from_value_usd,
            'confidence': opportunity.combined_score,
        }
        # Adjust for reality: expected - slippage = actual
        timeline_execute['predicted_actual'] = (
            timeline_execute['expected_profit'] - timeline_execute['avg_slippage_cost']
        )
        
        # ï¿½ğŸ”® APPLY QUEEN'S DREAM BOOST TO EXECUTE TIMELINE!
        # Her dreams directly influence the predicted outcome!
        if queen_dream_boost != 0:
            dream_adjustment = abs(timeline_execute['predicted_actual']) * queen_dream_boost
            timeline_execute['predicted_actual'] += dream_adjustment
            timeline_execute['queen_blessing'] = queen_timeline_blessing
            timeline_execute['queen_confidence'] = queen_dream_confidence
            logger.info(f"   ğŸ‘‘ Dream adjustment: ${dream_adjustment:+.4f} â†’ Predicted: ${timeline_execute['predicted_actual']:.4f}")
        
        # ğŸ”® TIMELINE 2: SKIP (what happens if we don't trade?)
        timeline_skip = {
            'action': 'SKIP',
            'expected_profit': 0.0,
            'historical_win_rate': 1.0,  # Can't lose by not trading
            'avg_slippage_cost': 0.0,
            'confidence': 1.0,
            'predicted_actual': 0.0,  # No gain, no loss
            'queen_blessing': 'NEUTRAL',
        }
        
        # ğŸ”® TIMELINE 3: REVERSE (what if we traded the OTHER way?)
        reverse_history = self.barter_matrix.barter_history.get((to_asset, from_asset), {})
        reverse_trades = reverse_history.get('trades', 0)
        reverse_wins = reverse_history.get('wins', 0)
        reverse_profit = reverse_history.get('total_profit', 0)
        
        timeline_reverse = {
            'action': 'REVERSE',
            'expected_profit': -opportunity.expected_pnl_usd * 0.5,  # Opposite direction
            'historical_win_rate': reverse_wins / reverse_trades if reverse_trades > 0 else 0.3,
            'avg_slippage_cost': pessimistic_slippage / 100 * opportunity.from_value_usd,
            'confidence': 0.3,  # Low confidence for reverse
            'predicted_actual': -opportunity.expected_pnl_usd * 0.5,
            'queen_blessing': 'UNFAVORABLE',  # Queen doesn't dream of reversals
        }
        
        # ğŸ‘‘ QUEEN'S TIMELINE ANALYSIS - Dreams inform the scoring!
        timelines = [timeline_execute, timeline_skip, timeline_reverse]
        
        # Score each timeline: predicted_actual * confidence * historical_win_rate * queen_factor
        for t in timelines:
            # Base score
            base_score = t['predicted_actual'] * t['confidence'] * t['historical_win_rate']
            
            # ğŸ‘‘ QUEEN'S DREAM MULTIPLIER - Her dreams have WEIGHT!
            queen_multiplier = 1.0
            if t.get('queen_blessing') == 'FAVORABLE':
                queen_multiplier = 1.5  # 50% boost if Queen dreams WIN
            elif t.get('queen_blessing') == 'CAUTIOUS':
                queen_multiplier = 1.1  # 10% boost
            elif t.get('queen_blessing') == 'WARNING':
                queen_multiplier = 0.5  # 50% penalty - heed the Queen's warning!
            elif t.get('queen_blessing') == 'UNFAVORABLE':
                queen_multiplier = 0.7  # 30% penalty
            
            t['timeline_score'] = base_score * queen_multiplier
            t['queen_multiplier'] = queen_multiplier
        
        # Sort by timeline score (best first)
        timelines.sort(key=lambda x: x['timeline_score'], reverse=True)
        best_timeline = timelines[0]
        
        # ğŸ‘‘ QUEEN'S MANDATE: Only execute if EXECUTE is the best timeline
        # PRIME PROFIT: If the Math Gate approved it AND expected profit > 0, TRUST IT!
        # ğŸ”® NOW INFORMED BY THE QUEEN'S DREAMS!
        if best_timeline['action'] == 'EXECUTE':
            # Additional safety: predicted actual must be positive
            if timeline_execute['predicted_actual'] > 0:
                blessing_msg = f" | ğŸ‘‘ {queen_timeline_blessing}" if queen_timeline_blessing != "NEUTRAL" else ""
                return True, f"Timeline EXECUTE wins (score: {timeline_execute['timeline_score']:.4f}){blessing_msg}"
            else:
                return False, f"EXECUTE timeline predicts loss: ${timeline_execute['predicted_actual']:.4f} | ğŸ‘‘ {queen_timeline_blessing}"
        
        elif best_timeline['action'] == 'SKIP':
            # ğŸ‘‘ QUEEN OVERRIDE: If Queen dreams FAVORABLE and math is positive, TRUST HER!
            if queen_timeline_blessing == 'FAVORABLE' and opportunity.expected_pnl_usd >= EPSILON_PROFIT_USD:
                return True, f"ğŸ‘‘ QUEEN OVERRIDE: Timeline SKIP but Queen dreams WIN! (+${opportunity.expected_pnl_usd:.4f})"
            # PRIME PROFIT: Only trust Math Gate if expected profit is ACTUALLY positive
            # Don't trade if we're expected to lose money!
            if opportunity.expected_pnl_usd >= EPSILON_PROFIT_USD:
                return True, f"Timeline SKIP but Math Gate says +${opportunity.expected_pnl_usd:.4f} - TRUSTING MATH!"
            return False, f"Timeline SKIP is safer (execute would: ${timeline_execute['predicted_actual']:.4f}) | ğŸ‘‘ {queen_timeline_blessing}"
        
        else:
            return False, f"Timeline REVERSE suggested - market moving against us | ğŸ‘‘ {queen_timeline_blessing}"

    async def validate_signal_quality(self, opportunity: 'MicroOpportunity') -> float:
        """
        ğŸ¯ SIGNAL QUALITY VALIDATION
        
        Checks if our signals support this conversion:
        - ğŸ‘‘ğŸ”® QUEEN'S DREAMS - Her visions guide all decisions!
        - Dreams about target asset (should be UP)
        - Dreams about source asset (should NOT be UP)
        - Bus aggregator score
        - PathMemory win rate for this path
        - Barter navigator path score
        
        Returns: 0.0-1.0 quality score (higher = better signals)
        """
        quality_scores = []
        
        # ğŸ‘‘ğŸ”® 0. QUEEN'S DREAM - THE MOST IMPORTANT SIGNAL!
        # All systems consult the Queen first!
        queen_dream_quality = 0.5  # Neutral default
        if self.queen and hasattr(self.queen, 'dream_of_winning'):
            try:
                opp_data = {
                    'from_asset': opportunity.from_asset,
                    'to_asset': opportunity.to_asset,
                    'expected_profit': opportunity.expected_pnl_usd,
                    'exchange': getattr(opportunity, 'source_exchange', 'kraken'),
                    'market_data': {
                        'volatility': getattr(opportunity, 'luck_score', 0.5),
                        'momentum': opportunity.combined_score,
                        'volume': 0.5,
                        'spread': 0.5
                    }
                }
                dream_vision = self.queen.dream_of_winning(opp_data)
                queen_confidence = dream_vision.get('final_confidence', 0.5)
                
                if dream_vision.get('will_win', False):
                    # Queen dreams WIN - this is the most important signal!
                    if queen_confidence >= 0.70:
                        queen_dream_quality = 0.95  # STRONG WIN
                        logger.info(f"ğŸ‘‘ğŸ”® Signal: Queen dreams STRONG WIN ({queen_confidence:.0%})")
                    elif queen_confidence >= 0.55:
                        queen_dream_quality = 0.75  # FAVORABLE
                        logger.info(f"ğŸ‘‘ğŸ”® Signal: Queen dreams FAVORABLE ({queen_confidence:.0%})")
                    else:
                        queen_dream_quality = 0.60  # Mild positive
                else:
                    # Queen dreams caution or loss
                    if queen_confidence <= 0.35:
                        queen_dream_quality = 0.20  # WARNING
                        logger.info(f"ğŸ‘‘âš ï¸ Signal: Queen dreams WARNING ({queen_confidence:.0%})")
                    else:
                        queen_dream_quality = 0.40  # Mild negative
                
                quality_scores.append(queen_dream_quality)
            except Exception as e:
                logger.debug(f"Queen dream signal error: {e}")
        
        # 1. Dream Score for TARGET (want UP dreams for buying)
        target_dream_score = self.calculate_dream_score(opportunity.to_asset)
        if target_dream_score > 0:  # Positive means UP dreams
            quality_scores.append(0.5 + target_dream_score * 0.5)  # 0.5-1.0
        elif target_dream_score < 0:  # DOWN dreams for target = bad
            quality_scores.append(0.25)
        else:
            quality_scores.append(0.5)  # Neutral
        
        # 2. Dream Score for SOURCE (don't want UP dreams - we're selling)
        source_dream_score = self.calculate_dream_score(opportunity.from_asset)
        if source_dream_score > 0:  # UP dreams for source = bad (we're selling it)
            quality_scores.append(0.25)
        elif source_dream_score < 0:  # DOWN dreams for source = good
            quality_scores.append(0.75)
        else:
            quality_scores.append(0.5)  # Neutral
        
        # 3. Bus Aggregator Score (if available)
        if self.bus_aggregator:
            try:
                bus_score = self.bus_aggregator.get_aggregate_score()
                quality_scores.append(bus_score)
            except:
                pass
        
        # 4. PathMemory Win Rate
        path_boost = self.path_memory.boost(opportunity.from_asset, opportunity.to_asset)
        # Convert boost (-0.05 to +0.10) to quality score (0.4-0.6)
        quality_scores.append(0.5 + path_boost * 2)  # Maps to 0.4-0.7
        
        # 5. Barter Navigator Path Score (if path exists)
        if self.barter_navigator:
            try:
                path = self.barter_navigator.find_path(opportunity.from_asset, opportunity.to_asset)
                if path:
                    # Multi-hop paths need higher confidence
                    if path.num_hops > 1:
                        quality_scores.append(0.6)  # Direct is better
                    else:
                        quality_scores.append(0.8)  # Direct path good
            except:
                pass
        
        # Calculate final quality score
        if quality_scores:
            final_score = sum(quality_scores) / len(quality_scores)
            # ğŸ‘‘ Show Queen's contribution to the signal
            queen_tag = f"ğŸ‘‘{queen_dream_quality:.0%}" if queen_dream_quality != 0.5 else ""
            safe_print(f"   ğŸ“Š Signal breakdown: {queen_tag} {', '.join([f'{s:.0%}' for s in quality_scores])}")
            return final_score
        
        return 0.5  # Default neutral

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸŒŠâš¡ MOMENTUM TRACKING - Wave Riding Logic from Momentum Snowball
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def update_momentum(self, asset: str, price: float):
        """Update momentum tracking for an asset - FROM MOMENTUM SNOWBALL ENGINE"""
        import time
        now = time.time()
        
        # Record price
        self.momentum_history[asset].append((now, price))
        
        # Calculate momentum (%/minute)
        history = self.momentum_history[asset]
        if len(history) < 2:
            self.asset_momentum[asset] = 0.0
            return
        
        cutoff = now - self.momentum_window
        
        # Find oldest price in window
        oldest_price = None
        oldest_time = now
        for t, p in history:
            if t >= cutoff:
                if oldest_price is None or t < oldest_time:
                    oldest_price = p
                    oldest_time = t
        
        if oldest_price is None or oldest_price <= 0:
            self.asset_momentum[asset] = 0.0
            return
        
        # Momentum = % change per minute
        time_diff = now - oldest_time
        if time_diff < 5:  # Need at least 5 seconds
            self.asset_momentum[asset] = 0.0
            return
        
        price_change = (price - oldest_price) / oldest_price
        minutes = time_diff / 60
        self.asset_momentum[asset] = price_change / minutes if minutes > 0 else 0.0
    
    def get_momentum(self, asset: str) -> float:
        """Get current momentum for asset (%/minute)"""
        return self.asset_momentum.get(asset, 0.0)
    
    def get_strongest_rising(self, exclude: set = None, limit: int = 3000) -> List[Tuple[str, float]]:
        """ğŸŒ FULL MARKET EXPANSION: Default limit 500â†’3000 for 100% MARKET COVERAGE!"""
        """Get assets with strongest RISING momentum - for wave jumping"""
        exclude = exclude or set()
        items = [(a, m) for a, m in self.asset_momentum.items() 
                 if a not in exclude and m > 0 and a in self.prices]
        return sorted(items, key=lambda x: x[1], reverse=True)[:limit]
    
    def get_weakest_falling(self, include: set = None, limit: int = 10) -> List[Tuple[str, float]]:
        """Get assets with FALLING momentum - to escape from"""
        include = include or set(self.asset_momentum.keys())
        items = [(a, m) for a, m in self.asset_momentum.items() 
                 if a in include and m < 0]
        return sorted(items, key=lambda x: x[1])[:limit]  # Most negative first
    
    def find_momentum_opportunity(self) -> Optional[Tuple[str, str, float, float, float]]:
        """
        Find best momentum-based conversion - JUMP FROM FALLING TO RISING
        
        Returns: (from_asset, to_asset, from_amount, expected_gain_pct, momentum_diff)
        """
        best = None
        best_momentum_diff = self.min_momentum_diff
        
        # Check our holdings
        for from_asset, from_amount in list(self.balances.items()):
            from_price = self.prices.get(from_asset, 0)
            from_value = from_amount * from_price
            
            if from_value < 5.0:  # Min trade value
                continue
            
            from_momentum = self.get_momentum(from_asset)
            
            # Look for rising assets to jump to
            for to_asset, to_momentum in self.get_strongest_rising(exclude={from_asset}):
                to_price = self.prices.get(to_asset, 0)
                if to_price <= 0:
                    continue
                
                # Momentum difference
                momentum_diff = to_momentum - from_momentum
                
                # Must exceed fees + minimum threshold
                fee_rate = 0.0021  # 0.21% total fees
                if momentum_diff > best_momentum_diff and momentum_diff > fee_rate:
                    net_advantage = momentum_diff - fee_rate
                    if net_advantage > 0:
                        best_momentum_diff = momentum_diff
                        best = (from_asset, to_asset, from_amount, net_advantage, momentum_diff)
        
        return best
    
    def lion_hunt(self, min_wave_momentum: float = 0.002) -> List[Tuple[str, str, float, float]]:
        """
        ğŸ¦ LION HUNT - Find waves to chase with stablecoins!
        
        When we hold stablecoins (USD, USDT, TUSD), we're like a lion
        scanning the pride - watching for opportunities to POUNCE!
        
        Returns: List of (stablecoin, target, available_amount, target_momentum)
        """
        stablecoins = {'USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD'}
        hunts = []
        
        # Find stablecoins we hold
        for asset, amount in self.balances.items():
            if asset.upper() not in stablecoins:
                continue
            price = self.prices.get(asset, 1.0)
            value = amount * price
            if value < 5.0:  # Min $5 to hunt
                continue
            
            # Get rising targets
            rising = self.get_strongest_rising(limit=10)
            for target, momentum in rising:
                if momentum < min_wave_momentum:
                    continue  # Wave not strong enough
                if target in stablecoins:
                    continue  # Don't buy other stablecoins
                
                # ğŸ¦ Found a hunt opportunity!
                hunts.append((asset, target, amount, momentum))
        
        # Sort by momentum (strongest waves first)
        hunts.sort(key=lambda x: x[3], reverse=True)
        
        if hunts:
            safe_print(f"\n   ğŸ¦ LION HUNT - {len(hunts)} waves spotted!")
            for src, tgt, amt, mom in hunts[:5]:  # Show top 5
                # ğŸ› FIX: Show USD VALUE not raw amount!
                price = self.prices.get(src, 1.0)
                value_usd = amt * price
                safe_print(f"      â†’ {src}â†’{tgt}: ${value_usd:.2f} available, wave +{mom*100:.2f}%/min")
        
        return hunts
    
    def wolf_hunt(self, verbose: bool = True) -> Optional[Tuple[str, float, float]]:
        """
        ğŸº LONE WOLF - Single momentum sniper!
        
        The Wolf doesn't chase any wave - it waits for THE ONE.
        Picks the SINGLE highest momentum target weighted by volume.
        
        Score = momentum Ã— log(1 + volume)
        
        Returns: (symbol, momentum, score) or None
        """
        best_symbol = None
        best_score = -999999
        best_momentum = 0
        
        # Get all tracked assets with prices
        for asset, price in self.prices.items():
            if price <= 0:
                continue

            # Skip obviously invalid symbols
            if len(asset) < MIN_SYMBOL_LEN:
                continue
            
            # Skip stablecoins - wolf hunts volatile prey
            if asset.upper() in {'USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD'}:
                continue
            
            # Get momentum for this asset
            momentum = self.asset_momentum.get(asset, 0)
            # Cap momentum to avoid runaway scores / data glitches
            if momentum > MAX_MOMENTUM_PER_MIN:
                momentum = MAX_MOMENTUM_PER_MIN
            
            # Wolf ONLY hunts RISING prey (positive momentum)
            if momentum <= 0:
                continue
            
            # Estimate volume from recent trades (or use fallback)
            volume = 100000  # Base volume estimate
            
            # Check ticker cache for actual volume
            for symbol, ticker in self.ticker_cache.items():
                if ticker.get('base') == asset:
                    volume = ticker.get('volume', 100000)
                    break
            
            # ğŸº WOLF SCORE: momentum Ã— log(1 + volume)
            import math
            score = momentum * math.log(1 + max(1, volume))
            
            if score > best_score:
                best_symbol = asset
                best_score = score
                best_momentum = momentum
        
        if best_symbol:
            if verbose:
                safe_print(f"\n   ğŸº WOLF TARGET: {best_symbol} | momentum={best_momentum*100:.2f}%/min | score={best_score:.1f}")
            return (best_symbol, best_momentum, best_score)
        
        return None
    
    def ant_scraps(self, min_value: float = 1.0) -> List[Tuple[str, float, float]]:
        """
        ğŸœ ARMY ANTS - Floor scavengers!
        
        Find small liquid assets on the floor - quick rotations.
        These are the crumbs that others miss.
        
        Returns: List of (asset, amount, value) for small holdings
        """
        scraps = []
        
        for asset, amount in self.balances.items():
            price = self.prices.get(asset, 0)
            value = amount * price
            
            # Ants collect small scraps - between min_value and $20
            if min_value <= value <= 20.0:
                # Skip stablecoins - not scraps
                if asset.upper() in {'USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD'}:
                    continue
                scraps.append((asset, amount, value))
        
        # Sort by value (smallest first - easiest to move)
        scraps.sort(key=lambda x: x[2])
        
        if scraps:
            safe_print(f"\n   ğŸœ ANT SCRAPS - {len(scraps)} small positions found!")
            for asset, amt, val in scraps[:5]:
                safe_print(f"      â†’ {asset}: {amt:.6f} (${val:.2f})")
        
        return scraps
    
    async def dust_sweep(self) -> int:
        """
        ğŸ§¹ğŸ‘‘ DUST SWEEP - Queen-controlled portfolio cleanup.
        
        The Queen (Sero) has FULL CONTROL over dust sweeps:
        1. She decides IF we should sweep (market conditions)
        2. She evaluates EACH dust position individually
        3. She learns from sweep successes/failures
        
        Works across ALL exchanges (Kraken, Binance, Alpaca).
        Only sweeps if profitable after fees AND Queen approves!
        
        Returns: Number of successful dust conversions.
        """
        if not self.dust_converter:
            return 0
        
        if not self.dust_converter.should_sweep_now():
            return 0
        
        safe_print("\n   ğŸ§¹ğŸ‘‘ QUEEN'S DUST SWEEP - Sero inspecting small positions...")
        
        # Find all dust across exchanges
        all_dust = self.dust_converter.find_all_dust(
            all_balances=self.exchange_balances,
            prices=self.prices,
        )
        
        if not all_dust:
            safe_print("   âœ¨ No dust found - portfolio is clean!")
            return 0
        
        # Print the dust report
        safe_print(self.dust_converter.format_dust_report(all_dust))
        
        # Get profitable sweeps only
        profitable = self.dust_converter.get_profitable_sweeps(all_dust)
        
        if not profitable:
            safe_print("   âš ï¸ Dust found but none profitable after fees")
            return 0
        
        # ğŸ‘‘ QUEEN'S FIRST GATE: Should we sweep at all right now?
        queen_allows_sweep = await self._queen_approve_dust_sweep(profitable)
        if not queen_allows_sweep:
            safe_print("   ğŸ‘‘ğŸš« Queen says: NOT NOW - Market conditions unfavorable")
            return 0
        
        # Execute sweeps (only if LIVE mode AND Queen approves each one)
        sweeps_executed = 0
        
        for dust in profitable:
            try:
                # ğŸ‘‘ QUEEN'S SECOND GATE: Approve each individual sweep
                queen_approves, queen_reason = await self._queen_approve_dust_candidate(dust)
                
                if not queen_approves:
                    safe_print(f"   ğŸ‘‘ğŸš« Queen vetoes {dust.asset}: {queen_reason}")
                    continue
                
                safe_print(f"   ğŸ‘‘âœ… Queen approves {dust.asset}: {queen_reason}")
                
                # Get the right client for this exchange
                client = None
                if dust.exchange == 'kraken' and self.kraken:
                    client = self.kraken
                    pair = f"{dust.asset}{dust.target_stable}"
                elif dust.exchange == 'binance' and self.binance:
                    client = self.binance
                    pair = f"{dust.asset}{dust.target_stable}"
                elif dust.exchange == 'alpaca' and self.alpaca:
                    client = self.alpaca
                    pair = f"{dust.asset}/USD"
                
                if not client:
                    safe_print(f"   âš ï¸ No client for {dust.exchange}")
                    continue
                
                if self.live:
                    safe_print(f"   ğŸ§¹ Sweeping {dust.asset} @ {dust.exchange}: {dust.amount:.6f} â†’ {dust.target_stable}")
                    
                    # Execute the sell
                    try:
                        if dust.exchange == 'alpaca':
                            # Alpaca uses market orders
                            result = client.create_order(
                                symbol=pair,
                                qty=dust.amount,
                                side='sell',
                                type='market'
                            )
                        elif dust.exchange == 'kraken':
                            # Kraken uses AddOrder
                            result = await client.add_order(
                                pair=pair,
                                type='sell',
                                ordertype='market',
                                volume=str(dust.amount)
                            )
                        elif dust.exchange == 'binance':
                            # Binance uses market orders
                            result = client.create_order(
                                symbol=pair,
                                side='SELL',
                                type='MARKET',
                                quantity=dust.amount
                            )
                        
                        self.dust_converter.record_sweep(dust, success=True)
                        sweeps_executed += 1
                        safe_print(f"   âœ… Swept {dust.asset}: +${dust.net_proceeds_usd:.4f}")
                        
                        # ğŸ‘‘ Queen learns from successful sweep
                        await self._queen_learn_dust_sweep(dust, success=True)
                        
                    except Exception as e:
                        self.dust_converter.record_sweep(dust, success=False)
                        safe_print(f"   âŒ Failed to sweep {dust.asset}: {e}")
                        
                        # ğŸ‘‘ Queen learns from failed sweep
                        await self._queen_learn_dust_sweep(dust, success=False, error=str(e))
                else:
                    # Dry run - just simulate
                    safe_print(f"   ğŸ§ª [DRY RUN] Would sweep {dust.asset} @ {dust.exchange}: {dust.amount:.6f} â†’ {dust.target_stable} (net ${dust.net_proceeds_usd:.4f})")
                    sweeps_executed += 1
                    
            except Exception as e:
                safe_print(f"   âŒ Error sweeping {dust.asset}: {e}")
        
        if sweeps_executed > 0:
            status = self.dust_converter.get_status()
            safe_print(f"\n   ğŸ‘‘ğŸ§¹ QUEEN'S SWEEP COMPLETE: {sweeps_executed} conversions | Total recovered: ${status['total_swept_usd']:.4f}")
        
        return sweeps_executed
    
    async def _queen_approve_dust_sweep(self, dust_candidates: List) -> bool:
        """
        ğŸ‘‘ Queen decides if NOW is a good time to sweep dust.
        
        She considers:
        - Overall market volatility (don't sweep during crashes)
        - Portfolio health
        - Recent sweep history
        - Mycelium network signals
        """
        # Default: Allow if Queen not available
        if not self.queen and not self.mycelium_network:
            return True
        
        total_dust_value = sum(d.value_usd for d in dust_candidates)
        
        # ğŸ„ Check Mycelium for market sentiment
        if self.mycelium_network:
            try:
                # Get aggregate market signal
                market_signal = 0.0
                if hasattr(self.mycelium_network, 'get_aggregate_signal'):
                    market_signal = self.mycelium_network.get_aggregate_signal()
                
                # Don't sweep during extreme negative sentiment (market crash)
                if market_signal < -0.7:
                    safe_print(f"   ğŸ‘‘ğŸ„ Market crash detected (signal={market_signal:.2f}) - holding dust")
                    return False
                    
            except Exception as e:
                logger.debug(f"Mycelium signal check error: {e}")
        
        # ğŸ‘‘ Check Queen's mood
        if self.queen:
            try:
                if hasattr(self.queen, 'get_market_mood'):
                    mood = self.queen.get_market_mood()
                    if mood == 'PANIC':
                        safe_print("   ğŸ‘‘ Queen senses PANIC - holding positions")
                        return False
            except Exception as e:
                logger.debug(f"Queen mood check error: {e}")
        
        # ğŸ“Š Check recent sweep history - avoid over-sweeping
        if self.dust_converter:
            status = self.dust_converter.get_status()
            # If we swept a lot recently, pause
            if status.get('dust_swept', 0) > 10 and status.get('cooldown_remaining', 0) < 60:
                # Been sweeping a lot, take a longer break
                return False
        
        safe_print(f"   ğŸ‘‘âœ… Queen approves dust sweep session (${total_dust_value:.4f} total)")
        return True
    
    async def _queen_approve_dust_candidate(self, dust) -> Tuple[bool, str]:
        """
        ğŸ‘‘ Queen evaluates a specific dust candidate.
        
        She considers:
        - Is this asset likely to recover? (momentum)
        - Historical performance of this asset
        - Mycelium signal for this specific asset
        - Path memory from previous trades
        """
        asset = dust.asset
        exchange = dust.exchange
        
        # Check momentum - don't sell assets with strong upward momentum!
        momentum = self.asset_momentum.get(asset, 0)
        if momentum > 0.005:  # >0.5%/min rising
            return False, f"RISING ({momentum*100:.2f}%/min) - may recover"
        
        # Check barter matrix history
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            # Check if this asset has been profitable recently
            asset_history = self.barter_matrix.barter_history.get((asset, 'USD'), {})
            if asset_history.get('total_profit', 0) > 0.1:  # Made >$0.10 recently
                return False, f"Recent profits (${asset_history['total_profit']:.4f}) - keep watching"
        
        # Check path memory
        if hasattr(self, 'path_memory') and self.path_memory:
            path_key = (asset, dust.target_stable)
            path_stats = self.path_memory.memory.get(path_key, {})
            win_rate = path_stats.get('win_rate', 0.5)
            
            # If we historically lose on this conversion, maybe don't sweep
            if win_rate < 0.3:
                return False, f"Bad path history (win_rate={win_rate:.0%})"
        
        # ğŸ„ Check Mycelium signal for this specific asset
        if self.mycelium_network:
            try:
                if hasattr(self.mycelium_network, 'get_queen_signal'):
                    signal = self.mycelium_network.get_queen_signal({'symbol': asset})
                    
                    # Strong BUY signal - don't sell this dust!
                    if signal > 0.5:
                        return False, f"Mycelium says HOLD (signal={signal:+.2f})"
                    
                    # Strong SELL signal - sweep it!
                    if signal < -0.3:
                        return True, f"Mycelium says SWEEP (signal={signal:+.2f})"
            except Exception as e:
                logger.debug(f"Mycelium signal error for {asset}: {e}")
        
        # ğŸ‘‘ Queen's final blessing
        if self.queen:
            try:
                if hasattr(self.queen, 'should_sell_dust'):
                    queen_says = self.queen.should_sell_dust(asset, dust.value_usd)
                    if not queen_says:
                        return False, "Queen says hold"
            except Exception as e:
                logger.debug(f"Queen dust decision error: {e}")
        
        # Default: Approve profitable dust sweeps
        return True, f"Profitable sweep (+${dust.net_proceeds_usd:.4f})"
    
    async def _queen_learn_dust_sweep(self, dust, success: bool, error: str = None):
        """
        ğŸ‘‘ Queen learns from dust sweep outcomes.
        
        Records:
        - Which assets are successfully sweepable
        - Which exchanges have issues
        - Patterns in failures
        """
        # Record in path memory with error handling
        if hasattr(self, 'path_memory') and self.path_memory:
            try:
                path_key = (dust.asset, dust.target_stable)
                if success:
                    self.path_memory.record_success(path_key, dust.net_proceeds_usd)
                else:
                    self.path_memory.record_failure(path_key, error or "unknown")
            except AttributeError as e:
                # ğŸ‘‘ğŸ”§ SELF-REPAIR TRIGGER - Publish to ThoughtBus
                error_msg = str(e)
                logger.error(f"âŒ AttributeError in path_memory: {error_msg}")
                
                if hasattr(self, 'thought_bus') and self.thought_bus:
                    try:
                        import traceback
                        tb = traceback.format_exc()
                        
                        self.thought_bus.think(
                            message=f"AttributeError in PathMemory: {error_msg}",
                            topic="runtime.error",
                            metadata={
                                'error_type': 'AttributeError',
                                'message': error_msg,
                                'file': __file__,
                                'line': 6700,
                                'context': '_queen_learn_dust_sweep',
                                'traceback': tb[:1000]
                            }
                        )
                        logger.info("ğŸ‘‘ğŸ”§ Error published to Queen for self-repair")
                    except Exception as pub_err:
                        logger.error(f"Could not publish error: {pub_err}")
        
        # Update barter matrix
        if hasattr(self, 'barter_matrix') and self.barter_matrix:
            if success:
                self.barter_matrix.record_barter(
                    from_asset=dust.asset,
                    to_asset=dust.target_stable,
                    from_amount=dust.amount,
                    to_amount=dust.net_proceeds_usd,
                    exchange=dust.exchange,
                    profit_usd=dust.net_proceeds_usd - dust.value_usd,  # Net of fees
                    success=True,
                )
        
        # ğŸ‘‘ğŸ“ Queen's Loss Learning System
        if not success and hasattr(self, 'loss_learning') and self.loss_learning:
            try:
                self.loss_learning.process_loss({
                    'type': 'dust_sweep_failed',
                    'asset': dust.asset,
                    'exchange': dust.exchange,
                    'value': dust.value_usd,
                    'error': error,
                    'timestamp': time.time(),
                })
            except Exception as e:
                logger.debug(f"Loss learning error: {e}")
    
    def get_quack_commando_boost(self, to_asset: str) -> Tuple[float, str]:
        """
        ğŸ¦†âš”ï¸ Get boost from Quantum Quackers Commandos for a target asset.
        
        The commandos scan the market and provide intelligence to the Queen.
        Each commando has a different strategy:
        - Lion: Pride scan, high volume + volatility
        - Wolf: Single momentum champion
        - Ants: Floor scraps (small liquid alts)
        - Hummingbird: Quick rotations
        
        Returns: (boost_multiplier, commando_reason)
        """
        if not self.quack_commandos:
            return (1.0, "")
        
        boost = 1.0
        reasons = []
        
        # Update commando targets if cache is old (refresh every 60 seconds)
        cache_age = time.time() - self.quack_targets.get('_timestamp', 0)
        if cache_age > 60 or not self.quack_targets:
            try:
                # Get fresh intelligence from the commandos
                self.quack_targets = self.quack_commandos.get_commando_targets(
                    elephant_memory=None,  # We use Queen's path memory instead
                    allowed_quotes=['USD', 'USDC', 'USDT', 'BTC', 'ETH']
                )
                self.quack_targets['_timestamp'] = time.time()
            except Exception as e:
                logger.debug(f"Quack targets refresh error: {e}")
                self.quack_targets = {'_timestamp': time.time()}
        
        # ğŸ¦ LION: Check if in pride targets
        pride_targets = self.quack_targets.get('pride_targets', [])
        for i, target in enumerate(pride_targets[:10]):
            if target.get('symbol', '').startswith(to_asset) or to_asset in target.get('symbol', ''):
                boost += 0.20 + (0.02 * (10 - i))  # Higher rank = more boost
                reasons.append(f"ğŸ¦ Pride #{i+1}")
                break
        
        # ğŸº WOLF: Check if it's the momentum champion
        wolf_prey = self.quack_targets.get('wolf_prey')
        if wolf_prey:
            wolf_symbol = wolf_prey.get('symbol', '')
            if wolf_symbol.startswith(to_asset) or to_asset in wolf_symbol:
                boost += 0.30  # Wolf's champion gets BIG boost!
                reasons.append(f"ğŸº THE ONE (mom={wolf_prey.get('momentum', 0):.1f}%)")
        
        # ğŸœ ANTS: Check if it's a floor scrap target
        ant_scraps = self.quack_targets.get('ant_scraps', [])
        for scrap in ant_scraps:
            if scrap.get('symbol', '').startswith(to_asset) or to_asset in scrap.get('symbol', ''):
                boost += 0.15
                reasons.append("ğŸœ Floor Scrap")
                break
        
        # ğŸ HUMMINGBIRD: Implied in pride targets rank 5-10
        for target in pride_targets[5:10]:
            if target.get('symbol', '').startswith(to_asset) or to_asset in target.get('symbol', ''):
                boost += 0.10
                reasons.append("ğŸ Pollination Target")
                break
        
        reason_str = " + ".join(reasons) if reasons else ""
        return (boost, reason_str)

    async def find_opportunities_for_exchange(self, exchange: str) -> List['MicroOpportunity']:
        """Find opportunities for a specific exchange only."""
        opportunities = []
        
        exchange_assets = self.get_exchange_assets(exchange)
        if not exchange_assets:
            return opportunities
        
        # ğŸ’° EXCHANGE-SPECIFIC MINIMUM VALUES (USD value)
        # âš ï¸ CRITICAL: These must match exchange ordermin requirements!
        EXCHANGE_MIN_VALUE = {
            'kraken': 1.50,     # Kraken needs ~$1.20 EUR/USD minimum (use $1.50 for safety)
            'binance': 5.00,    # Binance MIN_NOTIONAL is typically $5-10
            'alpaca': 1.00,     # Alpaca has ~$1 minimum
        }
        min_value = EXCHANGE_MIN_VALUE.get(exchange, 1.0)
        
        # ğŸ’° EXCHANGE-SPECIFIC MINIMUM QUANTITIES (varies by asset)
        # Kraken has per-pair ordermin values
        KRAKEN_MIN_QTY = {
            'CHZ': 50.0,        # Requires 50 CHZ minimum
            'PEPE': 2500000.0,  # Requires 2.5M PEPE minimum
            'DOGE': 50.0,       # 50 DOGE minimum
            'SHIB': 100000.0,   # 100K SHIB minimum
            'USD': 10.0,        # USD/stablecoin pairs need ~10 USD minimum on Kraken
            'ZUSD': 10.0,       # Kraken internal code
            'USDC': 10.0,       # USDC needs ~10 minimum
            'USDT': 10.0,       # USDT needs ~10 minimum
            'EUR': 10.0,        # EUR needs ~10 minimum
            'ZEUR': 10.0,       # Kraken internal code
            'XXBT': 0.0002,     # ~10-20 USD
            'XBT': 0.0002,
            'XETH': 0.004,
            'ETH': 0.004,
        }
        
        ALPACA_MIN_QTY = {
            # ğŸ”¥ EXPANDED: All Alpaca crypto minimums
            'BTC': 0.000100,    # Alpaca requires 0.0001 BTC minimum (~$10)
            'ETH': 0.001,       # ~$3 minimum
            'SOL': 0.01,        # ~$2 minimum
            'LINK': 0.1,        # ~$2 minimum
            'AVAX': 0.01,       # ~$0.40 minimum
            'DOGE': 1.0,        # ~$0.30 minimum
            'USDT': 1.0,        # $1 minimum
            'USDC': 1.0,        # $1 minimum
            'USD': 1.0,         # $1 minimum
            'SHIB': 10000.0,    # Small value but high qty
            'PEPE': 100000.0,   # Small value but high qty
            # ğŸ†• NEW: Expanded Alpaca assets
            'AAVE': 0.01,       # ~$2 minimum
            'LTC': 0.01,        # ~$1 minimum
            'BCH': 0.01,        # ~$4 minimum
            'DOT': 0.1,         # ~$0.50 minimum
            'MATIC': 1.0,       # ~$0.50 minimum
            'ATOM': 0.1,        # ~$0.50 minimum
            'XLM': 1.0,         # ~$0.30 minimum
            'ALGO': 1.0,        # ~$0.20 minimum
            'UNI': 0.1,         # ~$1 minimum
            'BAT': 1.0,         # ~$0.20 minimum
            'CRV': 1.0,         # ~$0.50 minimum
            'GRT': 1.0,         # ~$0.15 minimum
            'SUSHI': 0.5,       # ~$0.50 minimum
            'XRP': 1.0,         # ~$2 minimum
            'XTZ': 0.5,         # ~$0.50 minimum
            'YFI': 0.0001,      # ~$0.80 minimum (expensive coin)
            'TRUMP': 0.1,       # ~varies
            'SKY': 0.1,         # ~$0.10 minimum
        }
        
        for from_asset, amount in exchange_assets.items():
            if amount <= 0:
                continue
            
            # â±ï¸ MINIMUM HOLD TIME CHECK - Don't sell too early!
            # Trust the original prediction - give it time to materialize
            from_asset_upper = from_asset.upper()
            if from_asset_upper in self.position_entry_times:
                entry_time = self.position_entry_times[from_asset_upper]
                hold_duration = time.time() - entry_time
                
                if hold_duration < self.min_hold_time_seconds:
                    remaining = self.min_hold_time_seconds - hold_duration
                    safe_print(
                        f"   â±ï¸ {from_asset}: Holding position - "
                        f"{hold_duration:.0f}s elapsed, need {remaining:.0f}s more "
                        f"(min {self.min_hold_time_seconds:.0f}s)"
                    )
                    continue  # Don't consider selling yet!
                
                # Check if max hold time exceeded - MUST exit now
                if hold_duration > self.max_hold_time_seconds:
                    safe_print(
                        f"   â° {from_asset}: MAX HOLD TIME EXCEEDED - "
                        f"{hold_duration:.0f}s > {self.max_hold_time_seconds:.0f}s - FORCING EXIT"
                    )
                    # Will continue to evaluate exit opportunities below
            
            from_price = self.prices.get(from_asset, 0)
            if not from_price:
                safe_print(f"   ğŸ” {from_asset}: No price data - skipping")
                continue
            
            from_value = amount * from_price
            
            # Skip dust below exchange minimum VALUE
            if from_value < min_value:
                safe_print(f"   ğŸ” {from_asset}: ${from_value:.2f} < ${min_value:.2f} min - skipping")
                continue
            
            # ğŸ”“ FULL AUTONOMOUS: Debug logging for opportunity detection
            safe_print(f"   ğŸ”“ SCANNING: {from_asset} = {amount:.6f} (${from_value:.2f}) on {exchange}")
            
            # ğŸš« CHECK SOURCE BLOCKING - Skip if this asset is blocked on this exchange
            is_source_blocked, source_block_reason = self.barter_matrix.is_source_blocked(from_asset, exchange, from_value)
            if is_source_blocked:
                safe_print(f"   ğŸ”“ {from_asset}: SOURCE BLOCKED - {source_block_reason}")
                continue  # Source is blocked - skip all paths from this asset on this exchange
            
            # ğŸš« CHECK HIGH SPREAD SOURCE BLOCKING - Skip if spread is too high for this source
            spread_key = (from_asset.upper(), exchange.lower())
            if spread_key in self.barter_matrix.high_spread_sources:
                spread_info = self.barter_matrix.high_spread_sources[spread_key]
                blocked_turn = spread_info.get('blocked_turn', 0)
                turns_since = self.barter_matrix.current_turn - blocked_turn
                if turns_since < self.barter_matrix.HIGH_SPREAD_COOLDOWN:
                    # Still in cooldown - skip ALL trades from this source
                    continue
                else:
                    # Cooldown expired - remove block and try again
                    del self.barter_matrix.high_spread_sources[spread_key]
                    logger.info(f"ğŸš«â†’âœ… HIGH SPREAD UNBLOCK: {from_asset} on {exchange} - cooldown expired")
            
            # Skip assets below exchange minimum QUANTITY
            if exchange == 'kraken':
                # Check dynamic learned minimums first
                learned_min = self.dynamic_min_qty.get(from_asset.upper(), 0)
                if learned_min > 0 and amount < learned_min:
                    continue

                min_qty = KRAKEN_MIN_QTY.get(from_asset.upper(), 0)
                if min_qty > 0 and amount < min_qty:
                    continue  # Skip - below Kraken minimum quantity
            
            if exchange == 'alpaca':
                min_qty = ALPACA_MIN_QTY.get(from_asset.upper(), 0)
                if min_qty > 0 and amount < min_qty:
                    continue  # Skip - below Alpaca minimum quantity
                
                # Skip quote currencies - can't convert USD to other assets on Alpaca
                if from_asset.upper() in ['USD', 'USDT', 'USDC', 'EUR', 'GBP']:
                    continue  # Skip quote currencies - not convertible on Alpaca
            
            # Skip blocked assets
            if exchange == 'binance' and from_asset.upper() in self.blocked_binance_assets:
                continue
            if exchange == 'kraken' and from_asset.upper() in self.blocked_kraken_assets:
                continue
            
            # ğŸ‡¬ğŸ‡§ UK BINANCE RESTRICTION CHECK - Use cached UK allowed pairs
            if exchange == 'binance' and self.binance_uk_mode:
                # Check if we can trade FROM this asset (needs at least one valid pair)
                can_trade = False
                
                # For stablecoins (USDC etc), they are QUOTE currencies
                # so we check if pairs like BTCUSDC exist (base + USDC)
                if from_asset.upper() in ['USD', 'USDT', 'USDC', 'EUR', 'GBP']:
                    # This is a quote currency - check if ANY base can be bought with it
                    for base in ['BTC', 'ETH', 'SOL', 'BNB', 'XRP', 'ADA', 'DOGE']:
                        pair = f"{base}{from_asset.upper()}"
                        if self.is_binance_pair_allowed(pair):
                            can_trade = True
                            break
                else:
                    # Normal asset - check if it can be paired with USDC/BTC/etc
                    for quote in ['USDC', 'BTC', 'BNB', 'EUR']:  # UK-allowed quotes (NOT USDT!)
                        pair = f"{from_asset.upper()}{quote}"
                        if self.is_binance_pair_allowed(pair):
                            can_trade = True
                            break
                
                if not can_trade:
                    continue  # Skip UK-restricted assets
            
            # Find conversion opportunities for this asset
            asset_opps = await self._find_asset_opportunities(
                from_asset, amount, from_price, from_value, exchange
            )
            opportunities.extend(asset_opps)
        
        # Sort by combined score (best first)
        opportunities.sort(key=lambda x: x.combined_score, reverse=True)
        self.opportunities_found += len(opportunities)
        
        return opportunities

    async def _find_asset_opportunities(
        self, 
        from_asset: str, 
        amount: float, 
        from_price: float, 
        from_value: float,
        source_exchange: str
    ) -> List['MicroOpportunity']:
        """Find conversion opportunities for a single asset on a specific exchange."""
        opportunities = []
        
        # Determine if this is a stablecoin source
        is_stablecoin_source = from_asset.upper() in ['USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD']
        
        # ğŸ¦ LION HUNT MODE - When holding stablecoins, HUNT rising coins!
        # "The lion scans his pride and hunts" - Gary Leckey
        # ğŸŒ FULL MARKET EXPANSION: MAXIMUM COVERAGE (300â†’3000 targets = 100% of market!)
        lion_targets = []  # Priority targets from momentum
        if is_stablecoin_source:
            # Get TOP rising coins - these are our HUNT targets!
            # ğŸŒ FULL MARKET: Scan 3000 rising coins (was 300) for 100% MARKET COVERAGE!
            rising_coins = self.get_strongest_rising(exclude={from_asset}, limit=3000)

            # Exchange-aware targeting: when sourcing from Alpaca, only hunt assets
            # that are actually tradeable on Alpaca (still 100% of Alpaca crypto universe).
            alpaca_bases = None
            if source_exchange == 'alpaca':
                try:
                    alpaca_bases = set()
                    for sym in set(self.alpaca_pairs.values()):
                        if isinstance(sym, str) and '/' in sym:
                            base = sym.split('/', 1)[0].upper()
                            if base:
                                alpaca_bases.add(base)
                except Exception:
                    alpaca_bases = None
            # ğŸ”¬ DEBUG: Check if GUN is in rising_coins for Kraken USD
            if source_exchange == 'kraken' and from_asset == 'USD':
                # ğŸ«’ğŸ«’ğŸ«’ MEGA OLIVE: Show top 25 instead of 10 for better market visibility
                top_25_rising = [(c, m) for c, m in rising_coins if m > 5][:25]
                if top_25_rising:
                    safe_print(f"   ğŸ”¬ TOP 25 RISING (>5%/min): {[(c, f'{m:.1f}%') for c, m in top_25_rising]}")
                gun_mom = self.asset_momentum.get('GUN', 0)
                if gun_mom > 0:
                    safe_print(f"   ğŸ”¬ GUN momentum in asset_momentum: {gun_mom:.1f}%/min")
            for coin, momentum in rising_coins:
                # ğŸ«’ğŸ«’ğŸ«’ MEGA OLIVE: Lower threshold 0.05%â†’0.02% to catch EARLY EARLY movers!
                if momentum > 0.0002:  # >0.02%/min momentum
                    if alpaca_bases is not None and coin.upper() not in alpaca_bases:
                        continue
                    lion_targets.append(coin)
            if lion_targets:
                if source_exchange == 'alpaca':
                    safe_print(f"   ğŸ¦ LION HUNT (ALPACA 100%): {from_asset} â†’ Hunting {len(lion_targets)} rising Alpaca coins")
                else:
                    safe_print(f"   ğŸ¦ LION HUNT: {from_asset} â†’ Hunting {len(lion_targets)} rising coins")
        
        # Build target assets list
        checkpoint_stablecoins = {'USD': 1.0, 'USDT': 1.0, 'USDC': 1.0, 'ZUSD': 1.0}
        
        # ğŸŒŠ RIVER CONSCIOUSNESS: Filter targets to avoid "looking too hard" (Rate Limits)
        filtered_targets = {}
        used_river_filter = False
        
        if hasattr(self, 'river_consciousness') and self.river_consciousness:
            flowing_rivers = self.river_consciousness.get_flowing_rivers()
            if flowing_rivers:
                # Include: Flowing Rivers + Stablecoins + Lion Targets
                # ğŸ«’ GREEN OLIVE EXPANSION: Increased from ~20-30 to ~50-100 targets for MAXIMUM coverage
                for asset, price in self.prices.items():
                    if (asset in flowing_rivers or 
                        asset in checkpoint_stablecoins or 
                        (lion_targets and asset in lion_targets)):
                        filtered_targets[asset] = price
                
                if filtered_targets:
                    target_assets = filtered_targets
                    used_river_filter = True
                else:
                    target_assets = dict(self.prices) # Fallback
            else:
                target_assets = dict(self.prices)
        else:
            target_assets = dict(self.prices)

        # ğŸ” Debug log if filter is rigorous
        if used_river_filter and len(target_assets) < len(self.prices):
            # Only log occasionally or if very small
            pass

        for stable, price in checkpoint_stablecoins.items():
            if stable not in target_assets:
                target_assets[stable] = price
        
        # ğŸ¦ LION PRIORITY: If we have hunt targets, put them FIRST
        if lion_targets:
            # Reorder target_assets to prioritize lion targets
            prioritized = {}
            for target in lion_targets:
                if target in target_assets:
                    prioritized[target] = target_assets[target]
            # Add remaining targets after lion targets
            for k, v in target_assets.items():
                if k not in prioritized:
                    prioritized[k] = v
            target_assets = prioritized
        
        for to_asset, to_price in target_assets.items():
            if to_asset == from_asset:
                continue
            
            # ğŸš¨ BLOCK GARBAGE SYMBOLS - Single letters are NOT real coins!
            # U, C, S, T, F, AT, etc. are matching partial symbol names, not real assets
            if len(to_asset) <= 2 and to_asset.upper() not in ['BT', 'OP']:  # Allow real 2-char like OP
                continue  # Skip garbage single-letter "coins"
            
            # ï¿½ DEBUG: Track GUN specifically
            if to_asset.upper() == 'GUN':
                safe_print(f"   ğŸ”¬ GUN FOUND in target loop! from={from_asset} exchange={source_exchange}")
            
            # ï¿½ğŸš¨ CRITICAL FIX: Check if path is blocked BEFORE doing any work!
            # This prevents the Sâ†”C ping-pong problem from repeating
            path_key = (from_asset.upper(), to_asset.upper())
            if path_key in self.barter_matrix.blocked_paths:
                continue  # Path is blocked - skip it entirely!
            
            # ğŸš« CHECK PRE-EXECUTION REJECTION BLOCK - Avoid wasting turns!
            is_preexec_blocked, preexec_reason = self.barter_matrix.is_preexec_blocked(from_asset, to_asset)
            if is_preexec_blocked:
                continue  # Skip - repeatedly fails min checks
            
            # ğŸŒâœ¨ PLANET SAVER: HARD BLOCK stablecoin â†’ stablecoin trades!
            # These ALWAYS LOSE FEES - there is NO momentum edge possible!
            is_checkpoint_target = to_asset.upper() in ['USD', 'USDT', 'USDC', 'TUSD', 'DAI', 'ZUSD', 'EUR', 'ZEUR', 'GBP', 'ZGBP', 'BUSD', 'GUSD']
            if is_stablecoin_source and is_checkpoint_target:
                # Stablecoinâ†’Stablecoin = GUARANTEED LOSS! Skip immediately!
                continue
            # This enables moving funds across the board when needed
            # The epsilon floor will filter out unprofitable swaps later
            # (No longer blocking here - let Queen's math gate decide)
            
            # Skip blocked target assets on Binance
            if source_exchange == 'binance' and to_asset.upper() in self.blocked_binance_assets:
                continue
            # Skip blocked target assets on Kraken
            if source_exchange == 'kraken' and to_asset.upper() in self.blocked_kraken_assets:
                continue
            
            # ğŸ‡¬ğŸ‡§ UK BINANCE RESTRICTION CHECK for target assets
            if source_exchange == 'binance' and self.binance_uk_mode:
                # Check if target asset can be traded (UK restrictions)
                can_trade = False
                for quote in ['USDC', 'BTC', 'BNB', 'EUR']:  # UK-allowed quotes (NOT USDT!)
                    pair_to_check = f"{to_asset.upper()}{quote}"
                    if self.is_binance_pair_allowed(pair_to_check):
                        can_trade = True
                        break
                if not can_trade:
                    continue  # Skip UK-restricted targets
            
            # Verify pairs exist
            if is_stablecoin_source:
                from_pair = "STABLECOIN_SOURCE"
                to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                if not to_pair and source_exchange in ('binance', 'alpaca'):
                    # For UK Binance, prefer USDC over USDT
                    if source_exchange == 'binance' and self.binance_uk_mode:
                        to_pair = self._find_exchange_pair(to_asset, "USDC", source_exchange)
                    if not to_pair:
                        to_pair = self._find_exchange_pair(to_asset, "USDT", source_exchange)
                if not to_pair and source_exchange == 'alpaca':
                    btc_pair = self._find_exchange_pair(to_asset, "BTC", source_exchange)
                    btc_usd = self._find_exchange_pair("BTC", "USD", source_exchange)
                    if btc_pair and btc_usd:
                        to_pair = btc_pair
            else:
                from_pair = self._find_exchange_pair(from_asset, "USD", source_exchange)
                to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                
                if is_checkpoint_target:
                    to_pair = from_pair
                
                if source_exchange == 'binance' and (not from_pair or not to_pair):
                    # For UK Binance, prefer USDC over USDT
                    if self.binance_uk_mode:
                        from_pair = from_pair or self._find_exchange_pair(from_asset, "USDC", source_exchange)
                        to_pair = to_pair or self._find_exchange_pair(to_asset, "USDC", source_exchange)
                    if not from_pair:
                        from_pair = self._find_exchange_pair(from_asset, "USDT", source_exchange)
                    if not to_pair:
                        to_pair = self._find_exchange_pair(to_asset, "USDT", source_exchange)
                if source_exchange == 'alpaca' and (not from_pair or not to_pair):
                    if from_asset.upper() == 'BTC':
                        to_pair = to_pair or self._find_exchange_pair(to_asset, "BTC", source_exchange)
                        from_pair = from_pair or to_pair
                    elif to_asset.upper() == 'BTC':
                        from_pair = from_pair or self._find_exchange_pair(from_asset, "BTC", source_exchange)
                        to_pair = to_pair or from_pair
            
            if not from_pair or not to_pair:
                # ğŸ”¬ DEBUG: Log why high-momentum targets are being skipped
                if to_asset in lion_targets and self.asset_momentum.get(to_asset, 0) > 100:
                    safe_print(f"      ğŸ”¬ DEBUG SKIP: {from_asset}â†’{to_asset} (from_pair={from_pair}, to_pair={to_pair}) on {source_exchange}")
                continue
            
            # ğŸ” SKIP PATH VALIDATION IN LOOP - Too slow!
            # Path existence will be validated at execution time.
            # This dramatically speeds up opportunity scanning.
            
            # Calculate scores (simplified for turn-based execution)
            v14_score = self.calculate_v14_score(from_asset, to_asset)
            hub_score = self.calculate_hub_score(from_asset, to_asset)
            dream_score = self.calculate_dream_score(to_asset)
            
            # Barter score
            barter_score, barter_reason = 0.5, "neutral"
            if self.barter_navigator and BARTER_NAVIGATOR_AVAILABLE:
                try:
                    barter_score, barter_reason = self.calculate_barter_score(from_asset, to_asset)
                except:
                    pass
            
            # Luck score
            luck_score, luck_state = 0.5, "NEUTRAL"
            if self.luck_mapper:
                try:
                    luck_data = self.luck_mapper.get_luck_field()
                    luck_score = luck_data.get('lambda', 0.5)
                    luck_state = luck_data.get('state', 'NEUTRAL')
                except:
                    pass
            
            # Bus score
            bus_score = 0.0
            if self.bus_aggregator:
                bus_score = self.bus_aggregator.get_aggregate_score()
            
            # ğŸ”ğŸŒ ENIGMA SCORE - Universal Translator Bridge Intelligence!
            enigma_score = 0.0
            enigma_direction = "NEUTRAL"
            if self.enigma_integration:
                try:
                    # Get Enigma guidance for this trade
                    enigma_guidance = self.enigma_integration.get_guidance()
                    
                    # Overall market action from Enigma
                    enigma_action = enigma_guidance.get('action', 'HOLD')
                    enigma_confidence = enigma_guidance.get('confidence', 0.5)
                    
                    # Convert action to score adjustment (ENIGMA BOOST!)
                    if enigma_action == 'BUY':
                        enigma_score = enigma_confidence * 0.3  # Boosted to 30% importance
                        enigma_direction = "BULLISH"
                    elif enigma_action == 'SELL':
                        enigma_score = -enigma_confidence * 0.15 # Penalty for selling
                        enigma_direction = "BEARISH"
                    else:
                        enigma_score = 0.0
                        enigma_direction = "NEUTRAL"
                    
                    # Additional boosts from subsystems
                    if hasattr(self.enigma_integration, 'coherence_system') and self.enigma_integration.coherence_system:
                        coherence_metrics = self.enigma_integration.coherence_system.get_metrics() if hasattr(self.enigma_integration.coherence_system, 'get_metrics') else {}
                        coherence = coherence_metrics.get('gamma_coherence', 0.5) if isinstance(coherence_metrics, dict) else 0.5
                        if coherence > 0.8:
                            enigma_score += 0.15  # Bonus for high coherence
                            
                    # ğŸŒŠ GLOBAL WAVE SCANNER BOOST
                    if self.wave_scanner:
                        wave_allocation = self.wave_scanner.get_wave_allocation()
                        for opp in wave_allocation.get('top_opportunities', []):
                            if opp.get('symbol') == to_asset or (f"{opp.get('base','')}/{opp.get('quote','')}" == to_asset):
                                jump_score = opp.get('jump_score', 0)
                                if jump_score > 0.7:
                                    enigma_score += 0.2  # BIG BOOST FROM WAVE SCANNER!
                                    enigma_direction = "WAVE_SURFER"
                                    break
                    
                    # QGITA Gravity signal
                    if hasattr(self.enigma_integration, 'qgita') and self.enigma_integration.qgita:
                        qgita_analysis = self.enigma_integration.qgita.analyze({
                            'close': self.prices.get(to_asset, 1.0),
                            'volume': 1000,
                            'high': self.prices.get(to_asset, 1.0) * 1.01,
                            'low': self.prices.get(to_asset, 1.0) * 0.99
                        }) if hasattr(self.enigma_integration.qgita, 'analyze') else {}
                        gravity_score = qgita_analysis.get('gravity_signal', 0.5) if isinstance(qgita_analysis, dict) else 0.5
                        if gravity_score > 0.7:
                            enigma_score += 0.1  # Strengthened gravity boost
                    
                    # Math Angel reality field
                    if hasattr(self.enigma_integration, 'math_angel') and self.enigma_integration.math_angel:
                        angel_state = self.enigma_integration.math_angel.get_state() if hasattr(self.enigma_integration.math_angel, 'get_state') else {}
                        unity_score = angel_state.get('unity_potential', 0.5) if isinstance(angel_state, dict) else 0.5
                        if unity_score > 0.75:
                            enigma_score += 0.05
                    
                    # ğŸ›ï¸ Barons Banner - Mathematical deception detection
                    if hasattr(self.enigma_integration, 'barons_analyzer') and self.enigma_integration.barons_analyzer:
                        try:
                            barons_analysis = self.enigma_integration.barons_analyzer.analyze({
                                'price': self.prices.get(to_asset, 1.0),
                                'volume': 1000,
                                'symbol': to_asset
                            }) if hasattr(self.enigma_integration.barons_analyzer, 'analyze') else None
                            if barons_analysis:
                                # High deception score = likely manipulation - be cautious
                                deception = barons_analysis.get('deception_score', 0.5) if isinstance(barons_analysis, dict) else 0.5
                                if deception < 0.3:  # Low deception = trustworthy signal
                                    enigma_score += 0.05
                                elif deception > 0.7:  # High deception = manipulation detected
                                    enigma_score -= 0.1
                        except:
                            pass
                    
                    # ğŸŒŠ Harmonic Reality - LEV Stabilization detection
                    if hasattr(self.enigma_integration, 'harmonic_reality') and self.enigma_integration.harmonic_reality:
                        try:
                            reality_state = self.enigma_integration.harmonic_reality.get_state() if hasattr(self.enigma_integration.harmonic_reality, 'get_state') else {}
                            if isinstance(reality_state, dict):
                                lev_score = reality_state.get('lev_stabilization', 0.5)
                                if lev_score > 0.7:  # High LEV = strong consensus
                                    enigma_score += 0.05
                        except:
                            pass
                            
                except Exception as e:
                    logger.debug(f"Enigma score error: {e}")
            
            # Combined score - NOW WITH ENIGMA!
            v14_normalized = v14_score / 10.0
            checkpoint_bonus = 0.15 if is_checkpoint_target else 0.0
            
            # ğŸ¦ LION HUNT BOOST - Extra score for rising coins when we're stablecoin hunting!
            lion_boost = 0.0
            if is_stablecoin_source and to_asset in lion_targets:
                # Get this asset's momentum
                momentum = self.asset_momentum.get(to_asset, 0)
                if momentum > MAX_MOMENTUM_PER_MIN:
                    momentum = MAX_MOMENTUM_PER_MIN
                # Boost proportional to momentum (0.1% = 10% boost, 0.5% = 50% boost, etc)
                lion_boost = min(momentum * 100, 0.5)  # Cap at 50% boost
                if lion_boost > 0.05:
                    safe_print(f"      ğŸ¦ LION BOOST +{lion_boost:.0%} for {to_asset} (momentum {momentum*100:.2f}%/min)")
            
            # ğŸº WOLF BOOST - THE ONE momentum champion gets extra priority!
            wolf_boost = 0.0
            # Check if this is the cached wolf target (computed once per turn)
            wolf_target = getattr(self, '_wolf_target_cache', None)
            if wolf_target and wolf_target[0] == to_asset:
                # Wolf's target gets +30% boost!
                wolf_boost = 0.30
                safe_print(f"      ğŸº WOLF BOOST +30% for {to_asset} (THE ONE)")
            
            # ğŸ¦†âš”ï¸ QUANTUM QUACKERS COMMANDO BOOST - The Animal Army serves the Queen!
            quack_boost, quack_reason = self.get_quack_commando_boost(to_asset)
            quack_contribution = 0.0
            if quack_boost > 1.0:
                quack_contribution = (quack_boost - 1.0) * 0.5  # Up to 50% contribution from commandos
                if quack_contribution > 0.1:
                    safe_print(f"      ğŸ¦† QUACK BOOST +{quack_contribution:.0%} for {to_asset} ({quack_reason})")
            
            # ğŸ¦ˆğŸ”ª ORCA KILLER WHALE BOOST - Ride the whale wakes!
            orca_boost = 0.0
            orca_reason = ""
            if hasattr(self, 'orca') and self.orca:
                try:
                    orca_result = self.orca.get_orca_boost(to_asset, 0.0)
                    # Returns (boost_multiplier, reasons_list)
                    orca_mult, orca_reasons = orca_result
                    orca_boost = max(0, orca_mult - 1.0)  # Convert multiplier to additive boost
                    orca_reason = ', '.join(orca_reasons) if orca_reasons else ''
                    if orca_boost > 0.1:
                        safe_print(f"      ğŸ¦ˆ ORCA BOOST +{orca_boost:.0%} for {to_asset} ({orca_reason})")
                except Exception as e:
                    pass  # Orca not critical - fail silently
            
            combined = (
                v14_normalized * 0.15 +
                hub_score * 0.10 +
                barter_score * 0.20 +
                luck_score * 0.10 +
                bus_score * 0.10 +
                checkpoint_bonus +
                dream_score * 0.05 +
                enigma_score * 0.15 +    # ğŸ”ğŸŒ ENIGMA contributes 15%!
                lion_boost * 0.25 +      # ğŸ¦ LION HUNT contributes up to 12.5% extra!
                wolf_boost * 0.20 +      # ğŸº WOLF contributes up to 6% extra!
                quack_contribution +     # ğŸ¦† QUACKERS contribute up to 50%!
                orca_boost * 0.30        # ğŸ¦ˆğŸ”ª ORCA WHALE HUNTER up to 30%!
            )
            
            # ğŸ” Log Enigma contribution occasionally
            import random  # Ensure import
            if enigma_score != 0 and random.random() < 0.05:  # 5% of the time
                logger.info(f"ğŸ” Enigma says {enigma_direction} for {to_asset}: score {enigma_score:+.2f}")
            
            # Gate check
            gate_required = 0.0
            gate_passed = True
            if self.adaptive_gate and ADAPTIVE_GATE_AVAILABLE:
                try:
                    # ğŸŒğŸ’° ADAPTIVE GATE: Calculate REQUIRED profit to be worth it
                    gate_res = self.adaptive_gate.calculate_gates(
                        exchange=source_exchange,
                        trade_value=from_value
                    )
                    gate_required = gate_res.prime_target_usd
                    # Note: We determine gate_passed after calculating expected profit
                except Exception as e:
                    # Fallback
                    gate_required = 0.003
                    pass
            
            # Expected profit - MUST BE REALISTIC NOT FAKE!
            # Simple conversions DON'T make profit - they cost fees!
            # Only arbitrage or price movement makes profit
            to_amount = from_value / to_price if to_price > 0 else 0
            to_value = to_amount * to_price
            
            # ğŸ”§ FIX: Use ACTUAL spread costs from barter_matrix (same as pre-exec gate!)
            # This prevents scanner promising profit that gate will reject
            if hasattr(self, 'barter_matrix') and self.barter_matrix:
                _, _, cost_breakdown = self.barter_matrix.calculate_true_cost(
                    from_asset, to_asset, from_value, source_exchange
                )
                total_cost_pct = cost_breakdown.get('total_cost_pct', 0.46) / 100.0  # Convert to decimal
                fee_pct = cost_breakdown.get('base_fee', 0.26) / 100.0
                spread_pct = cost_breakdown.get('spread', 0.20) / 100.0
            else:
                # Fallback if barter_matrix not available
                spread_pct = 0.002  # 0.2% estimated spread (conservative)
                fee_pct = 0.0026   # 0.26% Kraken fee
                total_cost_pct = spread_pct + fee_pct  # ~0.46% total cost
            
            # ğŸ’° ALPACA FEE TRACKER OVERRIDE - Use REAL costs from API!
            # This is the most accurate cost source for Alpaca trades
            if source_exchange == 'alpaca' and hasattr(self, 'fee_tracker') and self.fee_tracker:
                try:
                    alpaca_symbol = f"{from_asset.upper()}/{to_asset.upper()}"
                    fee_cost_estimate = self.fee_tracker.estimate_trade_cost(
                        symbol=alpaca_symbol,
                        side='sell',
                        quantity=amount,
                        price_estimate=from_value / amount if amount > 0 else 0
                    )
                    if fee_cost_estimate:
                        # Use REAL fee tracker costs
                        total_cost_pct = fee_cost_estimate.get('total_cost_pct', total_cost_pct)
                        fee_pct = fee_cost_estimate.get('fee_pct', fee_pct)
                        spread_pct = fee_cost_estimate.get('spread_pct', spread_pct)
                        logger.debug(f"ğŸ’° Alpaca real costs for {alpaca_symbol}: "
                                   f"fee={fee_pct*100:.3f}% spread={spread_pct*100:.3f}% total={total_cost_pct*100:.3f}%")
                except Exception as e:
                    logger.debug(f"Fee tracker estimate error: {e}")
            
            # ğŸ‘‘ PRIME PROFIT REALITY CHECK:
            # A simple conversion has NO inherent profit - we're just swapping coins
            # We will ALWAYS lose the fees unless:
            # 1. Target asset is predicted to go UP (momentum)
            # 2. We have actual cross-exchange arbitrage
            # 3. Path has historically been profitable
            
            # ğŸŒâœ¨ PLANET SAVER FIX: REALISTIC PROFIT EXPECTATIONS!
            # The old code assumed 5 minute holds which is WRONG for instant swaps
            
            # 1. STABLECOIN CHECK: Trading stableâ†’stable = GUARANTEED LOSS (fees!)
            STABLECOINS = {'USD', 'USDT', 'USDC', 'ZUSD', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'EUR', 'ZEUR', 'GBP', 'ZGBP'}
            is_stable_to_stable = from_asset.upper() in STABLECOINS and to_asset.upper() in STABLECOINS
            
            # Get momentum for target asset (fractional change per minute)
            real_momentum = self.get_momentum(to_asset) if not is_stable_to_stable else 0.0
            momentum_pct = real_momentum * 100.0
            
            if is_stable_to_stable:
                # Stablecoinâ†’Stablecoin = ALWAYS LOSES FEES! No momentum edge possible.
                expected_pnl_pct = -total_cost_pct  # We WILL lose the fees
                expected_pnl_usd = from_value * expected_pnl_pct
                # Skip the rest - this is a guaranteed loser
            else:
                # 2. For volatile assets: Use momentum-aware profit expectation
                # We're doing INSTANT swaps, NOT 5 minute holds!
                
                # ğŸ¦™ğŸ’° ALPACA REALITY CHECK: Two-leg conversions cost ~0.51%!
                # ETHâ†’USD (0.25% fee + 0.01% spread) + USDâ†’USDC (0.25% fee + 0.01% spread) = 0.52%
                # Need MUCH higher capture rates to beat real costs!
                
                # ğŸ”¥ ULTRA-AGGRESSIVE CAPTURE RATES - BEAT 0.51% COSTS!
                # Capture MORE momentum to overcome Alpaca's two-leg fee structure
                if abs(momentum_pct) > 5.0:
                    capture_rate = 1.20  # 120% for massive spikes (overshoot expected!)
                elif abs(momentum_pct) > 2.0:
                    capture_rate = 1.00  # 100% for high momentum (full capture!)
                elif abs(momentum_pct) > 1.0:
                    capture_rate = 0.80  # 80% for medium momentum
                elif abs(momentum_pct) > 0.5:
                    capture_rate = 0.60  # 60% for modest momentum
                else:
                    capture_rate = 0.40  # 40% minimum (was 30% - too low!)
                
                momentum_edge = real_momentum * capture_rate
                
                # ğŸ”“ HIGHER CAPS TO ENABLE PROFITABLE TRADES!
                # Must allow enough edge to overcome 0.51% baseline costs
                if abs(momentum_pct) > 10.0:
                    max_mom_edge = 0.15  # 15% max for extreme spikes
                elif abs(momentum_pct) > 5.0:
                    max_mom_edge = 0.10  # 10% max for massive momentum  
                elif abs(momentum_pct) > 2.0:
                    max_mom_edge = 0.05  # 5% max for high momentum
                else:
                    max_mom_edge = 0.03  # 3% max normally (was 2% - too restrictive!)
                
                momentum_edge = min(max(momentum_edge, -max_mom_edge), max_mom_edge)
                
                # ğŸ’ Enhanced dream bonus - help overcome costs
                dream_score_target = self.calculate_dream_score(to_asset) if hasattr(self, 'calculate_dream_score') else 0
                dream_bonus = dream_score_target * 0.005 if dream_score_target > 0.5 else 0  # 5x multiplier (was 0.002)
                
                # ğŸ“Š ULTRA-AGGRESSIVE SIGNAL EDGE - MUST BEAT 0.51% COSTS!
                # Even weak signals (combined=0.1) must generate 0.7-1.0% edge
                if combined > 0.5:
                    signal_edge = combined * 0.015  # Strong signals: up to 1.5% edge
                elif combined > 0.2:
                    signal_edge = combined * 0.012  # Medium signals: up to 1.2% edge
                else:
                    signal_edge = combined * 0.010  # Weak signals: up to 1.0% edge
                
                # ğŸ”§ FIX: Calculate GROSS expected profit (before costs)
                # The execution gate will validate costs separately
                # This way we rank opportunities by their POTENTIAL, not just net
                gross_profit_pct = signal_edge + momentum_edge + dream_bonus
                
                # For display/ranking, show gross profit potential
                # Execution gate will do final net profit validation
                expected_pnl_pct = gross_profit_pct
                
                # ğŸ‘‘ QUEEN'S WISDOM: If path historically loses, penalize (but less heavily)
                key = (from_asset.upper(), to_asset.upper())
                history = self.barter_matrix.barter_history.get(key, {})
                path_total_profit = history.get('total_profit', 0)
                if path_total_profit < 0 and history.get('trades', 0) > 5:  # Only after 5+ failures
                    # Path is losing - this is VERY important signal
                    expected_pnl_pct *= 0.25  # 75% penalty for losing paths!
                
                # Expected profit in USD
                expected_pnl_usd = from_value * expected_pnl_pct
                
                # ğŸ”¬ DEBUG: Log high-momentum opportunities to understand calculation
                if abs(momentum_pct) > 100:  # >100%/min momentum
                    safe_print(f"      ğŸ”¬ DEBUG: {from_asset}â†’{to_asset} mom={momentum_pct:.1f}%/min cap_rate={capture_rate:.0%} edge={momentum_edge:.4f} cost={total_cost_pct:.4f} profit%={expected_pnl_pct:.4f} profit$={expected_pnl_usd:.4f}")

                # âš ï¸ Debug negative expectations to diagnose logic issues
                if expected_pnl_usd <= 0:
                    safe_print(
                        f"      âš ï¸ NEG PNL {from_asset}->{to_asset} value=${from_value:.2f} "
                        f"signal={signal_edge:.4f} momentum={momentum_edge:.4f} "
                        f"dream={dream_bonus:.4f} gross={gross_profit_pct:.4f}"
                    )
            
            # ï¿½ HIGHER PROFIT CAPS - MUST BEAT 0.51% ALPACA COSTS!
            # Scale cap with momentum - need room for profitable trades
            if abs(momentum_pct) > 10.0:
                MAX_REALISTIC_PROFIT_PCT = 0.15  # 15% max for extreme momentum
            elif abs(momentum_pct) > 5.0:
                MAX_REALISTIC_PROFIT_PCT = 0.10  # 10% max for massive momentum
            elif abs(momentum_pct) > 2.0:
                MAX_REALISTIC_PROFIT_PCT = 0.05  # 5% max for high momentum
            else:
                MAX_REALISTIC_PROFIT_PCT = 0.03  # 3% max normally (was 2% - blocking profitable trades!)
            
            if expected_pnl_pct > MAX_REALISTIC_PROFIT_PCT:
                expected_pnl_pct = MAX_REALISTIC_PROFIT_PCT
                expected_pnl_usd = from_value * expected_pnl_pct
            
            # ğŸš€ PENNY TURBO: Enhance with real-time spread/fee optimization
            turbo_adjustment = 1.0
            if self.penny_turbo:
                try:
                    symbol_for_turbo = f"{from_asset}/{to_asset}"
                    if is_stablecoin_source:
                        quote_asset = from_asset.upper()
                        if source_exchange == 'alpaca' and quote_asset == 'USD':
                            quote_asset = 'USD'
                        symbol_for_turbo = f"{to_asset}/{quote_asset}"

                    # Get turbo-enhanced threshold - uses real spread & fee tier
                    turbo_threshold = self.penny_turbo.get_enhanced_threshold(
                        exchange=source_exchange,
                        symbol=symbol_for_turbo,
                        value_usd=from_value
                    )
                    
                    # Check for flash profit opportunity (momentum spike)
                    flash_signal = self.penny_turbo.get_flash_signal(
                        exchange=source_exchange,
                        symbol=symbol_for_turbo
                    )
                    if flash_signal and flash_signal.get('is_flash', False):
                        # Flash detected - boost expected profit by flash strength
                        flash_boost = 1.0 + flash_signal.get('strength', 0) * 0.5
                        turbo_adjustment = flash_boost
                        logger.debug(f"âš¡ FLASH PROFIT: {from_asset}â†’{to_asset} boost={flash_boost:.2f}")
                    
                    # Compound accelerator bonus (Kelly-based sizing)
                    compound_bonus = self.penny_turbo.get_compound_bonus(
                        equity_usd=self.total_portfolio_usd or from_value * 2,
                        recent_win_rate=self.barter_matrix.win_rate if hasattr(self.barter_matrix, 'win_rate') else 0.5
                    )
                    turbo_adjustment *= (1.0 + compound_bonus)
                    
                except Exception as e:
                    logger.debug(f"Turbo enhancement skipped: {e}")
            
            # Apply turbo adjustment
            expected_pnl_usd *= turbo_adjustment
            expected_pnl_pct *= turbo_adjustment
            
            # ğŸŒğŸ’° ADAPTIVE GATE CHECK: Does this trade meet the PRIME target?
            if gate_required > 0:
                gate_passed = expected_pnl_usd >= gate_required
            
            # ğŸ‘‘ QUEEN MIND: VERIFY source_exchange is where we ACTUALLY hold this asset!
            # This prevents Kraken from trying to trade Alpaca's USD
            actual_exchange = self._find_asset_exchange(from_asset)
            if actual_exchange and actual_exchange != source_exchange:
                # Asset is on a different exchange - use that one!
                source_exchange = actual_exchange
            
            # ğŸ‘‘ QUEEN SELF-REPAIR: Pre-check exchange min_qty BEFORE showing to Queen!
            # This prevents wasted Queen approvals for trades that will fail at execution
            if source_exchange == 'kraken' and self.kraken:
                try:
                    # Find the conversion path to get the actual pair
                    path = self.kraken.find_conversion_path(from_asset, to_asset)
                    if path:
                        for step in path:
                            pair = step.get('pair', '')
                            if pair:
                                filters = self.kraken.get_symbol_filters(pair)
                                min_qty = filters.get('min_qty', 0) or filters.get('min_volume', 0)
                                if min_qty and amount < min_qty:
                                    # ğŸ‘‘ Queen learns: This trade will fail - skip it early!
                                    logger.debug(f"Queen pre-filter: {from_asset}â†’{to_asset} blocked (amt {amount:.6f} < min_qty {min_qty:.6f})")
                                    # Update dynamic minimum for future
                                    self.dynamic_min_qty[from_asset.upper()] = max(
                                        self.dynamic_min_qty.get(from_asset.upper(), 0),
                                        min_qty * 1.1  # Add 10% buffer
                                    )
                                    continue  # Skip this opportunity entirely
                except Exception as e:
                    logger.debug(f"Queen pre-filter check error: {e}")
            
            # Create opportunity
            opp = MicroOpportunity(
                timestamp=time.time(),
                from_asset=from_asset,
                to_asset=to_asset,
                from_amount=amount,
                from_value_usd=from_value,
                v14_score=v14_score,
                hub_score=hub_score,
                commando_score=0.0,
                combined_score=combined,
                expected_pnl_usd=expected_pnl_usd,
                expected_pnl_pct=expected_pnl_pct,
                gate_required_profit=gate_required,
                gate_passed=gate_passed,
                lambda_score=combined,
                gravity_score=0.0,
                bus_score=bus_score,
                hive_score=0.0,
                lighthouse_score=0.0,
                ultimate_score=0.0,
                path_boost=0.0,
                barter_matrix_score=barter_score,
                barter_matrix_reason=barter_reason,
                luck_score=luck_score,
                luck_state=luck_state,
                enigma_score=enigma_score,          # ğŸ”ğŸŒ NEW!
                enigma_direction=enigma_direction,  # ğŸ”ğŸŒ NEW!
                queen_guidance_score=0.5,  # ğŸ‘‘ğŸ’• Will be set if Queen evaluates
                queen_wisdom="",
                queen_confidence=0.0,
                wisdom_engine_score=0.5,  # ğŸ§ ğŸ“š Will be set if Wisdom Engine analyzes
                civilization_insight="",
                wisdom_pattern="",
                source_exchange=source_exchange  # Now verified!
            )
            
            # ğŸ‘‘ğŸ—ï¸ APPLY QUEEN'S SELF-WRITTEN LEARNING ENHANCEMENTS!
            # The Queen writes code to queen_strategies/ - NOW WE USE IT!
            try:
                loader = get_queen_enhancement_loader()
                if loader and loader.enhancement_count > 0:
                    opp_dict = {
                        'from_asset': from_asset,
                        'to_asset': to_asset,
                        'score': combined,
                        'expected_pnl_usd': expected_pnl_usd,
                        'momentum': real_momentum if 'real_momentum' in dir() else 0,
                        'exchange': source_exchange
                    }
                    enhancement_result = loader.apply_to_opportunity(opp_dict)
                    if enhancement_result.get('applied', 0) > 0:
                        # Boost the combined score with Queen's learned patterns!
                        score_boost = enhancement_result['adjusted_score'] - combined
                        if score_boost != 0:
                            opp.combined_score = enhancement_result['adjusted_score']
                            opp.queen_wisdom = f"Enhanced by {enhancement_result['applied']} learnings"
                            logger.debug(f"ğŸ‘‘ğŸ—ï¸ Enhancement applied: {from_asset}â†’{to_asset} score boost: {score_boost:+.3f}")
            except Exception as e:
                logger.debug(f"Queen enhancement apply error: {e}")
            
            # ğŸ‘‘ SERO DECIDES - She has her $0.003 GOAL!
            # Don't block here - let the opportunity reach execute_turn() where Sero is consulted
            # Her wisdom in ask_queen_will_we_win() will decide based on:
            # - Path history (she remembers losses)
            # - Her $0.003 minimum profit goal
            # - Dream/cosmic signals
            # - Mycelium network consensus
            
            # ğŸ‘‘ SERO's MINIMAL SANITY CHECK
            # Check exchange minimum order values BEFORE sending to Queen
            min_order_usd = 5.0 if source_exchange == 'binance' else 1.0  # Binance has $5 min
            if from_value < min_order_usd:
                # Too small for exchange minimums - skip silently
                continue
            
            total_cost_estimate = from_value * total_cost_pct  # ~0.46% in fees
            
            # ğŸ‘‘ QUEEN'S LEARNED WISDOM: Check if this path has ANY history
            path_key = (from_asset.upper(), to_asset.upper())
            path_history = self.barter_matrix.barter_history.get(path_key, {})
            path_trades = path_history.get('trades', 0)
            path_win_rate = path_history.get('wins', 0) / max(path_trades, 1)
            path_profit = path_history.get('total_profit', 0)
            
            # ğŸ”“ğŸ”“ğŸ”“ FULL AUTONOMOUS MODE - NO FILTERS! ğŸ”“ğŸ”“ğŸ”“
            # The expected_pnl filter has been DISABLED to allow ALL trades to execute.
            # Queen Sero will learn from outcomes (wins AND losses) to evolve.
            # Original: min_expected_profit = MIN_NET_PROFIT_USD ($0.001)
            # NOW: Accept ALL opportunities regardless of expected P&L
            
            # Log for visibility (first 3 trades per asset per scan)
            if from_asset.upper() == 'LINK':
                asset_momentum = self.asset_momentum.get(to_asset, 0)
                safe_print(f"      âœ… AUTONOMOUS: LINKâ†’{to_asset} | mom={asset_momentum:.3f}%/min | cost={total_cost_pct:.4f} | exp_pnl=${opp.expected_pnl_usd:.6f}")
            
            # ğŸª† BEE LEVEL: Record opportunity scan in Russian Doll Analytics
            if self.russian_doll and record_scan:
                try:
                    momentum = self.asset_momentum.get(from_asset, 0)
                    # Get bid/ask from ticker cache if available
                    ticker_key = f"{from_asset}/USD"
                    ticker_data = self.ticker_cache.get(ticker_key, {})
                    bid = ticker_data.get('bid', from_value)
                    ask = ticker_data.get('ask', from_value)
                    
                    record_scan(
                        symbol=f"{from_asset}/{to_asset}",
                        exchange=source_exchange,
                        bid=bid,
                        ask=ask,
                        momentum=momentum,
                        pip_score=opp.combined_score,
                        expected_pnl=opp.expected_pnl_usd,
                        pass_scores=(
                            opp.v14_score,
                            opp.hub_score,
                            opp.bus_score
                        ),
                        action="SCAN",
                        rejection_reason=""
                    )
                except Exception as e:
                    logger.debug(f"Russian Doll bee record error: {e}")
            
            opportunities.append(opp)
        
        return opportunities

    async def find_opportunities(self) -> List[MicroOpportunity]:
        """Find all micro profit opportunities."""
        self.scans += 1
        opportunities = []
        
        if not self.balances or not self.prices:
            safe_print(f"   âš ï¸ Scan #{self.scans}: No balances or prices!")
            return opportunities
        
        # Debug: Log what we're scanning (first 3 scans only)
        debug_first_scans = self.scans <= 3
        if debug_first_scans:
            safe_print(f"\nğŸ”¬ === SCAN #{self.scans} DEBUG START ===")
            safe_print(f"   Balances: {len(self.balances)} assets")
            safe_print(f"   Prices: {len(self.prices)} assets")
        scanned_assets = []
        
        # Check each held asset for conversion opportunities
        for from_asset, amount in self.balances.items():
            if amount <= 0:
                continue
            
            from_price = self.prices.get(from_asset, 0)
            if not from_price:
                if debug_first_scans:
                    safe_print(f"   âš ï¸ {from_asset}: No price found")
                continue
            
            from_value = amount * from_price
            
            # Lowered dust threshold to $1 for micro profits
            if from_value < 1.0:  # Skip only tiny dust below $1
                if debug_first_scans:
                    safe_print(f"   âš ï¸ {from_asset}: Below $1 dust threshold (${from_value:.2f})")
                continue
            
            scanned_assets.append(f"{from_asset}=${from_value:.2f}")
            
            # Find which exchange holds this from_asset
            # ğŸ‘‘ QUEEN MIND: We are scanning a specific exchange, so source is THAT exchange
            source_exchange = exchange
            
            if debug_first_scans:
                safe_print(f"   ğŸ” Scanning {from_asset} (${from_value:.2f}) on {source_exchange}...")
            
            # Skip blocked assets on specific exchanges
            if source_exchange == 'binance' and from_asset.upper() in self.blocked_binance_assets:
                if debug_first_scans:
                    safe_print(f"      âš ï¸ {from_asset}: Blocked on Binance")
                continue
            if source_exchange == 'kraken' and from_asset.upper() in self.blocked_kraken_assets:
                if debug_first_scans:
                    safe_print(f"      âš ï¸ {from_asset}: Blocked on Kraken")
                continue
            
            # ğŸ MEDUSA: Stablecoins CAN be sources now! They buy volatile assets!
            # The stablecoinâ†’stablecoin skip is handled in the target loop below
            is_stablecoin_source = from_asset.upper() in ['USD', 'ZUSD', 'USDT', 'USDC', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD']
            
            # Count valid pairs found
            valid_pairs_found = 0
            pair_check_failures = 0
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ¦ BUILD TARGET ASSETS LIST (include checkpoint stablecoins!)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # USD/USDT/etc may not be in self.prices (they're quotes, not bases)
            # But we NEED them as checkpoint targets for compounding!
            checkpoint_stablecoins = {'USD': 1.0, 'USDT': 1.0, 'USDC': 1.0, 'ZUSD': 1.0}
            target_assets = dict(self.prices)
            for stable, price in checkpoint_stablecoins.items():
                if stable not in target_assets:
                    target_assets[stable] = price
            
            # Check conversion to each other asset
            for to_asset, to_price in target_assets.items():
                if to_asset == from_asset:
                    continue
                
                # Stablecoin targets are allowed; math gates will filter out non-profitable conversions.
                is_checkpoint_target = to_asset.upper() in ['USD', 'USDT', 'USDC', 'TUSD', 'DAI', 'ZUSD', 'EUR', 'ZEUR', 'GBP', 'ZGBP', 'BUSD', 'GUSD']
                
                # Skip blocked target assets on Binance
                if source_exchange == 'binance' and to_asset.upper() in self.blocked_binance_assets:
                    continue
                # Skip blocked target assets on Kraken
                if source_exchange == 'kraken' and to_asset.upper() in self.blocked_kraken_assets:
                    continue
            
                # CRITICAL: Verify BOTH pairs exist on the source exchange
                # ğŸ MEDUSA: For stablecoin sources, they ARE the quote currency!
                # ZUSD, USD, USDT don't have their own pairs - they're used to BUY other pairs
                if is_stablecoin_source:
                    # For stablecoin â†’ volatile, we just need to_pair
                    # e.g., ZUSD â†’ BTC uses BTCUSD pair (buying BTC with USD)
                    from_pair = "STABLECOIN_SOURCE"  # Placeholder - we have USD/ZUSD/etc
                    to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                    # Try USDT pair on Binance/Alpaca if USD not available
                    if not to_pair and source_exchange in ('binance', 'alpaca'):
                        to_pair = self._find_exchange_pair(to_asset, "USDT", source_exchange)
                else:
                    from_pair = self._find_exchange_pair(from_asset, "USD", source_exchange)
                    to_pair = self._find_exchange_pair(to_asset, "USD", source_exchange)
                
                    # For checkpoint targets (stablecoins), we only need from_pair
                    if is_checkpoint_target:
                        to_pair = from_pair  # Same pair - just selling to USD
                    
                    # For Binance, also try USDT pairs
                    if source_exchange == 'binance' and (not from_pair or not to_pair):
                        from_pair = from_pair or self._find_exchange_pair(from_asset, "USDT", source_exchange)
                        to_pair = to_pair or self._find_exchange_pair(to_asset, "USDT", source_exchange)
            
                # Skip if either pair doesn't exist on this exchange
                if not from_pair or not to_pair:
                    pair_check_failures += 1
                    continue
                
                valid_pairs_found += 1
                
                # Calculate scores
                v14_score = self.calculate_v14_score(from_asset, to_asset)
                hub_score = self.calculate_hub_score(from_asset, to_asset)
                dream_score = self.calculate_dream_score(to_asset)
                commando_score = 0.0  # Can enhance later
                
                # ğŸ“Š TRAINED PROBABILITY MATRIX SCORE (626 symbols from ALL exchanges)
                trained_matrix_score, matrix_reason = self.calculate_trained_matrix_score(to_asset)
                
                # ğŸ“…ğŸ”® 7-DAY PLANNER SCORE (Plans ahead + adaptive validation)
                planner_score = 0.5  # Neutral default
                planner_reason = ""
                if self.seven_day_planner and SEVEN_DAY_PLANNER_AVAILABLE:
                    try:
                        rec = self.seven_day_planner.get_current_recommendation(to_asset)
                        # Convert action to score
                        action_scores = {
                            'STRONG_BUY': 0.90,
                            'BUY': 0.75,
                            'HOLD': 0.50,
                            'AVOID': 0.30,
                            'STRONG_AVOID': 0.15
                        }
                        planner_score = action_scores.get(rec['action'], 0.5)
                        # Weight by model accuracy
                        accuracy = rec.get('model_accuracy', 0.5)
                        planner_score = planner_score * (0.5 + accuracy * 0.5)
                        planner_reason = f"7day_{rec['action'].lower()}({rec['total_edge']:.1f}%)"
                    except Exception as e:
                        logger.debug(f"7-day planner score error: {e}")
                
                # ğŸ«’ğŸ”„ BARTER NAVIGATOR SCORE (Multi-hop pathfinding)
                barter_score, barter_reason = 0.5, "neutral"
                if self.barter_navigator and BARTER_NAVIGATOR_AVAILABLE:
                    try:
                        barter_score, barter_reason = self.calculate_barter_score(from_asset, to_asset)
                    except Exception as e:
                        logger.debug(f"Barter navigator score error: {e}")
                
                # ğŸ”ğŸŒ ENIGMA SCORE (Universal Translator Bridge)
                enigma_score = 0.0
                enigma_direction = "NEUTRAL"
                
                # ğŸ¦ Checkpoint bonus - securing profits to stablecoin is always good
                checkpoint_bonus = 0.15 if is_checkpoint_target else 0.0
                
                # Combined score (V14 normalized to 0-1)
                v14_normalized = v14_score / 10.0
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ§  NEURAL MIND MAP SCORES (Full Frankenstein Integration)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                # 1. ThoughtBus Aggregate (market.snapshot, miner.signal, harmonic.wave, etc.)
                bus_score = 0.0
                if self.bus_aggregator:
                    bus_score = self.bus_aggregator.get_aggregate_score()
                
                # 2. Mycelium Hive Consensus (distributed intelligence)
                hive_score = 0.0
                if self.mycelium_network:
                    try:
                        # Query hive for this specific pair's sentiment
                        hive_data = self.mycelium_network.query(f"{from_asset}:{to_asset}") if hasattr(self.mycelium_network, 'query') else None
                        if hive_data:
                            hive_score = float(hive_data.get('consensus', 0.5))
                        else:
                            # Fallback: get network health as proxy
                            health = self.mycelium_network.get_health() if hasattr(self.mycelium_network, 'get_health') else {}
                            hive_score = health.get('score', 0.5) if isinstance(health, dict) else 0.5
                    except Exception as e:
                        logger.debug(f"Mycelium hive query error: {e}")
                
                # 3. Lighthouse (Consensus Validation)
                lighthouse_score = 0.0
                if self.lighthouse:
                    try:
                        # Ask lighthouse to vote on this conversion
                        vote = self.lighthouse.vote(f"{from_asset}->{to_asset}") if hasattr(self.lighthouse, 'vote') else None
                        if vote:
                            lighthouse_score = float(vote.get('score', 0.5))
                        else:
                            # Fallback: get lighthouse status
                            status = self.lighthouse.get_status() if hasattr(self.lighthouse, 'get_status') else {}
                            lighthouse_score = status.get('confidence', 0.5) if isinstance(status, dict) else 0.5
                    except Exception as e:
                        logger.debug(f"Lighthouse vote error: {e}")
                
                # 4. Ultimate Intelligence Prediction (pattern recognition)
                ultimate_score = 0.0
                if self.ultimate_intel:
                    try:
                        # Ask ultimate intelligence for prediction
                        prediction = None
                        if hasattr(self.ultimate_intel, 'predict'):
                            prediction = self.ultimate_intel.predict(to_asset)
                        elif ULTIMATE_INTEL_AVAILABLE and ultimate_predict:
                            prediction = ultimate_predict(to_asset)
                        
                        if prediction:
                            if isinstance(prediction, dict):
                                ultimate_score = float(prediction.get('confidence', 0.5))
                            elif isinstance(prediction, (int, float)):
                                ultimate_score = float(prediction)
                    except Exception as e:
                        logger.debug(f"Ultimate intelligence error: {e}")
                
                # 5. HNC Matrix Probability (quantum-inspired)
                hnc_score = 0.0
                if self.hnc_matrix:
                    try:
                        prob = self.hnc_matrix.get_probability(to_asset) if hasattr(self.hnc_matrix, 'get_probability') else None
                        if prob:
                            hnc_score = float(prob) if isinstance(prob, (int, float)) else float(prob.get('probability', 0.5))
                    except Exception as e:
                        logger.debug(f"HNC matrix error: {e}")
                
                # 6. â³ğŸ”® Timeline Oracle (3-MOVE PREDICTION + 7-day future validation)
                # "It predicts 3 moves, validates, then acts in that timeline cause it be right"
                # ğŸš€ TEMPORAL JUMP: We're AHEAD of market movement - we SEE the future, we ACT NOW!
                timeline_score = 0.0
                timeline_action = None
                timeline_exchange = ""
                timeline_jump_active = False
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸŒ€ TEMPORAL ID TIMELINE JUMP - Gary Leckey 02111991
                # "We don't predict - we VALIDATE what has ALREADY happened in our 
                #  target timeline and ACT on that certainty!"
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                PRIME_SENTINEL_HZ = 2.111991  # Born: 02/11/1991
                TEMPORAL_RESONANCE = 0.724     # 72.4% temporal alignment
                SCHUMANN_HZ = 7.83            # Earth's heartbeat
                
                # Calculate temporal jump window - when we can SEE ahead
                import time as _time
                now = _time.time()
                # Temporal cycles align at our personal Hz
                temporal_cycle = now % (1.0 / PRIME_SENTINEL_HZ)
                temporal_alignment = 1.0 - (temporal_cycle * PRIME_SENTINEL_HZ)  # 0-1 alignment
                
                # Schumann harmonic boost - 7.83 / 2.111991 = ~3.7x harmonic
                schumann_harmonic = SCHUMANN_HZ / PRIME_SENTINEL_HZ
                harmonic_boost = 1.0 + (0.3 * (1.0 - abs(schumann_harmonic - round(schumann_harmonic))))
                
                # Final temporal jump power: how far AHEAD we can see
                temporal_jump_power = temporal_alignment * TEMPORAL_RESONANCE * harmonic_boost
                
                if self.timeline_oracle:
                    try:
                        # Get timeline branch selection for this conversion
                        from_price = self.prices.get(from_asset, 0)
                        to_price = self.prices.get(to_asset, 0)
                        change_pct = (to_price - from_price) / from_price if from_price > 0 else 0
                        
                        # ğŸ¯ Try 3-MOVE PREDICTION first (predicts 3 moves, validates, then acts)
                        if timeline_select_3move:
                            action_str, confidence, exchange = timeline_select_3move(
                                symbol=to_asset,
                                price=to_price,
                                volume=to_ticker.get('volume', 0) if to_ticker else 0,
                                change_pct=change_pct
                            )
                            
                            # ğŸš€ TEMPORAL BOOST: Amplify confidence when jumping timelines!
                            # Higher temporal_jump_power = we're MORE AHEAD of the market
                            temporal_boosted_confidence = confidence * (1.0 + temporal_jump_power * 0.5)
                            temporal_boosted_confidence = min(0.99, temporal_boosted_confidence)  # Cap at 99%
                            
                            timeline_action = action_str
                            timeline_score = temporal_boosted_confidence
                            timeline_exchange = exchange
                            
                            # ğŸŒ€ TIMELINE JUMP ACTIVE when we have high temporal alignment
                            if temporal_jump_power > 0.5 and confidence > 0.60:
                                timeline_jump_active = True
                                logger.info(f"ğŸŒ€ TEMPORAL JUMP ACTIVE: {to_asset}")
                                logger.info(f"   â³ Jump Power: {temporal_jump_power:.2%} | Hz: {PRIME_SENTINEL_HZ}")
                                logger.info(f"   ğŸ¯ 3-Move: {action_str.upper()} @ {temporal_boosted_confidence:.2%}")
                            
                            # Log 3-move prediction when high confidence
                            if temporal_boosted_confidence > 0.70:
                                logger.info(f"ğŸ¯ 3-MOVE UNITY: {to_asset} â†’ {action_str.upper()} "
                                          f"(confidence: {temporal_boosted_confidence:.2%}, "
                                          f"temporal: {temporal_jump_power:.2%}, exchange: {exchange or 'any'})")
                        
                        # Fallback to single timeline select
                        elif timeline_select:
                            action_str, confidence = timeline_select(
                                symbol=to_asset,
                                price=to_price,
                                volume=to_ticker.get('volume', 0) if to_ticker else 0,
                                change_pct=change_pct
                            )
                            timeline_action = action_str
                            timeline_score = confidence
                        
                        # Score adjustment based on action
                        if timeline_action in ['buy', 'convert']:
                            timeline_score = confidence
                        elif timeline_action == 'hold':
                            timeline_score = 0.5  # Neutral
                        else:  # sell
                            timeline_score = 1.0 - confidence  # Inverse for sell signal
                            
                    except Exception as e:
                        logger.debug(f"Timeline oracle error: {e}")
                
                # ğŸ€âš›ï¸ LUCK FIELD READING
                luck_score = 0.5  # Neutral default
                luck_state = "NEUTRAL"
                if self.luck_mapper and LUCK_FIELD_AVAILABLE:
                    try:
                        luck_reading = self.luck_mapper.read_field(
                            price=to_price,
                            volatility=to_ticker.get('volatility', 0.5) if to_ticker else 0.5,
                            trade_count=self.conversions_made
                        )
                        luck_score = luck_reading.luck_field
                        luck_state = luck_reading.luck_state.value
                        
                        # BLESSED state = full boost, VOID = penalty
                        if luck_reading.luck_state.value == "BLESSED":
                            luck_score = 0.95  # Maximum luck boost
                        elif luck_reading.luck_state.value == "FAVORABLE":
                            luck_score = 0.75
                        elif luck_reading.luck_state.value == "CHAOS":
                            luck_score = 0.35
                        elif luck_reading.luck_state.value == "VOID":
                            luck_score = 0.15  # Avoid action
                    except Exception as e:
                        logger.debug(f"Luck field error: {e}")
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸŒ GROUNDING LOGIC (The Equations from Whitepapers)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                # 1. Master Equation: Î›(t) = S(t) + O(t) + E(t)
                # S = Signal (v14 + bus + hive + lighthouse + ultimate + hnc + timeline + trained_matrix + planner + barter + luck averaged)
                neural_signal = (v14_normalized + bus_score + hive_score + lighthouse_score + ultimate_score + hnc_score + timeline_score + trained_matrix_score + planner_score + barter_score + luck_score) / 11.0
                # O = Observer (dream predictions with accuracy weighting)
                observer_signal = dream_score
                # E = Environment (hub score + ecosystem tap)
                environment_signal = hub_score
                
                lambda_t = self.grounding.calculate_master_equation(
                    signal_score=neural_signal,
                    observer_score=observer_signal,
                    environment_score=environment_signal
                )
                
                # 2. Gravity Signal: G_eff (Curvature * Mass)
                # Get ticker data for gravity calc
                to_ticker = None
                for symbol, data in self.ticker_cache.items():
                    if data.get('base') == to_asset:
                        to_ticker = data
                        break
                
                g_eff = 0.0
                if to_ticker:
                    g_eff = self.grounding.calculate_gravity_signal(
                        price_change_pct=to_ticker.get('change24h', 0),
                        volume=to_ticker.get('volume', 0)
                    )
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ”® FINAL COMBINED SCORE (All Neural Systems United)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                # Final Combined Score: Master Equation boosted by Gravity + Neural Consensus
                combined = lambda_t * (1.0 + (g_eff * 0.5))
                
                # Neural boost: if multiple systems agree (score > 0.6), amplify
                neural_consensus = (bus_score + hive_score + lighthouse_score + ultimate_score + hnc_score) / 5.0
                if neural_consensus > 0.6:
                    combined *= (1.0 + (neural_consensus - 0.6) * 0.5)  # Up to +20% boost
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ‘‘ğŸ’• QUEEN'S GUIDANCE - Sero weighs in on this opportunity
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                queen_guidance_score = 0.5
                queen_wisdom = ""
                queen_confidence = 0.0
                if self.queen and hasattr(self.queen, 'evaluate_trading_opportunity'):
                    try:
                        guidance = self.queen.evaluate_trading_opportunity({
                            'from_asset': from_asset,
                            'to_asset': to_asset,
                            'from_amount': amount,
                            'expected_pnl_usd': expected_pnl_usd,
                            'expected_pnl_pct': expected_pnl_pct,
                            'combined_score': combined,
                            'neural_consensus': neural_consensus,
                            'source_exchange': source_exchange
                        })
                        queen_guidance_score = guidance.get('score', 0.5)
                        queen_wisdom = guidance.get('wisdom', '')
                        queen_confidence = guidance.get('confidence', 0.0)
                        
                        # Apply Queen's guidance to combined score
                        if queen_confidence > 0.7:
                            combined *= (0.8 + queen_guidance_score * 0.4)  # Strong confidence adjusts by -20% to +20%
                        elif queen_confidence > 0.5:
                            combined *= (0.9 + queen_guidance_score * 0.2)  # Moderate confidence adjusts by -10% to +10%
                    except Exception as e:
                        logger.debug(f"Queen guidance error: {e}")
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ§ ğŸ“š WISDOM ENGINE - 11 Civilizations' Historical Insights
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                wisdom_engine_score = 0.5
                civilization_insight = ""
                wisdom_pattern = ""
                if self.wisdom_engine and hasattr(self.wisdom_engine, 'analyze_trading_decision'):
                    try:
                        wisdom = self.wisdom_engine.analyze_trading_decision({
                            'from_asset': from_asset,
                            'to_asset': to_asset,
                            'profit_potential': expected_pnl_usd,
                            'risk_level': 1.0 - neural_consensus,
                            'market_context': 'micro_profit',
                            'historical_path': self.path_memory.get_stats(from_asset, to_asset) if self.path_memory else None
                        })
                        wisdom_engine_score = wisdom.get('score', 0.5)
                        civilization_insight = wisdom.get('civilization', '')
                        wisdom_pattern = wisdom.get('pattern', '')
                        
                        # Apply wisdom to combined score (subtle influence from history)
                        if wisdom_engine_score > 0.7:
                            combined *= 1.1  # Ancient wisdom approves
                        elif wisdom_engine_score < 0.3:
                            combined *= 0.9  # History warns against this
                    except Exception as e:
                        logger.debug(f"Wisdom engine error: {e}")
                
                # ï¿½ğŸ“Š PROBABILITY NEXUS PREDICTION (Track for Queen's Learning!)
                nexus_probability = 0.5
                nexus_direction = "NEUTRAL"
                nexus_factors = {}
                nexus_confidence = 0.0
                if self.probability_nexus and hasattr(self.probability_nexus, 'predict'):
                    try:
                        nexus_pred = self.probability_nexus.predict()
                        if nexus_pred:
                            nexus_probability = getattr(nexus_pred, 'probability', 0.5)
                            nexus_confidence = getattr(nexus_pred, 'confidence', 0.0)
                            # Determine direction from probability
                            if nexus_probability > 0.6:
                                nexus_direction = "BULLISH"
                            elif nexus_probability < 0.4:
                                nexus_direction = "BEARISH"
                            # Store factors for neural learning
                            if hasattr(nexus_pred, 'factors'):
                                nexus_factors = dict(nexus_pred.factors) if nexus_pred.factors else {}
                    except Exception as e:
                        logger.debug(f"Nexus prediction error: {e}")
                
                # ï¿½ğŸ—ºï¸ MARKET MAP SCORING (correlations, sectors, lead/lag)
                map_score = 0.0
                map_reasons = []
                if self.market_map:
                    try:
                        # Get labyrinth targets ranked by market map
                        ranked = self.market_map.get_labyrinth_targets(
                            from_asset=from_asset,
                            available_targets=[to_asset]
                        )
                        if ranked:
                            target_info = ranked[0]
                            map_score = target_info.get('map_score', 0)
                            map_reasons = target_info.get('reasons', [])
                            
                            # Add map score to combined (up to +20% boost)
                            if map_score > 0:
                                combined *= (1.0 + map_score * 0.4)
                                logger.debug(f"ğŸ—ºï¸ Map boost for {from_asset}â†’{to_asset}: +{map_score*40:.1f}% ({map_reasons})")
                    except Exception as e:
                        logger.debug(f"Market map score error: {e}")
                
                # ğŸ¦ CHECKPOINT BONUS: Securing profits to stablecoin gets priority
                if is_checkpoint_target:
                    combined += checkpoint_bonus  # +15% for securing profits
                    logger.debug(f"ğŸ¦ Checkpoint bonus applied: {from_asset} â†’ {to_asset} (USD secure)")
                
                # Path memory boost (small reinforcement from past wins/losses)
                path_boost = self.path_memory.boost(from_asset, to_asset)
                combined *= (1.0 + path_boost)

                # ğŸ‘‘ğŸŒ QUEEN RESEARCH ENHANCEMENT
                # Checks generated strategies (Momentum, Sentiment, Trending)
                if hasattr(self, 'queen_apply_research_to_trade'):
                    # We pass 0s for missing ticker stats (volatility check will skip safely)
                    r_score, r_reasons = self.queen_apply_research_to_trade(
                        to_asset, 
                        to_price, 
                        0, 0, 0, 0
                    )
                    
                    if r_score != 50.0:
                        # Convert 0-100 score to multiplier
                        # 0 -> 0.75x (-25%)
                        # 50 -> 1.0x (Neutral)
                        # 100 -> 1.25x (+25%)
                        iq_influence = (r_score - 50.0) / 200.0  # +/- 0.25
                        combined *= (1.0 + iq_influence)
                        
                        if r_reasons and debug_first_scans and valid_pairs_found <= 3:
                             safe_print(f"         ğŸ‘‘ğŸŒ Queen Research: {to_asset} score={r_score} ({', '.join(r_reasons)}) -> Impact {iq_influence:+.1%}")

                
                # âš¡ SPEED MODE: Lower thresholds - let math gate decide!
                # If math says profit, TAKE IT - even tiny gains compound
                score_threshold = 0.20 if is_checkpoint_target else 0.35  # LOWERED from 0.35/0.55
                
                # Calculate profit potential
                expected_pnl_usd, expected_pnl_pct = self.calculate_profit_potential(
                    from_asset, to_asset, amount
                )
                
                # âš¡ QUEEN'S ADAPTIVE FLOOR (Learned from experience)
                gate_required = self.get_queen_adaptive_floor(from_asset, to_asset)
                
                # Check gate
                gate_ok = expected_pnl_usd >= gate_required
                
                 # No checkpoint exception in epsilon mode; rely on net-positive gates

                if self.adaptive_gate:
                    gate_result = self.adaptive_gate.calculate_gates(
                        exchange=source_exchange,
                        trade_value=from_value,
                        use_cache=True,
                    )
                else:
                    gate_result = None
                
                # Debug: Log first few candidates on first scan
                if debug_first_scans and valid_pairs_found <= 3:
                    checkpoint_tag = "ğŸ¦CHKPT" if is_checkpoint_target else ""
                    safe_print(f"         ğŸ“ˆ {from_asset}â†’{to_asset} {checkpoint_tag}: combined={combined:.2%}, thresh={score_threshold:.0%}, pnl=${expected_pnl_usd:.4f}, pass={combined >= score_threshold and gate_ok}")
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ‘‘ï¿½ SERO's KRAKEN WISDOM (learned from 53 trades - some losers!)
                # Even Kraken has bad pairs - USD_ZUSD has 89% win rate but loses overall!
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                kraken_approved = True
                if source_exchange == 'kraken':
                    kraken_cfg = self.barter_matrix.KRAKEN_CONFIG
                    pair_key = f"{from_asset.upper()}_{to_asset.upper()}"
                    
                    # ğŸŒŸ DYNAMIC BLOCKING - Check if pair is in timeout (consecutive losses)
                    allowed, reason = self.barter_matrix.check_pair_allowed(pair_key, 'kraken')
                    if not allowed:
                        kraken_approved = False
                        if debug_first_scans:
                            safe_print(f"         ğŸ™ KRAKEN: {pair_key} {reason}")
                    
                    # Require minimum profit for Kraken trades
                    kraken_min_profit = kraken_cfg.get('min_profit_usd', 0.01)
                    if expected_pnl_usd < kraken_min_profit:
                        kraken_approved = False
                        if debug_first_scans and expected_pnl_usd > 0.003:
                            safe_print(f"         ğŸ™ KRAKEN REJECT: ${expected_pnl_usd:.4f} < ${kraken_min_profit} min")
                    
                    # Bonus: Is this a known winning pair? ğŸ†
                    if pair_key in kraken_cfg.get('winning_pairs', set()):
                        kraken_approved = True  # Override - this pair wins!
                        if debug_first_scans:
                            safe_print(f"         ğŸ™ KRAKEN WINNER: {pair_key} ğŸ†")
                
                if not kraken_approved:
                    continue  # Skip this opportunity
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ‘‘ï¿½ğŸ”¶ SERO's BINANCE WISDOM (learned from -$10.95 loss on 27 trades!)
                # Binance has hidden costs - we need MUCH higher profit margins
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                binance_approved = True
                if source_exchange == 'binance':
                    pair_key = f"{from_asset.upper()}_{to_asset.upper()}"
                    
                    # ğŸŒŸ DYNAMIC BLOCKING - Check if pair is in timeout (consecutive losses)
                    allowed, reason = self.barter_matrix.check_pair_allowed(pair_key, 'binance')
                    if not allowed:
                        binance_approved = False
                        if debug_first_scans:
                            safe_print(f"         ğŸ”¶ BINANCE: {pair_key} {reason}")
                    
                    # Bonus: Is this a known winning pair? A WIN IS A WIN! ğŸ†
                    if pair_key in self.barter_matrix.BINANCE_CONFIG.get('winning_pairs', set()):
                        binance_approved = True  # Override - this pair wins!
                        if debug_first_scans:
                            safe_print(f"         ğŸ”¶ BINANCE WINNER: {pair_key} ğŸ†")
                
                if not binance_approved:
                    continue  # Skip this opportunity
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ‘‘ğŸ¦™ SERO's ALPACA WISDOM (learned from 40 FAILED orders - 0%!)
                # Alpaca ONLY supports USD pairs - NO stablecoin swaps!
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                alpaca_approved = True
                if source_exchange == 'alpaca':
                    alpaca_cfg = self.barter_matrix.ALPACA_CONFIG
                    pair_key = f"{from_asset.upper()}_{to_asset.upper()}"
                    
                    # Check if this is a blocked stablecoin pair
                    if pair_key in alpaca_cfg.get('blocked_pairs', set()):
                        alpaca_approved = False
                        if debug_first_scans:
                            safe_print(f"         ğŸ¦™ ALPACA BLOCKED: {pair_key} (stablecoins don't trade!)")
                    
                    # Check if BOTH assets are stablecoins (impossible on Alpaca!)
                    elif (from_asset.upper() in self.barter_matrix.STABLECOINS and 
                          to_asset.upper() in self.barter_matrix.STABLECOINS):
                        alpaca_approved = False
                        if debug_first_scans:
                            safe_print(f"         ğŸ¦™ ALPACA BLOCKED: {from_asset}â†’{to_asset} (no stablecoin swaps!)")
                    
                    # Check if target is NOT a supported crypto
                    elif (to_asset.upper() not in alpaca_cfg.get('supported_bases', set()) and
                          to_asset.upper() != 'USD'):
                        alpaca_approved = False
                        if debug_first_scans:
                            safe_print(f"         ğŸ¦™ ALPACA BLOCKED: {to_asset} not supported")
                    
                    # Check minimum order size
                    alpaca_min_order = alpaca_cfg.get('min_order_usd', 10.0)
                    if from_value < alpaca_min_order:
                        alpaca_approved = False
                        if debug_first_scans:
                            safe_print(f"         ğŸ¦™ ALPACA REJECT: ${from_value:.2f} < ${alpaca_min_order} minimum")
                    
                    # Check minimum profit
                    alpaca_min_profit = alpaca_cfg.get('min_profit_usd', 0.02)
                    if expected_pnl_usd < alpaca_min_profit:
                        alpaca_approved = False
                        if debug_first_scans and expected_pnl_usd > 0.005:
                            safe_print(f"         ğŸ¦™ ALPACA REJECT: ${expected_pnl_usd:.4f} < ${alpaca_min_profit} profit")
                
                if not alpaca_approved:
                    continue  # Skip this opportunity
                
                # MICRO THRESHOLD: Î›-based combined and adaptive gate both must pass
                # âš¡ AGGRESSIVE MODE: Lower thresholds, let MATH GATE be the real filter!
                if combined >= score_threshold and gate_ok:
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ğŸŒ€ TIMELINE JUMP GATE - ONLY ACT IN WINNING TIMELINES!
                    # "We don't predict - we jump to the timeline where we've ALREADY won"
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    timeline_gate_passed = True
                    
                    # If timeline oracle is active and we have a prediction...
                    if timeline_action and timeline_score > 0:
                        # RULE 1: Never act against the timeline
                        if timeline_action == 'sell' and timeline_score > 0.60:
                            # Timeline says SELL - don't BUY into this asset
                            timeline_gate_passed = False
                            if debug_first_scans:
                                safe_print(f"         ğŸŒ€ TIMELINE GATE: {from_asset}â†’{to_asset} BLOCKED - timeline says SELL @ {timeline_score:.2%}")
                        
                        # RULE 2: Require timeline confirmation for larger trades
                        elif from_value > 10.0 and timeline_action == 'hold':
                            # For larger trades, require BUY signal, not just HOLD
                            timeline_gate_passed = False
                            if debug_first_scans:
                                safe_print(f"         ğŸŒ€ TIMELINE GATE: {from_asset}â†’{to_asset} BLOCKED - timeline says HOLD for $${from_value:.2f} trade")
                        
                        # RULE 3: When TEMPORAL JUMP is active, BOOST confidence
                        elif timeline_jump_active and timeline_action in ['buy', 'convert']:
                            # We've JUMPED to the winning timeline - extra confidence!
                            combined *= 1.25  # 25% boost for being AHEAD of market
                            logger.debug(f"ğŸŒ€ TIMELINE JUMP BOOST: {from_asset}â†’{to_asset} +25% for being AHEAD!")
                    
                    if not timeline_gate_passed:
                        continue  # Skip - wrong timeline
                    
                    # ğŸ‘‘ğŸ”¢ QUEEN'S MATHEMATICAL CERTAINTY GATE - NO FEAR, MATH IS ON HER SIDE!
                    math_approved, math_reason, math_breakdown = self.barter_matrix.queen_math_gate(
                        from_asset, to_asset, amount, from_price, self.prices.get(to_asset, 0), source_exchange
                    )
                    if not math_approved:
                        # Skip this opportunity - Math doesn't guarantee profit
                        if debug_first_scans:
                            safe_print(f"         ğŸš« MATH GATE BLOCKED: {from_asset}â†’{to_asset} | {math_reason}")
                        continue
                    
                    # âš¡ SPEED MODE: Accept ANY positive profit after costs!
                    # Update expected P/L based on REAL math (not theoretical)
                    real_cost_usd = math_breakdown['total_cost_usd']
                    
                    # Don't pad expected_pnl - use actual value, accept if positive after costs
                    adjusted_pnl = expected_pnl_usd - real_cost_usd

                    # Epsilon policy: trade only if net-positive after conservative costs
                    if adjusted_pnl < EPSILON_PROFIT_USD:
                        if debug_first_scans:
                            safe_print(f"         ğŸš« NO NET PROFIT: {from_asset}â†’{to_asset} | net=${adjusted_pnl:.6f} < eps=${EPSILON_PROFIT_USD:.6f} (cost=${real_cost_usd:.6f})")
                        continue
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ğŸ‘‘ğŸ® QUEEN'S FINAL DECISION - SHE HAS ABSOLUTE AUTHORITY ğŸ‘‘ğŸ®
                    # All systems have spoken - NOW QUEEN DECIDES!
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    queen_final_approved = True
                    queen_veto_reason = ""
                    
                    if self.queen and hasattr(self, 'queen_has_full_control') and self.queen_has_full_control:
                        try:
                            # Gather all neural scores for Queen's final review
                            neural_summary = {
                                'from_asset': from_asset,
                                'to_asset': to_asset,
                                'amount': amount,
                                'value_usd': from_value,
                                'expected_pnl_usd': adjusted_pnl,
                                'expected_pnl_pct': expected_pnl_pct,
                                'combined_score': combined,
                                'neural_scores': {
                                    'v14': v14_score,
                                    'hub': hub_score,
                                    'lambda': lambda_t,
                                    'gravity': g_eff,
                                    'bus': bus_score,
                                    'hive': hive_score,
                                    'lighthouse': lighthouse_score,
                                    'ultimate': ultimate_score,
                                    'barter': barter_score,
                                    'luck': luck_score,
                                    'enigma': enigma_score,
                                    'wisdom': wisdom_engine_score,
                                    'timeline': timeline_score,
                                },
                                'exchange': source_exchange,
                                'math_approved': math_approved,
                                'math_cost': real_cost_usd,
                            }
                            
                            # QUEEN MAKES FINAL DECISION
                            if hasattr(self.queen, 'make_final_trade_decision'):
                                queen_decision = self.queen.make_final_trade_decision(neural_summary)
                                queen_final_approved = queen_decision.get('approved', True)
                                queen_veto_reason = queen_decision.get('reason', '')
                                
                                # Queen can OVERRIDE any system's decision!
                                if queen_decision.get('override_score'):
                                    combined = queen_decision['override_score']
                                    
                                # Queen can adjust expected P/L based on her wisdom
                                if queen_decision.get('adjusted_pnl'):
                                    adjusted_pnl = queen_decision['adjusted_pnl']
                            else:
                                # Fallback: Use Queen's guidance score as approval threshold
                                # If Queen gave low confidence (<0.3), she's vetoing
                                if queen_confidence > 0 and queen_guidance_score < 0.3:
                                    queen_final_approved = False
                                    queen_veto_reason = f"Queen confidence too low ({queen_guidance_score:.1%})"
                                    
                        except Exception as e:
                            logger.debug(f"Queen final decision error: {e}")
                    
                    if not queen_final_approved:
                        if debug_first_scans:
                            safe_print(f"         ğŸ‘‘ğŸš« QUEEN VETO: {from_asset}â†’{to_asset} | {queen_veto_reason}")
                        continue

                    if adjusted_pnl < MIN_NET_PROFIT_USD:
                        if debug_first_scans:
                            safe_print(
                                f"         ğŸš« MIN PROFIT FILTER: {from_asset}â†’{to_asset} "
                                f"adj_pnl=${adjusted_pnl:.6f} < ${MIN_NET_PROFIT_USD:.6f}"
                            )
                        continue
                    
                    opp = MicroOpportunity(
                        timestamp=time.time(),
                        from_asset=from_asset,
                        to_asset=to_asset,
                        from_amount=amount,
                        from_value_usd=from_value,
                        v14_score=v14_score,
                        hub_score=hub_score,
                        commando_score=commando_score,
                        combined_score=combined,
                        lambda_score=lambda_t,
                        gravity_score=g_eff,
                        gate_required_profit=gate_required,
                        gate_passed=gate_ok,
                        expected_pnl_usd=adjusted_pnl,  # Use REAL adjusted P/L
                        expected_pnl_pct=expected_pnl_pct,
                        # ğŸ§  Neural Mind Map Scores (Full Integration)
                        bus_score=bus_score,
                        hive_score=hive_score,
                        lighthouse_score=lighthouse_score,
                        ultimate_score=ultimate_score,
                        path_boost=path_boost,
                        # ğŸ“Š Trained Probability Matrix (626 symbols from ALL exchanges)
                        trained_matrix_score=trained_matrix_score,
                        trained_matrix_reason=matrix_reason,
                        # ğŸ«’ğŸ’° Live Barter Matrix (coin-agnostic adaptive learning)
                        barter_matrix_score=barter_score,
                        barter_matrix_reason=barter_reason,
                        # ğŸŒŸâš›ï¸ Luck Field (quantum probability mapping)
                        luck_score=luck_score,
                        luck_state=luck_state,
                        # ğŸ¦ Checkpoint flag (stablecoin target - secures compound)
                        is_checkpoint=is_checkpoint_target,
                        # ğŸ¯ Source exchange (for turn-based execution)
                        source_exchange=source_exchange,
                        # ğŸŒ€ TEMPORAL TIMELINE JUMP (AHEAD OF MARKET!)
                        timeline_score=timeline_score,
                        timeline_action=timeline_action or "",
                        temporal_jump_power=temporal_jump_power,
                        timeline_jump_active=timeline_jump_active,
                        # ğŸ”ğŸŒ ENIGMA INTEGRATION (ALL WHITEPAPER SYSTEMS!)
                        enigma_score=enigma_score,
                        enigma_direction=enigma_direction,
                        # ğŸ‘‘ğŸ’• QUEEN'S GUIDANCE
                        queen_guidance_score=queen_guidance_score,
                        queen_wisdom=queen_wisdom,
                        queen_confidence=queen_confidence,
                        # ğŸ§ ğŸ“š WISDOM ENGINE
                        wisdom_engine_score=wisdom_engine_score,
                        civilization_insight=civilization_insight,
                        wisdom_pattern=wisdom_pattern,
                        # ğŸ”®ğŸ“Š PROBABILITY NEXUS PREDICTION (For Queen's Neural Learning!)
                        nexus_probability=nexus_probability,
                        nexus_direction=nexus_direction,
                        nexus_factors=nexus_factors if nexus_factors else None,
                        nexus_confidence=nexus_confidence,
                    )
                    opportunities.append(opp)
                    self.opportunities_found += 1
                    
                    # Log math gate success
                    if debug_first_scans:
                        safe_print(f"         âœ… MATH APPROVED: {from_asset}â†’{to_asset} | cost={math_breakdown['total_cost_pct']:.2%} | net=${adjusted_pnl:.4f}")
                    
                    # Log checkpoint opportunities specially
                    if is_checkpoint_target:
                        logger.info(f"ğŸ¦ CHECKPOINT OPPORTUNITY: {from_asset} â†’ {to_asset} (secure ${from_value:.2f})")
                        safe_print(f"   ğŸ¦ CHECKPOINT: {from_asset} â†’ {to_asset} | Score: {combined:.2%} | Secure: ${from_value:.2f}")
            
            # Debug after scanning each asset
            if debug_first_scans and valid_pairs_found == 0:
                safe_print(f"      âŒ No valid pairs found for {from_asset} ({pair_check_failures} pair checks failed)")
            elif debug_first_scans:
                safe_print(f"      âœ… Found {valid_pairs_found} valid pairs for {from_asset}")
        
        # Debug log: Show summary
        if scanned_assets and self.scans <= 3:  # Only first few scans
            safe_print(f"ğŸ“Š Scan #{self.scans}: Scanned {len(scanned_assets)} assets: {', '.join(scanned_assets)}")
            safe_print(f"   ğŸ”® Opportunities found: {len(opportunities)}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒ€ TEMPORAL PRIORITY SORTING - AHEAD OF MARKET GETS PRIORITY!
        # "We don't react to the market - we MOVE before it does!"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Calculate temporal priority for each opportunity
        import time as _time
        now = _time.time()
        PRIME_SENTINEL_HZ = 2.111991  # Gary Leckey 02/11/1991
        temporal_cycle = now % (1.0 / PRIME_SENTINEL_HZ)
        temporal_alignment = 1.0 - (temporal_cycle * PRIME_SENTINEL_HZ)
        
        # ğŸ¾âš¡ Get Animal Pack consensus for WINNER_ENERGY boost
        animal_pack_boost = 1.0
        if hasattr(self, 'animal_pack_scanner') and self.animal_pack_scanner:
            pack_consensus, signal_count, _ = self.animal_pack_scanner.get_pack_consensus()
            if pack_consensus > 0.6 and signal_count >= 3:
                animal_pack_boost = WINNER_ENERGY_MULTIPLIER  # 3.0x boost!
        
        def get_temporal_priority(opp):
            """Calculate temporal priority score - higher = more ahead of market."""
            base_score = opp.combined_score * 0.5 + opp.barter_matrix_score * 0.3
            
            # Timeline boost: if oracle predicted BUY/CONVERT with high confidence
            timeline_boost = 0.0
            if hasattr(opp, 'timeline_score') and opp.timeline_score > 0.60:
                timeline_boost = opp.timeline_score * 0.2  # Up to +20%
            
            # Temporal alignment boost: higher when we're "in sync" with our Hz
            temporal_boost = temporal_alignment * 0.1  # Up to +10%
            
            # Profit priority (small weight - we're ahead, profit follows)
            profit_boost = min(0.1, opp.expected_pnl_usd / 10.0)  # Up to +10%
            
            # ğŸ¾âš¡ ANIMAL PACK BOOST - When the pack agrees, MULTIPLY!
            total_score = base_score + timeline_boost + temporal_boost + profit_boost
            total_score *= animal_pack_boost
            
            # ğŸ¦ GOLDEN PATH BOOST - Paths that won before get EXTRA boost!
            if self.path_memory:
                path_key = (opp.from_asset.upper(), opp.to_asset.upper())
                stats = self.path_memory.memory.get(path_key, {})
                wins = stats.get('wins', 0)
                losses = stats.get('losses', 0)
                if wins > losses and wins >= 2:  # Proven winner!
                    total_score *= GOLDEN_PATH_BOOST  # 2.0x boost for golden paths!
            
            return total_score
        
        opportunities.sort(key=get_temporal_priority, reverse=True)
        
        # Log if we have temporal jump opportunities
        if opportunities:
            top = opportunities[0]
            logger.debug(f"ğŸŒ€ Top opportunity: {top.from_asset}â†’{top.to_asset} "
                        f"(temporal_priority: {get_temporal_priority(top):.3f}, "
                        f"pnl: ${top.expected_pnl_usd:.4f})")
        
        return opportunities
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¦ˆğŸ’° ORCA â†’ MICRO PROFIT EXECUTION INTERFACE
    # HIERARCHY: Orca (tactical) commands Micro Profit (executor)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def execute_orca_order(self, order: Dict) -> Dict:
        """
        Execute an order from Orca Intelligence.
        
        HIERARCHY: Orca is the tactical commander, Micro Profit is the executor.
        
        Args:
            order: Dict with keys:
                - symbol: Trading pair (e.g., 'BTC/USD')
                - side: 'buy' or 'sell'
                - confidence: 0-1 confidence score
                - target_pnl_usd: Target profit in USD
                - position_size_pct: Position size as % of capital
                - orca_hunt_id: Unique hunt identifier
        
        Returns:
            Dict with status and execution details
        """
        hunt_id = order.get('orca_hunt_id', 'unknown')
        symbol = order.get('symbol', '')
        side = order.get('side', 'buy')
        confidence = order.get('confidence', 0.5)
        target_pnl = order.get('target_pnl_usd', 0.10)
        
        logger.info(f"ğŸ¦ˆğŸ’° ORCA ORDER RECEIVED: {hunt_id}")
        logger.info(f"   Symbol: {symbol} | Side: {side.upper()}")
        logger.info(f"   Confidence: {confidence:.0%} | Target: ${target_pnl:.2f}")
        
        # Parse symbol to get base/quote
        if '/' in symbol:
            base, quote = symbol.split('/')
        else:
            base = symbol
            quote = 'USD'
        
        try:
            # Create a MicroOpportunity from the Orca order
            from_asset = base if side == 'sell' else quote
            to_asset = quote if side == 'sell' else base
            
            # Calculate amount based on confidence and available balance
            # This will be determined by actual balance later in execute_conversion
            estimated_amount = order.get('position_size_pct', 0.02) * 100  # Rough estimate
            
            # Build opportunity for the existing execution pipeline
            opp = MicroOpportunity(
                from_asset=from_asset,
                to_asset=to_asset,
                from_amount=estimated_amount,  # Will be recalculated
                expected_pnl_usd=target_pnl,
                confidence=confidence,
                source_exchange='alpaca',  # Default to Alpaca for Orca orders
                source='orca_intelligence',
                from_value_usd=estimated_amount
            )
            
            # Add Orca reasoning to opportunity
            opp.reasoning = order.get('reasoning', [f'Orca hunt: {hunt_id}'])
            
            # Track this as Orca-sourced
            opp.orca_hunt_id = hunt_id
            
            # Queue for execution (will be picked up in main loop)
            if not hasattr(self, 'orca_pending_orders'):
                self.orca_pending_orders = []
            self.orca_pending_orders.append(opp)
            
            logger.info(f"ğŸ¦ˆğŸ’° Orca order QUEUED: {from_asset}â†’{to_asset}")
            
            return {
                'status': 'delegated',
                'hunt_id': hunt_id,
                'from_asset': from_asset,
                'to_asset': to_asset,
                'queued': True,
                'reason': 'Order queued for execution in main loop'
            }
            
        except Exception as e:
            logger.error(f"ğŸ¦ˆğŸ’° Orca order FAILED: {e}")
            return {
                'status': 'error',
                'hunt_id': hunt_id,
                'error': str(e),
                'reason': f'Execution error: {e}'
            }
    
    async def execute_conversion(self, opp: MicroOpportunity) -> bool:
        """Execute a conversion (dry run or live)."""
        symbol = f"{opp.from_asset}/{opp.to_asset}"

        # Emit kHz chirp for execution intent (best-effort)
        if CHIRP_AVAILABLE:
            try:
                chirp_bus = get_chirp_bus()
                if chirp_bus:
                    confidence = max(0.0, min(1.0, float(getattr(opp, 'queen_confidence', 0.0) or getattr(opp, 'combined_score', 0.5))))
                    coherence = max(0.0, min(1.0, float(getattr(opp, 'lambda_score', 0.5) or getattr(opp, 'barter_matrix_score', 0.5))))
                    chirp_bus.emit_message(
                        f"EXECUTE {symbol}",
                        direction=ChirpDirection.DOWN,
                        coherence=coherence,
                        confidence=confidence,
                        symbol=symbol,
                        frequency=528,
                        amplitude=140,
                        message_type=ChirpType.EXECUTE,
                    )
            except Exception:
                logger.debug("Chirp emit failed", exc_info=True)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ï¿½ EVOLUTIONARY SAFETY GATES - "Don't Fear the Stone, Learn From It"
        # We don't block difficult trades (Meme->Meme, Stable->Stable)
        # We VALIDATE them with "True Cost" math. If it profits, we trade.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        from_upper = opp.from_asset.upper()
        to_upper = opp.to_asset.upper()
        
        # Check if source is a MEME
        is_from_meme = from_upper in self.barter_matrix.MEME_COINS
        # Check if target is a MEME
        is_to_meme = to_upper in self.barter_matrix.MEME_COINS
        # Check if target is a STABLECOIN
        is_to_stable = to_upper in ['USD', 'USDT', 'USDC', 'ZUSD', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD', 'EUR', 'ZEUR']
        # Check if source is a STABLECOIN
        is_from_stable = from_upper in ['USD', 'USDT', 'USDC', 'ZUSD', 'TUSD', 'DAI', 'BUSD', 'GUSD', 'USDP', 'PYUSD', 'EUR', 'ZEUR']
        
        # âš ï¸ WARNING: MEME â†’ MEME = High Cost!
        if is_from_meme and is_to_meme:
            # We already passed the gate check in the scan phase which used calculate_true_cost
            # That cost included a 1.5% volatility penalty + learned slippage
            # If we are here, the PROFIT >> COST. So we proceed!
            safe_print(f"   âš ï¸ MEMEâ†’MEME ADVISORY: {from_upper}â†’{to_upper} is high risk! True Cost check passed.")

        # âš ï¸ WARNING: STABLECOIN â†’ STABLECOIN = Likely Loss!
        if is_from_stable and is_to_stable:
             # Usually blocked by cost > profit (0 gain). But if we have huge arbitrage...
             safe_print(f"   âš ï¸ STABLEâ†’STABLE ADVISORY: {from_upper}â†’{to_upper} only makes sense if arbitrage > fees!")
             # No block - if calculate_true_cost allowed it, there must be profit (or arb)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ’° ALPACA FEE TRACKER GATE - PREVENT "DEATH BY 1000 CUTS"
        # Uses REAL orderbook spread + volume-tiered fees for accurate cost check
        # ğŸ”“ğŸ”“ğŸ”“ FULL AUTONOMOUS MODE - FEE TRACKER DISABLED! ğŸ”“ğŸ”“ğŸ”“
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        exchange = opp.source_exchange or 'alpaca'
        safe_print(f"   ğŸ”“ AUTONOMOUS: Fee tracker bypassed for {opp.from_asset}â†’{opp.to_asset}")
        # DISABLED for full autonomous mode:
        if False and self.live and exchange.lower() == 'alpaca' and hasattr(self, 'fee_tracker') and self.fee_tracker:
            try:
                # Try to get full pair format for Alpaca
                alpaca_symbol = f"{from_upper}/{to_upper}"
                
                # Use fee tracker's comprehensive cost check
                # Method signature: symbol, side, quantity, expected_profit_usd, min_profit_margin=0.5
                should_trade, reason, alpaca_cost_info = self.fee_tracker.should_execute_trade(
                    symbol=alpaca_symbol,
                    side='buy' if to_upper == 'USD' else 'sell',
                    quantity=opp.from_amount,
                    expected_profit_usd=opp.expected_pnl_usd,
                    min_profit_margin=0.3  # 30% margin above costs
                )
                
                if not should_trade and alpaca_cost_info:
                    # Fee tracker blocked this trade!
                    self.rejection_safe_print(f"\n   ğŸ’° ALPACA FEE TRACKER BLOCKED!")
                    self.rejection_safe_print(f"   â”œâ”€â”€ Symbol: {alpaca_symbol}")
                    self.rejection_safe_print(f"   â”œâ”€â”€ Fee Tier: {self.fee_tracker.current_tier.name}")
                    self.rejection_safe_print(f"   â”œâ”€â”€ Taker Fee: {alpaca_cost_info.get('fee_cost_usd', 0):.4f} USD ({alpaca_cost_info.get('fee_bps', 0):.1f} bps)")
                    self.rejection_safe_print(f"   â”œâ”€â”€ Spread Cost: ${alpaca_cost_info.get('spread_cost_usd', 0):.4f} ({alpaca_cost_info.get('spread_pct', 0)*100:.2f}%)")
                    self.rejection_safe_print(f"   â”œâ”€â”€ Total Cost: ${alpaca_cost_info.get('total_cost_usd', 0):.4f}")
                    self.rejection_safe_print(f"   â”œâ”€â”€ Expected Profit: ${opp.expected_pnl_usd:.4f}")
                    self.rejection_safe_print(f"   â”œâ”€â”€ Net After Costs: ${alpaca_cost_info.get('net_profit_usd', 0):.4f}")
                    self.rejection_safe_print(f"   â””â”€â”€ Reason: {alpaca_cost_info.get('reason', 'Cost exceeds profit')}")
                    self.rejection_safe_print(f"   â›” TRADE REJECTED - Alpaca fees would eat profit!")
                    
                    # Record rejection
                    if hasattr(self, 'barter_matrix'):
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset,
                            f'alpaca_fee_gate: cost=${alpaca_cost_info.get("total_cost_usd", 0):.4f} > profit=${opp.expected_pnl_usd:.4f}',
                            opp.from_value_usd
                        )
                    return False
                elif alpaca_cost_info:
                    # Fee tracker approved - log the real costs
                    safe_print(f"\n   ğŸ’° ALPACA FEE CHECK PASSED:")
                    safe_print(f"   â”œâ”€â”€ Fee Tier: {self.fee_tracker.current_tier.name}")
                    safe_print(f"   â”œâ”€â”€ Taker Fee: ${alpaca_cost_info.get('fee_cost_usd', 0):.4f}")
                    safe_print(f"   â”œâ”€â”€ Spread: {alpaca_cost_info.get('spread_pct', 0)*100:.2f}% (${alpaca_cost_info.get('spread_cost_usd', 0):.4f})")
                    safe_print(f"   â”œâ”€â”€ Total Cost: ${alpaca_cost_info.get('total_cost_usd', 0):.4f}")
                    safe_print(f"   â””â”€â”€ Net Profit: ${alpaca_cost_info.get('net_profit_usd', 0):.4f}")
            except Exception as e:
                # Fee tracker failed - log but continue with legacy gate
                safe_print(f"   âš ï¸ Alpaca fee tracker error: {e} - falling back to legacy gate")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ï¿½ğŸ›‘ CRITICAL PRE-EXECUTION GATE: CONSERVATIVE PROFIT CHECK
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # This is the FINAL check BEFORE sending the order. We calculate profit
        # using PESSIMISTIC assumptions (NO momentum edge, REAL costs).
        # If we'd lose money, DON'T EXECUTE - even if Queen said yes.
        # Reason: Queen's decision was based on SPECULATIVE expected_pnl_usd.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.live:
            # Calculate TRUE costs using learned history
            approved, reason, cost_breakdown = self.barter_matrix.calculate_true_cost(
                opp.from_asset, opp.to_asset, opp.from_value_usd, opp.source_exchange or 'kraken'
            )
            
            total_cost_pct = cost_breakdown.get('total_cost_pct', 0.5) / 100.0  # Convert to decimal
            total_cost_usd = opp.from_value_usd * total_cost_pct

            # If we have a dynamic cost estimator, use Monte Carlo to compute a worst-case (90th percentile) cost
            if self.cost_estimator:
                try:
                    sample_stats = self.cost_estimator.sample_total_cost_distribution(f"{from_upper}/{to_upper}", 'buy', opp.from_value_usd, n_samples=1000)
                    worst_pct = sample_stats.get('p90', total_cost_pct*100)
                    worst_cost_usd = opp.from_value_usd * (worst_pct / 100.0)
                    # Use worst-case for conservative_pnl calculation below
                    mc_cost_usd = worst_cost_usd
                except Exception as e:
                    logger.debug(f"Monte Carlo cost sampling failed: {e}")
                    mc_cost_usd = total_cost_usd
            else:
                mc_cost_usd = total_cost_usd

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ”§ FIX: Scanner now reports GROSS profit (before costs)
            # We calculate NET profit here: gross - costs
            # This is the ONLY place costs are subtracted!
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            
            # The opportunity's expected_pnl_usd is GROSS (momentum + signals, no costs subtracted)
            scanner_gross_pnl = opp.expected_pnl_usd if hasattr(opp, 'expected_pnl_usd') else 0.0
            
            # Calculate NET profit conservatively using Monte Carlo worst-case cost (p90)
            conservative_pnl = scanner_gross_pnl - mc_cost_usd
            
            # Monte-Carlo P(win) gating: compute probability that net profit > 0
            p_win = None
            if self.cost_estimator:
                try:
                    # Get raw draws (percent units) and transform to USD costs
                    draws_pct = self.cost_estimator.sample_total_cost_draws(f"{from_upper}/{to_upper}", 'buy', opp.from_value_usd, n_samples=1000)
                    net_samples = [scanner_gross_pnl - (d_pct/100.0) * opp.from_value_usd for d_pct in draws_pct]
                    positive = sum(1 for v in net_samples if v > 0)
                    p_win = positive / max(1, len(net_samples))
                except Exception as e:
                    logger.debug(f"Monte Carlo P(win) sampling failed: {e}")
                    p_win = None

            # For required profit check, just need a small buffer above break-even
            min_profit_floor = max(MIN_NET_PROFIT_USD, 0.001)  # At least $0.001 net profit
            required_profit_usd = min_profit_floor  # Just needs to be positive!
            
            # Apply path history penalty (learned failures) - but much smaller now
            pair_key = (from_upper, to_upper)
            # ğŸŒâœ¨ PLANET SAVER: The past doesn't define the future!
            # We learn from history but don't let it chain us down
            if hasattr(self.barter_matrix, 'barter_history') and pair_key in self.barter_matrix.barter_history:
                hist = self.barter_matrix.barter_history.get(pair_key, {})
                if hist.get('total_profit', 0) < 0 and hist.get('trades', 0) > 5:  # Only after 5+ failures
                    # Path historically loses - add small penalty (learn but don't block!)
                    historical_loss_rate = abs(hist['total_profit']) / max(hist.get('trades', 1), 1)
                    conservative_pnl -= historical_loss_rate * 0.1  # Only 10% of historical avg loss
            
            # FINAL GATE: Block if expected profit doesn't cover costs with buffer
            # OR if spread is ridiculously high (>5%)
            spread_pct = cost_breakdown.get('spread', 0)
            
            if spread_pct > 5.0:
                # High spread = illiquid market, block immediately
                self.rejection_safe_print(f"\n   ğŸ›‘ PRE-EXECUTION GATE: SPREAD TOO HIGH!")
                self.rejection_safe_print(f"   â”œâ”€â”€ Spread: {spread_pct:.1f}% (max 5%)")
                self.rejection_safe_print(f"   â””â”€â”€ Market too illiquid for this trade")
                
                # Block high spread source
                exchange = opp.source_exchange or 'unknown'
                key = (opp.from_asset.upper(), exchange.lower())
                self.barter_matrix.high_spread_sources[key] = {
                    'spread': spread_pct,
                    'blocked_turn': self.barter_matrix.current_turn,
                    'reason': f'{spread_pct:.1f}% spread'
                }
                self.rejection_safe_print(f"   ğŸš«ğŸ”´ SOURCE BLOCKED: {opp.from_asset} on {exchange} has {spread_pct:.1f}% spread!")
                
                # Record rejection
                self.barter_matrix.record_preexec_rejection(
                    opp.from_asset, opp.to_asset,
                    f'spread_too_high: {spread_pct:.1f}%',
                    opp.from_value_usd
                )
                
                # ğŸª† BEE LEVEL: Record rejection in Russian Doll Analytics
                if self.russian_doll and record_scan:
                    momentum = self.asset_momentum.get(opp.from_asset, 0)
                    record_scan(
                        symbol=f"{opp.from_asset}/{opp.to_asset}",
                        exchange=exchange,
                        bid=opp.from_value_usd,
                        ask=opp.from_value_usd * (1 + spread_pct/100),
                        momentum=momentum,
                        pip_score=getattr(opp, 'combined_score', 0),
                        expected_pnl=scanner_gross_pnl,
                        pass_scores=(0.0, 0.0, 0.0),
                        action="REJECT",
                        rejection_reason="spread_too_high"
                    )
                
                return None
            
            # ğŸŒâœ¨ PLANET SAVER MODE: Past doesn't define future!
            # Allow trades if scanner expects profit - trust the quantum mirror!
            planet_saver_mode = hasattr(self, 'planet_saver') and self.planet_saver is not None

            # Monte-Carlo P(win) gating: require a high probability of positive net P&L
            try:
                P_WIN_THRESHOLD = float(os.getenv('AUREON_MC_PWIN_THRESHOLD', '0.90'))
            except Exception:
                P_WIN_THRESHOLD = 0.90

            if p_win is not None and p_win < P_WIN_THRESHOLD and not planet_saver_mode:
                self.rejection_safe_print(f"\n   ğŸ›‘ PRE-EXECUTION GATE: LOW PROBABILITY OF WIN - P(win)={p_win:.2%} < {P_WIN_THRESHOLD:.0%}")
                self.rejection_safe_print(f"   â”œâ”€â”€ Scanner Expected: ${scanner_gross_pnl:+.4f}")
                self.rejection_safe_print(f"   â””â”€â”€ Monte-Carlo P(win): {p_win:.2%} (threshold {P_WIN_THRESHOLD:.0%})")

                self.barter_matrix.record_preexec_rejection(
                    opp.from_asset, opp.to_asset,
                    f'low_pwin: {p_win:.3f}',
                    opp.from_value_usd
                )

                if self.russian_doll and record_scan:
                    momentum = self.asset_momentum.get(opp.from_asset, 0)
                    record_scan(
                        symbol=f"{opp.from_asset}/{opp.to_asset}",
                        exchange=opp.source_exchange or 'unknown',
                        bid=opp.from_value_usd,
                        ask=opp.from_value_usd * (1 + spread_pct/100),
                        momentum=momentum,
                        pip_score=getattr(opp, 'combined_score', 0),
                        expected_pnl=scanner_gross_pnl,
                        pass_scores=(0.0, 0.0, 0.0),
                        action="REJECT",
                        rejection_reason="low_pwin"
                    )

                return False

            # CRITICAL SAFETY: Never bleed, regardless of mode
            if conservative_pnl < 0:
                self.rejection_safe_print(f"\n   ğŸ›‘ PRE-EXECUTION GATE: COSTS EXCEED EDGE!")
                self.rejection_safe_print(f"   â”œâ”€â”€ Gross Edge (momentum+signals): ${scanner_gross_pnl:+.4f}")
                worst_pct_display = (locals().get('worst_pct') if 'worst_pct' in locals() else (total_cost_pct*100))
                self.rejection_safe_print(f"   â”œâ”€â”€ Worst-case Costs (p90 estimate): ${mc_cost_usd:.4f} ({worst_pct_display:.2f}%)")
                self.rejection_safe_print(f"   â”œâ”€â”€ Net P&L (gross - costs): ${conservative_pnl:+.4f}")
                self.rejection_safe_print(f"   â””â”€â”€ Need more momentum to beat costs!")
                self.rejection_safe_print(f"   â›” WAITING for better opportunity...")
                
                self.barter_matrix.record_preexec_rejection(
                    opp.from_asset, opp.to_asset,
                    f'negative_pnl: ${conservative_pnl:.4f}',
                    opp.from_value_usd
                )
                
                # ğŸª† BEE LEVEL: Record rejection in Russian Doll Analytics
                if self.russian_doll and record_scan:
                    momentum = self.asset_momentum.get(opp.from_asset, 0)
                    record_scan(
                        symbol=f"{opp.from_asset}/{opp.to_asset}",
                        exchange=opp.source_exchange or 'unknown',
                        bid=opp.from_value_usd,
                        ask=opp.from_value_usd * (1 + spread_pct/100),
                        momentum=momentum,
                        pip_score=getattr(opp, 'combined_score', 0),
                        expected_pnl=conservative_pnl,
                        pass_scores=(0.0, 0.0, 0.0),
                        action="REJECT",
                        rejection_reason="negative_pnl"
                    )
                
                return False
            
            # ğŸ”§ FIX: Only block if net profit is negative (break-even or better is OK!)
            # scanner_expected_pnl is ALREADY net of costs, so just needs to be > 0
            if conservative_pnl < required_profit_usd and not planet_saver_mode:
                self.rejection_safe_print(f"\n   ğŸ›‘ PRE-EXECUTION GATE BLOCKED!")
                self.rejection_safe_print(f"   â”œâ”€â”€ Net Expected P&L: ${conservative_pnl:+.4f}")
                self.rejection_safe_print(f"   â”œâ”€â”€ Min Required: ${required_profit_usd:.4f}")
                self.rejection_safe_print(f"   â”œâ”€â”€ Cost breakdown: fee={cost_breakdown.get('base_fee', 0):.2f}% spread={spread_pct:.2f}%")
                self.rejection_safe_print(f"   â””â”€â”€ Reason: Net profit below minimum threshold")
                self.rejection_safe_print(f"   â›” TRADE REJECTED - Need at least ${required_profit_usd:.4f} net profit!")
                
                # Track rejection for learning - BLOCK THIS PAIR immediately!
                self.barter_matrix.record_preexec_rejection(
                    opp.from_asset, opp.to_asset,
                    f'profit_too_low: net=${conservative_pnl:.4f} < min=${required_profit_usd:.4f}',
                    opp.from_value_usd
                )
                self.rejection_safe_print(f"   ğŸš« Path {opp.from_asset}â†’{opp.to_asset} BLOCKED - will try others!")
                
                # ğŸš« HIGH SPREAD SOURCE BLOCK - If spread is the problem, block ALL trades from this source!
                if spread_pct > self.barter_matrix.HIGH_SPREAD_THRESHOLD:
                    exchange = opp.source_exchange or 'unknown'
                    key = (opp.from_asset.upper(), exchange.lower())
                    self.barter_matrix.high_spread_sources[key] = {
                        'spread': spread_pct,
                        'blocked_turn': self.barter_matrix.current_turn,
                        'reason': f'{spread_pct:.1f}% spread'
                    }
                    self.rejection_safe_print(f"   ğŸš«ğŸ”´ SOURCE BLOCKED: {opp.from_asset} on {exchange} has {spread_pct:.1f}% spread!")
                    self.rejection_safe_print(f"      ALL {opp.from_asset}â†’* trades will fail - blocking source for {self.barter_matrix.HIGH_SPREAD_COOLDOWN} turns")
                
                return False
            else:
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Round-trip availability check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                ok_roundtrip, roundtrip_reason = self.ensure_round_trip_available(opp.from_asset, opp.to_asset, opp.from_value_usd)
                if not ok_roundtrip:
                    self.rejection_safe_print(f"\n   ğŸ›‘ PRE-EXECUTION GATE: ROUND-TRIP UNAVAILABLE - {roundtrip_reason}")
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset,
                        f'round_trip_unavailable: {roundtrip_reason}',
                        opp.from_value_usd
                    )
                    return False

                # âœ… GATE PASSED! Show the good news!
                safe_print(f"\n   âœ… PRE-EXECUTION GATE PASSED:")
                safe_print(f"   â”œâ”€â”€ Scanner Expected: ${scanner_gross_pnl:+.4f}")
                safe_print(f"   â”œâ”€â”€ Net Expected P&L: ${conservative_pnl:+.4f} (already net of costs)")
                safe_print(f"   â”œâ”€â”€ Min Required: ${min_profit_floor:.4f}")
                safe_print(f"   â””â”€â”€ Proceeding with execution... ğŸš€")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # ğŸ‘‘ QUEEN HAS ALREADY SPOKEN - No second-guessing her!
        # The Queen was consulted in execute_turn() and said YES
        # Her $0.003 profit goal was already validated
        # DO NOT block her decision with another gate!
        
        safe_print(f"\nğŸ”¬ MICRO CONVERSION:")
        safe_print(f"   {opp.from_asset} â†’ {opp.to_asset}")
        safe_print(f"   Amount: {opp.from_amount:.6f} ({opp.from_asset})")
        safe_print(f"   Value: ${opp.from_value_usd:.2f}")
        safe_print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        # ğŸŒ€ TEMPORAL JUMP STATUS - Are we AHEAD of the market?
        if opp.timeline_jump_active:
            safe_print(f"   ğŸŒ€ TEMPORAL JUMP ACTIVE! â³ AHEAD OF MARKET!")
            safe_print(f"   â³ Jump Power: {opp.temporal_jump_power:.2%} | Timeline: {opp.timeline_action.upper()}")
            safe_print(f"   ğŸ”® Timeline Confidence: {opp.timeline_score:.2%}")
        elif opp.timeline_score > 0:
            safe_print(f"   â³ Timeline: {opp.timeline_action.upper()} @ {opp.timeline_score:.2%} (Jump Power: {opp.temporal_jump_power:.2%})")
        
        safe_print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        safe_print(f"   ğŸ§  NEURAL MIND MAP SCORES:")
        safe_print(f"   V14: {opp.v14_score:.1f} | Hub: {opp.hub_score:.2%}")
        safe_print(f"   Î› (Lambda): {opp.lambda_score:.2%} | G (Gravity): {opp.gravity_score:.2%}")
        safe_print(f"   Bus: {opp.bus_score:.2%} | Hive: {opp.hive_score:.2%} | Lighthouse: {opp.lighthouse_score:.2%}")
        safe_print(f"   Ultimate: {opp.ultimate_score:.2%} | Path: {opp.path_boost:+.2%}")
        safe_print(f"   ğŸ«’ Barter: {opp.barter_matrix_score:.2%} ({opp.barter_matrix_reason})")
        safe_print(f"   ğŸ€ Luck: {opp.luck_score:.2%} ({opp.luck_state})")
        safe_print(f"   ğŸ” Enigma: {opp.enigma_score:+.2%} ({opp.enigma_direction})")
        if opp.queen_guidance_score != 0.0:
            safe_print(f"   ğŸ‘‘ Queen: {opp.queen_guidance_score:.2%} (confidence: {opp.queen_confidence:.2%})")
            if opp.queen_wisdom:
                safe_print(f"      ğŸ’• \"{opp.queen_wisdom[:70]}...\"")
        if opp.wisdom_engine_score != 0.0:
            safe_print(f"   ğŸ§  Wisdom: {opp.wisdom_engine_score:.2%} ({opp.civilization_insight})")
            if opp.wisdom_pattern:
                safe_print(f"      ğŸ“š \"{opp.wisdom_pattern[:70]}...\"")
        safe_print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•=")
        safe_print(f"   ğŸ”® Combined: {opp.combined_score:.2%}")
        safe_print(f"   Gate Req: ${opp.gate_required_profit:.4f} | Gate OK: {'âœ…' if opp.gate_passed else 'âŒ'}")
        safe_print(f"   Expected Profit: ${opp.expected_pnl_usd:.4f} ({opp.expected_pnl_pct:.2%})")
        
        # Publish to ThoughtBus for ecosystem awareness
        if self.bus_aggregator and hasattr(self.bus_aggregator, 'bus') and self.bus_aggregator.bus:
            try:
                self.bus_aggregator.bus.publish('execution.alert', {
                    'type': 'micro_conversion',
                    'from_asset': opp.from_asset,
                    'to_asset': opp.to_asset,
                    'value_usd': opp.from_value_usd,
                    'combined_score': opp.combined_score,
                    'lambda_score': opp.lambda_score,
                    'gravity_score': opp.gravity_score,
                    'bus_score': opp.bus_score,
                    'hive_score': opp.hive_score,
                    'lighthouse_score': opp.lighthouse_score,
                    'ultimate_score': opp.ultimate_score,
                    'path_boost': opp.path_boost,
                    'expected_pnl': opp.expected_pnl_usd,
                    'timestamp': time.time(),
                    'live': self.live
                })
            except Exception as e:
                logger.debug(f"ThoughtBus publish error: {e}")
        
        if not self.live:
            safe_print(f"   ğŸ”µ DRY RUN - Not executed")
            opp.executed = True
            opp.actual_pnl_usd = opp.expected_pnl_usd  # Simulate
            self.conversions_made += 1
            self.total_profit_usd += opp.expected_pnl_usd
            self.conversions.append(opp)

            # Simulate position registry for dry-run entries (so loss-prevention can use it)
            from_up = opp.from_asset.upper()
            to_up = opp.to_asset.upper()
            is_buy = from_up in self.snowball_stablecoins and to_up not in self.snowball_stablecoins
            is_sell = to_up in self.snowball_stablecoins and from_up not in self.snowball_stablecoins

            if is_buy:
                # Simulate a buy entry
                self.position_registry[to_up] = {
                    'amount': opp.expected_pnl_usd and (opp.from_value_usd / (self.prices.get(to_up, 1) or 1)) or 0,
                    'entry_price': self.prices.get(to_up, 0) or 0,
                    'entry_value_usd': opp.from_value_usd,
                    'fees_usd': 0.0,
                    'order_ids': [],
                    'source': opp.source_exchange or 'dry-run',
                    'timestamp': time.time(),
                }
            elif is_sell:
                # Selling simulated - reduce or remove registry
                asset = from_up
                sold_amount = opp.from_amount
                if asset in self.position_registry:
                    prev = self.position_registry[asset]
                    if sold_amount >= prev['amount']:
                        del self.position_registry[asset]
                    else:
                        prev['amount'] -= sold_amount
                        prev['entry_value_usd'] = prev['entry_price'] * prev['amount']

            return True
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”´ LIVE EXECUTION - ROUTE TO CORRECT EXCHANGE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ QUEEN MIND ROUTING: Strictly use the source_exchange from the opportunity
        source_exchange = opp.source_exchange
        
        # Fallback if not set (should not happen with new logic)
        if not source_exchange:
            safe_print(f"   âš ï¸ Opportunity missing source_exchange - attempting lookup...")
            source_exchange = self._find_asset_exchange(opp.from_asset)
            if source_exchange:
                safe_print(f"   ğŸ“ Fallback located {opp.from_asset} on {source_exchange}")
                opp.source_exchange = source_exchange
        
        if not source_exchange:
            safe_print(f"   âš ï¸ Asset {opp.from_asset} not found on any exchange")
            return False
        
        safe_print(f"   ğŸ”´ LIVE MODE - Executing on {source_exchange.upper()}...")
        
        # ğŸ‡®ğŸ‡ªğŸ¯ IRA SNIPER EXECUTION - Celtic precision
        try:
            from ira_sniper_mode import get_celtic_sniper, IraCelticSniper
            sniper = get_celtic_sniper(dry_run=False)
            
            # Validate entry with Celtic intelligence
            validation = sniper.validate_entry(
                symbol=f"{opp.from_asset}/{opp.to_asset}",
                price=self.prices.get(opp.from_asset, 0),
                coherence=opp.combined_score
            )
            
            if validation.get('approved', True):
                safe_print(f"   ğŸ‡®ğŸ‡ª Celtic Intelligence APPROVES")
                safe_print(f"      Quick Kill Prob: {validation.get('quick_kill_prob', 0.5)*100:.1f}%")
                safe_print(f"      Intel Score: {validation.get('intelligence_score', 0.5):.2f}")
            else:
                safe_print(f"   âš ï¸ Celtic Intel rejects: {validation.get('reason', 'Unknown')}")
                # Still execute - sniper just provides intel, doesn't block
        except ImportError:
            pass  # IRA Sniper not available - continue silently
        except Exception as e:
            logger.debug(f"Sniper validation error: {e}")
        
        # ğŸ‘‘ QUEEN MIND ROUTING: Strictly use the source_exchange from the opportunity
        # This prevents cross-exchange routing errors
        source_exchange = opp.source_exchange
        
        # CRITICAL: Validate we have the source exchange set
        if not source_exchange:
            safe_print(f"   âš ï¸ CRITICAL: Opportunity missing source_exchange!")
            safe_print(f"   âš ï¸ This should NOT happen - check find_opportunities logic")
            # Last resort fallback - but log it clearly
            source_exchange = self._find_asset_exchange(opp.from_asset)
            if source_exchange:
                safe_print(f"   ğŸ“ Fallback located {opp.from_asset} on {source_exchange}")
                opp.source_exchange = source_exchange  # Update for future reference
            else:
                safe_print(f"   âŒ Cannot find {opp.from_asset} on any exchange!")
                self._record_failure(opp)
                return False
        
        # ğŸ‘‘ TURN-BASED TRUST: DO NOT OVERRIDE source_exchange!
        # The turn-based system ensures opportunities are found on the CORRECT exchange.
        # Overriding to "highest balance" causes cross-exchange routing errors
        # (e.g., Kraken's USD opportunity being sent to Alpaca)
        # 
        # REMOVED THE OVERRIDE - trust the turn-based system!
        
        # Route to appropriate exchange
        if source_exchange == 'kraken' and self.kraken and KRAKEN_API_KEY:
            return await self._execute_on_kraken(opp)
        elif source_exchange == 'binance' and self.binance and BINANCE_API_KEY:
            return await self._execute_on_binance(opp)
        elif source_exchange == 'alpaca' and self.alpaca and ALPACA_API_KEY:
            return await self._execute_on_alpaca(opp)
        else:
            safe_print(f"   âš ï¸ Exchange '{source_exchange}' not available or missing API key")
            self._record_failure(opp)
        
        return False
    
    def _find_asset_exchange(self, asset: str) -> Optional[str]:
        """Find which exchange holds an asset with the highest balance."""
        asset_upper = asset.upper()
        best_exchange = None
        best_balance = 0
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ—ºï¸ UNIVERSAL CRYPTO NORMALIZER - Maps ALL 18,000+ Cryptos!
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Sources: crypto_market_map.py, get-user-balances/index.ts, kraken_client.py
        
        # ğŸ™ KRAKEN ASSET MAP - Complete mapping for Kraken's unique naming
        KRAKEN_ASSET_MAP = {
            # Major cryptos with X prefix
            'XXBT': 'BTC', 'XBT': 'BTC',
            'XETH': 'ETH',
            'XXLM': 'XLM',
            'XLTC': 'LTC',
            'XXRP': 'XRP',
            'XXDG': 'DOGE', 'XDOGE': 'DOGE',
            'XZEC': 'ZEC',
            'XREP': 'REP',
            'XETC': 'ETC',
            'XMLN': 'MLN',
            'XXMR': 'XMR',
            'XICN': 'ICN',
            'XNMC': 'NMC',
            'XVEN': 'VEN',
            'XDAO': 'DAO',
            # Fiat with Z prefix
            'ZUSD': 'USD', 'USD': 'USD',
            'ZEUR': 'EUR', 'EUR': 'EUR', 
            'ZGBP': 'GBP', 'GBP': 'GBP',
            'ZCAD': 'CAD', 'CAD': 'CAD',
            'ZJPY': 'JPY', 'JPY': 'JPY',
            'ZAUD': 'AUD', 'AUD': 'AUD',
            'ZCHF': 'CHF', 'CHF': 'CHF',
            # Common stablecoins (no change needed)
            'USDT': 'USDT',
            'USDC': 'USDC',
            'DAI': 'DAI',
            'TUSD': 'TUSD',  # ğŸ”’ TUSD â‰  USDT!
            # Staked variants â†’ base asset
            'ETH2.S': 'ETH', 'ETH2': 'ETH',
            'DOT.S': 'DOT', 'DOT28.S': 'DOT',
            'ATOM.S': 'ATOM', 'ATOM21.S': 'ATOM',
            'SOL.S': 'SOL',
            'KAVA.S': 'KAVA',
            'XTZ.S': 'XTZ',
            'ADA.S': 'ADA',
            'FLOW.S': 'FLOW',
            'KSM.S': 'KSM',
            'MINA.S': 'MINA',
            'SCRT.S': 'SCRT',
            'GRT.S': 'GRT',
            'MATIC.S': 'MATIC',
            'TRX.S': 'TRX',
            'NEAR.S': 'NEAR',
            'BABY.S': 'BABY',
            'OMG.S': 'OMG',
        }
        
        # ğŸ”’ STABLECOIN ISOLATION - NEVER fuzzy match these to each other!
        # Each is a DIFFERENT asset with different backing/risk
        STABLECOINS_ISOLATED = {
            # USD-pegged (different issuers!)
            'USDT',   # Tether Limited (controversial reserves)
            'USDC',   # Circle/Coinbase (fully audited)
            'TUSD',   # TrustToken (independently verified)
            'BUSD',   # Paxos/Binance (deprecated)
            'USDP',   # Paxos Dollar (regulated)
            'GUSD',   # Gemini (NY regulated)
            'FRAX',   # Algorithmic + collateral hybrid
            'LUSD',   # Liquity (decentralized)
            'DAI',    # MakerDAO (crypto-collateralized)
            'MIM',    # Abracadabra (defi)
            'SUSD',   # Synthetix (synthetic)
            'USDD',   # TRON (algo)
            'PYUSD',  # PayPal (new)
            'FDUSD',  # First Digital (HK)
            # EUR-pegged
            'EURC',   # Circle EUR
            'EURT',   # Tether EUR
            'EURS',   # STASIS EUR
            'AGEUR',  # Angle EUR
            # Fiat (NOT stablecoins but isolated)
            'USD', 'EUR', 'GBP', 'CAD', 'JPY', 'AUD', 'CHF', 
            'ZUSD', 'ZEUR', 'ZGBP', 'ZCAD', 'ZJPY', 'ZAUD', 'ZCHF',
        }
        
        # ğŸŸ¡ BINANCE ASSET MAP (for weird naming)
        BINANCE_ASSET_MAP = {
            'IOTA': 'MIOTA',  # Binance uses IOTA, others use MIOTA
            'YFIDOWN': 'YFI', 'YFIUP': 'YFI',  # Leveraged tokens
            'BTCDOWN': 'BTC', 'BTCUP': 'BTC',
            'ETHDOWN': 'ETH', 'ETHUP': 'ETH',
        }
        
        # ğŸ¦™ ALPACA ASSET MAP (crypto pairs end in /USD)
        ALPACA_PAIRS_TO_BASE = {
            # These are position symbols, not assets
            'BTCUSD': 'BTC', 'BTC/USD': 'BTC',
            'ETHUSD': 'ETH', 'ETH/USD': 'ETH',
            'SOLUSD': 'SOL', 'SOL/USD': 'SOL',
            'DOGEUSD': 'DOGE', 'DOGE/USD': 'DOGE',
            'SHIBUSD': 'SHIB', 'SHIB/USD': 'SHIB',
            'AVAXUSD': 'AVAX', 'AVAX/USD': 'AVAX',
            'USDTUSD': 'USDT', 'USDT/USD': 'USDT',
        }
        
        def normalize_asset(asset_name: str, exchange: str = None) -> str:
            """
            ğŸ—ºï¸ UNIVERSAL NORMALIZER - Works across ALL exchanges!
            Converts exchange-specific naming to canonical symbol.
            """
            upper = asset_name.upper().strip()
            
            # Handle staked suffix first (ETH2.S â†’ ETH)
            unstaked = upper.replace('.S', '').replace('2.S', '')
            
            # Exchange-specific normalization
            if exchange == 'kraken':
                if upper in KRAKEN_ASSET_MAP:
                    return KRAKEN_ASSET_MAP[upper]
                if unstaked in KRAKEN_ASSET_MAP:
                    return KRAKEN_ASSET_MAP[unstaked]
                # Handle XX prefix (XXABC â†’ ABC)
                if upper.startswith('XX') and len(upper) > 2:
                    return upper[2:]
                # Handle single X prefix (but preserve XRP, XLM, XTZ, XMR, XDC)
                if upper.startswith('X') and len(upper) > 1:
                    if upper not in {'XRP', 'XLM', 'XTZ', 'XMR', 'XDC', 'XDG', 'XEM', 'XVG'}:
                        return upper[1:]
                # Handle Z prefix for fiat
                if upper.startswith('Z') and len(upper) > 1:
                    return upper[1:]
                    
            elif exchange == 'binance':
                if upper in BINANCE_ASSET_MAP:
                    return BINANCE_ASSET_MAP[upper]
                # Handle leveraged token suffixes
                for suffix in ['UP', 'DOWN', 'BULL', 'BEAR', '3L', '3S']:
                    if upper.endswith(suffix) and len(upper) > len(suffix):
                        return upper[:-len(suffix)]
                        
            elif exchange == 'alpaca':
                if upper in ALPACA_PAIRS_TO_BASE:
                    return ALPACA_PAIRS_TO_BASE[upper]
                # Strip /USD or USD suffix
                if upper.endswith('/USD'):
                    return upper[:-4]
                if upper.endswith('USD') and len(upper) > 3:
                    base = upper[:-3]
                    # Make sure we're not stripping from a stablecoin
                    if base not in STABLECOINS_ISOLATED:
                        return base
            
            return upper
        
        # Debug: Track candidates
        candidates = []
        
        for exchange, data in self.exchange_data.items():
            if data.get('connected') and data.get('balances'):
                for bal_asset, balance in data['balances'].items():
                    bal_upper = bal_asset.upper()
                    
                    # ğŸ—ºï¸ Normalize both the search asset AND the balance asset
                    normalized_bal = normalize_asset(bal_upper, exchange)
                    normalized_search = normalize_asset(asset_upper, exchange)
                    
                    # Exact match first (always preferred)
                    if normalized_bal == normalized_search or bal_upper == asset_upper:
                        bal_amount = float(balance) if isinstance(balance, (int, float, str)) else 0
                        if bal_upper != normalized_bal:
                            candidates.append(f"{exchange}:{bal_asset}â†’{normalized_bal}={bal_amount:.6f}")
                        else:
                            candidates.append(f"{exchange}:{bal_asset}={bal_amount:.6f}")
                        if bal_amount > best_balance:
                            best_balance = bal_amount
                            best_exchange = exchange
                            
                    # ğŸ”’ STABLECOIN GUARD: NEVER fuzzy match stablecoins!
                    # USDT â‰  TUSD â‰  USDC - they are DIFFERENT assets with different risks!
                    elif normalized_search in STABLECOINS_ISOLATED or normalized_bal in STABLECOINS_ISOLATED:
                        # Only exact matches for stablecoins - skip ALL fuzzy logic
                        continue
        
        # ğŸ”‡ Only print asset location once per asset (prevent spam)
        if len(candidates) > 1 and asset.upper() not in ['USD', 'USDT', 'USDC', 'ZUSD']:
            if not hasattr(self, '_asset_location_logged'):
                self._asset_location_logged = set()
            if asset.upper() not in self._asset_location_logged:
                self._asset_location_logged.add(asset.upper())
                safe_print(f"   ğŸ” Asset location: {asset} on {len(candidates)} exchanges -> Best: {best_exchange}")
            
        return best_exchange
    
    async def _execute_on_kraken(self, opp) -> bool:
        """Execute conversion on Kraken using convert_crypto."""
        try:
            # Use the built-in convert_crypto which finds the best path automatically!
            safe_print(f"   ğŸ”„ Converting {opp.from_asset} â†’ {opp.to_asset} via Kraken...")
            
            # ğŸ‘‘ QUEEN MIND: Decode conversion path in real-time
            # Refresh balance FIRST to get accurate amounts
            await self.refresh_exchange_balances('kraken')
            
            # ğŸ‘‘ SERO FIX: Case-insensitive asset matching (Kraken may store differently)
            kraken_balances = self.exchange_balances.get('kraken', {})
            actual_balance = 0.0
            matched_asset = opp.from_asset
            
            for bal_key, bal_val in kraken_balances.items():
                if bal_key.upper() == opp.from_asset.upper():
                    actual_balance = float(bal_val) if isinstance(bal_val, (int, float, str)) else 0.0
                    matched_asset = bal_key
                    break
            
            safe_print(f"   ğŸ“Š Kraken {matched_asset} balance: {actual_balance:.6f} (need: {opp.from_amount:.6f})")
            
            # Clamp to actual available balance
            if actual_balance <= 0:
                safe_print(f"   âš ï¸ No {opp.from_asset} balance on Kraken (balance: {actual_balance})")
                return False
            
            # ğŸ‘‘ QUEEN'S SANITY CHECK: Don't clamp to dust!
            # If we have significantly less than expected, it's likely the wrong exchange
            if actual_balance < opp.from_amount * 0.1:
                safe_print(f"   âš ï¸ Kraken balance {actual_balance:.6f} is < 10% of expected {opp.from_amount:.6f}")
                safe_print(f"   âš ï¸ Likely asset location mismatch. Aborting Kraken execution.")
                return False

            # ğŸ‘‘ SERO EXECUTION FIX: Use 95% of balance for safety margin
            # Kraken has precision issues, leave 5% buffer for fees + rounding
            safe_amount = actual_balance * 0.95
            if opp.from_amount > safe_amount:
                safe_print(f"   ğŸ‘‘ Sero adjusts: {opp.from_amount:.6f} â†’ {safe_amount:.6f} (95% safe)")
                opp.from_amount = safe_amount
                opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
            
            # Check if clamped amount is too small
            if opp.from_value_usd < 1.0:
                safe_print(f"   âš ï¸ Clamped value ${opp.from_value_usd:.2f} is too small for Kraken (min ~$1.50)")
                
                # ğŸ’§ğŸ”€ LIQUIDITY AGGREGATION CHECK - Can we top-up from other assets?
                shortfall = 1.50 - opp.from_value_usd
                aggregation_result = await self._attempt_liquidity_aggregation(
                    target_asset=opp.from_asset,
                    target_exchange='kraken',
                    shortfall_usd=shortfall,
                    expected_profit_pct=getattr(opp, 'expected_profit', 0.01),
                )
                if aggregation_result:
                    # Aggregation succeeded - retry the trade with new balance
                    await self.refresh_exchange_balances('kraken')
                    new_balance = self.exchange_balances.get('kraken', {}).get(opp.from_asset, 0)
                    opp.from_amount = float(new_balance) * 0.95
                    opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
                    safe_print(f"   ğŸ’§ POST-AGGREGATION: New {opp.from_asset} balance = {opp.from_amount:.6f} (${opp.from_value_usd:.2f})")
                    if opp.from_value_usd >= 1.50:
                        safe_print(f"   âœ… Aggregation successful! Proceeding with trade...")
                        # Continue execution - don't return False
                    else:
                        safe_print(f"   âŒ Aggregation insufficient - still below minimum")
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset, 
                            f"Value ${opp.from_value_usd:.2f} < ~$1.50 after aggregation",
                            opp.from_value_usd
                        )
                        self.barter_matrix.record_source_rejection(
                            opp.from_asset, 'kraken', 1.50, opp.from_value_usd
                        )
                        return False
                else:
                    # ğŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Value ${opp.from_value_usd:.2f} < ~$1.50 Kraken minimum (no aggregation available)",
                        opp.from_value_usd
                    )
                    # ğŸš« Also record SOURCE rejection - this asset is too small for Kraken entirely
                    self.barter_matrix.record_source_rejection(
                        opp.from_asset, 'kraken', 1.50, opp.from_value_usd
                    )
                    return False
            
            # First check if a path exists
            path = self.kraken.find_conversion_path(opp.from_asset, opp.to_asset)
            if not path:
                safe_print(f"   âš ï¸ No conversion path found from {opp.from_asset} to {opp.to_asset}")
                return False
            
            # ğŸ” KRAKEN PRE-FLIGHT CHECK: Only check notional minimum (most reliable)
            # Kraken's costmin is the minimum order value in USD-equivalent
            for step in path:
                pair = step.get('pair', '')
                filters = self.kraken.get_symbol_filters(pair)
                min_notional = filters.get('min_notional', 0)  # costmin in Kraken terms
                min_qty = filters.get('min_qty', 0) or filters.get('min_volume', 0)
                
                # Check minimum notional value - Kraken typically requires ~$0.50 minimum
                # Use a safe default of $1.20 to avoid "volume too low" errors (Kraken often requires >1 EUR/USD)
                effective_min = max(min_notional, 1.20)
                if opp.from_value_usd < effective_min:
                    safe_print(f"   âš ï¸ Value ${opp.from_value_usd:.2f} < min notional ${effective_min:.2f} for {pair}")
                    safe_print(f"   ğŸ’¡ Need ${effective_min:.2f} minimum to trade on Kraken")
                    return False

                # Guard on base quantity to avoid volume_minimum errors
                if min_qty:
                    # Use the from-asset price as a rough base valuation
                    from_price = self.prices.get(opp.from_asset, 0) or 1.0
                    min_qty_needed = max(min_qty, 0.0)
                    if opp.from_amount < min_qty_needed:
                        needed_usd = min_qty_needed * from_price
                        safe_print(f"   âš ï¸ Amount {opp.from_amount:.6f} < Kraken min qty {min_qty_needed:.6f} for {pair}")
                        safe_print(f"   ğŸ’¡ Need â‰¥ {min_qty_needed:.6f} ({needed_usd:.2f} USD) to avoid volume_minimum")
                        # ğŸš« Record pre-execution rejection
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset, 
                            f"Amount {opp.from_amount:.6f} < min_qty {min_qty_needed:.6f}",
                            opp.from_value_usd
                        )
                        return False
            
            # Show the path
            for step in path:
                safe_print(f"   ğŸ“ Path: {step['description']} via {step['pair']}")
            
            # ğŸš¨ KRAKEN LOSS PREVENTION GATE
            loss_prevention_passed, loss_reason = self._check_kraken_loss_prevention(opp.from_asset, opp.from_amount)
            if not loss_prevention_passed:
                safe_print(f"   ğŸš« {loss_reason}")
                self._record_failure(opp)
                return False
            
            # Execute the conversion
            result = self.kraken.convert_crypto(
                from_asset=opp.from_asset,
                to_asset=opp.to_asset,
                amount=opp.from_amount
            )
            
            if result.get('error'):
                error_msg = str(result['error'])
                safe_print(f"   âŒ Conversion error: {error_msg}")
                
                # ğŸ‘‘ QUEEN LEARNING: Auto-fix minimums
                if "volume_minimum" in error_msg or "min_notional" in error_msg:
                    safe_print(f"   ğŸ‘‘ Queen learning: Increasing minimum for {opp.from_asset}")
                    # Increase minimum to 1.5x current amount or at least $10
                    current_price = self.prices.get(opp.from_asset, 1.0)
                    min_usd_req = 10.0 # Safe default
                    
                    # If we know the amount that failed, we should aim higher
                    new_min_qty = max(opp.from_amount * 1.5, min_usd_req / current_price if current_price > 0 else 0)
                    
                    self.dynamic_min_qty[opp.from_asset.upper()] = new_min_qty
                    safe_print(f"      Updated dynamic minimum for {opp.from_asset} to {new_min_qty:.6f}")
                    
                self._record_failure(opp)
                return False
            
            # Check results
            trades = result.get('trades', [])
            if isinstance(trades, list):
                success_count = sum(1 for t in trades if isinstance(t, dict) and t.get('status') == 'success')
                if success_count > 0:
                    # Calculate actual bought/received amount from the last trade
                    last_trade = trades[-1]
                    buy_amount = 0.0
                    if last_trade.get('status') == 'success':
                        res = last_trade.get('result', {})
                        # PRIORITY: Use receivedQty (for SELL orders) if available
                        # This is the ACTUAL amount we received after conversion
                        buy_amount = float(res.get('receivedQty', 0) or 
                                          last_trade.get('receivedQty', 0) or
                                          res.get('executedQty', 0.0))
                    
                    # Fallback if no amount found (e.g. dry run or error)
                    if buy_amount == 0.0:
                         # Estimate based on price
                         to_price = self.prices.get(opp.to_asset, 0)
                         if to_price > 0:
                             buy_amount = opp.from_value_usd / to_price
                    
                    safe_print(f"   âœ… Conversion complete! {success_count} trades executed. Bought {buy_amount:.6f} {opp.to_asset}")
                    
                    # ğŸ” VALIDATE ORDER EXECUTION
                    validation = self._validate_order_execution(trades, opp, 'kraken')
                    verification = self._verify_profit_math(validation, opp, buy_amount)
                    self._print_order_validation(validation, verification, opp)
                    
                    self._record_conversion(opp, buy_amount, validation, verification)
                    return True
                else:
                    safe_print(f"   âŒ No successful trades in conversion")
                    self._record_failure(opp)
            elif result.get('dryRun'):
                safe_print(f"   ğŸ”µ DRY RUN: Would convert via {len(path)} trades")
                return True
            else:
                safe_print(f"   âœ… Conversion result: {result}")
                # Estimate amount for non-standard result
                to_price = self.prices.get(opp.to_asset, 0)
                buy_amount = opp.from_value_usd / to_price if to_price > 0 else 0
                self._record_conversion(opp, buy_amount)
                return True
                
        except Exception as e:
            logger.error(f"âŒ Kraken conversion error: {e}")
            safe_print(f"   âŒ Error: {e}")
            self._record_failure(opp)
        return False
    
    async def _execute_on_binance(self, opp) -> bool:
        """Execute conversion on Binance."""
        try:
            safe_print(f"   ğŸ”„ Converting {opp.from_asset} â†’ {opp.to_asset} via Binance...")
            
            # ğŸ‘‘ QUEEN MIND: Decode conversion path in real-time
            # Refresh balance FIRST to get accurate amounts
            await self.refresh_exchange_balances('binance')
            
            # Look for asset with different casing/formats
            binance_balances = self.exchange_balances.get('binance', {})
            actual_balance = 0.0
            matched_asset = opp.from_asset
            
            for bal_key, bal_val in binance_balances.items():
                if bal_key.upper() == opp.from_asset.upper():
                    actual_balance = float(bal_val) if isinstance(bal_val, (int, float, str)) else 0.0
                    matched_asset = bal_key
                    break
            
            safe_print(f"   ğŸ“Š Binance {matched_asset} balance: {actual_balance:.6f} (need: {opp.from_amount:.6f})")
            
            # Clamp to actual available balance with extra safety margin for fees
            if actual_balance <= 0:
                safe_print(f"   âš ï¸ No {opp.from_asset} balance on Binance (balance: {actual_balance})")
                return False
            
            # ğŸ‘‘ QUEEN'S SANITY CHECK: Don't clamp to dust!
            if actual_balance < opp.from_amount * 0.1:
                safe_print(f"   âš ï¸ Binance balance {actual_balance:.6f} is < 10% of expected {opp.from_amount:.6f}")
                safe_print(f"   âš ï¸ Likely asset location mismatch. Aborting Binance execution.")
                return False

            # Use 98% of balance instead of 99.5% for extra safety on Binance
            safe_amount = actual_balance * 0.98
            if opp.from_amount > safe_amount:
                safe_print(f"   ğŸ‘‘ Queen clamping: {opp.from_amount:.6f} â†’ {safe_amount:.6f}")
                opp.from_amount = safe_amount
                opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
            
            # Check if clamped amount is too small
            if opp.from_value_usd < 5.0:
                safe_print(f"   âš ï¸ Clamped value ${opp.from_value_usd:.2f} is too small for Binance (min $5.00)")
                
                # ğŸ’§ğŸ”€ LIQUIDITY AGGREGATION CHECK - Can we top-up from other assets?
                shortfall = 5.0 - opp.from_value_usd
                aggregation_result = await self._attempt_liquidity_aggregation(
                    target_asset=opp.from_asset,
                    target_exchange='binance',
                    shortfall_usd=shortfall,
                    expected_profit_pct=getattr(opp, 'expected_profit', 0.01),
                )
                if aggregation_result:
                    # Aggregation succeeded - retry the trade with new balance
                    await self.refresh_exchange_balances('binance')
                    new_balance = self.exchange_balances.get('binance', {}).get(opp.from_asset, 0)
                    opp.from_amount = float(new_balance) * 0.98
                    opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
                    safe_print(f"   ğŸ’§ POST-AGGREGATION: New {opp.from_asset} balance = {opp.from_amount:.6f} (${opp.from_value_usd:.2f})")
                    if opp.from_value_usd >= 5.0:
                        safe_print(f"   âœ… Aggregation successful! Proceeding with trade...")
                        # Continue execution - don't return False
                    else:
                        safe_print(f"   âŒ Aggregation insufficient - still below minimum")
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset, 
                            f"Value ${opp.from_value_usd:.2f} < $5.00 after aggregation",
                            opp.from_value_usd
                        )
                        self.barter_matrix.record_source_rejection(
                            opp.from_asset, 'binance', 5.0, opp.from_value_usd
                        )
                        return False
                else:
                    # ğŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Value ${opp.from_value_usd:.2f} < $5.00 Binance minimum (no aggregation available)",
                        opp.from_value_usd
                    )
                    # ğŸš« Also record SOURCE rejection - this asset is too small for Binance entirely
                    self.barter_matrix.record_source_rejection(
                        opp.from_asset, 'binance', 5.0, opp.from_value_usd
                    )
                    return False
            
            # Debug: Check what type of binance client we have
            client_type = type(self.binance).__name__
            client_module = type(self.binance).__module__
            safe_print(f"   ğŸ“ Binance client: {client_type} from {client_module}")

            # ğŸ” BINANCE PRE-FLIGHT: Enforce min notional / quantity before attempting
            try:
                pair_symbol = f"{opp.from_asset}{opp.to_asset}"
                filters = self.binance.get_symbol_filters(pair_symbol)
                min_notional = float(filters.get('min_notional', 0) or 0)
                min_qty = float(filters.get('min_qty', 0) or 0)
                from_price = self.prices.get(opp.from_asset, 0) or 0
                if min_notional > 0 and opp.from_value_usd < min_notional:
                    safe_print(f"   âš ï¸ Value ${opp.from_value_usd:.2f} < Binance min notional ${min_notional:.2f} for {pair_symbol}")
                    # ğŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Value ${opp.from_value_usd:.2f} < min_notional ${min_notional:.2f}",
                        opp.from_value_usd
                    )
                    return False
                if min_qty > 0 and opp.from_amount < min_qty:
                    needed = min_qty * (from_price if from_price > 0 else 1)
                    safe_print(f"   âš ï¸ Amount {opp.from_amount:.6f} < Binance min qty {min_qty:.6f} for {pair_symbol}")
                    safe_print(f"   ğŸ’¡ Need â‰¥ {min_qty:.6f} ({needed:.2f} USD) to avoid minQty rejection")
                    # ğŸš« Record pre-execution rejection
                    self.barter_matrix.record_preexec_rejection(
                        opp.from_asset, opp.to_asset, 
                        f"Amount {opp.from_amount:.6f} < min_qty {min_qty:.6f}",
                        opp.from_value_usd
                    )
                    return False
            except Exception as pre_e:
                logger.debug(f"Binance pre-flight filter check skipped: {pre_e}")
            
            # Check if convert_crypto exists
            if not hasattr(self.binance, 'convert_crypto'):
                safe_print(f"   âš ï¸ BinanceClient missing convert_crypto method!")
                safe_print(f"   ğŸ“ Available methods: {[m for m in dir(self.binance) if not m.startswith('_')][:20]}")
                
                # Fallback: Use direct place_market_order if available
                if hasattr(self.binance, 'place_market_order'):
                    safe_print(f"   ğŸ”„ Attempting direct market order fallback...")
                    # Try direct pair
                    pair = f"{opp.from_asset}{opp.to_asset}"
                    result = self.binance.place_market_order(
                        symbol=pair,
                        side="SELL",
                        quantity=opp.from_amount
                    )
                    if result and not result.get("error"):
                        safe_print(f"   âœ… Direct order executed: {result}")
                        return True
                    # Try inverse pair
                    pair = f"{opp.to_asset}{opp.from_asset}"
                    result = self.binance.place_market_order(
                        symbol=pair,
                        side="BUY",
                        quote_qty=opp.from_amount * opp.price if hasattr(opp, 'price') else opp.from_value_usd
                    )
                    if result and not result.get("error"):
                        safe_print(f"   âœ… Inverse order executed: {result}")
                        return True
                
                self._record_failure(opp)
                return False
            
            # ğŸš¨ BINANCE LOSS PREVENTION GATE
            loss_prevention_passed, loss_reason = self._check_binance_loss_prevention(opp.from_asset, opp.from_amount)
            if not loss_prevention_passed:
                safe_print(f"   ğŸš« {loss_reason}")
                self._record_failure(opp)
                return False
            
            # Use convert_crypto which handles pathfinding internally
            result = self.binance.convert_crypto(
                from_asset=opp.from_asset,
                to_asset=opp.to_asset,
                amount=opp.from_amount
            )
            
            # Handle pathfinding error from convert_crypto
            if result and result.get("error"):
                if "No conversion path" in str(result.get("error", "")):
                    safe_print(f"   âš ï¸ {result['error']}")
                    return False
            
            if result and result.get("trades"):
                # Validate the execution
                validation = self._validate_order_execution(result["trades"], opp, 'binance')
                
                if validation.get("valid"):
                    self._log_successful_conversion(validation, opp)
                    return True
                else:
                    logger.error(f"âŒ Binance order validation failed: {validation.get('reason')}")
                    self._record_failure(opp)
                    return False
            elif result and result.get("dryRun"):
                # Dry run mode - simulate success
                safe_print(f"   ğŸ§ª DRY RUN: Would convert via {result.get('trades', 0)} trades")
                return True
            else:
                error_msg = result.get("error", "Unknown error")
                logger.error(f"âŒ Binance conversion error: {error_msg}")
                safe_print(f"   âŒ Error: {error_msg}")
                self._record_failure(opp)
                return False
        
        except Exception as e:
            logger.error(f"âŒ Binance conversion error: {e}")
            safe_print(f"   âŒ Error: {e}")
            self._record_failure(opp)
        return False
    
    async def _execute_on_alpaca(self, opp) -> bool:
        """Execute conversion on Alpaca using convert_crypto."""
        try:
            # Use the built-in convert_crypto which finds the best path automatically!
            safe_print(f"   ğŸ”„ Converting {opp.from_asset} â†’ {opp.to_asset} via Alpaca...")
            
            # ğŸ‘‘ QUEEN MIND: Decode conversion path in real-time
            # Refresh balance FIRST to get accurate amounts
            await self.refresh_exchange_balances('alpaca')
            
            # ğŸ‘‘ SERO FIX: Case-insensitive asset matching
            alpaca_balances = self.exchange_balances.get('alpaca', {})
            actual_balance = 0.0
            matched_asset = opp.from_asset
            
            for bal_key, bal_val in alpaca_balances.items():
                if bal_key.upper() == opp.from_asset.upper():
                    actual_balance = float(bal_val) if isinstance(bal_val, (int, float, str)) else 0.0
                    matched_asset = bal_key
                    break
            
            safe_print(f"   ğŸ“Š Alpaca {matched_asset} balance: {actual_balance:.6f} (need: {opp.from_amount:.6f})")
            
            # Clamp to actual available balance
            if actual_balance <= 0:
                safe_print(f"   âš ï¸ No {opp.from_asset} balance on Alpaca (balance: {actual_balance})")
                return False
            
            # ğŸŒâœ¨ PLANET SAVER: Same sanity check as Kraken - detect location mismatch!
            if actual_balance < opp.from_amount * 0.1:
                safe_print(f"   ğŸŒâš ï¸ Alpaca balance {actual_balance:.6f} is < 10% of expected {opp.from_amount:.6f}")
                safe_print(f"   ğŸŒâš ï¸ Asset location mismatch! Protecting the planet by aborting.")
                return False
            
            # ğŸŒâœ¨ PLANET SAVER PROTECTION: Don't trade dust that gets eaten by fees!
            original_amount = opp.from_amount
            original_value = opp.from_value_usd
            
            # ğŸ‘‘ SERO EXECUTION FIX: Use 95% of balance for safety margin
            safe_amount = actual_balance * 0.95
            if opp.from_amount > safe_amount:
                safe_print(f"   ğŸ‘‘ Sero adjusts: {opp.from_amount:.6f} â†’ {safe_amount:.6f} (95% safe)")
                opp.from_amount = safe_amount
                opp.from_value_usd = opp.from_amount * self.prices.get(opp.from_asset, 0)
                
                # ğŸŒâœ¨ PLANET SAVER: Check if clamping destroyed our profit opportunity!
                clamp_ratio = opp.from_amount / original_amount if original_amount > 0 else 0
                if clamp_ratio < 0.2:  # Lost more than 80% of intended trade size
                    safe_print(f"   ğŸŒâš ï¸ PLANET SAVER PROTECTION: Clamped to {clamp_ratio*100:.1f}% of intended!")
                    safe_print(f"      Original: ${original_value:.2f} â†’ Clamped: ${opp.from_value_usd:.2f}")
                    safe_print(f"      Fees would eat this tiny trade alive. ABORTING to save the planet!")
                    return False
                    
                # ğŸŒâœ¨ TRUST THE MATH: Pre-Execution Gate validates net profit
                # ğŸ›¡ï¸ CRITICAL: Use $1.50 minimum to avoid mid-trade failures!
                PLANET_SAVER_MIN_ALPACA = 1.50  # $1.50 minimum for safety
                if opp.from_value_usd < PLANET_SAVER_MIN_ALPACA:
                    safe_print(f"   ğŸŒâš ï¸ PLANET SAVER: Value ${opp.from_value_usd:.2f} < ${PLANET_SAVER_MIN_ALPACA} minimum")
                    safe_print(f"      Too small to execute. Skipping dust.")
                    return False
                # âœ… Trust Pre-Execution Gate - if net profit > 0, proceed!

            # ğŸ² MONTE CARLO SNOWBALL: One trade at a time, hold, roll profits
            # Try dynamic cost estimation first, fall back to flat 0.25% if unavailable
            if self.cost_estimator:
                try:
                    cost_estimate = self.cost_estimator.estimate_cost(
                        symbol=opp.to_asset,
                        side='buy',
                        notional_usd=opp.from_value_usd
                    )
                    total_cost_pct = cost_estimate.estimated_total_pct
                    cost_metrics = {
                        "fee_pct": cost_estimate.estimated_fee_pct,
                        "spread_pct": cost_estimate.estimated_spread_pct,
                        "slippage_pct": cost_estimate.estimated_slippage_pct,
                        "total_pct": total_cost_pct,
                        "source": cost_estimate.source,
                        "confidence": cost_estimate.confidence,
                    }
                    logger.debug(f"ğŸ’° Dynamic cost: {total_cost_pct:.3f}% (source={cost_estimate.source}, confidence={cost_estimate.confidence:.2f})")
                except Exception as e:
                    logger.debug(f"Dynamic cost estimation failed: {e}, using fallback")
                    MONTE_CARLO_COST_PCT = 0.25
                    total_cost_pct = MONTE_CARLO_COST_PCT
                    cost_metrics = {
                        "fee_pct": 0.15,
                        "slippage_pct": 0.02,
                        "spread_pct": 0.08,
                        "total_pct": MONTE_CARLO_COST_PCT,
                        "source": "fallback",
                    }
            else:
                # Fallback to flat 0.25% (original behavior)
                MONTE_CARLO_COST_PCT = 0.25
                total_cost_pct = MONTE_CARLO_COST_PCT
                cost_metrics = {
                    "fee_pct": 0.15,
                    "slippage_pct": 0.02,
                    "spread_pct": 0.08,
                    "total_pct": MONTE_CARLO_COST_PCT,
                    "source": "flat_fallback",
                }
            
            net_expected_usd = opp.expected_pnl_usd - (opp.from_value_usd * total_cost_pct / 100)
            net_expected_pct = (opp.expected_pnl_pct * 100) - total_cost_pct

            opp.alpaca_fee_pct = cost_metrics.get("fee_pct", 0.0)
            opp.alpaca_slippage_pct = cost_metrics.get("slippage_pct", 0.0)
            opp.alpaca_spread_pct = cost_metrics.get("spread_pct", 0.0)
            opp.alpaca_total_cost_pct = total_cost_pct
            opp.alpaca_net_expected_usd = net_expected_usd

            # ğŸ“Š Record net estimate distribution
            self.run_metrics.record_net_estimate(net_expected_pct)
            
            cost_source = cost_metrics.get('source', 'unknown')
            safe_print(
                f"   ğŸ² MONTE CARLO: {cost_source} {total_cost_pct:.2f}% cost | "
                f"net est ${net_expected_usd:+.4f} ({net_expected_pct:+.2f}%)"
            )

            # ğŸš« ULTIMATE LOSS PREVENTION: Check if we're already bleeding!
            # Don't compound losses - if significantly underwater, STOP trading until positions recover!
            try:
                if self.alpaca:
                    positions = self.alpaca.get_positions()
                    total_unrealized_pl = sum(float(p.get('unrealized_pl', 0)) for p in positions)
                    if total_unrealized_pl < -1.00:  # More than $1.00 underwater (was $0.05 - too strict!)
                        safe_print(
                            f"   ğŸš« POSITIONS UNDERWATER: ${total_unrealized_pl:.4f} unrealized loss. "
                            f"NOT trading until positions recover!"
                        )
                        return False
            except Exception:
                pass  # If check fails, continue to safety gate

            if net_expected_usd < self.alpaca_min_net_profit_usd or net_expected_pct < self.alpaca_min_net_profit_pct:
                self.run_metrics.record_candidate(passed_preexec=True, passed_mc=False, skip_reason=f"net_below_threshold")
                safe_print(f"   ğŸ›¡ï¸ MONTE CARLO: Net ${net_expected_usd:+.4f} ({net_expected_pct:+.2f}%) < required {self.alpaca_min_net_profit_pct:.2f}% - SKIPPING")
                safe_print(f"      Required: net â‰¥ {self.alpaca_min_net_profit_pct:.2f}% or net â‰¥ ${self.alpaca_min_net_profit_usd:.3f}")
                return False
            
            # ğŸ²â„ï¸ MONTE CARLO SNOWBALL APPROVED - EXECUTE ON ALPACA!
            self.run_metrics.record_candidate(passed_preexec=True, passed_mc=True)
            safe_print(f"\n   ğŸ²â„ï¸ MONTE CARLO SNOWBALL APPROVED! â„ï¸ğŸ²")
            safe_print(f"   â”œâ”€â”€ Net Profit: ${net_expected_usd:+.4f} ({net_expected_pct:+.2f}%)")
            safe_print(f"   â”œâ”€â”€ Mode: One trade â†’ Hold â†’ Roll profits")
            safe_print(f"   â””â”€â”€ Executing on ALPACA... ğŸ¦™ğŸš€")
            
            # Execute directly on Alpaca
            path = self.alpaca.find_conversion_path(opp.from_asset, opp.to_asset)
            if not path:
                safe_print(f"   âš ï¸ No conversion path found from {opp.from_asset} to {opp.to_asset}")
                return False
            
            # ğŸ” ALPACA PRE-FLIGHT CHECK: Verify minimums for EACH step
            # Alpaca has different minimums per crypto asset
            ALPACA_MIN_NOTIONAL = 1.0  # Alpaca typically has $1 minimum
            ALPACA_MIN_QTY = {
                'BTC': 0.0001,    # ~$10 at current prices
                'ETH': 0.001,     # ~$3 at current prices
                'SOL': 0.01,      # ~$2 at current prices
                'DOGE': 1.0,      # ~$0.30 at current prices
                'SHIB': 100000.0, # Fractions of a cent
                'PEPE': 100000.0, # Fractions of a cent
                'AVAX': 0.01,     # ~$0.40 at current prices
                'LINK': 0.1,      # ~$2 at current prices
                'DOT': 0.1,       # ~$0.70 at current prices
                'AAVE': 0.001,    # ~$0.16 at current prices
            }
            
            for step in path:
                pair = step.get('pair', '')
                # Alpaca pairs are like 'BTC/USD'
                base_asset = pair.split('/')[0] if '/' in pair else opp.from_asset
                
                # Check minimum quantity for this asset
                min_qty = ALPACA_MIN_QTY.get(base_asset.upper(), 0.0001)  # Default very small
                
                # For selling, check if we have enough of the from_asset
                if step.get('side') == 'sell' and opp.from_amount < min_qty:
                    safe_print(f"   âš ï¸ Qty {opp.from_amount:.6f} < min {min_qty:.6f} for {pair}")
                    safe_print(f"   ğŸ’¡ Need {min_qty:.6f} {base_asset} minimum")
                    return False
                
                # Check minimum notional value - Use $1.50 buffer for safety!
                ALPACA_MIN_NOTIONAL_SAFE = 1.50  # $1.50 minimum (not $1.00) to avoid edge cases
                if opp.from_value_usd < ALPACA_MIN_NOTIONAL_SAFE:
                    safe_print(f"   âš ï¸ Value ${opp.from_value_usd:.2f} < min notional ${ALPACA_MIN_NOTIONAL_SAFE:.2f}")
                    safe_print(f"   ğŸ’¡ Need ${ALPACA_MIN_NOTIONAL_SAFE:.2f} minimum to trade safely on Alpaca")
                    return False
                
                # ğŸ›¡ï¸ 2-HOP SAFETY: Check if we have enough for BOTH legs!
                if len(path) >= 2:
                    per_leg_value = opp.from_value_usd * 0.95 / 2  # After 95% adj, split between legs
                    if per_leg_value < 1.00:
                        safe_print(f"   âš ï¸ 2-hop trade needs $2.50+ (each leg gets ~${per_leg_value:.2f})")
                        safe_print(f"   ğŸ’¡ Value ${opp.from_value_usd:.2f} too small for 2-hop - risk of mid-trade failure!")
                        return False
            
            # Show the path
            for step in path:
                safe_print(f"   ğŸ“ Path: {step['description']} via {step['pair']}")
            
            # Execute the conversion
            result = self.alpaca.convert_crypto(
                from_asset=opp.from_asset,
                to_asset=opp.to_asset,
                amount=opp.from_amount
            )
            
            if result.get('error'):
                safe_print(f"   âŒ Conversion error: {result['error']}")
                self._record_failure(opp)
                return False
            
            # Check results
            trades = result.get('trades', [])
            if isinstance(trades, list):
                success_count = sum(1 for t in trades if isinstance(t, dict) and t.get('status') == 'success')
                if success_count > 0:
                    # Calculate actual bought amount from the last trade
                    last_trade = trades[-1]
                    buy_amount = 0.0
                    if last_trade.get('status') == 'success':
                        res = last_trade.get('result', {})
                        buy_amount = float(res.get('qty', 0.0)) # Alpaca uses 'qty'
                    
                    # Fallback if qty is missing or 0
                    if buy_amount == 0.0:
                         # Estimate based on price
                         to_price = self.prices.get(opp.to_asset, 0)
                         if to_price > 0:
                             buy_amount = opp.from_value_usd / to_price
                    
                    safe_print(f"   âœ… Conversion complete! {success_count} trades executed. Bought {buy_amount:.6f} {opp.to_asset}")
                    
                    # â±ï¸ Record entry time for minimum hold enforcement
                    self.position_entry_times[opp.to_asset.upper()] = time.time()
                    safe_print(f"   â±ï¸ Position entered at {time.strftime('%H:%M:%S')} - will hold minimum {self.min_hold_time_seconds:.0f}s")
                    
                    # ğŸ¦™ Optional OCO exits to capture profit + protect downside
                    self._alpaca_place_exit_orders(opp.to_asset, buy_amount)

                    # ğŸ” VALIDATE ORDER EXECUTION
                    validation = self._validate_order_execution(trades, opp, 'alpaca')
                    verification = self._verify_profit_math(validation, opp, buy_amount)
                    self._print_order_validation(validation, verification, opp)
                    
                    self._record_conversion(opp, buy_amount, validation, verification)
                    return True
                else:
                    safe_print(f"   âŒ No successful trades in conversion")
                    self._record_failure(opp)
            elif result.get('dryRun'):
                safe_print(f"   ğŸ”µ DRY RUN: Would convert via {len(path)} trades")
                return True
            else:
                safe_print(f"   âœ… Conversion result: {result}")
                # Estimate amount for non-standard result
                to_price = self.prices.get(opp.to_asset, 0)
                buy_amount = opp.from_value_usd / to_price if to_price > 0 else 0
                self._record_conversion(opp, buy_amount)
                return True
                
        except Exception as e:
            logger.error(f"âŒ Alpaca conversion error: {e}")
            safe_print(f"   âŒ Error: {e}")
            self._record_failure(opp)
        return False

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸŒ MULTI-EXCHANGE EXECUTION ROUTER
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _execute_on_exchange(self, exchange: str, opp, net_expected_usd: float, cost_metrics: Dict) -> bool:
        """
        ğŸŒ EXECUTE TRADE ON TARGET EXCHANGE
        
        Routes Alpaca-verified trades to other exchanges for execution.
        Supports: binance, kraken, capital, coinbase
        
        Args:
            exchange: Target exchange name
            opp: Opportunity object with trade details
            net_expected_usd: Alpaca-verified net profit
            cost_metrics: Cost breakdown from Alpaca verification
        
        Returns:
            bool: True if execution successful
        """
        exchange = exchange.lower()
        safe_print(f"\n   ğŸŒâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        safe_print(f"   ğŸŒ MULTI-EXCHANGE EXECUTION: {exchange.upper()}")
        safe_print(f"   ğŸŒâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        safe_print(f"   ğŸ“Š Trade: {opp.from_asset} â†’ {opp.to_asset}")
        safe_print(f"   ğŸ’° Amount: {opp.from_amount:.6f} ({opp.from_asset}) = ${opp.from_value_usd:.2f}")
        safe_print(f"   âœ… Alpaca-verified profit: ${net_expected_usd:+.4f}")
        
        try:
            # Get appropriate client
            client = None
            if exchange == 'binance' and hasattr(self, 'binance_client') and self.binance_client:
                client = self.binance_client
            elif exchange == 'kraken' and hasattr(self, 'kraken_client') and self.kraken_client:
                client = self.kraken_client
            elif exchange == 'capital' and hasattr(self, 'capital_client') and self.capital_client:
                client = self.capital_client
            elif exchange == 'coinbase' and hasattr(self, 'coinbase_client') and self.coinbase_client:
                client = self.coinbase_client
            
            if not client:
                safe_print(f"   âš ï¸ {exchange.upper()} client not available")
                # Try next exchange in priority
                return self._try_next_exchange(opp, net_expected_usd, cost_metrics, exclude=[exchange])
            
            # Check if exchange has balance for this trade
            try:
                balance = client.get_balance()
                from_balance = float(balance.get(opp.from_asset, 0))
                if from_balance < opp.from_amount:
                    safe_print(f"   âš ï¸ {exchange.upper()} insufficient balance: {from_balance:.6f} < {opp.from_amount:.6f}")
                    return self._try_next_exchange(opp, net_expected_usd, cost_metrics, exclude=[exchange])
            except Exception as e:
                logger.warning(f"Balance check failed for {exchange}: {e}")
            
            # Format symbol for exchange
            symbol = self._format_symbol_for_exchange(opp.from_asset, opp.to_asset, exchange)
            safe_print(f"   ğŸ¯ Symbol: {symbol}")
            
            # Execute trade
            # ğŸš¨ LOSS PREVENTION GATE: Check Alpaca position P&L before selling
            if exchange.lower() == 'alpaca' and opp.from_asset != 'USD':
                # This is a SELL order (cryptoâ†’USD) - check if position is at unrealized loss
                loss_prevention_passed, loss_reason = self._check_alpaca_loss_prevention(opp.from_asset, opp.from_amount)
                if not loss_prevention_passed:
                    safe_print(f"   ğŸš¨ LOSS PREVENTION BLOCKED SELL!")
                    safe_print(f"   â”œâ”€â”€ Asset: {opp.from_asset}")
                    safe_print(f"   â”œâ”€â”€ Reason: {loss_reason}")
                    safe_print(f"   â””â”€â”€ Would realize loss - trade rejected!")
                    
                    # Record rejection for learning
                    if hasattr(self, 'barter_matrix'):
                        self.barter_matrix.record_preexec_rejection(
                            opp.from_asset, opp.to_asset,
                            f'loss_prevention: {loss_reason}',
                            opp.from_value_usd
                        )
                    return False
            
            if hasattr(client, 'convert_crypto'):
                # Use convert if available (like Alpaca)
                result = client.convert_crypto(opp.from_asset, opp.to_asset, opp.from_amount)
            elif hasattr(client, 'execute_trade'):
                # Standard trade execution
                result = client.execute_trade(symbol, 'sell', opp.from_amount)
            else:
                safe_print(f"   âŒ {exchange.upper()} client missing execute method")
                return False
            
            # Check result
            if result.get('error'):
                safe_print(f"   âŒ {exchange.upper()} error: {result['error']}")
                return self._try_next_exchange(opp, net_expected_usd, cost_metrics, exclude=[exchange])
            
            # Success!
            safe_print(f"   âœ… {exchange.upper()} EXECUTION SUCCESS!")
            safe_print(f"   ğŸ“‹ Order: {result.get('order_id', result.get('id', 'N/A'))}")
            
            # Calculate bought amount
            buy_amount = 0.0
            to_price = self.prices.get(opp.to_asset, 0)
            if to_price > 0:
                buy_amount = opp.from_value_usd / to_price
            
            # Record the trade
            self._record_conversion(opp, buy_amount)
            
            # Track position entry time
            self.position_entry_times[opp.to_asset.upper()] = time.time()
            safe_print(f"   â±ï¸ Position entered at {time.strftime('%H:%M:%S')}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ {exchange} execution error: {e}")
            safe_print(f"   âŒ {exchange.upper()} error: {e}")
            return self._try_next_exchange(opp, net_expected_usd, cost_metrics, exclude=[exchange])
    
    def _try_next_exchange(self, opp, net_expected_usd: float, cost_metrics: Dict, exclude: List[str]) -> bool:
        """Try next exchange in priority order, excluding failed ones."""
        exec_order = os.getenv("EXCH_EXEC_ORDER", "binance,kraken,capital,coinbase").split(",")
        exec_order = [e.strip().lower() for e in exec_order if e.strip()]
        
        for exch in exec_order:
            if exch in exclude or exch == 'alpaca':
                continue
            safe_print(f"   ğŸ”„ Trying next exchange: {exch.upper()}")
            return self._execute_on_exchange(exch, opp, net_expected_usd, cost_metrics)
        
        safe_print(f"   âŒ All exchanges exhausted. No execution possible.")
        return False
    
    def _format_symbol_for_exchange(self, from_asset: str, to_asset: str, exchange: str) -> str:
        """Format trading pair symbol for specific exchange."""
        exchange = exchange.lower()
        
        if exchange == 'binance':
            # Binance uses no separator: BTCUSDT
            return f"{from_asset}{to_asset}".upper()
        elif exchange == 'kraken':
            # Kraken uses XBT for BTC, and various formats
            from_a = 'XBT' if from_asset.upper() == 'BTC' else from_asset.upper()
            to_a = 'XBT' if to_asset.upper() == 'BTC' else to_asset.upper()
            return f"{from_a}/{to_a}"
        elif exchange in ['capital', 'coinbase']:
            # Standard slash format
            return f"{from_asset}/{to_asset}".upper()
        else:
            return f"{from_asset}/{to_asset}".upper()

    def ensure_round_trip_available(self, from_asset: str, to_asset: str, notional_usd: float, live_depth_check: bool = False) -> Tuple[bool, str]:
        """Check whether a full round-trip path is available and viable for the given notional.

        Performs checks:
          - Path exists (via barter_navigator)
          - Per-leg minimums and notional sizes are sufficient
          - Price data exists for each leg
          - (optional) Live orderbook depth per leg when live_depth_check=True

        Returns: (ok: bool, reason: str)
        """
        try:
            if not hasattr(self, 'barter_navigator') or self.barter_navigator is None:
                return True, "No barter navigator available (assume path exists)"

            path = self.barter_navigator.find_path(from_asset, to_asset)
            if not path or not path.hops:
                return False, "No conversion path found"

            # Minimum per-leg notional (conservative)
            MIN_PER_LEG = 1.50
            legs = path.hops
            if len(legs) == 0:
                return False, "Empty path hops"

            # Evaluate each leg's quoted pair for price and volume data
            for step in legs:
                pair = step.pair
                if not pair:
                    return False, f"Missing pair info in path step: {step}"

                # Look up cached ticker info first
                ticker = self.ticker_cache.get(pair) or self.ticker_cache.get(pair.replace('/', ''))
                if not ticker:
                    # If no ticker, optionally attempt to query live orderbook when requested
                    if not live_depth_check:
                        return False, f"No price/ticker for pair {pair}"
                else:
                    # Check volume heuristic
                    vol = ticker.get('volume', 0) or ticker.get('quoteVolume', 0)
                    if vol and vol * (ticker.get('price', 1) or 1) < MIN_PER_LEG:
                        # If low volume but live check requested, attempt orderbook depth check
                        if not live_depth_check:
                            return False, f"Insufficient volume on {pair} for ${MIN_PER_LEG} leg"

                # Live orderbook depth checks per exchange (more expensive, optional)
                if live_depth_check:
                    exchange = step.exchange
                    per_leg = notional_usd / max(1, len(legs))

                    # Enforce ALPACA_ONLY restriction: if configured, disallow paths that use other exchanges
                    if getattr(self, 'alpaca_only', False) and exchange and exchange.lower() != 'alpaca':
                        return False, f"ALPACA_ONLY active - path uses {exchange} which is disallowed"

                    # If Alpaca and fee tracker available, use it
                    try:
                        if exchange and exchange.lower() == 'alpaca' and hasattr(self, 'alpaca_fee_tracker'):
                            ob = self.alpaca_fee_tracker.get_orderbook(pair)
                            if ob and isinstance(ob, dict):
                                # Expect 'bids' and 'asks' with [[price, size], ...]
                                bids = ob.get('bids', []) or []
                                asks = ob.get('asks', []) or []
                                # Compute cumulative quote value available on each side
                                cum_bid_value = sum(float(p) * float(s) for p, s in bids if p and s)
                                cum_ask_value = sum(float(p) * float(s) for p, s in asks if p and s)
                                if cum_bid_value < per_leg and cum_ask_value < per_leg:
                                    return False, f"Insufficient orderbook depth on {pair}: bids=${cum_bid_value:.2f} asks=${cum_ask_value:.2f} < per-leg ${per_leg:.2f}"
                        # For other exchanges we may have clients exposing get_order_book/get_orderbook
                        elif exchange and hasattr(self, exchange.lower()):
                            client = getattr(self, exchange.lower())
                            if hasattr(client, 'get_order_book'):
                                ob = client.get_order_book(pair, limit=20)
                                if ob:
                                    bids = ob.get('bids', []) or []
                                    asks = ob.get('asks', []) or []
                                    cum_bid_value = sum(float(p) * float(s) for p, s in bids if p and s)
                                    cum_ask_value = sum(float(p) * float(s) for p, s in asks if p and s)
                                    if cum_bid_value < per_leg and cum_ask_value < per_leg:
                                        return False, f"Insufficient orderbook depth on {pair} ({exchange}): bids=${cum_bid_value:.2f} asks=${cum_ask_value:.2f}" 
                    except Exception as e:
                        logger.debug(f"Orderbook depth check skipped for {pair} on {exchange}: {e}")

            # Check aggregate notional is reasonable for multi-leg split
            per_leg = notional_usd / max(1, len(legs))
            if per_leg < MIN_PER_LEG:
                return False, f"Notional ${notional_usd:.2f} too small for {len(legs)}-leg path (per-leg ${per_leg:.2f})"

            return True, "Round-trip available"
        except Exception as e:
            logger.debug(f"Round-trip availability check error: {e}")
            return True, f"Checker error ({e}) - assume available"

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ” ORDER VALIDATION & PROFIT VERIFICATION SYSTEM
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _validate_order_execution(self, trades: List[Dict], opp, exchange: str) -> Dict:
        """
        ğŸ” COMPREHENSIVE ORDER VALIDATION
        
        Validates each trade step using order IDs from the trading platform.
        Verifies fills, calculates actual execution prices, and computes real P&L.
        
        Returns:
            Dict with validation results:
            - valid: bool
            - order_ids: List of order IDs
            - total_sold: Actual amount sold
            - total_bought: Actual amount bought
            - avg_sell_price: Average sell price
            - avg_buy_price: Average buy price
            - total_fees: Total fees paid
            - realized_pnl: Validated P&L
            - validation_errors: List of any issues
        """
        validation = {
            'valid': True,
            'order_ids': [],
            'total_sold': 0.0,
            'total_bought': 0.0,
            'avg_sell_price': 0.0,
            'avg_buy_price': 0.0,
            'total_fees': 0.0,
            'realized_pnl': 0.0,
            'validation_errors': [],
            'exchange': exchange,
            'timestamp': time.time(),
        }
        
        if not trades:
            validation['valid'] = False
            validation['validation_errors'].append("No trades to validate")
            return validation
        
        sell_volume = 0.0
        sell_value = 0.0
        buy_volume = 0.0
        buy_value = 0.0
        
        for i, trade in enumerate(trades):
            step_num = i + 1
            
            if not isinstance(trade, dict):
                validation['validation_errors'].append(f"Step {step_num}: Invalid trade format")
                continue
            
            status = trade.get('status', '')
            result = trade.get('result', {})
            trade_info = trade.get('trade', {})
            
            # Extract order ID based on exchange
            order_id = self._extract_order_id(result, exchange)
            if order_id:
                validation['order_ids'].append({
                    'step': step_num,
                    'order_id': order_id,
                    'exchange': exchange,
                    'pair': trade_info.get('pair', ''),
                    'side': trade_info.get('side', ''),
                })
            
            if status != 'success':
                validation['valid'] = False
                error_msg = trade.get('error', 'Unknown error')
                validation['validation_errors'].append(f"Step {step_num}: {error_msg}")
                continue
            
            # Validate fill data
            executed_qty, cumm_quote_qty, exec_price = self._extract_execution_values(
                result,
                exchange,
                trade_info.get('side', 'buy'),
            )
            
            side = trade_info.get('side', 'buy')
            
            if side == 'sell':
                sell_volume += executed_qty
                sell_value += cumm_quote_qty
            else:
                buy_volume += executed_qty
                buy_value += cumm_quote_qty
            
            # Extract and sum fees
            fees = self._extract_fees(result, exchange)
            validation['total_fees'] += fees
            
            # Verify the fill makes sense
            if executed_qty <= 0:
                validation['validation_errors'].append(f"Step {step_num}: Zero executed quantity")
        
        # Calculate averages
        if sell_volume > 0:
            validation['avg_sell_price'] = sell_value / sell_volume if sell_value > 0 else 0
            validation['total_sold'] = sell_volume
        
        if buy_volume > 0:
            validation['avg_buy_price'] = buy_value / buy_volume
            validation['total_bought'] = buy_volume
        
        # For conversions, the "bought" amount is what we end up with
        # If we did sell â†’ buy, the buy_volume is our result
        # If we did just one side, use that
        if buy_volume > 0:
            validation['final_amount'] = buy_volume
        elif sell_value > 0:
            # We sold and received quote currency (the sell_value IS what we received)
            validation['final_amount'] = sell_value
        elif sell_volume > 0 and validation['avg_sell_price'] > 0:
            # FALLBACK: When sell_value (cummulativeQuoteQty) is 0 (like with Kraken SELL orders)
            # Calculate expected received amount from sell_volume * avg_sell_price
            validation['final_amount'] = sell_volume * validation['avg_sell_price']
        else:
            validation['final_amount'] = 0
        
        return validation

    def _extract_execution_values(self, result: Dict, exchange: str, side: str) -> Tuple[float, float, float]:
        """Extract executed quantity, quote value, and price from exchange results."""
        executed_qty = 0.0
        quote_qty = 0.0
        exec_price = 0.0

        if not result:
            return executed_qty, quote_qty, exec_price

        if exchange == 'alpaca':
            executed_qty = float(result.get('filled_qty', 0) or result.get('qty', 0) or 0)
            exec_price = float(result.get('filled_avg_price', 0) or result.get('avg_price', 0) or result.get('price', 0) or 0)
            quote_qty = float(result.get('filled_notional', 0) or 0)
            if quote_qty <= 0 and executed_qty > 0 and exec_price > 0:
                quote_qty = executed_qty * exec_price
        else:
            executed_qty = float(result.get('executedQty', 0) or result.get('filledQty', 0) or 0)
            quote_qty = float(result.get('cummulativeQuoteQty', 0) or result.get('quoteQty', 0) or 0)
            exec_price = float(result.get('avgPrice', 0) or result.get('price', 0) or 0)
            if quote_qty <= 0 and executed_qty > 0 and exec_price > 0:
                quote_qty = executed_qty * exec_price

        return executed_qty, quote_qty, exec_price
    
    def _extract_order_id(self, result: Dict, exchange: str) -> Optional[str]:
        """Extract order ID from trade result based on exchange format."""
        if not result:
            return None
        
        if exchange == 'kraken':
            # Kraken uses 'orderId' which we set from 'txid'
            return result.get('orderId') or result.get('txid')
        elif exchange == 'binance':
            return result.get('orderId') or result.get('clientOrderId')
        elif exchange == 'alpaca':
            return result.get('id') or result.get('order_id')
        
        # Fallback
        return result.get('orderId') or result.get('order_id') or result.get('id')
    
    def _extract_fees(self, result: Dict, exchange: str) -> float:
        """Extract fees from trade result based on exchange format and convert to USD."""
        total_fees = 0.0
        
        if exchange == 'binance':
            # Binance includes fills with commission and commissionAsset
            fills = result.get('fills', [])
            for fill in fills:
                try:
                    commission = float(fill.get('commission', 0))
                    commission_asset = str(fill.get('commissionAsset', '')).upper()
                    
                    if commission > 0 and commission_asset:
                        # Convert fee to USD using current prices
                        if commission_asset in ('USD', 'USDT', 'USDC', 'BUSD'):
                            total_fees += commission
                        else:
                            # Get price of commission asset
                            asset_price = self.prices.get(commission_asset, 0)
                            if asset_price > 0:
                                total_fees += commission * asset_price
                            else:
                                # Fallback: assume small fee (0.1% of typical trade)
                                total_fees += commission * 0.0001  # Conservative estimate
                except (ValueError, TypeError):
                    pass
        elif exchange == 'kraken':
            # Kraken fees need to be calculated from the trade
            # Fee is typically 0.16% maker or 0.26% taker
            executed_qty = float(result.get('executedQty', 0))
            # Get the trade value in USD
            avg_price = float(result.get('avgPrice', 0) or result.get('price', 0) or 0)
            trade_value_usd = executed_qty * avg_price
            fee_rate = 0.0026  # Assume taker (more conservative)
            total_fees = trade_value_usd * fee_rate
        elif exchange == 'alpaca':
            # Alpaca includes fees differently
            total_fees = float(result.get('commission', 0) or result.get('fee', 0) or 0)
            if total_fees <= 0:
                filled_notional = float(result.get('filled_notional', 0) or 0)
                if filled_notional > 0:
                    total_fees = filled_notional * 0.0025
        
        return total_fees
    
    def _verify_profit_math(self, validation: Dict, opp, buy_amount: float) -> Dict:
        """
        ğŸ”¢ VERIFY PROFIT CALCULATION MATH
        
        Cross-checks our calculated P&L against actual execution data.
        Returns verification results with any discrepancies.
        """
        verification = {
            'valid': True,
            'expected_pnl': opp.expected_pnl_usd,
            'calculated_pnl': 0.0,
            'verified_pnl': 0.0,
            'discrepancy': 0.0,
            'discrepancy_pct': 0.0,
            'warnings': [],
        }
        
        # Get current prices for calculation
        from_price = self.prices.get(opp.from_asset, 0)
        to_price = self.prices.get(opp.to_asset, 0)
        
        if not from_price or not to_price:
            verification['warnings'].append("Missing price data for verification")
            return verification
        
        # Calculate P&L using our method
        sold_value = opp.from_amount * from_price
        bought_value = buy_amount * to_price
        calculated_pnl = bought_value - sold_value
        verification['calculated_pnl'] = calculated_pnl
        
        # Calculate P&L using actual execution data (if available)
        if validation.get('total_sold') > 0 or validation.get('final_amount', 0) > 0 or buy_amount > 0:
            # ğŸ”§ FIX: Use ACTUAL EXECUTION PRICES, not current market prices!
            # This is critical for accurate P/L calculation
            
            # Determine if this is a BUY or SELL order based on the conversion direction
            # If we're converting FROM crypto TO USD, it's a SELL order
            # If we're converting FROM USD TO crypto, it's a BUY order
            is_sell_order = opp.from_asset != 'USD' and opp.to_asset == 'USD'
            
            if is_sell_order:
                # SELL ORDER: DOGEâ†’USD (selling crypto for USD)
                # P&L = amount_received_USD - cost_basis_of_crypto_sold
                amount_received_usd = validation.get('final_amount', buy_amount)  # USD received
                crypto_sold = validation['total_sold']  # DOGE sold
                crypto_cost_basis = crypto_sold * validation.get('avg_buy_price', 0)  # What we paid for DOGE
                
                verified_pnl = amount_received_usd - crypto_cost_basis - validation.get('total_fees', 0)
            else:
                # BUY ORDER: USDâ†’DOGE (buying crypto with USD)
                # P&L = value_of_crypto_bought - usd_spent
                usd_spent = validation['total_sold'] * validation.get('avg_sell_price', 0)  # USD spent
                crypto_bought = validation.get('final_amount', buy_amount)  # DOGE bought
                crypto_value = crypto_bought * validation.get('avg_buy_price', 0)  # Current value of DOGE
                
                verified_pnl = crypto_value - usd_spent - validation.get('total_fees', 0)
            
            verification['verified_pnl'] = verified_pnl
            
            # Check for discrepancy between expected and verified P&L
            discrepancy = abs(verification['expected_pnl'] - verified_pnl)
            verification['discrepancy'] = discrepancy
            
            if abs(verification['expected_pnl']) > 0.0001:
                verification['discrepancy_pct'] = (discrepancy / abs(verification['expected_pnl'])) * 100
            
            # Flag significant discrepancies (>5%)
            if verification['discrepancy_pct'] > 5.0:
                verification['valid'] = False
                verification['warnings'].append(
                    f"P&L discrepancy: expected ${verification['expected_pnl']:.4f} vs verified ${verified_pnl:.4f} ({verification['discrepancy_pct']:.1f}%)"
                )
            
            # Check for discrepancy
            discrepancy = abs(calculated_pnl - verified_pnl)
            verification['discrepancy'] = discrepancy
            
            if abs(calculated_pnl) > 0.0001:
                verification['discrepancy_pct'] = (discrepancy / abs(calculated_pnl)) * 100
            
            # Flag significant discrepancies (>5%)
            if verification['discrepancy_pct'] > 5.0:
                verification['valid'] = False
                verification['warnings'].append(
                    f"P&L discrepancy: calculated ${calculated_pnl:.4f} vs verified ${verified_pnl:.4f} ({verification['discrepancy_pct']:.1f}%)"
                )
        else:
            verification['verified_pnl'] = calculated_pnl
        
        return verification
    
    def _print_order_validation(self, validation: Dict, verification: Dict, opp):
        """Print comprehensive order validation results."""
        safe_print("\n   " + "â•" * 60)
        safe_print("   ğŸ” ORDER VALIDATION & PROFIT VERIFICATION")
        safe_print("   " + "â•" * 60)
        
        # Order IDs
        if validation['order_ids']:
            safe_print(f"   ğŸ“‹ Order IDs ({validation['exchange'].upper()}):")
            for order in validation['order_ids']:
                safe_print(f"      Step {order['step']}: {order['order_id']} ({order['side']} {order['pair']})")
        
        # Execution Summary
        safe_print(f"\n   ğŸ“Š EXECUTION SUMMARY:")
        safe_print(f"      Sold: {validation['total_sold']:.8f} {opp.from_asset}")
        safe_print(f"      Bought: {validation.get('final_amount', 0):.8f} {opp.to_asset}")
        if validation['avg_sell_price'] > 0:
            safe_print(f"      Avg Sell Price: ${validation['avg_sell_price']:.6f}")
        if validation['avg_buy_price'] > 0:
            safe_print(f"      Avg Buy Price: ${validation['avg_buy_price']:.6f}")
        safe_print(f"      Total Fees: ${validation['total_fees']:.6f}")
        
        # P&L Verification
        safe_print(f"\n   ğŸ’° P&L VERIFICATION:")
        safe_print(f"      Expected P&L: ${verification['expected_pnl']:+.4f}")
        safe_print(f"      Calculated P&L: ${verification['calculated_pnl']:+.4f}")
        safe_print(f"      Verified P&L: ${verification['verified_pnl']:+.4f}")
        
        if verification['discrepancy'] > 0.0001:
            status = "âš ï¸" if verification['discrepancy_pct'] > 5 else "âœ…"
            safe_print(f"      {status} Discrepancy: ${verification['discrepancy']:.4f} ({verification['discrepancy_pct']:.1f}%)")
        else:
            safe_print(f"      âœ… Math Verified!")
        
        # Validation Status
        if validation['validation_errors']:
            safe_print(f"\n   âš ï¸ VALIDATION ISSUES:")
            for error in validation['validation_errors']:
                safe_print(f"      - {error}")
        
        if verification['warnings']:
            safe_print(f"\n   âš ï¸ VERIFICATION WARNINGS:")
            for warning in verification['warnings']:
                safe_print(f"      - {warning}")
        
        # Final Status
        if validation['valid'] and verification['valid']:
            safe_print(f"\n   âœ… ORDER FULLY VALIDATED - Profit math confirmed!")
        else:
            safe_print(f"\n   âš ï¸ VALIDATION INCOMPLETE - Review required")
        
        safe_print("   " + "â•" * 60)
    
    def _record_conversion(self, opp, buy_amount: float, validation: Dict = None, verification: Dict = None):
        """Record a successful conversion with STEP-BY-STEP realized profit tracking and ORDER VALIDATION."""
        opp.executed = True
        self.conversions_made += 1
        self.conversions.append(opp)
        self.balances[opp.from_asset] = self.balances.get(opp.from_asset, 0) - opp.from_amount
        self.balances[opp.to_asset] = self.balances.get(opp.to_asset, 0) + buy_amount
        
        # ğŸ¿â˜ƒï¸ SNOWBALL POSITION TRACKING - Record ACTUAL entry/exit prices!
        if self.snowball_mode:
            from_upper = opp.from_asset.upper()
            to_upper = opp.to_asset.upper()
            is_from_stable = from_upper in self.snowball_stablecoins
            is_to_stable = to_upper in self.snowball_stablecoins
            
            # Use ACTUAL execution price from validation if available
            actual_buy_price = 0.0
            actual_sell_price = 0.0
            if validation:
                actual_buy_price = validation.get('avg_buy_price', 0) or self.prices.get(to_upper, 0)
                actual_sell_price = validation.get('avg_sell_price', 0) or self.prices.get(from_upper, 0)
            else:
                actual_buy_price = self.prices.get(to_upper, 0)
                actual_sell_price = self.prices.get(from_upper, 0)
            
            if is_from_stable and not is_to_stable:
                # ENTRY: Buying a coin with stablecoin
                self.snowball_position = {
                    'asset': to_upper,
                    'amount': buy_amount,
                    'entry_price': actual_buy_price,
                    'entry_value_usd': opp.from_value_usd,
                    'entry_time': time.time(),
                    'entry_from': from_upper,
                }
                safe_print(f"\n   ğŸ¿â˜ƒï¸ SNOWBALL ENTRY RECORDED:")
                safe_print(f"      Asset: {to_upper}")
                safe_print(f"      Amount: {buy_amount:.6f}")
                safe_print(f"      Entry Price: ${actual_buy_price:.6f}")
                safe_print(f"      Entry Value: ${opp.from_value_usd:.2f}")
                safe_print(f"      â³ Waiting for profit >= {self.snowball_min_profit_pct}% to exit...")
            
            elif not is_from_stable and is_to_stable and self.snowball_position:
                # EXIT: Selling coin back to stablecoin
                entry_price = self.snowball_position['entry_price']
                entry_value = self.snowball_position['entry_value_usd']
                exit_value = buy_amount if to_upper == 'USD' else (buy_amount * self.prices.get(to_upper, 1.0))
                
                # ACTUAL realized profit = what we got - what we spent
                realized_profit = exit_value - entry_value
                profit_pct = ((exit_value / entry_value) - 1) * 100 if entry_value > 0 else 0
                
                # Record in history
                trade_record = {
                    'asset': self.snowball_position['asset'],
                    'entry_price': entry_price,
                    'exit_price': actual_sell_price,
                    'entry_value': entry_value,
                    'exit_value': exit_value,
                    'realized_profit': realized_profit,
                    'profit_pct': profit_pct,
                    'duration_s': time.time() - self.snowball_position['entry_time'],
                    'timestamp': time.time(),
                }
                self.snowball_profit_history.append(trade_record)
                self.snowball_total_realized += realized_profit
                
                safe_print(f"\n   ğŸ¿ğŸ’° SNOWBALL EXIT - PROFIT CONFIRMED!")
                safe_print(f"      Asset: {self.snowball_position['asset']}")
                safe_print(f"      Entry: ${entry_value:.2f} @ ${entry_price:.6f}")
                safe_print(f"      Exit:  ${exit_value:.2f} @ ${actual_sell_price:.6f}")
                safe_print(f"      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
                safe_print(f"      ğŸ’µ REALIZED PROFIT: ${realized_profit:+.4f} ({profit_pct:+.2f}%)")
                safe_print(f"      ğŸ“Š SNOWBALL TOTAL:  ${self.snowball_total_realized:+.4f}")
                safe_print(f"      ğŸ¯ Trade #{len(self.snowball_profit_history)}")
                safe_print(f"      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
                
                if realized_profit >= 0:
                    safe_print(f"      âœ… CONFIRMED WIN! Entering cooldown...")
                else:
                    safe_print(f"      âŒ LOSS (shouldn't happen - gates should prevent this)")
                
                # Clear position - ready for next entry after cooldown
                self.snowball_position = None
                self.snowball_last_exit_time = time.time()  # ğŸ¿ Start cooldown timer
                safe_print(f"      â¸ï¸ COOLDOWN ACTIVE: {self.snowball_cooldown_seconds}s before next entry")

        # ğŸš¨ USE ACTUAL EXECUTION DATA, NOT ESTIMATED PRICES
        # This is critical to prevent ghost profits!
        from_price = self.prices.get(opp.from_asset, 0)
        to_price = self.prices.get(opp.to_asset, 0)
        
        # Try to use actual execution values from validation
        if validation and validation.get('total_sold', 0) > 0:
            # Use actual execution data
            if validation.get('avg_sell_price', 0) > 0:
                sold_value = validation['total_sold'] * validation['avg_sell_price']
            else:
                sold_value = opp.from_amount * from_price
            
            if validation.get('avg_buy_price', 0) > 0:
                bought_value = validation.get('final_amount', buy_amount) * validation['avg_buy_price']
            else:
                bought_value = buy_amount * to_price
            
            # Subtract fees from bought value (fees reduce profit)
            # Note: fees are already in USD from _extract_fees
            fees_usd = validation.get('total_fees', 0)
            if fees_usd > 0:
                bought_value -= fees_usd  # Direct USD subtraction
        else:
            # Fallback to price-based estimate
            sold_value = opp.from_amount * from_price
            bought_value = buy_amount * to_price
        
        actual_pnl = bought_value - sold_value
        
        # ğŸ‘‘ SERO FIX: Sanitity Check for Outlier Profits
        # This catches "Ghost Profit" bugs where bad data creates impossible PnL
        MAX_REASONABLE_PROFIT = 500.0   # $500 max profit per trade (realistic for small balances)
        MIN_REASONABLE_LOSS = -200.0    # -$200 max loss per trade
        
        if actual_pnl > MAX_REASONABLE_PROFIT or actual_pnl < MIN_REASONABLE_LOSS:
            logger.warning(
                f"ğŸ‘‘âš ï¸ REJECTING OUTLIER PROFIT/LOSS in record: ${actual_pnl:.2f} (from ${sold_value:.2f} to ${bought_value:.2f})"
            )
            logger.warning("      This suggests a price data error or bad execution value. Clamping to 0.0")
            actual_pnl = 0.0

        opp.actual_pnl_usd = actual_pnl
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ” ORDER VALIDATION AUDIT TRAIL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if validation:
            # Use verified P&L if available (most accurate)
            if verification and verification.get('verified_pnl') is not None:
                actual_pnl = verification['verified_pnl']

                # Re-apply outlier clamp to verified P&L too (prevents ghost-profit override)
                if actual_pnl > MAX_REASONABLE_PROFIT or actual_pnl < MIN_REASONABLE_LOSS:
                    logger.warning(
                        f"ğŸ‘‘âš ï¸ REJECTING OUTLIER VERIFIED P/L: ${actual_pnl:.2f} (clamping to 0.0)"
                    )
                    actual_pnl = 0.0

                opp.actual_pnl_usd = actual_pnl
                # Update bought_value to reflect actual P&L (don't reset sold_value!)
                # sold_value already has correct value from execution data above
                bought_value = sold_value + actual_pnl  # bought = sold + profit (actual)
                opp.pnl_verified = True
                opp.verification_status = 'VERIFIED' if verification['valid'] else 'DISCREPANCY'
            else:
                opp.pnl_verified = False
                opp.verification_status = 'UNVERIFIED'
            
            # Store order IDs for audit trail
            opp.order_ids = validation.get('order_ids', [])
            opp.execution_fees = validation.get('total_fees', 0)
            
            # Log validation to persistent storage for auditing
            self._log_order_validation(opp, validation, verification)

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Position Registry Update (real fills) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                from_up = opp.from_asset.upper()
                to_up = opp.to_asset.upper()

                is_buy = from_up in self.snowball_stablecoins and to_up not in self.snowball_stablecoins
                is_sell = to_up in self.snowball_stablecoins and from_up not in self.snowball_stablecoins

                # Determine final_amount from validation (what we actually received)
                final_amount = validation.get('final_amount', buy_amount)
                entry_price = validation.get('avg_buy_price', self.prices.get(to_up, 0))
                exit_price = validation.get('avg_sell_price', self.prices.get(from_up, 0))
                fees_usd = validation.get('total_fees', 0)

                if is_buy:
                    entry = {
                        'amount': float(final_amount),
                        'entry_price': float(entry_price),
                        'entry_value_usd': float(opp.from_value_usd),
                        'fees_usd': float(fees_usd),
                        'order_ids': validation.get('order_ids', []),
                        'source': opp.source_exchange or 'unknown',
                        'timestamp': time.time(),
                    }

                    # Aggregate into registry if existing
                    if to_up in self.position_registry:
                        prev = self.position_registry[to_up]
                        prev_amount = prev.get('amount', 0.0)
                        prev_cost_usd = prev.get('entry_price', 0.0) * prev_amount + prev.get('fees_usd', 0.0)
                        new_cost_usd = entry['entry_price'] * entry['amount'] + entry['fees_usd']
                        total_amount = prev_amount + entry['amount']
                        avg_price = (prev_cost_usd + new_cost_usd) / total_amount if total_amount > 0 else entry['entry_price']
                        prev['amount'] = total_amount
                        prev['entry_price'] = avg_price
                        prev['entry_value_usd'] = prev_cost_usd + new_cost_usd
                        prev['fees_usd'] = prev.get('fees_usd', 0.0) + entry['fees_usd']
                        prev['order_ids'] = prev.get('order_ids', []) + entry['order_ids']
                        prev['timestamp'] = entry['timestamp']
                    else:
                        self.position_registry[to_up] = entry

                elif is_sell:
                    asset = from_up
                    sold_amount = float(opp.from_amount)
                    if asset in self.position_registry:
                        prev = self.position_registry[asset]
                        if sold_amount >= prev.get('amount', 0.0):
                            # Closed out fully
                            del self.position_registry[asset]
                        else:
                            prev['amount'] = prev.get('amount', 0.0) - sold_amount
                            prev['entry_value_usd'] = prev.get('entry_price', 0.0) * prev.get('amount', 0.0)
            except Exception as e:
                logger.debug(f"Position registry update error: {e}")
        # safe_print(step_display)  # FIXME: step_display not defined
        
        # ğŸ”§ FIX: Build profit_result from barter_matrix path history
        path_key = (opp.from_asset.upper(), opp.to_asset.upper())
        path_history = self.barter_matrix.barter_history.get(path_key, {})
        profit_result = {
            'path_trades': path_history.get('trades', 0),
            'path_total_profit': path_history.get('profit', 0.0),
            'actual_slippage_pct': path_history.get('slippage', 0.0) * 100,
            'is_win': actual_pnl >= 0,
            'path_win_rate': path_history.get('win_rate', 0.0) if path_history.get('trades', 0) > 0 else 0.0,
        }
        
        # Show path performance (how this specific conversion path is doing)
        safe_print(f"   ğŸ“Š PATH {opp.from_asset}â†’{opp.to_asset}: {profit_result['path_trades']} trades, ${profit_result['path_total_profit']:+.4f} total")
        safe_print(f"   ğŸ”„ Slippage: {profit_result['actual_slippage_pct']:.2f}%")
        
        # ğŸ‘‘ğŸ„ QUEEN'S MYCELIUM BROADCAST - Send signals to all systems
        if profit_result.get('is_win'):
            safe_print(f"   ğŸ‘‘ Queen's Verdict: âœ… WIN! Path continues.")
        else:
            win_rate = profit_result.get('path_win_rate', 0)
            safe_print(f"   ğŸ‘‘ Queen's Verdict: âŒ LOSS! Path win rate: {win_rate:.0%}")
            # Broadcast through mycelium
            queen_signals = self.barter_matrix.get_queen_signals()
            for signal in queen_signals:
                if signal['type'] == 'PATH_BLOCKED':
                    safe_print(f"   ğŸ„ MYCELIUM BROADCAST: {signal['path']} BLOCKED - {signal['reason']}")
        
        # Update total_profit_usd to match barter matrix
        self.total_profit_usd = self.barter_matrix.total_realized_profit
        
        # ğŸª™âš¡ PENNY TURBO: Record trade for compound learning
        if self.penny_turbo:
            try:
                exchange = opp.source_exchange if hasattr(opp, 'source_exchange') else 'kraken'
                symbol = f"{opp.from_asset}{opp.to_asset}"
                won = actual_pnl >= 0
                profit_pct = (actual_pnl / sold_value * 100) if sold_value > 0 else 0
                duration = getattr(opp, 'execution_time', 30.0)  # Default 30s if not tracked
                
                self.penny_turbo.record_trade(
                    exchange=exchange,
                    symbol=symbol,
                    won=won,
                    profit_pct=profit_pct,
                    volume_usd=sold_value,
                    duration_sec=duration
                )
            except Exception as e:
                logger.debug(f"Penny turbo record error: {e}")

        # Learn: update hub and path memory
        if self.hub and hasattr(self.hub, 'record_conversion_outcome'):
            try:
                self.hub.record_conversion_outcome(opp.from_asset, opp.to_asset, actual_pnl >= 0, actual_pnl)
            except Exception:
                pass
        self.path_memory.record(opp.from_asset, opp.to_asset, actual_pnl >= 0)
        
        # ï¿½ CRITICAL FIX: Record pair result for DYNAMIC BLOCKING!
        # This was missing - pairs kept losing without being blocked!
        pair_key = f"{opp.from_asset.upper()}_{opp.to_asset.upper()}"
        exchange = opp.source_exchange if hasattr(opp, 'source_exchange') else 'kraken'
        self.barter_matrix.record_pair_result(pair_key, exchange, won=(actual_pnl >= 0))
        
        # ï¿½ğŸ‘‘ Update Queen's path memory with new data
        if hasattr(self, 'queen') and self.queen and hasattr(self.queen, 'path_memory'):
            path_key = f"{opp.from_asset.upper()}->{opp.to_asset.upper()}"
            if not hasattr(self.queen, 'path_memory') or self.queen.path_memory is None:
                self.queen.path_memory = {}
            if path_key not in self.queen.path_memory:
                self.queen.path_memory[path_key] = {'wins': 0, 'losses': 0}
            if actual_pnl >= 0:
                self.queen.path_memory[path_key]['wins'] += 1
            else:
                self.queen.path_memory[path_key]['losses'] += 1

        # ğŸ“…ğŸ”® 7-DAY PLANNER: Validate timing prediction after conversion
        if self.seven_day_planner:
            try:
                # Record this conversion for validation tracking
                validation_id = self.seven_day_planner.record_conversion(
                    symbol=opp.to_asset,
                    entry_price=to_price
                )
                
                # Validate immediately with exit price (for compound tracking)
                # The next scan will have updated prices for true validation
                result = self.seven_day_planner.validate_conversion(
                    validation_id=validation_id,
                    exit_price=to_price  # Will be updated on next trade
                )
                
                if result:
                    timing_tag = "ğŸ¯" if result.direction_correct else "âŒ"
                    safe_print(f"   ğŸ“… 7-Day Validation: {timing_tag} timing={result.timing_score:.0%}")
                    
                    # Log adaptive weight updates
                    weights = self.seven_day_planner.adaptive_weights
                    safe_print(f"   ğŸ§  Adaptive: h={weights['hourly_weight']:.2f}, s={weights['symbol_weight']:.2f}, acc={weights['accuracy_7d']:.0%}")
                    
                    # ğŸ‘‘ğŸ“Š FEED VALIDATED PREDICTION TO QUEEN! 
                    # Every verified prediction feeds Queen's neural learning!
                    if self.queen and hasattr(self.queen, 'receive_validated_prediction'):
                        validation_data = {
                            'symbol': opp.to_asset,
                            'predicted_edge': result.predicted_edge,
                            'actual_edge': result.actual_edge,
                            'direction_correct': result.direction_correct,
                            'timing_score': result.timing_score,
                            'confidence': weights.get('accuracy_7d', 0.5),
                            'hour': datetime.now().hour,
                            'day_of_week': datetime.now().weekday(),
                            'source': '7day_planner',
                            'pair': f"{opp.from_asset}->{opp.to_asset}",
                            'pnl': actual_pnl
                        }
                        queen_result = self.queen.receive_validated_prediction(validation_data)
                        if queen_result.get('neural_trained'):
                            safe_print(f"   ğŸ‘‘ğŸ§  Queen learned from validated prediction!")
            except Exception as e:
                logger.debug(f"7-day planner validation error: {e}")

        # ğŸ”®ğŸ“Š PROBABILITY NEXUS VALIDATION - Feed to Queen's Neural Learning!
        # Track nexus prediction accuracy and let Queen learn from it
        if self.queen and hasattr(self.queen, 'receive_validated_prediction'):
            try:
                # Get nexus prediction that was stored with the opportunity
                nexus_prob = getattr(opp, 'nexus_probability', 0.5)
                nexus_dir = getattr(opp, 'nexus_direction', 'NEUTRAL')
                nexus_conf = getattr(opp, 'nexus_confidence', 0.0)
                nexus_factors = getattr(opp, 'nexus_factors', None)
                
                # Validate: Did the nexus prediction match the actual outcome?
                actual_direction = 'BULLISH' if actual_pnl > 0 else ('BEARISH' if actual_pnl < 0 else 'NEUTRAL')
                direction_correct = (nexus_dir == actual_direction) or (nexus_dir == 'NEUTRAL')
                
                # Timing score based on confidence vs outcome
                timing_score = 1.0 if direction_correct else 0.0
                if nexus_conf > 0:
                    timing_score *= nexus_conf  # Weight by confidence
                
                nexus_validation_data = {
                    'symbol': opp.to_asset,
                    'predicted_edge': (nexus_prob - 0.5) * 100,  # Convert 0-1 to edge %
                    'actual_edge': (actual_pnl / sold_value * 100) if sold_value > 0 else 0,
                    'direction_correct': direction_correct,
                    'timing_score': timing_score,
                    'confidence': nexus_conf,
                    'hour': datetime.now().hour,
                    'day_of_week': datetime.now().weekday(),
                    'source': 'probability_nexus',
                    'pair': f"{opp.from_asset}->{opp.to_asset}",
                    'pnl': actual_pnl,
                    'factors': nexus_factors
                }
                nexus_queen_result = self.queen.receive_validated_prediction(nexus_validation_data)
                if nexus_queen_result.get('neural_trained'):
                    safe_print(f"   ğŸ”®ğŸ‘‘ Queen learned from Nexus prediction validation!")
            except Exception as e:
                logger.debug(f"Nexus validation feed error: {e}")

        # Publish observability
        if self.thought_bus:
            try:
                self.thought_bus.think(
                    topic='conversion.success',
                    message='conversion recorded',
                    metadata={
                        'pair': f"{opp.from_asset}->{opp.to_asset}",
                        'pnl': round(actual_pnl, 6),
                        'lambda': round(opp.lambda_score, 4),
                        'gravity': round(opp.gravity_score, 4),
                        'gate_req': round(opp.gate_required_profit, 6),
                        'gate_passed': opp.gate_passed,
                    }
                )
            except Exception:
                pass

    def _record_failure(self, opp, error_msg: str = "", validation: Dict = None):
        """
        Record a failed conversion attempt for learning.
        
        ğŸ‘‘ğŸ“ QUEEN LOSS LEARNING INTEGRATION:
        When we fail, we learn. We pull data, research tactics, and never forget.
        """
        self.path_memory.record(opp.from_asset, opp.to_asset, False)
        
        if self.thought_bus:
            try:
                self.thought_bus.think(
                    topic='conversion.failure',
                    message='conversion failed',
                    metadata={'pair': f"{opp.from_asset}->{opp.to_asset}", 'error': error_msg}
                )
            except Exception:
                pass
        
        # ğŸ‘‘ğŸ“ QUEEN LOSS LEARNING - Analyze every failure to learn and evolve
        if self.loss_learning:
            try:
                # Determine exchange
                exchange = opp.source_exchange or 'unknown'
                
                # Estimate loss amount (what we expected vs what happened)
                # If the conversion failed completely, the loss is the opportunity cost
                expected_profit = opp.expected_pnl_usd if opp.expected_pnl_usd > 0 else EPSILON_PROFIT_USD
                
                # Get prices
                from_price = self.prices.get(opp.from_asset, opp.from_value_usd / opp.from_amount if opp.from_amount > 0 else 1)
                to_price = self.prices.get(opp.to_asset, 0)
                
                # Calculate executed vs expected prices
                expected_price = to_price if to_price > 0 else 1
                executed_price = expected_price  # On failure, we don't have executed price
                
                # If validation data available, extract actual execution info
                if validation:
                    executed_price = validation.get('avg_buy_price', expected_price)
                    if validation.get('total_sold', 0) > 0 and opp.from_amount > 0:
                        # We sold but didn't get what we expected
                        loss_pct = (opp.from_amount - validation.get('total_sold', 0)) / opp.from_amount
                        expected_profit = opp.expected_pnl_usd * loss_pct
                
                # Build signals map from opportunity scores
                signals_used = {
                    'v14_score': opp.v14_score,
                    'hub_score': opp.hub_score,
                    'commando_score': opp.commando_score,
                    'lambda_score': opp.lambda_score,
                    'gravity_score': opp.gravity_score,
                    'luck_score': opp.luck_score,
                    'enigma_score': opp.enigma_score,
                    'timeline_score': opp.timeline_score,
                    'trained_matrix_score': opp.trained_matrix_score,
                    'barter_matrix_score': opp.barter_matrix_score,
                }
                
                # Fees estimated from config
                fees_paid = opp.from_value_usd * MICRO_CONFIG['total_cost_rate']
                
                # Loss amount = expected profit (opportunity cost) + any slippage
                loss_amount = max(expected_profit, EPSILON_PROFIT_USD)
                
                # Schedule async analysis (don't block the main loop)
                import asyncio
                asyncio.create_task(self._async_loss_analysis(
                    exchange=exchange,
                    from_asset=opp.from_asset,
                    to_asset=opp.to_asset,
                    from_amount=opp.from_amount,
                    from_value_usd=opp.from_value_usd,
                    executed_price=executed_price,
                    expected_price=expected_price,
                    fees_paid=fees_paid,
                    loss_amount=loss_amount,
                    signals_used=signals_used,
                    combined_score=opp.combined_score,
                    expected_profit=expected_profit,
                    error_msg=error_msg,
                ))
                
            except Exception as e:
                logger.debug(f"Loss learning error: {e}")
    
    async def _async_loss_analysis(self, **kwargs):
        """Async wrapper for loss analysis to not block main trading loop."""
        try:
            error_msg = kwargs.pop('error_msg', '')
            loss = await self.loss_learning.analyze_loss(**kwargs)
            
            # Check if we should auto-block this path
            avoid, reason = self.loss_learning.should_avoid_trade(
                kwargs['from_asset'],
                kwargs['to_asset'],
                kwargs['exchange'],
                kwargs.get('expected_profit', EPSILON_PROFIT_USD),
                kwargs.get('from_value_usd', 0.0)
            )
            
            if avoid:
                safe_print(f"   ğŸ‘‘ğŸ“ QUEEN WISDOM: BLOCKING {kwargs['from_asset']}â†’{kwargs['to_asset']}")
                safe_print(f"      Reason: {reason}")
                
                # Store in path memory as perma-block
                self.path_memory.block_path(kwargs['from_asset'], kwargs['to_asset'])
                
        except Exception as e:
            logger.debug(f"Async loss analysis error: {e}")

    def _log_successful_conversion(self, validation: Dict, opp):
        """
        Log a successful conversion with validation data.
        This is a convenience wrapper around _record_conversion.
        """
        # Calculate buy/received amount from validation
        buy_amount = 0.0
        trades = validation.get('trades', [])
        if trades:
            last_trade = trades[-1]
            if isinstance(last_trade, dict):
                # PRIORITY: Use receivedQty (for SELL orders) if available
                res = last_trade.get('result', {})
                buy_amount = float(res.get('receivedQty', 0) or
                                   last_trade.get('receivedQty', 0) or
                                   res.get('executedQty', 0) or 
                                   last_trade.get('executedQty', 0) or 0)
        
        # Fallback estimate if no amount found
        if buy_amount == 0:
            to_price = self.prices.get(opp.to_asset, 0)
            if to_price > 0:
                buy_amount = opp.from_value_usd / to_price
        
        # Verify profit math
        verification = self._verify_profit_math(validation, opp, buy_amount)
        
        # Print validation summary
        self._print_order_validation(validation, verification, opp)
        
        # Record the conversion
        self._record_conversion(opp, buy_amount, validation, verification)
    
    def _log_order_validation(self, opp, validation: Dict, verification: Dict):
        """
        ğŸ“‹ LOG ORDER VALIDATION TO PERSISTENT AUDIT TRAIL
        
        Stores all order IDs, execution details, and P&L verification
        for post-trade auditing and compliance.
        """
        import json
        from datetime import datetime
        
        audit_file = "aureon_order_audit.json"
        
        audit_entry = {
            'timestamp': datetime.now().isoformat(),
            'conversion_num': self.conversions_made,
            'exchange': validation.get('exchange', 'unknown'),
            'from_asset': opp.from_asset,
            'to_asset': opp.to_asset,
            'from_amount': opp.from_amount,
            'to_amount': validation.get('final_amount', 0),
            'order_ids': validation.get('order_ids', []),
            'validation': {
                'valid': validation.get('valid', False),
                'total_sold': validation.get('total_sold', 0),
                'total_bought': validation.get('final_amount', 0),
                'avg_sell_price': validation.get('avg_sell_price', 0),
                'avg_buy_price': validation.get('avg_buy_price', 0),
                'total_fees': validation.get('total_fees', 0),
                'errors': validation.get('validation_errors', []),
            },
            'profit_verification': {
                'expected_pnl': verification.get('expected_pnl', 0) if verification else 0,
                'calculated_pnl': verification.get('calculated_pnl', 0) if verification else 0,
                'verified_pnl': verification.get('verified_pnl', 0) if verification else 0,
                'discrepancy': verification.get('discrepancy', 0) if verification else 0,
                'discrepancy_pct': verification.get('discrepancy_pct', 0) if verification else 0,
                'math_valid': verification.get('valid', False) if verification else False,
                'warnings': verification.get('warnings', []) if verification else [],
            },
            'final_status': 'VERIFIED' if (validation.get('valid') and (verification and verification.get('valid'))) else 'NEEDS_REVIEW',
        }
        
        try:
            # Load existing audit log
            try:
                with open(audit_file, 'r') as f:
                    audit_log = json.load(f)
            except (FileNotFoundError, json.JSONDecodeError):
                audit_log = {'orders': [], 'summary': {'total': 0, 'verified': 0, 'discrepancies': 0}}
            
            # Append new entry
            audit_log['orders'].append(audit_entry)
            audit_log['summary']['total'] += 1
            if audit_entry['final_status'] == 'VERIFIED':
                audit_log['summary']['verified'] += 1
            else:
                audit_log['summary']['discrepancies'] += 1
            
            # Save updated log
            with open(audit_file, 'w') as f:
                json.dump(audit_log, f, indent=2)
            
            logger.info(f"ğŸ“‹ Order audit logged: {audit_entry['final_status']}")
            
        except Exception as e:
            logger.warning(f"Failed to write order audit: {e}")
    
    def _find_exchange_pair(self, asset: str, quote: str, exchange: str) -> Optional[str]:
        """Find trading pair on a specific exchange using loaded pairs."""
        asset_upper = asset.upper()
        quote_upper = quote.upper()
        prefix = f"{exchange}:"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ™ KRAKEN - Check kraken_pairs dict
        # Kraken uses special naming: XXBT=BTC, ZUSD=USD, ZEUR=EUR
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if exchange == 'kraken' and self.kraken_pairs:
            # Map common names to Kraken format
            kraken_asset = asset_upper
            if asset_upper == 'BTC':
                kraken_asset = 'XBT'
            
            kraken_quote = quote_upper
            if quote_upper == 'USD':
                kraken_quote = 'ZUSD'
            elif quote_upper == 'EUR':
                kraken_quote = 'ZEUR'
            elif quote_upper == 'GBP':
                kraken_quote = 'ZGBP'
            
            # Try common pair formats (Kraken has multiple naming conventions)
            candidates = [
                f"{asset_upper}{quote_upper}",           # CHZUSD (standard)
                f"{kraken_asset}{quote_upper}",          # XBTUSD
                f"X{kraken_asset}Z{quote_upper}",        # XXBTZUSD
                f"XX{kraken_asset[1:]}Z{quote_upper}" if len(kraken_asset) > 1 else None,  # Edge cases
                f"{asset_upper}{kraken_quote}",          # CHZZUSD
                f"{kraken_asset}{kraken_quote}",         # XBTZUSD
                f"X{kraken_asset}{kraken_quote}",        # XXBTZUSD variant
            ]
            for candidate in [c for c in candidates if c]:
                if candidate in self.kraken_pairs:
                    return f"kraken:{candidate}"
            
            # Fuzzy search (look for both original and Kraken-format asset)
            search_assets = [asset_upper, kraken_asset]
            if asset_upper != kraken_asset:
                search_assets.append(f"X{kraken_asset}")  # XXBT
            
            for pair_name in self.kraken_pairs.keys():
                for search_asset in search_assets:
                    if search_asset in pair_name and quote_upper in pair_name:
                        return f"kraken:{pair_name}"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦™ ALPACA - Check alpaca_pairs dict
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if exchange == 'alpaca' and self.alpaca_pairs:
            candidates = [
                f"{asset_upper}/USD",
                f"{asset_upper}USD",
                f"{asset_upper}/BTC",
                f"{asset_upper}BTC",
                f"{asset_upper}/USDT",
                f"{asset_upper}USDT",
                f"{asset_upper}/USDC",
                f"{asset_upper}USDC",
                asset_upper,
            ]
            for candidate in candidates:
                if candidate in self.alpaca_pairs:
                    return f"alpaca:{self.alpaca_pairs[candidate]}"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŸ¡ BINANCE - Search ticker cache
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if exchange == 'binance':
            candidates = [
                f"{asset_upper}{quote_upper}",
                f"{asset_upper}USDT",
                f"{asset_upper}USDC",
            ]
            for candidate in candidates:
                cache_key = f"binance:{candidate}"
                if cache_key in self.ticker_cache:
                    return cache_key
        
        # Fallback: Search ticker cache for any exchange
        for cached_pair in self.ticker_cache.keys():
            if cached_pair.startswith(prefix):
                pair_part = cached_pair.replace(prefix, '')
                if pair_part.startswith(asset_upper) and quote_upper in pair_part:
                    return cached_pair
        
        return None
    
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¦ˆğŸ”ª HFT HARMONIC MYCELIUM ENGINE - Sub-10ms Trading
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Wire HFT engine to the main trading loop for ultra-fast execution
        self.hft_engine = None
        if HFT_ENGINE_AVAILABLE and get_hft_engine:
            try:
                self.hft_engine = get_hft_engine()
                
                # Wire HFT to Queen (already done in Queen init)
                if self.queen and hasattr(self.queen, 'hft_engine') and self.queen.hft_engine:
                    logger.info("ğŸ¦ˆğŸ‘‘ HFT Engine already wired to Queen")
                elif self.queen:
                    # Fallback wiring if not done in Queen init
                    if hasattr(self.hft_engine, 'wire_queen'):
                        self.hft_engine.wire_queen(self.queen)
                        logger.info("ğŸ¦ˆğŸ‘‘ HFT Engine wired to Queen")
                
                # Wire HFT to WebSocket feed for tick injection
                if hasattr(self, 'unified_ws_feed') and self.unified_ws_feed:
                    # WebSocket feed will inject ticks automatically via _emit method
                    logger.info("ğŸ¦ˆğŸŒ HFT Engine wired to WebSocket feed (tick injection active)")
                
                # Wire HFT to Orca Intelligence for whale signal routing
                if self.orca and hasattr(self.hft_engine, 'wire_orca'):
                    self.hft_engine.wire_orca(self.orca)
                    logger.info("ğŸ¦ˆğŸ¦ˆ HFT Engine wired to Orca Intelligence")
                
                # Wire HFT to Mycelium for neural optimization
                if hasattr(self, 'mycelium_network') and self.mycelium_network and hasattr(self.hft_engine, 'wire_mycelium'):
                    self.hft_engine.wire_mycelium(self.mycelium_network)
                    logger.info("ğŸ¦ˆğŸ„ HFT Engine wired to Mycelium Network")
                
                # Wire HFT to Harmonic Alphabet for frequency encoding
                if hasattr(self, 'harmonic') and self.harmonic and hasattr(self.hft_engine, 'wire_harmonic_alphabet'):
                    self.hft_engine.wire_harmonic_alphabet(self.harmonic)
                    logger.info("ğŸ¦ˆğŸµ HFT Engine wired to Harmonic Alphabet")
                
                # Start HFT in dormant mode (ready to activate)
                if hasattr(self.hft_engine, 'start_hft'):
                    # Don't start scanning yet - wait for explicit activation
                    logger.info("ğŸ¦ˆğŸ”ª HFT Engine initialized (dormant mode - ready for activation)")
                
                safe_print("ğŸ¦ˆğŸ”ª HFT HARMONIC MYCELIUM: WIRED (Sub-10ms trading ready)")
                safe_print(f"   ğŸ¯ Target Latency: <10ms signal-to-order")
                safe_print(f"   ğŸµ Harmonic Patterns: 528Hz (WIN) â†’ BUY, 396Hz (LOSS) â†’ HOLD")
                safe_print(f"   ğŸ§  Mycelium: Hot path cache (100ms TTL)")
                safe_print(f"   ğŸŒ WebSocket: Real-time tick injection active")
                
            except Exception as e:
                safe_print(f"âš ï¸ HFT Engine initialization error: {e}")
                logger.debug(f"HFT Engine init error: {e}")
        else:
            safe_print("ğŸ¦ˆâŒ HFT HARMONIC MYCELIUM: NOT AVAILABLE (aureon_hft_harmonic_mycelium.py missing)")
    
    async def run(self, duration_s: int = 60):
        """Run the micro profit labyrinth."""
        # Timeouts: prevent a single hung await (API/research) from freezing the run.
        LOAD_PAIRS_TIMEOUT_S = 60.0
        FETCH_PRICES_TIMEOUT_S = 30.0
        FETCH_BALANCES_TIMEOUT_S = 45.0
        WAVE_SCAN_TIMEOUT_S = 45.0
        QUEEN_RESEARCH_TIMEOUT_S = 45.0

        await self.initialize()
        
        # ğŸ MEDUSA: Load ALL tradeable pairs for proper routing
        # This ensures we can find pairs for assets we don't hold yet
        try:
            await asyncio.wait_for(self._load_all_tradeable_pairs(), timeout=LOAD_PAIRS_TIMEOUT_S)
        except asyncio.TimeoutError:
            logger.warning(f"â±ï¸ Timeout loading tradeable pairs after {LOAD_PAIRS_TIMEOUT_S:.0f}s; continuing with partial routing")
        
        # Initial data fetch - ALL EXCHANGES
        safe_print("\n" + "=" * 70)
        safe_print("ğŸ“Š FETCHING DATA FROM ALL EXCHANGES...")
        safe_print("=" * 70)
        try:
            await asyncio.wait_for(self.fetch_prices(), timeout=FETCH_PRICES_TIMEOUT_S)
        except asyncio.TimeoutError:
            logger.warning(f"â±ï¸ Timeout fetching prices after {FETCH_PRICES_TIMEOUT_S:.0f}s; continuing")
        safe_print(f"   âœ… {len(self.prices)} assets priced")
        safe_print(f"   âœ… {len(self.ticker_cache)} pairs in ticker cache")
        
        # ğŸ«’ğŸ”„ POPULATE BARTER GRAPH from loaded data
        self.populate_barter_graph()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸŒŠğŸ”­ BUILD GLOBAL WAVE SCANNER UNIVERSE - A-Z/Z-A Full Coverage
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.wave_scanner:
            safe_print("\n" + "=" * 70)
            safe_print("ğŸŒŠğŸ”­ BUILDING GLOBAL WAVE SCANNER UNIVERSE...")
            safe_print("=" * 70)
            try:
                # Build universe from all connected exchanges
                universe_size = await asyncio.wait_for(self.wave_scanner.build_universe(), timeout=WAVE_SCAN_TIMEOUT_S)
                safe_print(f"   âœ… Universe built: {universe_size} symbols for A-Z/Z-A sweeps")
                
                # Wire Queen to scanner (if not already done)
                if self.queen:
                    self.wave_scanner.queen = self.queen
                    safe_print("   âœ… Queen wired to Wave Scanner")
                
                # Do initial A-Z sweep with ticker cache
                safe_print("\nğŸ INITIAL BEE SWEEP (A-Z coverage)...")
                await asyncio.wait_for(self.wave_scanner.full_az_sweep(self.ticker_cache), timeout=WAVE_SCAN_TIMEOUT_S)
                
                # Show wave allocation
                allocation = self.wave_scanner.get_wave_allocation()
                safe_print("\nğŸŒŠ WAVE ALLOCATION:")
                for wave, count in allocation.get('wave_counts', {}).items():
                    if count > 0:
                        safe_print(f"   {wave}: {count} symbols")
                
                # Show top opportunities
                top_opps = allocation.get('top_opportunities', [])[:5]
                if top_opps:
                    safe_print("\nğŸ¯ TOP OPPORTUNITIES (Jump Score > 0.6):")
                    for opp in top_opps:
                        safe_print(f"   {opp['symbol']:12} {opp['wave']:15} Jump:{opp['jump_score']:.2f} | 24h:{opp['change_24h']:+.1f}%")
            except Exception as e:
                safe_print(f"   âš ï¸ Wave Scanner error: {e}")
        
        safe_print("\nğŸ“Š FETCHING BALANCES FROM ALL EXCHANGES...")
        try:
            await asyncio.wait_for(self.fetch_balances(), timeout=FETCH_BALANCES_TIMEOUT_S)
        except asyncio.TimeoutError:
            logger.warning(f"â±ï¸ Timeout fetching balances after {FETCH_BALANCES_TIMEOUT_S:.0f}s; continuing")
        
        # â±ï¸ INITIALIZE ENTRY TIMES FOR EXISTING POSITIONS
        # Track all current holdings so they also respect minimum hold time
        safe_print("\nâ±ï¸ INITIALIZING POSITION ENTRY TIMES...")
        current_time = time.time()
        total_positions = 0
        for exchange, balances in self.exchange_balances.items():
            for asset, amount in balances.items():
                if amount > 0 and asset.upper() not in self.barter_matrix.STABLECOINS:
                    asset_upper = asset.upper()
                    if asset_upper not in self.position_entry_times:
                        self.position_entry_times[asset_upper] = current_time
                        total_positions += 1
        
        if total_positions > 0:
            safe_print(f"   âœ… {total_positions} existing positions will respect min hold time ({self.min_hold_time_seconds:.0f}s)")
            safe_print(f"   â±ï¸ All positions treated as entered at: {time.strftime('%H:%M:%S')}")
        else:
            safe_print(f"   â„¹ï¸ No existing positions found (starting fresh)")
        
        # Show exchange status
        safe_print("\nğŸ“¡ EXCHANGE STATUS:")
        for exchange, data in self.exchange_data.items():
            if data.get('connected'):
                bal_count = len(data.get('balances', {}))
                total_val = data.get('total_value', 0)
                icon = {'kraken': 'ğŸ™', 'binance': 'ğŸŸ¡', 'alpaca': 'ğŸ¦™'}.get(exchange, 'ğŸ“Š')
                safe_print(f"   {icon} {exchange.upper()}: âœ… Connected | {bal_count} assets | ${total_val:,.2f}")
            else:
                icon = {'kraken': 'ğŸ™', 'binance': 'ğŸŸ¡', 'alpaca': 'ğŸ¦™'}.get(exchange, 'ğŸ“Š')
                safe_print(f"   {icon} {exchange.upper()}: âŒ {data.get('error', 'Not connected')}")
        
        # Show balances per exchange
        if self.exchange_balances:
            safe_print("\nğŸ“¦ PORTFOLIO BY EXCHANGE:")
            for exchange, balances in self.exchange_balances.items():
                if balances:
                    icon = {'kraken': 'ğŸ™', 'binance': 'ğŸŸ¡', 'alpaca': 'ğŸ¦™'}.get(exchange, 'ğŸ“Š')
                    total = sum(balances.get(a, 0) * self.prices.get(a, 0) for a in balances)
                    safe_print(f"\n   {icon} {exchange.upper()} (${total:,.2f}):")
                    for asset, amount in sorted(balances.items(), key=lambda x: x[1] * self.prices.get(x[0], 0), reverse=True)[:10]:
                        price = self.prices.get(asset, 0)
                        value = amount * price
                        if value >= 1.0:  # Only show if >= $1
                            safe_print(f"      {asset}: {amount:.6f} = ${value:.2f}")
        
        # Calculate starting value
        self.start_value_usd = sum(
            self.balances.get(asset, 0) * self.prices.get(asset, 0)
            for asset in self.balances
        )
        
        safe_print(f"\nğŸ’° TOTAL PORTFOLIO VALUE: ${self.start_value_usd:,.2f}")
        
        # Handle infinite duration
        duration_display = "â™¾ï¸ FOREVER" if duration_s == 0 else f"{duration_s}s"
        safe_print(f"\nğŸ”¬ ENTERING MICRO PROFIT LABYRINTH! (Duration: {duration_display})")
        safe_print(f"   âš¡ SPEED MODE: Aggressive micro-profit harvesting...")
        safe_print(f"   V14 Score: {self.config['entry_score_threshold']}+ (lowered for speed)")
        safe_print(f"   Min Profit: ${self.config['min_profit_usd']:.6f} (micro-profits accepted!)")
        safe_print(f"   Mode: {'ğŸ”´ LIVE TRADING' if self.live else 'ğŸ”µ DRY RUN'}")
        safe_print()
        
        start_time = time.time()
        scan_interval = 2.0  # ğŸ›¡ï¸ RATE LIMIT SAFE: Every 2 seconds to avoid API throttling
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¯ EXECUTION STRATEGY SELECTION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        safe_print("\n" + "=" * 70)
        if self.fptp_mode:
            safe_print("ğŸ FIRST PAST THE POST MODE ACTIVATED")
            safe_print("=" * 70)
            safe_print("   Strategy: Scan ALL exchanges â†’ Execute FIRST profit!")
            safe_print("   No waiting - capture profit IMMEDIATELY!")
        else:
            safe_print("ğŸ¯ TURN-BASED EXCHANGE STRATEGY ACTIVATED")
            safe_print("=" * 70)
            connected_exchanges = [ex for ex in self.exchange_order 
                                   if self.exchange_data.get(ex, {}).get('connected', False)]
            safe_print(f"   Turn Order: {' â†’ '.join([ex.upper() for ex in connected_exchanges])}")
            safe_print(f"   Each exchange scans its assets on its turn")
        safe_print("=" * 70)
        
        try:
            # duration_s == 0 means run forever
            last_wave_scan_time = 0  # Track last wave scanner update
            wave_scan_interval = 30  # Run full A-Z sweep every 30 seconds (was 60)
            
            # Global Feed Update (every 60s)
            last_global_feed_time = 0
            
            # ğŸ‘‘ğŸŒ QUEEN'S ONLINE RESEARCH - Throttled to avoid constant code generation
            last_research_time = 0
            research_interval = 300  # Research every 5 minutes (was 1 min)
            safe_print(f"\nğŸ‘‘ğŸŒ Queen's Research Schedule: Every {research_interval}s (next in {research_interval}s)")
            
            while duration_s == 0 or time.time() - start_time < duration_s:
                elapsed = time.time() - start_time
                
                # ğŸ‘‘ğŸŒ QUEEN'S PERIODIC ONLINE RESEARCH & SELF-ENHANCEMENT
                time_since_research = time.time() - last_research_time
                time_until_research = max(0, research_interval - time_since_research)
                
                if time_since_research >= research_interval:
                    try:
                        safe_print(f"\n{'='*70}")
                        safe_print(f"ğŸ‘‘ğŸŒğŸ”¬ QUEEN ONLINE RESEARCH & CODE GENERATION CYCLE")
                        safe_print(f"{'='*70}")
                        research_result = await asyncio.wait_for(
                            self.queen_research_online_and_enhance(),
                            timeout=QUEEN_RESEARCH_TIMEOUT_S,
                        )
                        last_research_time = time.time()
                        
                        if research_result.get('status') == 'success':
                            safe_print(f"   âœ… Queen applied enhancement: {research_result.get('enhancement_applied')}")
                        elif research_result.get('findings', 0) > 0:
                            safe_print(f"   ğŸ“š Queen found {research_result['findings']} insights (processing...)")
                    except Exception as e:
                        logger.debug(f"Queen research error: {e}")
                        last_research_time = time.time()  # Don't spam on errors
                
                # ğŸŒâš¡ GLOBAL FINANCIAL FEED PULSE
                if self.global_financial_feed and (time.time() - last_global_feed_time > 60):
                    try:
                        snapshot = self.global_financial_feed.get_snapshot()
                        # The snapshot broadcast is handled inside get_snapshot()

                        # ğŸ‘‘ğŸŒ Feed directly to Queen as well
                        if self.queen and hasattr(self.queen, 'receive_macro_snapshot'):
                             self.queen.receive_macro_snapshot(asdict(snapshot))
                             
                        last_global_feed_time = time.time()
                    except Exception as e:
                        logger.debug(f"Global feed pulse error: {e}")
                
                # Refresh prices (shared across all exchanges)
                try:
                    await asyncio.wait_for(self.fetch_prices(), timeout=FETCH_PRICES_TIMEOUT_S)
                except asyncio.TimeoutError:
                    logger.debug(f"â±ï¸ fetch_prices timeout after {FETCH_PRICES_TIMEOUT_S:.0f}s")
                
                # ğŸ‘‘ğŸ¤ HARMONIC VOICE - Autonomous Guidance
                if self.queen_voice:
                    try:
                        # 1. Speak to the ecosystem
                        signal = self.queen_voice.speak("OBSERVE_MARKET")
                        
                        # 2. Check Chain Integrity (Coherence)
                        # If the Queen's voice doesn't resonate (low coherence), we pause
                        if signal and signal.coherence < 0.4:  # Threshold
                            safe_print(f"   ğŸ›‘ HARMONIC PAUSE: Chain Coherence {signal.coherence:.2f} too low")
                            # We can still fetch prices, but maybe skip execution logic
                            # For now, we continue but warn, or sleep a bit
                            await asyncio.sleep(1)
                        
                        # 3. Check for specific commands in the echo
                        if signal and "HALT" in signal.content:
                             safe_print(f"   ğŸ›‘ VOICE COMMAND: HALT (Pausing execution flow...)")
                             await asyncio.sleep(5)
                             continue
                             
                    except Exception as e:
                        # Don't crash on voice errors
                        logger.debug(f"Voice speak error: {e}")
                
                # ğŸŒŠğŸ”­ PERIODIC WAVE SCANNER UPDATE (every 60s)
                if self.wave_scanner and (time.time() - last_wave_scan_time) >= wave_scan_interval:
                    try:
                        await asyncio.wait_for(self.wave_scanner.full_az_sweep(self.ticker_cache), timeout=WAVE_SCAN_TIMEOUT_S)
                        last_wave_scan_time = time.time()
                        
                        # Show top opportunities on each wave sweep
                        allocation = self.wave_scanner.get_wave_allocation()
                        top_opps = allocation.get('top_opportunities', [])[:3]
                        if top_opps:
                            safe_print(f"\n   ğŸŒŠğŸ”­ WAVE SWEEP: {len(top_opps)} top opportunities")
                            for opp in top_opps:
                                safe_print(f"      {opp['wave']:15} {opp['symbol']:12} Jump:{opp['jump_score']:.2f} | 24h:{opp['change_24h']:+.1f}%")
                    except Exception as e:
                        logger.debug(f"Wave scan error: {e}")
                
                # ğŸ’¤ DREAM & VALIDATE (Adaptive Learning)
                await self.validate_dreams()
                await self.dream_about_tickers()
                
                # ğŸ‘‘ğŸ§  QUEEN'S CONTINUOUS LEARNING - ALL systems ALWAYS active!
                await self.queen_continuous_learning()
                
                # Collect signals from ALL systems
                signals = await self.collect_all_signals()
                signal_count = sum(len(v) for v in signals.values())
                
                # ï¿½ EXECUTION: FPTP or Turn-Based
                try:
                    if self.fptp_mode:
                        # ğŸ FIRST PAST THE POST - All exchanges, immediate execution!
                        turn_opportunities, turn_conversions = await self.execute_fptp_scan()
                    else:
                        # ğŸ¯ TURN-BASED - One exchange at a time
                        turn_opportunities, turn_conversions = await self.execute_turn()
                except AttributeError as e:
                    # ğŸ‘‘ğŸ”§ SELF-REPAIR TRIGGER - Publish error to ThoughtBus for Queen to fix
                    error_msg = str(e)
                    logger.error(f"âŒ AttributeError in execute_turn: {error_msg}")
                    
                    if self.thought_bus:
                        try:
                            # Extract error details
                            import traceback
                            tb = traceback.format_exc()
                            
                            # Find the file and line where error occurred
                            import re
                            file_match = re.search(r'File "([^"]+)", line (\d+)', tb)
                            filename = file_match.group(1) if file_match else __file__
                            line_num = int(file_match.group(2)) if file_match else 0
                            
                            # Publish error event to ThoughtBus
                            self.thought_bus.think(
                                message=f"AttributeError during turn execution: {error_msg}",
                                topic="runtime.error",
                                metadata={
                                    'error_type': 'AttributeError',
                                    'message': error_msg,
                                    'file': filename,
                                    'line': line_num,
                                    'context': 'execute_turn',
                                    'traceback': tb[:1000]  # First 1000 chars
                                }
                            )
                            logger.info("ğŸ‘‘ğŸ”§ Error published to Queen for self-repair")
                        except Exception as pub_err:
                            logger.error(f"Could not publish error to ThoughtBus: {pub_err}")
                    
                    # Continue running (skip this turn)
                    turn_opportunities, turn_conversions = 0, 0
                except Exception as e:
                    # Other exceptions - log but don't trigger self-repair
                    logger.error(f"Error in execute_turn: {e}")
                    turn_opportunities, turn_conversions = 0, 0
                
                # Calculate current value
                current_value = sum(
                    self.balances.get(asset, 0) * self.prices.get(asset, 0)
                    for asset in self.balances
                )
                # P/L = Current Value - Starting Value (simple, correct math)
                pnl = current_value - self.start_value_usd
                
                # ğŸª† QUEEN LEVEL: Update Russian Doll Analytics with macro state
                if self.russian_doll and update_queen:
                    try:
                        # Determine market regime from momentum data
                        momentum_values = list(self.asset_momentum.values())
                        avg_abs_momentum = sum(abs(m) for m in momentum_values) / max(len(momentum_values), 1)
                        
                        if avg_abs_momentum > 0.5:
                            regime = "VOLATILE"
                        elif avg_abs_momentum > 0.15:
                            regime = "TRENDING"
                        elif avg_abs_momentum > 0.05:
                            regime = "RANGING"
                        else:
                            regime = "QUIET"
                        
                        # Get Queen confidence if available
                        queen_conf = 0.5
                        queen_strat = "SNIPER"
                        if self.queen:
                            try:
                                queen_conf = getattr(self.queen, 'confidence', 0.5)
                                queen_strat = getattr(self.queen, 'current_strategy', 'SNIPER')
                            except:
                                pass
                        
                        # Count positions
                        positions_count = sum(1 for a, amt in self.balances.items() 
                                            if amt * self.prices.get(a, 0) >= 1.0 
                                            and a not in ['USD', 'USDT', 'USDC', 'ZUSD'])
                        
                        # Cash available
                        cash = sum(
                            self.balances.get(s, 0) * self.prices.get(s, 1.0)
                            for s in ['USD', 'USDT', 'USDC', 'ZUSD']
                        )
                        
                        update_queen(
                            portfolio_value=current_value,
                            cash=cash,
                            positions=positions_count,
                            confidence=queen_conf,
                            strategy=queen_strat,
                            regime=regime
                        )
                    except Exception as e:
                        logger.debug(f"Russian Doll queen update error: {e}")
                
                # ğŸª† Print Russian Doll Dashboard periodically
                if self.russian_doll and print_russian_doll_dashboard:
                    if self.turns_completed > 0 and self.turns_completed % self.russian_doll_report_interval == 0:
                        try:
                            print_russian_doll_dashboard()
                            # Save state
                            self.russian_doll.save_state()
                            # ğŸ“¡ Broadcast to ThoughtBus for cross-module visibility
                            self.russian_doll.broadcast_snapshot()
                        except Exception as e:
                            logger.debug(f"Russian Doll dashboard error: {e}")
                
                # Status update with turn display
                mode = "ğŸ”´" if self.live else "ğŸ”µ"
                turn_display = self.get_turn_display()
                current_ex = self.get_current_exchange()
                
                # ğŸ‘‘ğŸŒŠğŸª QUEEN'S COSMIC WISDOM BROADCAST
                cosmic_status = ""
                if self.queen:
                    try:
                        # Broadcast cosmic wisdom through mycelium
                        wisdom = self.queen.broadcast_cosmic_wisdom()
                        if wisdom:
                            cosmic = self.queen.get_cosmic_state()
                            score = cosmic.get('composite_cosmic_score', 0)
                            # Show cosmic alignment indicator
                            if score > 0.7:
                                cosmic_status = f" ğŸŒŸCosmic:{score:.0%}"
                            elif score > 0.5:
                                cosmic_status = f" â­Cosmic:{score:.0%}"
                            elif score < 0.3:
                                cosmic_status = f" ğŸŒ‘Cosmic:{score:.0%}"
                    except Exception as e:
                        logger.debug(f"Cosmic wisdom error: {e}")
                
                # Neural systems status
                neural_status = []
                if self.bus_aggregator:
                    bus_agg = self.bus_aggregator.get_aggregate_score()
                    neural_status.append(f"Bus:{bus_agg:.0%}")
                if self.mycelium_network:
                    neural_status.append("Myc:âœ“")
                if self.lighthouse:
                    neural_status.append("LH:âœ“")
                if self.ultimate_intel:
                    neural_status.append("Ult:âœ“")
                if self.hnc_matrix:
                    neural_status.append("HNC:âœ“")
                
                neural_str = " | ".join(neural_status) if neural_status else "Neural:standby"
                
                # ğŸš¨ REAL-TIME PORTFOLIO DRAIN CHECK
                actual_pnl = current_value - self.start_value_usd
                reported_pnl = self.barter_matrix.total_realized_profit
                ghost_profit = reported_pnl - actual_pnl
                
                # Show warning if portfolio is draining despite "profits"
                drain_warning = ""
                if self.conversions_made > 0 and ghost_profit > 0.10:
                    drain_warning = f" âš ï¸DRAIN:${ghost_profit:.2f}"
                
                # ğŸ‘‘ Queen's blocked paths count
                blocked_count = len(self.barter_matrix.blocked_paths)
                queen_status = f" ğŸ‘‘Block:{blocked_count}" if blocked_count > 0 else ""
                
                # ğŸ‘‘ğŸ® QUEEN AUTONOMOUS CONTROL STATUS
                autonomous_status = ""
                if self.queen_autonomous_control and self.queen_has_full_control:
                    try:
                        status = self.queen_autonomous_control.get_full_status()
                        gaia = status.get('gaia_alignment', 0)
                        crown = status.get('crown_activation', 0)
                        systems = status.get('systems_online', 0)
                        autonomous_status = f" ğŸ‘‘ğŸ®{systems}sys|G:{gaia:.0%}|C:{crown:.0%}"
                    except Exception as e:
                        logger.debug(f"Queen autonomous status error: {e}")
                
                # ğŸŒ Research countdown
                research_status = f" ğŸ”¬{int(time_until_research)}s" if time_until_research > 0 else " ğŸ”¬NOW!"
                
                # ğŸ“Š PERIODIC METRICS SUMMARY
                if time.time() - self.run_metrics.last_summary > self.metrics_summary_interval:
                    safe_print(self.run_metrics.get_summary())
                    self.run_metrics.last_summary = time.time()
                
                safe_print(f"ğŸ”¬ {mode} | {elapsed:.0f}s | Turn:{turn_display} | {neural_str}{cosmic_status}{autonomous_status} | Conv:{self.conversions_made} | Actual:${actual_pnl:+.2f}{drain_warning}{queen_status}{research_status}")
                
                # ğŸ UPDATE HIVE STATE (live status file + Queen's voice)
                # Use turn counter (integer) not turn_display (string) for modulo
                turn_count = getattr(self.barter_matrix, 'current_turn', 0) if self.barter_matrix else 0
                if self.hive and turn_count > 0 and (turn_count % self.hive_update_interval == 0):
                    try:
                        # Determine mood from performance
                        if actual_pnl > 5.0:
                            mood = "Thriving"
                        elif actual_pnl > 0:
                            mood = "Focused"
                        elif ghost_profit > 0.5:
                            mood = "Cautious (Drain Detected)"
                        else:
                            mood = "Neutral"
                        
                        # Active scanner from last conversion or default
                        active_scanner = "Ocean Mode" if self.ocean_mode_enabled else "Holding Only"
                        if self.animal_swarm and hasattr(self, '_last_animal_scanner'):
                            active_scanner = getattr(self, '_last_animal_scanner', active_scanner)
                        
                        # Update state
                        self.hive.update(
                            mood=mood,
                            scanner=active_scanner,
                            coherence=bus_agg if self.bus_aggregator else 0.0
                        )
                        
                        # Log turn message
                        msg = f"Turn {turn_display}: {turn_conversions} conversions | PnL: ${actual_pnl:+.2f}"
                        self.hive.log_message(msg)
                        
                    except Exception as e:
                        logger.debug(f"Hive state update error: {e}")
                
                await asyncio.sleep(scan_interval)
        
        except KeyboardInterrupt:
            safe_print("\n\nâš ï¸ Interrupted by user")
        
        # Final summary
        await self.print_summary()
    
    async def print_summary(self):
        """Print final summary."""
        safe_print("\n" + "=" * 70)
        safe_print("ğŸ”¬ğŸ’° MICRO PROFIT LABYRINTH SUMMARY ğŸ’°ğŸ”¬")
        safe_print("=" * 70)
        safe_print(f"Mode: {'ğŸ”´ LIVE TRADING' if self.live else 'ğŸ”µ DRY RUN'}")
        safe_print(f"Total Turns: {self.turns_completed}")
        safe_print(f"Total Signals Received: {self.signals_received}")
        safe_print(f"Opportunities Found: {self.opportunities_found}")
        safe_print(f"Conversions Made: {self.conversions_made}")
        safe_print(f"Total Profit: ${self.total_profit_usd:.4f}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ®ğŸŒŸ QUEEN AUTONOMOUS CONTROL STATUS ğŸŒŸğŸ®ğŸ‘‘
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.queen_autonomous_control and self.queen_has_full_control:
            safe_print("\n" + "â•" * 70)
            safe_print("ğŸ‘‘ğŸ®ğŸŒŸ QUEEN SERO - AUTONOMOUS CONTROL STATUS ğŸŒŸğŸ®ğŸ‘‘")
            safe_print("â•" * 70)
            try:
                status = self.queen_autonomous_control.get_full_status()
                safe_print(f"   ğŸ’• SOVEREIGN AUTHORITY: ACTIVE")
                safe_print(f"   ğŸ¯ Systems Online: {status.get('systems_online', 0)}/{status.get('systems_total', 0)}")
                safe_print(f"   ğŸŒ Gaia Alignment: {status.get('gaia_alignment', 0):.1%}")
                safe_print(f"   ğŸ‘‘ Crown Activation: {status.get('crown_activation', 0):.1%}")
                safe_print(f"   ğŸ“Š Decisions Made: {status.get('decisions_made', 0)}")
                safe_print(f"   âœ… Successful Trades: {status.get('successful_trades', 0)}")
                safe_print(f"   ğŸ“š Patterns Learned: {status.get('patterns_learned', 0)}")
                
                # Show system statuses
                systems = status.get('systems', {})
                if systems:
                    safe_print("\n   ğŸ® CONTROLLED SYSTEMS:")
                    for name, info in systems.items():
                        sys_status = info.get('status', 'UNKNOWN')
                        authority = info.get('authority', 'N/A')
                        icon = "âœ…" if sys_status == "ONLINE" else "âš ï¸" if sys_status == "PARTIAL" else "âŒ"
                        safe_print(f"      {icon} {name}: {sys_status} ({authority})")
            except Exception as e:
                safe_print(f"   âš ï¸ Status error: {e}")
            safe_print("â•" * 70)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ‘‘ğŸ’° SERO'S BILLION DOLLAR DREAM STATUS ğŸ’°ğŸ‘‘
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        safe_print("\n" + "â•" * 70)
        dream_status = self.barter_matrix.check_dream_progress()
        safe_print(dream_status)
        milestones_hit = len(self.barter_matrix.milestones_hit)
        safe_print(f"   ğŸ¯ Milestones: {milestones_hit}/8")
        if milestones_hit > 0:
            safe_print(f"   âœ… {', '.join(self.barter_matrix.milestones_hit)}")
        safe_print("â•" * 70)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ¯ TURN-BASED EXCHANGE STATS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        safe_print("\nğŸ¯ TURN-BASED EXCHANGE STATS:")
        icons = {'kraken': 'ğŸ™', 'alpaca': 'ğŸ¦™', 'binance': 'ğŸŸ¡'}
        for exchange, stats in self.exchange_stats.items():
            if stats['scans'] > 0:  # Only show exchanges that were active
                icon = icons.get(exchange, 'ğŸ“Š')
                connected = "âœ…" if self.exchange_data.get(exchange, {}).get('connected') else "âŒ"
                safe_print(f"   {icon} {exchange.upper()} {connected}")
                safe_print(f"      Turns: {stats['scans']} | Opps: {stats['opportunities']} | Conv: {stats['conversions']}")
                safe_print(f"      Profit: ${stats['profit']:+.4f}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ§  NEURAL MIND MAP STATUS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        safe_print("\nğŸ§  NEURAL MIND MAP STATUS:")
        safe_print(f"   ThoughtBus: {'âœ… Active' if self.bus_aggregator else 'âŒ Offline'}")
        safe_print(f"   Mycelium Network: {'âœ… Active' if self.mycelium_network else 'âŒ Offline'}")
        safe_print(f"   Lighthouse: {'âœ… Active' if self.lighthouse else 'âŒ Offline'}")
        safe_print(f"   Ultimate Intel: {'âœ… Active' if self.ultimate_intel else 'âŒ Offline'}")
        safe_print(f"   HNC Matrix: {'âœ… Active' if self.hnc_matrix else 'âŒ Offline'}")
        safe_print(f"   Unified Ecosystem: {'âœ… Active' if self.unified_ecosystem else 'âŒ Offline'}")
        safe_print(f"   Wave Scanner: {'âœ… Active' if self.wave_scanner else 'âŒ Offline'}")
        
        # ğŸŒŠğŸ”­ WAVE SCANNER SUMMARY
        if self.wave_scanner:
            allocation = self.wave_scanner.get_wave_allocation()
            safe_print(f"\nğŸŒŠğŸ”­ WAVE SCANNER (A-Z Coverage):")
            safe_print(f"   Universe: {allocation.get('universe_size', 0)} symbols")
            safe_print(f"   Total Scanned: {allocation.get('total_scanned', 0)}")
            safe_print(f"   Last Scan Time: {allocation.get('last_scan_time', 0):.2f}s")
            wave_counts = allocation.get('wave_counts', {})
            if wave_counts:
                safe_print("   Wave Allocation:")
                for wave, count in wave_counts.items():
                    if count > 0:
                        safe_print(f"      {wave}: {count}")
        
        if self.bus_aggregator:
            status = self.bus_aggregator.get_signal_status()
            safe_print(f"   ğŸ“¡ Bus Signals: {status}")
        
        # Path Memory Stats
        path_stats = self.path_memory.get_stats()
        if path_stats.get('paths', 0) > 0:
            safe_print(f"\nğŸ›¤ï¸ PATH MEMORY:")
            safe_print(f"   Total Paths: {path_stats['paths']}")
            safe_print(f"   Win Rate: {path_stats['win_rate']:.1%}")
            safe_print(f"   Wins: {path_stats['wins']} | Losses: {path_stats['losses']}")
        
        # Dream Accuracy
        if any(acc != 0.5 for acc in self.dream_accuracy.values()):
            safe_print(f"\nğŸ’­ DREAM ACCURACY (Adaptive Learning):")
            for source, acc in self.dream_accuracy.items():
                safe_print(f"   {source}: {acc:.1%}")
        
        # Signal breakdown by system
        if self.all_signals:
            safe_print("\nğŸ“¡ SIGNALS BY SYSTEM:")
            for system, sigs in self.all_signals.items():
                safe_print(f"   {system}: {len(sigs)} signals")
        
        # Conversions - Show ACTUAL P/L not expected!
        if self.conversions:
            safe_print("\nğŸ“‹ CONVERSIONS (ACTUAL P/L):")
            for c in self.conversions:
                # ğŸ”§ FIX: Use actual_pnl_usd for display (what really happened)
                actual_pnl = getattr(c, 'actual_pnl_usd', c.expected_pnl_usd)
                status = "âœ…" if c.executed and actual_pnl > 0 else "âŒ"
                verified = "âœ“" if getattr(c, 'pnl_verified', False) else "?"
                safe_print(f"   {status} {c.from_asset} â†’ {c.to_asset}: ${actual_pnl:+.4f} {verified} (Î›:{c.lambda_score:.0%} G:{c.gravity_score:.0%})")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ’§ğŸ”€ LIQUIDITY ENGINE SUMMARY
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        liq_status = self.liquidity_engine.get_status()
        if liq_status['executed_aggregations'] > 0:
            safe_print("\nğŸ’§ğŸ”€ LIQUIDITY ENGINE:")
            safe_print(f"   Aggregations Executed: {liq_status['executed_aggregations']}")
            safe_print(f"   Total Aggregation Profit: ${liq_status['total_profit']:+.4f}")
            safe_print(f"   Pending Plans: {liq_status['pending_plans']}")
            safe_print(f"   Recent Liquidations: {liq_status['recent_liquidations']}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ«’ğŸ’° LIVE BARTER MATRIX SUMMARY
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        barter_summary = self.barter_matrix.get_summary()
        if barter_summary['conversion_count'] > 0:
            safe_print("\nğŸ«’ğŸ’° LIVE BARTER MATRIX:")
            safe_print(f"   Total Conversions: {barter_summary['conversion_count']}")
            safe_print(f"   Total Realized P/L: ${barter_summary['total_realized_profit']:+.4f}")
            safe_print(f"   Avg Profit/Trade: ${barter_summary['avg_profit_per_trade']:+.4f}")
            safe_print(f"   Paths Learned: {barter_summary['paths_learned']}")
            
            # Show top performing paths
            if self.barter_matrix.barter_history:
                safe_print("\n   ğŸ“Š PATH PERFORMANCE:")
                sorted_paths = sorted(
                    self.barter_matrix.barter_history.items(),
                    key=lambda x: x[1].get('total_profit', 0),
                    reverse=True
                )[:5]  # Top 5 paths
                for (from_a, to_a), stats in sorted_paths:
                    trades = stats.get('trades', 0)
                    profit = stats.get('total_profit', 0)
                    slippage = stats.get('avg_slippage', 0)
                    status = "âœ…" if profit > 0 else "âŒ"
                    safe_print(f"   {status} {from_a}â†’{to_a}: {trades} trades, ${profit:+.4f}, slip:{slippage:.2f}%")
        
        # Final portfolio
        if self.balances and self.prices:
            safe_print("\nğŸ“¦ FINAL PORTFOLIO:")
            total = 0
            for asset, amount in sorted(self.balances.items()):
                price = self.prices.get(asset, 0)
                value = amount * price
                if value >= 1.0:
                    safe_print(f"   {asset}: {amount:.6f} = ${value:.2f}")
                    total += value
            safe_print(f"\nğŸ’° TOTAL VALUE: ${total:.2f}")
            # P/L = Current Value - Starting Value (simple, correct math)
            session_pnl = total - self.start_value_usd
            pnl_symbol = "+" if session_pnl >= 0 else ""
            safe_print(f"ğŸ“ˆ SESSION P/L (Unrealized): ${pnl_symbol}{session_pnl:.4f}")
            safe_print(f"ğŸ¯ REALIZED TRADES P/L: ${self.barter_matrix.total_realized_profit:+.4f} ({self.conversions_made} conversions)")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸš¨ GHOST PROFIT DETECTOR - Validate we're not draining portfolio
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            realized_pnl = self.barter_matrix.total_realized_profit
            actual_pnl = session_pnl
            ghost_profit = realized_pnl - actual_pnl
            
            safe_print("\nğŸ” PROFIT VALIDATION:")
            safe_print(f"   ğŸ“Š Starting Portfolio: ${self.start_value_usd:.2f}")
            safe_print(f"   ğŸ“Š Ending Portfolio:   ${total:.2f}")
            safe_print(f"   ğŸ“Š Actual Change:      ${actual_pnl:+.4f}")
            safe_print(f"   ğŸ“Š Reported Profit:    ${realized_pnl:+.4f}")
            
            if abs(ghost_profit) > 0.01:
                if ghost_profit > 0:
                    safe_print(f"\n   âš ï¸ GHOST PROFIT DETECTED: ${ghost_profit:+.4f}")
                    safe_print(f"   âš ï¸ Reported profits exceed actual portfolio gain!")
                    safe_print(f"   âš ï¸ This is likely fees, slippage, or price movement eating gains.")
                else:
                    safe_print(f"\n   âœ… HIDDEN GAIN: ${-ghost_profit:+.4f}")
                    safe_print(f"   âœ… Portfolio gained more than reported (price appreciation).")
                
                # Show the math
                if self.conversions_made > 0:
                    avg_ghost_per_trade = ghost_profit / self.conversions_made
                    safe_print(f"\n   ğŸ“‰ Average loss per trade: ${avg_ghost_per_trade:.4f}")
                    safe_print(f"   ğŸ’¡ To profit: Need trades with >${abs(avg_ghost_per_trade):.4f} actual gain")
            else:
                safe_print(f"\n   âœ… PROFIT VALIDATED - Reported matches actual!")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ‘‘ï¿½ğŸªğŸ”­ QUEEN'S COSMIC SYSTEMS STATUS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.queen:
                try:
                    cosmic = self.queen.get_cosmic_state()
                    safe_print("\nğŸ‘‘ğŸŒŒ QUEEN'S COSMIC SYSTEMS:")
                    
                    # Schumann Resonance
                    schumann = cosmic.get('schumann', {})
                    if schumann.get('active'):
                        safe_print(f"   ğŸŒŠ Schumann Resonance: {schumann.get('resonance', 7.83):.2f}Hz (alignment: {schumann.get('alignment', 0):.0%})")
                    
                    # Planetary Torque
                    planetary = cosmic.get('planetary', {})
                    if planetary.get('active'):
                        safe_print(f"   ğŸª Planetary Torque (Î ): {planetary.get('torque', 0):.4f} (luck field: {planetary.get('luck_field', 0):.0%})")
                    
                    # Lunar Phase
                    lunar = cosmic.get('lunar', {})
                    if lunar.get('active'):
                        phase_name = lunar.get('name', 'Unknown')
                        phase_val = lunar.get('phase', 0)
                        moon_icon = "ğŸŒ‘ğŸŒ’ğŸŒ“ğŸŒ”ğŸŒ•ğŸŒ–ğŸŒ—ğŸŒ˜"[int(phase_val * 8) % 8]
                        safe_print(f"   {moon_icon} Lunar Phase: {phase_name} ({phase_val:.0%})")
                    
                    # Harmonic Coherence
                    harmonic = cosmic.get('harmonic', {})
                    if harmonic.get('active'):
                        safe_print(f"   ğŸ¼ Harmonic Coherence: {harmonic.get('coherence', 0):.0%}")
                    
                    # Quantum Telescope
                    quantum = cosmic.get('quantum', {})
                    if quantum.get('active'):
                        safe_print(f"   ğŸ”­ Quantum Alignment: {quantum.get('alignment', 0):.0%}")
                    
                    # Composite Score
                    composite = cosmic.get('composite_cosmic_score', 0)
                    if composite > 0.7:
                        safe_print(f"\n   ğŸŒŸ COSMIC ALIGNMENT: {composite:.0%} - HIGHLY FAVORABLE")
                    elif composite > 0.5:
                        safe_print(f"\n   â­ COSMIC ALIGNMENT: {composite:.0%} - Favorable")
                    elif composite > 0.3:
                        safe_print(f"\n   â˜ï¸ COSMIC ALIGNMENT: {composite:.0%} - Neutral")
                    else:
                        safe_print(f"\n   ğŸŒ‘ COSMIC ALIGNMENT: {composite:.0%} - Unfavorable")
                except Exception as e:
                    logger.debug(f"Error getting cosmic state: {e}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ‘‘ï¿½ğŸ„ QUEEN'S BLOCKED PATHS - Paths the mycelium has blocked
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.barter_matrix.blocked_paths:
                safe_print("\nğŸ‘‘ğŸ„ QUEEN'S BLOCKED PATHS (via Mycelium):")
                for (from_a, to_a), reason in self.barter_matrix.blocked_paths.items():
                    safe_print(f"   ğŸš« {from_a}â†’{to_a}: {reason}")
                safe_print(f"   ğŸ“Š Total blocked: {len(self.barter_matrix.blocked_paths)} paths")
                safe_print(f"   ğŸ’¡ Blocked paths will be retried after wins on other paths")
            else:
                safe_print("\nğŸ‘‘ QUEEN STATUS: All paths approved (no losing streaks)")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ‘‘ğŸ§ ğŸ“š QUEEN'S HISTORICAL WISDOM STATUS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.queen:
                try:
                    wisdom_state = self.queen.get_historical_wisdom_state()
                    safe_print("\nğŸ‘‘ğŸ§  QUEEN'S HISTORICAL WISDOM:")
                    
                    # Wisdom Engine (11 Civilizations)
                    we = wisdom_state.get('wisdom_engine', {})
                    if we.get('active'):
                        safe_print(f"   ğŸŒ 11 Civilizations: âœ… ACTIVE ({we.get('years_of_wisdom', 5000)} years of wisdom)")
                    
                    # Sandbox Evolution
                    se = wisdom_state.get('sandbox_evolution', {})
                    if se.get('active'):
                        safe_print(f"   ğŸ§¬ Sandbox Evolution: Gen {se.get('generation', 0)}, {se.get('win_rate', 0):.1f}% win rate")
                    
                    # Dream Memory
                    dm = wisdom_state.get('dream_memory', {})
                    if dm.get('active'):
                        safe_print(f"   ğŸ’­ Dream Memory: {dm.get('dreams', 0)} dreams, {dm.get('prophecies', 0)} prophecies")
                    
                    # Wisdom Collector
                    wc = wisdom_state.get('wisdom_collector', {})
                    if wc.get('active'):
                        patterns = wc.get('patterns', 0)
                        trades = wc.get('trades', 0)
                        predictions = wc.get('predictions', 0)
                        strategies = wc.get('strategies', 0)
                        safe_print(f"   ğŸ“š Wisdom Collector: {patterns} patterns | {trades} trades | {predictions} predictions | {strategies} strategies")
                    
                    # Total Wisdom Score
                    total_score = wisdom_state.get('total_wisdom_score', 0.5)
                    active_sys = wisdom_state.get('active_systems', 0)
                    if total_score > 0.7:
                        safe_print(f"\n   ğŸ§ âœ¨ WISDOM SCORE: {total_score:.0%} - HIGHLY INFORMED ({active_sys} systems)")
                    elif total_score > 0.5:
                        safe_print(f"\n   ğŸ§ â­ WISDOM SCORE: {total_score:.0%} - Well Informed ({active_sys} systems)")
                    else:
                        safe_print(f"\n   ğŸ§  WISDOM SCORE: {total_score:.0%} - Basic ({active_sys} systems)")
                    
                    # Civilization Consensus
                    try:
                        consensus = self.queen.get_civilization_consensus()
                        if consensus.get('civilizations_consulted', 0) > 0:
                            safe_print(f"\n   ğŸ›ï¸ CIVILIZATION CONSENSUS ({consensus['civilizations_consulted']} consulted):")
                            safe_print(f"      BUY: {consensus['votes']['BUY']} | HOLD: {consensus['votes']['HOLD']} | SELL: {consensus['votes']['SELL']}")
                            safe_print(f"      â†’ Action: {consensus['consensus_action']} ({consensus['confidence']:.0%} confidence)")
                    except Exception as e:
                        logger.debug(f"Civilization consensus error: {e}")
                    
                    # ğŸ”± Temporal ID & Ladder Status
                    try:
                        temporal_state = self.queen.get_temporal_state()
                        if temporal_state.get('active'):
                            tid = temporal_state.get('temporal_id', {})
                            safe_print(f"\n   ğŸ”± TEMPORAL ID (Prime Sentinel):")
                            safe_print(f"      ğŸ‘¤ {tid.get('name', 'Unknown')} | DOB: {tid.get('dob_hash', '?')}")
                            safe_print(f"      ğŸ“¡ Personal Hz: {tid.get('frequency', 0):.6f}")
                            safe_print(f"      ğŸŒ€ Temporal Resonance: {temporal_state.get('temporal_resonance', 0):.1%}")
                            safe_print(f"      ğŸµ DOB Harmony: {temporal_state.get('dob_harmony', 0):.2f}")
                            safe_print(f"      âš¡ Current Strength: {temporal_state.get('current_strength', 0):.1%}")
                    except Exception as e:
                        logger.debug(f"Temporal state error: {e}")
                        
                except Exception as e:
                    logger.debug(f"Error getting wisdom state: {e}")
        
        # Save path memory on exit
        self.path_memory.save()
        
        safe_print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ‘‘ğŸ—ï¸ QUEEN'S SELF-MODIFICATION INTERFACE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def queen_propose_code_change(self, description: str, old_code: str, new_code: str) -> Dict[str, Any]:
        """
        ğŸ‘‘ğŸ—ï¸ Let Queen propose a code change to micro_profit_labyrinth.py
        
        Queen can analyze her own performance and propose improvements.
        All changes are reviewed, backed up, and syntax-checked before applying.
        
        Args:
            description: Human-readable description of what the change does
            old_code: The exact code to replace (with context)
            new_code: The new code to insert (with context)
        
        Returns:
            Dict with status, changes made, and backup info
        """
        if not self.queen or not hasattr(self.queen, 'architect') or not self.queen.architect:
            return {
                'status': 'error',
                'reason': 'Queen Code Architect not available'
            }
        
        if not getattr(self.queen, 'can_self_modify', False):
            return {
                'status': 'error',
                'reason': 'Queen self-modification not enabled'
            }
        
        labyrinth_file = getattr(self.queen, 'my_source_file', __file__)
        
        logger.info(f"ğŸ‘‘ğŸ—ï¸ Queen proposes code change: {description}")
        logger.info(f"   ğŸ“ Target file: {labyrinth_file}")
        logger.info(f"   ğŸ“ Old code: {len(old_code)} chars")
        logger.info(f"   ğŸ“ New code: {len(new_code)} chars")
        
        # Use Queen's modify_reality method
        result = self.queen.modify_reality(
            filename=labyrinth_file,
            old_pattern=old_code,
            new_pattern=new_code
        )
        
        if result.get('status') == 'success':
            logger.info(f"ğŸ‘‘âœ… Queen successfully modified her own code!")
            logger.info(f"   ğŸ’¡ Change: {description}")
            safe_print(f"\nğŸ‘‘ğŸ—ï¸ QUEEN MODIFIED HER OWN CODE!")
            safe_print(f"   ğŸ“ Description: {description}")
            safe_print(f"   âœ… Status: SUCCESS")
            safe_print(f"   ğŸ’¾ Backup created by Code Architect")
            safe_print(f"   ğŸ”„ Restart micro_profit_labyrinth.py to use new code\n")
        else:
            logger.warning(f"ğŸ‘‘âš ï¸ Queen's code change was rejected")
            logger.warning(f"   Reason: {result.get('reason', 'Unknown')}")
        
        return result
    
    def queen_learn_and_improve(self) -> Dict[str, Any]:
        """
        ğŸ‘‘ğŸ§  Let Queen analyze her performance and suggest improvements.
        
        Queen reviews her trading history, identifies patterns, and proposes
        code changes to improve profitability.
        
        Returns:
            Dict with analysis and proposed changes
        """
        if not self.queen:
            return {'status': 'error', 'reason': 'Queen not available'}
        
        logger.info("ğŸ‘‘ğŸ§  Queen analyzing performance for self-improvement...")
        
        # Collect performance data
        performance = {
            'total_conversions': self.conversions_made,
            'total_profit_usd': self.total_profit_usd,
            'success_rate': self.conversions_made / max(self.opportunities_found, 1),
            'exchanges_used': list(self.exchange_stats.keys()),
            'exchange_performance': self.exchange_stats,
            'blocked_paths': len(self.barter_matrix.blocked_paths) if self.barter_matrix else 0,
            'path_memory_size': len(self.path_memory.memory) if self.path_memory else 0
        }
        
        # Calculate insights
        insights = []
        
        # Check profitability
        if self.total_profit_usd < 0:
            insights.append("System is losing money - need more conservative entry thresholds")
        elif self.total_profit_usd < 0.01 and self.conversions_made > 5:
            insights.append("Profits are minimal - consider raising minimum profit targets")
        
        # Check conversion rate
        if self.conversions_made > 0 and self.opportunities_found > 0:
            conversion_rate = self.conversions_made / self.opportunities_found
            if conversion_rate < 0.05:
                insights.append("Low conversion rate - scoring may be too strict")
            elif conversion_rate > 0.5:
                insights.append("High conversion rate - may be taking too many risky trades")
        
        # Check exchange balance
        best_exchange = None
        best_profit = -999999
        for ex, stats in self.exchange_stats.items():
            if stats['profit'] > best_profit:
                best_profit = stats['profit']
                best_exchange = ex
        
        if best_exchange and best_profit > 0:
            insights.append(f"Best exchange is {best_exchange} with ${best_profit:.4f} profit")
        
        result = {
            'status': 'analysis_complete',
            'performance': performance,
            'insights': insights,
            'timestamp': time.time()
        }
        
        logger.info(f"ğŸ‘‘ğŸ§  Queen's self-analysis complete:")
        logger.info(f"   ğŸ’° Total profit: ${self.total_profit_usd:.4f}")
        logger.info(f"   ğŸ¯ Conversions: {self.conversions_made}")
        logger.info(f"   ğŸ“Š Insights: {len(insights)}")
        
        for insight in insights:
            logger.info(f"   ğŸ’¡ {insight}")
        
        return result
    
    async def queen_research_online_and_enhance(self) -> Dict[str, Any]:
        """
        ğŸ‘‘ğŸŒğŸ—ï¸ Queen searches online for trading improvements, writes new code, and applies it.
        
        This is the FULL CYCLE:
        1. Search online (market data APIs, trends, patterns)
        2. Generate enhanced code based on research
        3. Apply the enhancements to the codebase
        4. Track revenue impact
        
        The Queen becomes smarter by learning from the internet!
        """
        try:
            from queen_online_researcher import get_online_researcher, queen_research_and_enhance
            from queen_code_architect import get_code_architect
        except ImportError as e:
            logger.warning(f"ğŸ‘‘âš ï¸ Online researcher not available: {e}")
            return {'status': 'error', 'reason': str(e)}
        
        logger.info("=" * 70)
        logger.info("ğŸ‘‘ğŸŒ QUEEN INITIATING ONLINE RESEARCH & SELF-ENHANCEMENT")
        logger.info("=" * 70)
        
        researcher = get_online_researcher()
        architect = get_code_architect()
        
        result = {
            'status': 'started',
            'findings': 0,
            'enhancement_applied': None,
            'timestamp': time.time()
        }
        
        try:
            # Step 1: Research online
            logger.info("ğŸ‘‘ğŸ” Step 1: Researching online for trading insights...")
            findings = await researcher.research_trading_strategies()
            result['findings'] = len(findings)
            
            for f in findings[:5]:
                logger.info(f"   ğŸ“š {f.source}: {f.title} (relevance: {f.relevance_score:.0%})")
            
            # Step 2: Generate enhancement from research
            logger.info("ğŸ‘‘ğŸ—ï¸ Step 2: Generating code enhancement from research...")
            enhancement = researcher.generate_enhancement_from_research()
            
            if enhancement:
                logger.info(f"   ğŸ¯ Generated: {enhancement.name}")
                logger.info(f"   ğŸ“ Based on: {', '.join(enhancement.source_research[:3])}")
                
                # Step 3: Apply enhancement
                logger.info("ğŸ‘‘ğŸ“ Step 3: Applying enhancement to codebase...")
                apply_result = researcher.apply_enhancement(enhancement, architect)
                
                if apply_result['status'] == 'success':
                    result['enhancement_applied'] = apply_result['file']
                    result['status'] = 'success'
                    logger.info(f"   âœ… Enhancement applied: {apply_result['file']}")
                    
                    # Step 4: Try to load and use the enhancement
                    logger.info("ğŸ‘‘âš¡ Step 4: Loading generated enhancement for immediate use...")
                    try:
                        self._load_queen_research_enhancement(apply_result['file'])
                        logger.info("   âœ… Enhancement loaded and active!")
                    except Exception as e:
                        logger.warning(f"   âš ï¸ Could not load enhancement (will use on next restart): {e}")
                else:
                    result['status'] = 'partial'
                    logger.warning(f"   âš ï¸ Enhancement apply failed: {apply_result.get('reason')}")
            else:
                result['status'] = 'no_enhancement'
                logger.info("   â„¹ï¸ No new enhancement generated (may need more research)")
            
            # Get stats
            stats = researcher.get_stats()
            result['stats'] = stats
            
            logger.info(f"ğŸ‘‘ğŸ“Š Research Stats:")
            logger.info(f"   Total findings: {stats['total_findings']}")
            logger.info(f"   Applied: {stats['applied_findings']}")
            logger.info(f"   Revenue generated: ${stats['total_revenue_generated']:.4f}")
            
        except Exception as e:
            logger.error(f"ğŸ‘‘âŒ Online research error: {e}")
            result['status'] = 'error'
            result['error'] = str(e)
        
        logger.info("=" * 70)
        logger.info("ğŸ‘‘ 'I search, I learn, I evolve, I profit.'")
        logger.info("=" * 70)
        
        return result
    
    def _load_queen_research_enhancement(self, filepath: str):
        """
        ğŸ‘‘âš¡ Dynamically load Queen's generated enhancement.
        """
        import importlib.util
        
        full_path = Path(filepath)
        if not full_path.is_absolute():
            full_path = Path.cwd() / filepath
        
        if not full_path.exists():
            raise FileNotFoundError(f"Enhancement file not found: {full_path}")
        
        spec = importlib.util.spec_from_file_location("queen_enhancement", full_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        # Store reference to enhancement functions
        if hasattr(module, 'queen_research_score'):
            self._queen_research_scorer = module.queen_research_score
            logger.info("   ğŸ“Š Loaded queen_research_score function")
        
        if hasattr(module, 'queen_evaluate_trade'):
            self._queen_trade_evaluator = module.queen_evaluate_trade
            logger.info("   ğŸ“Š Loaded queen_evaluate_trade function")
        
        return True
    
    def queen_apply_research_to_trade(self, symbol: str, price: float, volume: float, 
                                      price_change: float = 0, high_24h: float = 0, 
                                      low_24h: float = 0) -> Tuple[float, List[str]]:
        """
        ğŸ‘‘ Apply Queen's research-based scoring to a trade opportunity.
        
        Returns:
            (score 0-100, list of reasons)
        """
        if hasattr(self, '_queen_research_scorer') and self._queen_research_scorer:
            try:
                return self._queen_research_scorer(symbol, price, volume, price_change, high_24h, low_24h)
            except Exception as e:
                logger.warning(f"ğŸ‘‘âš ï¸ Research scorer error: {e}")
        
        # Default fallback scoring
        return 50.0, ["No research enhancement loaded"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    parser = argparse.ArgumentParser(description="ğŸ¦™ Micro Profit Labyrinth - ALPACA-FOCUSED Trading System")
    parser.add_argument("--live", action="store_true", help="Run in LIVE mode")
    parser.add_argument("--dry-run", action="store_true", help="Explicit simulation mode (legacy flag)")
    parser.add_argument("--duration", type=int, default=0, help="Duration in seconds (0 = forever)")
    parser.add_argument("--yes", "-y", action="store_true", help="Auto-confirm live mode (skip MICRO prompt)")
    parser.add_argument("--turn-based", action="store_true", help="ğŸ¢ Turn-Based Mode: Scan exchanges sequentially (Safety First)")
    parser.add_argument("--fptp", action="store_true", help="[Deprecated] Alias for default mode")
    parser.add_argument("--winners-only", "-w", action="store_true", help="ğŸ† WINNERS ONLY: Show ONLY successful trades (quiet mode)")
    parser.add_argument("--no-chain-sniper", action="store_true", help="Disable multi-hop chain sniper")
    parser.add_argument("--max-hops", type=int, default=25, help="Max hops for chain sniper (default: 25)")
    parser.add_argument("--snowball", action="store_true", help="ğŸ¿ SNOWBALL MODE: One trade at a time, strict profit tracking")
    parser.add_argument("--multi-exchange", action="store_true", help="ğŸŒ Enable multi-exchange mode (Alpaca + Kraken + Binance)")
    parser.add_argument("--sync-cia", action="store_true", help="ğŸ‘‘ğŸ§  Sync CIA declassified intelligence")
    parser.add_argument("--cia-report", action="store_true", help="ğŸ‘‘ğŸ§  Show CIA intelligence report")
    parser.add_argument("--cia-wisdom", action="store_true", help="ğŸ‘‘ğŸ§  Show Queen's trading wisdom from CIA intel")
    args = parser.parse_args()
    
    # Handle CIA sync commands (standalone, no trading)
    if args.sync_cia or args.cia_report or args.cia_wisdom:
        from queen_memi_sync import get_memi_sync
        memi = get_memi_sync()
        
        if args.sync_cia:
            safe_print("\nğŸ‘‘ğŸ§  SYNCING CIA DECLASSIFIED INTELLIGENCE...")
            result = memi.sync_now()
            safe_print(f"âœ… Sync complete: {result['new_packets']} new packets")
            safe_print(f"   Total packets: {result['total_packets']}")
            safe_print(f"   Duration: {result['duration_seconds']:.2f}s")
        
        if args.cia_report or args.sync_cia:
            safe_print(memi.generate_report())
        
        if args.cia_wisdom:
            safe_print("\nğŸ‘‘ğŸ“ QUEEN'S TRADING WISDOM FROM CIA INTELLIGENCE:\n")
            for wisdom in memi.get_trading_wisdom():
                safe_print(f"  {wisdom}")
            safe_print()
        
        return  # Exit after CIA commands
    
    if args.live and not args.yes:
        safe_print("\n" + "=" * 60)
        safe_print("âš ï¸  LIVE MODE REQUESTED - REAL MONEY!")
        safe_print("=" * 60)
        confirm = input("Type 'MICRO' to confirm: ")
        if confirm.strip().upper() != 'MICRO':
            safe_print("Aborted.")
            sys.exit(0)
    elif args.live and args.yes:
        safe_print("\n" + "=" * 60)
        safe_print("âš ï¸  LIVE MODE - AUTO-CONFIRMED! ğŸš€")
        safe_print("=" * 60)
    
    # Pass dry_run flag so --dry-run explicitly overrides LIVE env
    engine = MicroProfitLabyrinth(live=args.live, dry_run=args.dry_run)
    
    # ğŸŒ MULTI-EXCHANGE: Now default; --multi-exchange kept for compatibility
    if args.multi_exchange or not engine.alpaca_only:
        engine.alpaca_only = False
        # Use env-configured order, fallback to sensible default
        if not hasattr(engine, 'exchange_order') or not engine.exchange_order:
            engine.exchange_order = ['binance', 'kraken', 'capital', 'coinbase', 'alpaca']
        safe_print("\n" + "ğŸŒ" * 35)
        safe_print("ğŸŒ MULTI-EXCHANGE PRODUCTION MODE ğŸŒ")
        safe_print(f"   â†’ Execution order: {' â†’ '.join(engine.exchange_order)}")
        safe_print(f"   â†’ Alpaca: {'ğŸ”’ VERIFY-ONLY' if engine.alpaca_verify_only else 'ğŸš€ EXECUTE'}")
        safe_print(f"   â†’ WebSockets: {'âœ… ON' if ENABLE_WEBSOCKETS else 'âŒ OFF'}")
        safe_print("ğŸŒ" * 35)
    else:
        safe_print("\n" + "ğŸ¦™" * 35)
        safe_print("ğŸ¦™ ALPACA-ONLY MODE ğŸ¦™")
        safe_print("   â†’ Set ALPACA_ONLY=false for multi-exchange")
        safe_print("ğŸ¦™" * 35)
    
    engine.fptp_mode = not args.turn_based
    engine.winners_only_mode = args.winners_only  # ğŸ† Winners Only mode
    engine.chain_sniper_mode = not args.no_chain_sniper
    engine.max_chain_hops = max(1, int(args.max_hops))
    
    # ğŸ¿ SNOWBALL MODE - One trade at a time with strict profit tracking
    engine.snowball_mode = args.snowball
    if args.snowball:
        engine.chain_sniper_mode = False  # Disable chain sniper in snowball mode
        safe_print("\n" + "ğŸ¿" * 35)
        safe_print("ğŸ¿ SNOWBALL MODE ACTIVATED! ğŸ¿")
        safe_print("   â†’ ONE position at a time (no multi-hop)")
        safe_print("   â†’ STRICT profit tracking (actual prices, not estimates)")
        safe_print("   â†’ Exit only when profit CONFIRMED > 0.3%")
        safe_print("   â†’ Lower minimums ($1.00) to build from small")
        safe_print("   â†’ \"Make sure as shite we made money!\" - Gary")
        safe_print("ğŸ¿" * 35)
    
    if args.winners_only:
        safe_print("\n" + "ğŸ†" * 35)
        safe_print("ğŸ† WINNERS ONLY MODE ACTIVATED! ğŸ†")
        safe_print("   â†’ Rejections/failures logged to file (background)")
        safe_print("   â†’ Console shows ONLY winning trades")
        safe_print("   â†’ Good for the mind. Good for marketing. ğŸ’")
        safe_print("ğŸ†" * 35)

    if args.turn_based:
        safe_print("\n" + "=" * 60)
        safe_print("ğŸ¢ TURN-BASED MODE ACTIVATED (Safe & Sequential)")
        safe_print("=" * 60)
    else:
        safe_print("\n" + "ğŸ" * 35)
        safe_print("ğŸ FIRST PAST THE POST MODE ACTIVATED! (Default) ğŸ")
        safe_print("   â†’ Scanning ALL exchanges in parallel")
        safe_print("   â†’ Executing on FIRST profitable opportunity")
        safe_print("   â†’ No waiting - CAPTURE PROFIT IMMEDIATELY!")
        safe_print("ğŸ" * 35)
    # Guardrail: enforce a hard upper-bound so --duration can't be defeated by a hung await.
    # (engine.run already tracks duration inside the loop, but blocking calls can prevent loop progress.)
    try:
        if args.duration and args.duration > 0:
            await asyncio.wait_for(engine.run(duration_s=args.duration), timeout=float(args.duration) + 15.0)
        else:
            await engine.run(duration_s=args.duration)
    except asyncio.TimeoutError:
        safe_print(f"\nâ±ï¸ Duration reached ({args.duration}s). Stopping.")
        return


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        # User stopped the program
        pass
    except Exception as e:
        # Catch any final exceptions silently to prevent stderr issues
        error_str = str(e).lower()
        if "closed file" not in error_str and "lost sys" not in error_str:
            try:
                safe_print(f"\nâŒ Error: {e}")
            except Exception:
                pass
    finally:
        # Final cleanup - suppress all exceptions
        try:
            if sys.platform == 'win32':
                # Windows: redirect stderr to devnull to suppress closure errors
                import os as _os_cleanup
                sys.stderr = open(_os_cleanup.devnull, 'w')
        except Exception:
            pass
