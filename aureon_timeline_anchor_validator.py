#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                      â•‘
â•‘     âš“ AUREON TIMELINE ANCHOR VALIDATOR âš“                                            â•‘
â•‘     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                                    â•‘
â•‘                                                                                      â•‘
â•‘     PERSISTENT TIMELINE VALIDATION & ANCHORING SYSTEM                                â•‘
â•‘                                                                                      â•‘
â•‘     ARCHITECTURE:                                                                    â•‘
â•‘       â€¢ Validates timeline branches over extended periods (7-day window)            â•‘
â•‘       â€¢ Anchors confirmed timelines into persistent memory                          â•‘
â•‘       â€¢ Tracks timeline drift and stability over time                               â•‘
â•‘       â€¢ Integrates with Stargate Protocol and Quantum Mirror Scanner                â•‘
â•‘                                                                                      â•‘
â•‘     VALIDATION CYCLES:                                                               â•‘
â•‘       â€¢ Hourly validation: Quick coherence check                                    â•‘
â•‘       â€¢ Daily validation: Full 3-pass validation                                    â•‘
â•‘       â€¢ Weekly validation: Deep timeline stability assessment                       â•‘
â•‘                                                                                      â•‘
â•‘     Gary Leckey & GitHub Copilot | January 2026                                     â•‘
â•‘     "Time reveals truth; patience anchors reality"                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import sys
import os

# Windows UTF-8 fix
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    try:
        import io
        def _is_utf8_wrapper(stream):
            return (isinstance(stream, io.TextIOWrapper) and 
                    hasattr(stream, 'encoding') and stream.encoding and
                    stream.encoding.lower().replace('-', '') == 'utf8')
        if hasattr(sys.stdout, 'buffer') and not _is_utf8_wrapper(sys.stdout):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        # Skip stderr wrapping (causes Windows exit errors)
    except Exception:
        pass

import math
import time
import json
import logging
import threading
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Optional, Any, Tuple
from collections import deque
from enum import Enum
from datetime import datetime, timezone, timedelta
from pathlib import Path
import numpy as np

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SACRED CONSTANTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PHI = (1 + math.sqrt(5)) / 2
SCHUMANN_BASE = 7.83
LOVE_FREQUENCY = 528

# Validation timing (seconds)
HOURLY_INTERVAL = 3600
DAILY_INTERVAL = 86400
WEEKLY_INTERVAL = 604800

# Fibonacci for validation windows
FIBONACCI = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987]

# Prime validation intervals (hours)
PRIME_HOURS = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIMELINE ANCHOR STRUCTURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AnchorStatus(Enum):
    """Status of a timeline anchor"""
    PENDING = "pending"              # Awaiting validation
    VALIDATING = "validating"        # Currently being validated
    PARTIAL = "partial"              # Some validations passed
    ANCHORED = "anchored"            # Fully anchored
    DRIFTING = "drifting"            # Anchor losing stability
    EXPIRED = "expired"              # Validation window closed
    FAILED = "failed"                # Failed validation


@dataclass
class ValidationRecord:
    """Record of a single validation event"""
    timestamp: float
    validation_type: str  # "hourly", "daily", "weekly"
    p1_score: float
    p2_score: float
    p3_score: float
    coherence: float
    lambda_stability: float
    drift: float
    passed: bool
    notes: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


from metrics import skipped_anchor_counter

@dataclass
class TimelineAnchor:
    """
    A timeline anchor represents a validated branch that has been
    confirmed through multiple validation passes over time.
    """
    anchor_id: str
    branch_id: str
    symbol: str
    exchange: str
    
    # Creation info
    created_at: float = 0.0
    initial_price: float = 0.0
    initial_frequency: float = SCHUMANN_BASE
    
    # Validation state
    status: AnchorStatus = AnchorStatus.PENDING
    validation_count: int = 0
    successful_validations: int = 0
    failed_validations: int = 0
    
    # Accumulated scores (weighted over time)
    cumulative_coherence: float = 0.0
    cumulative_stability: float = 0.0
    cumulative_beneficial: float = 0.0
    
    # Timeline metrics
    anchor_strength: float = 0.0  # How firmly anchored (0-1)
    drift_rate: float = 0.0  # Current drift rate
    time_to_expiry: float = 0.0  # Seconds until validation window closes
    
    # History
    validation_history: List[ValidationRecord] = field(default_factory=list)
    price_history: List[Tuple[float, float]] = field(default_factory=list)  # (timestamp, price)
    
    # Execution info (if traded)
    executed: bool = False
    execution_timestamp: float = 0.0
    execution_price: float = 0.0
    execution_result: str = ""
    
    def add_validation(self, record: ValidationRecord) -> None:
        """Add a validation record and update cumulative scores"""
        self.validation_history.append(record)
        self.validation_count += 1
        
        if record.passed:
            self.successful_validations += 1
        else:
            self.failed_validations += 1
            
        # Update cumulative scores with exponential weighting (recent = more weight)
        alpha = 0.3  # Recent weight
        self.cumulative_coherence = (
            alpha * record.coherence + 
            (1 - alpha) * self.cumulative_coherence
        )
        self.cumulative_stability = (
            alpha * record.lambda_stability + 
            (1 - alpha) * self.cumulative_stability
        )
        
        # Update anchor strength
        self._update_anchor_strength()
        
    def _update_anchor_strength(self) -> None:
        """Update anchor strength based on validation history"""
        if self.validation_count == 0:
            self.anchor_strength = 0.0
            return
            
        # Success ratio weighted by coherence and stability
        success_ratio = self.successful_validations / self.validation_count
        
        self.anchor_strength = (
            success_ratio * 0.4 +
            self.cumulative_coherence * 0.3 +
            self.cumulative_stability * 0.3
        ) * PHI  # Golden amplification
        
        self.anchor_strength = min(1.0, self.anchor_strength)
        
        # Update status based on strength
        if self.anchor_strength >= 0.9:
            self.status = AnchorStatus.ANCHORED
        elif self.anchor_strength >= 0.6:
            self.status = AnchorStatus.PARTIAL
        elif self.drift_rate > 0.1:
            self.status = AnchorStatus.DRIFTING
            
    def compute_score(self) -> float:
        """Compute overall anchor score"""
        return (
            self.anchor_strength *
            self.cumulative_coherence *
            self.cumulative_stability *
            PHI
        )
        
    def is_ready_for_execution(self) -> bool:
        """Check if anchor is ready for trade execution"""
        return (
            self.status == AnchorStatus.ANCHORED and
            self.anchor_strength >= 0.8 and
            self.drift_rate < 0.05 and
            not self.executed
        )
        
    def to_dict(self) -> Dict[str, Any]:
        """Convert to JSON-serializable dict"""
        return {
            "anchor_id": self.anchor_id,
            "branch_id": self.branch_id,
            "symbol": self.symbol,
            "exchange": self.exchange,
            "created_at": self.created_at,
            "initial_price": self.initial_price,
            "initial_frequency": self.initial_frequency,
            "status": self.status.value,
            "validation_count": self.validation_count,
            "successful_validations": self.successful_validations,
            "failed_validations": self.failed_validations,
            "cumulative_coherence": self.cumulative_coherence,
            "cumulative_stability": self.cumulative_stability,
            "cumulative_beneficial": self.cumulative_beneficial,
            "anchor_strength": self.anchor_strength,
            "drift_rate": self.drift_rate,
            "time_to_expiry": self.time_to_expiry,
            "executed": self.executed,
            "execution_timestamp": self.execution_timestamp,
            "execution_price": self.execution_price,
            "execution_result": self.execution_result,
            "validation_history": [v.to_dict() for v in self.validation_history[-100:]],
            "score": self.compute_score(),
        }
        
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TimelineAnchor':
        """Reconstruct from dict (tolerant to missing or legacy fields)."""
        # Provide robust defaults for older or partially corrupted state files
        anchor_id = data.get("anchor_id", f"anchor_{int(time.time() * 1000)}")
        branch_id = data.get("branch_id", f"{anchor_id}_branch")
        symbol = data.get("symbol", "UNKNOWN")
        exchange = data.get("exchange", "unknown")

        anchor = cls(
            anchor_id=anchor_id,
            branch_id=branch_id,
            symbol=symbol,
            exchange=exchange,
            created_at=data.get("created_at", 0.0),
            initial_price=data.get("initial_price", 0.0),
            initial_frequency=data.get("initial_frequency", SCHUMANN_BASE),
            status=AnchorStatus(data.get("status", AnchorStatus.PENDING.value)),
            validation_count=data.get("validation_count", 0),
            successful_validations=data.get("successful_validations", 0),
            failed_validations=data.get("failed_validations", 0),
            cumulative_coherence=data.get("cumulative_coherence", 0.0),
            cumulative_stability=data.get("cumulative_stability", 0.0),
            cumulative_beneficial=data.get("cumulative_beneficial", 0.0),
            anchor_strength=data.get("anchor_strength", 0.0),
            drift_rate=data.get("drift_rate", 0.0),
            time_to_expiry=data.get("time_to_expiry", 0.0),
            executed=data.get("executed", False),
            execution_timestamp=data.get("execution_timestamp", 0.0),
            execution_price=data.get("execution_price", 0.0),
            execution_result=data.get("execution_result", ""),
        )

        # Restore validation history defensively
        for v_data in data.get("validation_history", []):
            try:
                anchor.validation_history.append(ValidationRecord(
                    timestamp=v_data.get("timestamp", 0.0),
                    validation_type=v_data.get("validation_type", "unknown"),
                    p1_score=v_data.get("p1_score", 0.0),
                    p2_score=v_data.get("p2_score", 0.0),
                    p3_score=v_data.get("p3_score", 0.0),
                    coherence=v_data.get("coherence", 0.0),
                    lambda_stability=v_data.get("lambda_stability", 0.0),
                    drift=v_data.get("drift", 0.0),
                    passed=v_data.get("passed", False),
                    notes=v_data.get("notes", ""),
                ))
            except Exception as e:
                logger.debug(f"Skipping malformed validation entry for anchor {anchor_id}: {e}")

        return anchor


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIMELINE ANCHOR VALIDATOR ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TimelineAnchorValidator:
    """
    Manages timeline anchor validation over extended periods.
    Integrates with Quantum Mirror Scanner for branch validation.
    """
    
    # File paths
    PENDING_FILE = "7day_pending_validations.json"
    ANCHORED_FILE = "7day_anchored_timelines.json"
    HISTORY_FILE = "7day_validation_history.json"
    
    # Thresholds
    MIN_VALIDATIONS_FOR_ANCHOR = 7  # At least 7 successful validations
    ANCHOR_THRESHOLD = 0.618  # Golden ratio
    MAX_DRIFT_RATE = 0.1
    VALIDATION_WINDOW_DAYS = 7
    
    def __init__(self, quantum_scanner=None, stargate_engine=None, thought_bus=None):
        self.pending_anchors: Dict[str, TimelineAnchor] = {}
        self.anchored_timelines: Dict[str, TimelineAnchor] = {}
        self.expired_anchors: deque = deque(maxlen=1000)
        
        # Integration
        self._quantum_scanner = quantum_scanner
        self._stargate_engine = stargate_engine
        self._thought_bus = thought_bus
        self._lock = threading.RLock()
        
        # Validation scheduling
        self.last_hourly_validation = 0.0
        self.last_daily_validation = 0.0
        self.last_weekly_validation = 0.0
        
        # Load state
        self._load_state()
        
        logger.info("âš“ Timeline Anchor Validator initialized")
        logger.info(f"   Pending: {len(self.pending_anchors)}")
        logger.info(f"   Anchored: {len(self.anchored_timelines)}")
        
    def _load_state(self) -> None:
        """Load pending and anchored timelines from disk"""
        # Load pending
        if os.path.exists(self.PENDING_FILE):
            try:
                with open(self.PENDING_FILE, 'r') as f:
                    data = json.load(f)
                
                # Normalize data: handle both dict and list formats
                if isinstance(data, list):
                    # Convert list to dict (use anchor_id as key)
                    normalized_data = {}
                    for item in data:
                        if isinstance(item, dict):
                            anchor_id = item.get('anchor_id', f"anchor_{len(normalized_data)}")
                            normalized_data[anchor_id] = item
                    data = normalized_data
                elif not isinstance(data, dict):
                    logger.warning(f"Unexpected data type in {self.PENDING_FILE}: {type(data)}, resetting")
                    data = {}
                
                # Load anchors from normalized dict
                for anchor_id, anchor_data in data.items():
                    if isinstance(anchor_data, dict):
                        try:
                            self.pending_anchors[anchor_id] = TimelineAnchor.from_dict(anchor_data)
                        except Exception as e:
                            logger.warning(f"Could not load anchor {anchor_id}: {e}")
                            skipped_anchor_counter.inc(reason="pending_load_error")
                
                logger.info(f"  Loaded {len(self.pending_anchors)} pending anchors")
            except Exception as e:
                logger.error(f"Failed to load pending anchors: {e}")
                
        # Load anchored
        if os.path.exists(self.ANCHORED_FILE):
            try:
                with open(self.ANCHORED_FILE, 'r') as f:
                    data = json.load(f)
                
                # Normalize data: handle both dict and list formats
                if isinstance(data, list):
                    # Convert list to dict (use anchor_id as key)
                    normalized_data = {}
                    for item in data:
                        if isinstance(item, dict):
                            anchor_id = item.get('anchor_id', f"anchor_{len(normalized_data)}")
                            normalized_data[anchor_id] = item
                    data = normalized_data
                elif not isinstance(data, dict):
                    logger.warning(f"Unexpected data type in {self.ANCHORED_FILE}: {type(data)}, resetting")
                    data = {}
                
                # Load anchors from normalized dict
                for anchor_id, anchor_data in data.items():
                    if isinstance(anchor_data, dict):
                        try:
                            self.anchored_timelines[anchor_id] = TimelineAnchor.from_dict(anchor_data)
                        except Exception as e:
                            logger.warning(f"Could not load anchored timeline {anchor_id}: {e}")
                            skipped_anchor_counter.inc(reason="anchored_load_error")
                
                logger.info(f"  Loaded {len(self.anchored_timelines)} anchored timelines")
            except Exception as e:
                logger.error(f"Failed to load anchored timelines: {e}")
                
    def save_state(self) -> None:
        """Save state to disk atomically"""
        with self._lock:
            # Save pending
            try:
                pending_data = {
                    anchor_id: anchor.to_dict() 
                    for anchor_id, anchor in self.pending_anchors.items()
                }
                temp_path = f"{self.PENDING_FILE}.tmp"
                with open(temp_path, 'w') as f:
                    json.dump(pending_data, f, indent=2)
                os.replace(temp_path, self.PENDING_FILE)
            except Exception as e:
                logger.error(f"Failed to save pending anchors: {e}")
                
            # Save anchored
            try:
                anchored_data = {
                    anchor_id: anchor.to_dict() 
                    for anchor_id, anchor in self.anchored_timelines.items()
                }
                temp_path = f"{self.ANCHORED_FILE}.tmp"
                with open(temp_path, 'w') as f:
                    json.dump(anchored_data, f, indent=2)
                os.replace(temp_path, self.ANCHORED_FILE)
            except Exception as e:
                logger.error(f"Failed to save anchored timelines: {e}")
                
    def create_anchor(self, branch_id: str, symbol: str, exchange: str,
                      initial_price: float, frequency: float = SCHUMANN_BASE) -> TimelineAnchor:
        """Create a new timeline anchor from a validated branch"""
        with self._lock:
            anchor_id = f"anchor_{branch_id}_{int(time.time())}"
            
            anchor = TimelineAnchor(
                anchor_id=anchor_id,
                branch_id=branch_id,
                symbol=symbol,
                exchange=exchange,
                created_at=time.time(),
                initial_price=initial_price,
                initial_frequency=frequency,
                status=AnchorStatus.PENDING,
                time_to_expiry=self.VALIDATION_WINDOW_DAYS * DAILY_INTERVAL,
            )
            
            self.pending_anchors[anchor_id] = anchor
            
            self._emit_thought(
                topic="timeline.anchor.created",
                payload={
                    "anchor_id": anchor_id,
                    "branch_id": branch_id,
                    "symbol": symbol,
                    "exchange": exchange,
                }
            )
            
            logger.info(f"âš“ Created timeline anchor: {anchor_id}")
            return anchor
            
    def validate_anchor(self, anchor_id: str, validation_type: str = "hourly") -> Optional[ValidationRecord]:
        """
        Run a validation pass on an anchor.
        
        validation_type: "hourly", "daily", or "weekly"
        """
        with self._lock:
            if anchor_id not in self.pending_anchors:
                return None
                
            anchor = self.pending_anchors[anchor_id]
            anchor.status = AnchorStatus.VALIDATING
            
            # Get current market data from scanner if available
            current_data = self._get_branch_data(anchor.branch_id)
            
            # Run validation passes
            p1, p2, p3 = self._run_validation_passes(anchor, current_data)
            
            # Compute coherence
            probs = [p1, p2, p3]
            coherence = 1.0 - (max(probs) - min(probs)) if max(probs) > 0 else 0.0
            
            # Compute lambda stability
            current_price = current_data.get("price", anchor.initial_price)
            if anchor.price_history:
                last_price = anchor.price_history[-1][1]
                price_drift = abs(current_price - last_price) / last_price if last_price > 0 else 0.0
            else:
                price_drift = 0.0
                
            lambda_stability = math.exp(-0.1 * price_drift * 100)
            anchor.drift_rate = price_drift
            
            # Record price
            anchor.price_history.append((time.time(), current_price))
            
            # Determine if passed
            avg_score = (p1 + p2 + p3) / 3.0
            passed = (
                avg_score >= 0.5 and
                coherence >= 0.5 and
                lambda_stability >= 0.5
            )
            
            record = ValidationRecord(
                timestamp=time.time(),
                validation_type=validation_type,
                p1_score=p1,
                p2_score=p2,
                p3_score=p3,
                coherence=coherence,
                lambda_stability=lambda_stability,
                drift=anchor.drift_rate,
                passed=passed,
                notes=f"Price: {current_price:.4f}",
            )
            
            anchor.add_validation(record)
            
            # Update expiry
            elapsed = time.time() - anchor.created_at
            anchor.time_to_expiry = max(0, (self.VALIDATION_WINDOW_DAYS * DAILY_INTERVAL) - elapsed)
            
            # Check for anchoring or expiry
            self._check_anchor_status(anchor)
            
            self._emit_thought(
                topic=f"timeline.validation.{validation_type}",
                payload={
                    "anchor_id": anchor_id,
                    "passed": passed,
                    "scores": {"p1": p1, "p2": p2, "p3": p3},
                    "coherence": coherence,
                    "lambda": lambda_stability,
                    "anchor_strength": anchor.anchor_strength,
                    "status": anchor.status.value,
                }
            )
            
            logger.info(f"ğŸ“‹ Validation ({validation_type}): {anchor_id}")
            logger.info(f"   P1={p1:.3f} P2={p2:.3f} P3={p3:.3f} | Passed: {passed}")
            
            # Auto-save
            self.save_state()
            
            return record
            
    def _run_validation_passes(self, anchor: TimelineAnchor, 
                                data: Dict[str, Any]) -> Tuple[float, float, float]:
        """Run 3-pass validation on anchor"""
        # If we have quantum scanner, use it
        if self._quantum_scanner and anchor.branch_id in self._quantum_scanner.branches:
            scanner = self._quantum_scanner
            p1 = scanner.validation_pass_1_harmonic(anchor.branch_id)
            p2 = scanner.validation_pass_2_coherence(anchor.branch_id)
            p3 = scanner.validation_pass_3_stability(anchor.branch_id)
            return p1, p2, p3
            
        # Otherwise, compute directly
        frequency = data.get("frequency", anchor.initial_frequency)
        price = data.get("price", anchor.initial_price)
        
        # P1: Harmonic alignment
        schumann_ratio = frequency / SCHUMANN_BASE
        p1 = 1.0 - min(1.0, abs(schumann_ratio - round(schumann_ratio)) * 2)
        
        # P2: Coherence (based on price stability)
        if anchor.price_history:
            prices = [p for _, p in anchor.price_history[-24:]]  # Last 24 records
            if len(prices) >= 2:
                volatility = np.std(prices) / np.mean(prices) if np.mean(prices) > 0 else 1.0
                p2 = math.exp(-volatility * 10)
            else:
                p2 = 0.5
        else:
            p2 = 0.5
            
        # P3: Stability (based on drift)
        p3 = math.exp(-anchor.drift_rate * 50)
        
        return p1, p2, p3
        
    def _get_branch_data(self, branch_id: str) -> Dict[str, Any]:
        """Get current data for a branch"""
        if self._quantum_scanner and branch_id in self._quantum_scanner.branches:
            branch = self._quantum_scanner.branches[branch_id]
            return {
                "price": branch.amplitude,
                "frequency": branch.frequency,
                "phase": branch.phase,
            }
        return {"price": 0.0, "frequency": SCHUMANN_BASE, "phase": 0.0}
        
    def _check_anchor_status(self, anchor: TimelineAnchor) -> None:
        """Check if anchor should be promoted or expired"""
        # Check for expiry
        if anchor.time_to_expiry <= 0:
            anchor.status = AnchorStatus.EXPIRED
            self.expired_anchors.append(anchor)
            if anchor.anchor_id in self.pending_anchors:
                del self.pending_anchors[anchor.anchor_id]
            logger.info(f"âŒ› Anchor expired: {anchor.anchor_id}")
            return
            
        # Check for failed
        if anchor.failed_validations >= 5 and anchor.successful_validations < 3:
            anchor.status = AnchorStatus.FAILED
            self.expired_anchors.append(anchor)
            if anchor.anchor_id in self.pending_anchors:
                del self.pending_anchors[anchor.anchor_id]
            logger.info(f"âŒ Anchor failed: {anchor.anchor_id}")
            return
            
        # Check for anchoring
        if (anchor.successful_validations >= self.MIN_VALIDATIONS_FOR_ANCHOR and
            anchor.anchor_strength >= self.ANCHOR_THRESHOLD and
            anchor.drift_rate < self.MAX_DRIFT_RATE):
            
            anchor.status = AnchorStatus.ANCHORED
            
            # Move to anchored
            self.anchored_timelines[anchor.anchor_id] = anchor
            if anchor.anchor_id in self.pending_anchors:
                del self.pending_anchors[anchor.anchor_id]
                
            self._emit_thought(
                topic="timeline.anchor.confirmed",
                payload={
                    "anchor_id": anchor.anchor_id,
                    "branch_id": anchor.branch_id,
                    "symbol": anchor.symbol,
                    "exchange": anchor.exchange,
                    "strength": anchor.anchor_strength,
                    "score": anchor.compute_score(),
                }
            )
            
            logger.info(f"âœ… TIMELINE ANCHORED: {anchor.anchor_id}")
            logger.info(f"   Strength: {anchor.anchor_strength:.4f}")
            logger.info(f"   Score: {anchor.compute_score():.4f}")
            
    def run_scheduled_validations(self) -> Dict[str, Any]:
        """Run scheduled validations based on time intervals"""
        now = time.time()
        results = {
            "hourly": [],
            "daily": [],
            "weekly": [],
        }
        
        # Hourly validation
        if now - self.last_hourly_validation >= HOURLY_INTERVAL:
            self.last_hourly_validation = now
            for anchor_id in list(self.pending_anchors.keys()):
                record = self.validate_anchor(anchor_id, "hourly")
                if record:
                    results["hourly"].append(anchor_id)
                    
        # Daily validation (also check prime hours)
        current_hour = datetime.now(timezone.utc).hour
        if (now - self.last_daily_validation >= DAILY_INTERVAL or
            current_hour in PRIME_HOURS):
            self.last_daily_validation = now
            for anchor_id in list(self.pending_anchors.keys()):
                record = self.validate_anchor(anchor_id, "daily")
                if record:
                    results["daily"].append(anchor_id)
                    
        # Weekly validation
        if now - self.last_weekly_validation >= WEEKLY_INTERVAL:
            self.last_weekly_validation = now
            for anchor_id in list(self.pending_anchors.keys()):
                record = self.validate_anchor(anchor_id, "weekly")
                if record:
                    results["weekly"].append(anchor_id)
                    
            # Also validate anchored timelines weekly
            for anchor_id in list(self.anchored_timelines.keys()):
                anchor = self.anchored_timelines[anchor_id]
                record = ValidationRecord(
                    timestamp=now,
                    validation_type="weekly",
                    p1_score=0.8,  # Simplified for anchored
                    p2_score=anchor.cumulative_coherence,
                    p3_score=anchor.cumulative_stability,
                    coherence=anchor.cumulative_coherence,
                    lambda_stability=anchor.cumulative_stability,
                    drift=anchor.drift_rate,
                    passed=True,
                )
                anchor.add_validation(record)
                results["weekly"].append(anchor_id)
                
        return results
        
    def get_ready_for_execution(self) -> List[TimelineAnchor]:
        """Get all anchors ready for trade execution"""
        return [
            anchor for anchor in self.anchored_timelines.values()
            if anchor.is_ready_for_execution()
        ]
        
    def mark_executed(self, anchor_id: str, price: float, result: str) -> bool:
        """Mark an anchor as executed"""
        with self._lock:
            if anchor_id not in self.anchored_timelines:
                return False
                
            anchor = self.anchored_timelines[anchor_id]
            anchor.executed = True
            anchor.execution_timestamp = time.time()
            anchor.execution_price = price
            anchor.execution_result = result
            
            self._emit_thought(
                topic="timeline.anchor.executed",
                payload={
                    "anchor_id": anchor_id,
                    "symbol": anchor.symbol,
                    "exchange": anchor.exchange,
                    "price": price,
                    "result": result,
                }
            )
            
            self.save_state()
            logger.info(f"âš¡ Anchor executed: {anchor_id} @ {price}")
            return True
            
    def _emit_thought(self, topic: str, payload: Dict[str, Any]) -> None:
        """Emit thought to ThoughtBus if available"""
        if self._thought_bus:
            try:
                from aureon_thought_bus import Thought
                thought = Thought(
                    source="timeline_anchor_validator",
                    topic=topic,
                    payload=payload
                )
                self._thought_bus.publish(thought)
            except Exception as e:
                logger.debug(f"Could not emit thought: {e}")
                
    def get_status(self) -> Dict[str, Any]:
        """Get comprehensive validator status"""
        with self._lock:
            pending_by_status = {}
            for anchor in self.pending_anchors.values():
                status = anchor.status.value
                pending_by_status[status] = pending_by_status.get(status, 0) + 1
                
            ready_anchors = self.get_ready_for_execution()
            
            return {
                "timestamp": time.time(),
                "pending_count": len(self.pending_anchors),
                "anchored_count": len(self.anchored_timelines),
                "expired_count": len(self.expired_anchors),
                "pending_by_status": pending_by_status,
                "ready_for_execution": len(ready_anchors),
                "ready_anchor_ids": [a.anchor_id for a in ready_anchors],
                "last_hourly": self.last_hourly_validation,
                "last_daily": self.last_daily_validation,
                "last_weekly": self.last_weekly_validation,
            }
            
    def get_anchor_details(self, anchor_id: str) -> Optional[Dict[str, Any]]:
        """Get detailed information about an anchor"""
        with self._lock:
            anchor = self.pending_anchors.get(anchor_id) or self.anchored_timelines.get(anchor_id)
            if anchor:
                return anchor.to_dict()
            return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FACTORY & MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_timeline_validator(with_integrations: bool = True) -> TimelineAnchorValidator:
    """Factory function to create Timeline Anchor Validator with integrations"""
    quantum_scanner = None
    stargate_engine = None
    thought_bus = None
    
    if with_integrations:
        try:
            from aureon_thought_bus import ThoughtBus
            thought_bus = ThoughtBus()
            logger.info("âœ… ThoughtBus integration enabled")
        except ImportError:
            logger.warning("âš ï¸ ThoughtBus not available")
            
        try:
            from aureon_quantum_mirror_scanner import create_quantum_scanner
            quantum_scanner = create_quantum_scanner(with_integrations=False)
            logger.info("âœ… Quantum Scanner integration enabled")
        except ImportError:
            logger.warning("âš ï¸ Quantum Scanner not available")
            
        try:
            from aureon_stargate_protocol import create_stargate_engine
            stargate_engine = create_stargate_engine(with_integrations=False)
            logger.info("âœ… Stargate Protocol integration enabled")
        except ImportError:
            logger.warning("âš ï¸ Stargate Protocol not available")
            
    return TimelineAnchorValidator(
        quantum_scanner=quantum_scanner,
        stargate_engine=stargate_engine,
        thought_bus=thought_bus
    )


# Alias for wire_all_systems compatibility
create_timeline_anchor_validator = create_timeline_validator


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s'
    )
    
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘     âš“ AUREON TIMELINE ANCHOR VALIDATOR âš“                    â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    # Create validator
    validator = create_timeline_validator(with_integrations=True)
    
    # Create some test anchors
    print("ğŸ“ CREATING TEST ANCHORS")
    print("â”€" * 60)
    
    test_branches = [
        ("kraken:BTC/USD", "BTC/USD", "kraken", 43250.0),
        ("kraken:ETH/USD", "ETH/USD", "kraken", 2280.0),
        ("kraken:SOL/USD", "SOL/USD", "kraken", 98.5),
    ]
    
    for branch_id, symbol, exchange, price in test_branches:
        anchor = validator.create_anchor(
            branch_id=branch_id,
            symbol=symbol,
            exchange=exchange,
            initial_price=price,
            frequency=SCHUMANN_BASE * PHI
        )
        print(f"  Created: {anchor.anchor_id}")
        
    print()
    print("ğŸ”¬ RUNNING VALIDATION PASSES")
    print("â”€" * 60)
    
    # Run multiple validation cycles
    for cycle in range(5):
        print(f"\n  Cycle {cycle + 1}:")
        for anchor_id in list(validator.pending_anchors.keys()):
            record = validator.validate_anchor(anchor_id, "hourly")
            if record:
                print(f"    {anchor_id}: P={record.passed}, C={record.coherence:.3f}")
                
    print()
    print("ğŸ“Š VALIDATOR STATUS")
    print("â”€" * 60)
    status = validator.get_status()
    print(f"  Pending: {status['pending_count']}")
    print(f"  Anchored: {status['anchored_count']}")
    print(f"  Expired: {status['expired_count']}")
    print(f"  Ready for execution: {status['ready_for_execution']}")
    
    # Show anchored timelines
    if validator.anchored_timelines:
        print()
        print("âœ… ANCHORED TIMELINES")
        print("â”€" * 60)
        for anchor_id, anchor in validator.anchored_timelines.items():
            print(f"  {anchor_id}")
            print(f"    Symbol: {anchor.symbol}")
            print(f"    Strength: {anchor.anchor_strength:.4f}")
            print(f"    Score: {anchor.compute_score():.4f}")
            
    # Save state
    validator.save_state()
    
    print()
    print("âœ… Timeline Anchor Validator operational")
